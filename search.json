[
  {
    "objectID": "demos/set-membership/index.html",
    "href": "demos/set-membership/index.html",
    "title": "Pointblank",
    "section": "",
    "text": "Set Membership\nPerform validations that check whether values are part of a set (or not part of one).\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:21:20Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        \n        \n    f\n    low, mid, high\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_not_in_set\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_in_set()\n        \n        \n        \n    f\n    zero, infinity\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:21:20 UTC&lt; 1 s2025-11-23 00:21:20 UTC\n  \n\n\n\n\n\n\n        \n\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\")\n    )\n    .col_vals_in_set(columns=\"f\", set=[\"low\", \"mid\", \"high\"])    # part of this set\n    .col_vals_not_in_set(columns=\"f\", set=[\"zero\", \"infinity\"])  # not part of this set\n    .interrogate()\n)\n\nvalidation\n\n\nPreview of Input Table\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows13Columns8\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05\n    6\n    8-kdg-938\n    3\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    None\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09\n    8\n    3-ldm-038\n    7\n    283.94\n    True\n    low\n  \n  \n    6\n    2016-01-11 06:15:00\n    2016-01-11\n    4\n    2-dhe-923\n    4\n    3291.03\n    True\n    mid\n  \n  \n    7\n    2016-01-15 18:46:00\n    2016-01-15\n    7\n    1-knw-093\n    3\n    843.34\n    True\n    high\n  \n  \n    8\n    2016-01-17 11:27:00\n    2016-01-17\n    4\n    5-boe-639\n    2\n    1035.64\n    False\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26\n    4\n    2-dmx-010\n    7\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28\n    2\n    7-dmx-010\n    8\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30\n    1\n    3-dka-303\n    None\n    2230.09\n    True\n    high"
  },
  {
    "objectID": "demos/expect-no-duplicate-rows/index.html",
    "href": "demos/expect-no-duplicate-rows/index.html",
    "title": "Pointblank",
    "section": "",
    "text": "Expect No Duplicate Rows\nWe can check for duplicate rows in the table with rows_distinct().\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:21:11Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    rows_distinct\n    \n        \n            \n            \n                \n                \n                \n            \n        \n    \n\n        \n        \n            rows_distinct()\n        \n        \n        \n    ALL COLUMNS\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    90.69\n    20.15\n    —\n    —\n    —\n    CSV\n  \n\n  \n  \n  \n    2025-11-23 00:21:11 UTC&lt; 1 s2025-11-23 00:21:11 UTC\n  \n\n\n\n\n\n\n        \n\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\")\n    )\n    .rows_distinct()    # expect no duplicate rows\n    .interrogate()\n)\n\nvalidation\n\n\nPreview of Input Table\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows13Columns8\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05\n    6\n    8-kdg-938\n    3\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    None\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09\n    8\n    3-ldm-038\n    7\n    283.94\n    True\n    low\n  \n  \n    6\n    2016-01-11 06:15:00\n    2016-01-11\n    4\n    2-dhe-923\n    4\n    3291.03\n    True\n    mid\n  \n  \n    7\n    2016-01-15 18:46:00\n    2016-01-15\n    7\n    1-knw-093\n    3\n    843.34\n    True\n    high\n  \n  \n    8\n    2016-01-17 11:27:00\n    2016-01-17\n    4\n    5-boe-639\n    2\n    1035.64\n    False\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26\n    4\n    2-dmx-010\n    7\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28\n    2\n    7-dmx-010\n    8\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30\n    1\n    3-dka-303\n    None\n    2230.09\n    True\n    high"
  },
  {
    "objectID": "demos/datetime-validations/index.html",
    "href": "demos/datetime-validations/index.html",
    "title": "Pointblank",
    "section": "",
    "text": "Date and Datetime Validations\npointblank provides comprehensive support for validating date and datetime values, including timezone-aware comparisons. This ensures temporal data quality in applications that handle time-sensitive information.\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:21:02Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_ge\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_ge()\n        \n        Orders are from 2023 or later\n\n        \n    order_date\n    2023-01-01\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    41.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_between\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_between()\n        \n        Creation timestamps within expected range\n\n        \n    created_at\n    [2023-01-01 00:00:00, 2024-12-31 23:59:59]\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    41.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_vals_ge\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_ge()\n        \n        Timezone-aware events after 8 AM Eastern\n\n        \n    event_time_tz\n    2023-01-01 08:00:00-04:56\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    41.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_schema_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            col_schema_match()\n        \n        Schema includes proper date/datetime types\n\n        \n    —\n    SCHEMA\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:21:02 UTC&lt; 1 s2025-11-23 00:21:02 UTC\n  \n\n\n  \n    \nNotes\nStep 4 (schema_check) ✓ Schema validation passed.\n\nSchema Comparison\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n  \n    TARGET\n  \n  \n    EXPECTED\n  \n\n\n  \n  COLUMN\n  DATA TYPE\n  \n  COLUMN\n  \n  DATA TYPE\n  \n\n\n\n  \n    1\n    order_date\n    Date\n    1\n    order_date\n    ✓\n    Date\n    ✓\n  \n  \n    2\n    created_at\n    Datetime(time_unit='us', time_zone=None)\n    2\n    created_at\n    ✓\n    Datetime(time_unit='us', time_zone=None)\n    ✓\n  \n  \n    3\n    event_time_tz\n    Datetime(time_unit='us', time_zone='America/New_York')\n    3\n    event_time_tz\n    ✓\n    Datetime(time_unit='us', time_zone='America/New_York')\n    ✓\n  \n  \n    4\n    order_id\n    Int64\n    4\n    order_id\n    ✓\n    Int64\n    ✓\n  \n  \n    5\n    amount\n    Float64\n    5\n    amount\n    ✓\n    Float64\n    ✓\n  \n\n  \n  \n    Supplied Column Schema:[('order_date', 'Date'), ('created_at', \"Datetime(time_unit='us', time_zone=None)\"), ('event_time_tz', \"Datetime(time_unit='us', time_zone='America/New_York')\"), ('order_id', 'Int64'), ('amount', 'Float64')]\n  \n  \n    \nSchema Match Settings\nCOMPLETEIN ORDERCOLUMN ≠ columnDTYPE ≠ dtypefloat ≠ float64\n\n  \n\n\n\n\n\n\n  \n\n\n\n\n\n\n        \n\n\nimport pointblank as pb\nimport polars as pl\nfrom datetime import date, datetime\nimport pytz\n\n# Create sample data with various temporal data types\ntemporal_data = pl.DataFrame({\n    \"order_date\": [\n        date(2023, 1, 15),\n        date(2023, 6, 10),\n        date(2023, 12, 5),\n        date(2024, 3, 20)\n    ],\n    \"created_at\": [\n        datetime(2023, 1, 15, 9, 30, 0),\n        datetime(2023, 6, 10, 14, 45, 30),\n        datetime(2023, 12, 5, 8, 15, 0),\n        datetime(2024, 3, 20, 17, 22, 45)\n    ],\n    \"event_time_tz\": [\n        datetime(2023, 1, 15, 9, 0, tzinfo=pytz.timezone(\"America/New_York\")),\n        datetime(2023, 6, 10, 12, 30, tzinfo=pytz.timezone(\"America/New_York\")),\n        datetime(2023, 12, 5, 15, 45, tzinfo=pytz.timezone(\"America/New_York\")),\n        datetime(2024, 3, 20, 18, 15, tzinfo=pytz.timezone(\"America/New_York\"))\n    ],\n    \"order_id\": [1001, 1002, 1003, 1004],\n    \"amount\": [150.0, 275.5, 89.99, 420.00]\n})\n\nvalidation = (\n    pb.Validate(temporal_data)\n    .col_vals_ge(\n        columns=\"order_date\",\n        value=date(2023, 1, 1),\n        brief=\"Orders are from 2023 or later\"\n    )\n    .col_vals_between(\n        columns=\"created_at\",\n        left=datetime(2023, 1, 1, 0, 0, 0),\n        right=datetime(2024, 12, 31, 23, 59, 59),\n        brief=\"Creation timestamps within expected range\"\n    )\n    .col_vals_ge(\n        columns=\"event_time_tz\",\n        value=datetime(2023, 1, 1, 8, 0, tzinfo=pytz.timezone(\"America/New_York\")),\n        brief=\"Timezone-aware events after 8 AM Eastern\"\n    )\n    .col_schema_match(\n        pb.Schema(\n            columns=[\n                (\"order_date\", \"Date\"),\n                (\"created_at\", \"Datetime(time_unit='us', time_zone=None)\"),\n                (\"event_time_tz\", \"Datetime(time_unit='us', time_zone='America/New_York')\"),\n                (\"order_id\", \"Int64\"),\n                (\"amount\", \"Float64\")\n            ]\n        ),\n        brief=\"Schema includes proper date/datetime types\"\n    )\n    .interrogate()\n)\n\nvalidation\n\n\nPreview of Input Table\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows4Columns5\n  \n\n  \n  order_dateDate\n  created_atDatetime\n  event_time_tzDatetime\n  order_idInt64\n  amountFloat64\n\n\n\n  \n    1\n    2023-01-15\n    2023-01-15 09:30:00\n    2023-01-15 08:56:00-05:00\n    1001\n    150.0\n  \n  \n    2\n    2023-06-10\n    2023-06-10 14:45:30\n    2023-06-10 13:26:00-04:00\n    1002\n    275.5\n  \n  \n    3\n    2023-12-05\n    2023-12-05 08:15:00\n    2023-12-05 15:41:00-05:00\n    1003\n    89.99\n  \n  \n    4\n    2024-03-20\n    2024-03-20 17:22:45\n    2024-03-20 19:11:00-04:00\n    1004\n    420.0"
  },
  {
    "objectID": "demos/04-sundered-data/index.html",
    "href": "demos/04-sundered-data/index.html",
    "title": "Pointblank",
    "section": "",
    "text": "Sundered Data\nSplitting your data into ‘pass’ and ‘fail’ subsets.\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Sundering DataPandassmall_table\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    1000\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    70.54\n    60.46\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_le\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_le()\n        \n        \n        \n    c\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    50.38\n    80.62\n    —\n    —\n    —\n    CSV\n  \n\n  \n  \n  \n    2025-11-23 00:20:54 UTC&lt; 1 s2025-11-23 00:20:54 UTC\n  \n\n\n\n\n\n\n        \n\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PandasRows4Columns8\n  \n\n  \n  date_timedatetime64[ns]\n  datedatetime64[ns]\n  aint64\n  bobject\n  cfloat64\n  dfloat64\n  ebool\n  fobject\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04 00:00:00\n    2\n    1-bcd-345\n    3.0\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-05 13:32:00\n    2016-01-05 00:00:00\n    6\n    8-kdg-938\n    3.0\n    2343.23\n    True\n    high\n  \n  \n    3\n    2016-01-11 06:15:00\n    2016-01-11 00:00:00\n    4\n    2-dhe-923\n    4.0\n    3291.03\n    True\n    mid\n  \n  \n    4\n    2016-01-17 11:27:00\n    2016-01-17 00:00:00\n    4\n    5-boe-639\n    2.0\n    1035.64\n    False\n    low\n  \n\n\n\n\n\n\n        \n\n\nimport pointblank as pb\nimport polars as pl\n\nvalidation = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"pandas\"),\n        tbl_name=\"small_table\",\n        label=\"Sundering Data\"\n    )\n    .col_vals_gt(columns=\"d\", value=1000)\n    .col_vals_le(columns=\"c\", value=5)\n    .interrogate()\n)\n\nvalidation\npb.preview(validation.get_sundered_data(type=\"pass\"))\n\n\nPreview of Input Table\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PandasRows13Columns8\n  \n\n  \n  date_timedatetime64[ns]\n  datedatetime64[ns]\n  aint64\n  bobject\n  cfloat64\n  dfloat64\n  ebool\n  fobject\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04 00:00:00\n    2\n    1-bcd-345\n    3.0\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04 00:00:00\n    3\n    5-egh-163\n    8.0\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05 00:00:00\n    6\n    8-kdg-938\n    3.0\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06 00:00:00\n    2\n    5-jdo-903\n    NA\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09 00:00:00\n    8\n    3-ldm-038\n    7.0\n    283.94\n    True\n    low\n  \n  \n    6\n    2016-01-11 06:15:00\n    2016-01-11 00:00:00\n    4\n    2-dhe-923\n    4.0\n    3291.03\n    True\n    mid\n  \n  \n    7\n    2016-01-15 18:46:00\n    2016-01-15 00:00:00\n    7\n    1-knw-093\n    3.0\n    843.34\n    True\n    high\n  \n  \n    8\n    2016-01-17 11:27:00\n    2016-01-17 00:00:00\n    4\n    5-boe-639\n    2.0\n    1035.64\n    False\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20 00:00:00\n    3\n    5-bce-642\n    9.0\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20 00:00:00\n    3\n    5-bce-642\n    9.0\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26 00:00:00\n    4\n    2-dmx-010\n    7.0\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28 00:00:00\n    2\n    7-dmx-010\n    8.0\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30 00:00:00\n    1\n    3-dka-303\n    NA\n    2230.09\n    True\n    high"
  },
  {
    "objectID": "demos/custom-validation-specially/index.html",
    "href": "demos/custom-validation-specially/index.html",
    "title": "Pointblank",
    "section": "",
    "text": "Custom Validation with specially()\nCreate bespoke validations using specially() to implement domain-specific business rules.\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:20:45Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    specially\n    \n        \n            \n            \n                \n            \n        \n    \n\n        \n        \n            specially()\n        \n        All values in column 'a' should be within 2 std devs of mean\n\n        \n    \n    EXPR\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    19470.97\n    530.03\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    specially\n    \n        \n            \n            \n                \n            \n        \n    \n\n        \n        \n            specially()\n        \n        All values in column 'c' should be within 3 std devs of mean\n\n        \n    \n    EXPR\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:20:45 UTC&lt; 1 s2025-11-23 00:20:45 UTC\n  \n\n\n\n\n\n\n        \n\n\nimport pointblank as pb\nimport polars as pl\n\ndef within_std_deviations(df, column, n_std=2):\n    \"\"\"Check if all values are within n standard deviations of the mean\"\"\"\n    mean_val = df[column].mean()\n    std_val = df[column].std()\n\n    lower_bound = mean_val - (n_std * std_val)\n    upper_bound = mean_val + (n_std * std_val)\n\n    # Add a boolean column and return the modified DataFrame\n    return df.with_columns(\n        pl.col(column).is_between(lower_bound, upper_bound, closed=\"both\").alias(\"validation_result\")\n    )\n\nvalidation = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"polars\")\n    )\n    .specially(\n        expr=lambda df: within_std_deviations(df, column=\"session_duration\", n_std=2),\n        brief=\"All values in column 'a' should be within 2 std devs of mean\"\n    )\n    .specially(\n        expr=lambda df: within_std_deviations(df, column=\"session_duration\", n_std=3),\n        brief=\"All values in column 'c' should be within 3 std devs of mean\"\n    )\n    .interrogate()\n)\n\nvalidation\n\n\nPreview of Input Table\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows2,000Columns11\n  \n\n  \n  player_idString\n  session_idString\n  session_startDatetime\n  timeDatetime\n  item_typeString\n  item_nameString\n  item_revenueFloat64\n  session_durationFloat64\n  start_dayDate\n  acquisitionString\n  countryString\n\n\n\n  \n    1\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:31:27+00:00\n    iap\n    offer2\n    8.99\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    2\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:36:57+00:00\n    iap\n    gems3\n    22.49\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    3\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:37:45+00:00\n    iap\n    gold7\n    107.99\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    4\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:42:33+00:00\n    ad\n    ad_20sec\n    0.76\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    5\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-hdu9jkls\n    2015-01-01 11:50:02+00:00\n    2015-01-01 11:55:20+00:00\n    ad\n    ad_5sec\n    0.03\n    35.2\n    2015-01-01\n    google\n    Germany\n  \n  \n    1996\n    NAOJRDMCSEBI281\n    NAOJRDMCSEBI281-j2vs9ilp\n    2015-01-21 01:57:50+00:00\n    2015-01-21 02:02:50+00:00\n    ad\n    ad_survey\n    1.332\n    25.8\n    2015-01-11\n    organic\n    Norway\n  \n  \n    1997\n    NAOJRDMCSEBI281\n    NAOJRDMCSEBI281-j2vs9ilp\n    2015-01-21 01:57:50+00:00\n    2015-01-21 02:22:14+00:00\n    ad\n    ad_survey\n    1.35\n    25.8\n    2015-01-11\n    organic\n    Norway\n  \n  \n    1998\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-vbhcsmtr\n    2015-01-21 02:39:48+00:00\n    2015-01-21 02:40:00+00:00\n    ad\n    ad_5sec\n    0.03\n    8.4\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    1999\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-vbhcsmtr\n    2015-01-21 02:39:48+00:00\n    2015-01-21 02:47:12+00:00\n    iap\n    offer5\n    26.09\n    8.4\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    2000\n    GJCXNTWEBIPQ369\n    GJCXNTWEBIPQ369-9elq67md\n    2015-01-21 03:59:23+00:00\n    2015-01-21 04:06:29+00:00\n    ad\n    ad_5sec\n    0.12\n    18.5\n    2015-01-14\n    organic\n    United States"
  },
  {
    "objectID": "demos/05-step-report-column-check/index.html",
    "href": "demos/05-step-report-column-check/index.html",
    "title": "Pointblank",
    "section": "",
    "text": "Step Report: Column Data Checks\nA step report for column checks shows what went wrong.\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Step reports for column data checksPolarssmall_table\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_ge\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_ge()\n        \n        \n        \n    c\n    4\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    90.69\n    40.31\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    b\n    \\d-[a-z]{3}-\\d{3}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:20:36 UTC&lt; 1 s2025-11-23 00:20:36 UTC\n  \n\n\n\n\n\n\n        \n\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 1ASSERTION c ≥ 44 / 13 TEST UNIT FAILURES IN COLUMN 5 EXTRACT OF ALL 4 ROWS (WITH TEST UNIT FAILURES IN RED):\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05\n    6\n    8-kdg-938\n    3\n    2343.23\n    True\n    high\n  \n  \n    7\n    2016-01-15 18:46:00\n    2016-01-15\n    7\n    1-knw-093\n    3\n    843.34\n    True\n    high\n  \n  \n    8\n    2016-01-17 11:27:00\n    2016-01-17\n    4\n    5-boe-639\n    2\n    1035.64\n    False\n    low\n  \n\n\n\n\n\n\n        \n\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 2 ✓ASSERTION b matches regex \\d-[a-z]{3}-\\d{3}13 TEST UNITS ALL PASSED IN COLUMN 4PREVIEW OF TARGET TABLE:\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05\n    6\n    8-kdg-938\n    3\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    None\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09\n    8\n    3-ldm-038\n    7\n    283.94\n    True\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26\n    4\n    2-dmx-010\n    7\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28\n    2\n    7-dmx-010\n    8\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30\n    1\n    3-dka-303\n    None\n    2230.09\n    True\n    high\n  \n\n\n\n\n\n\n        \n\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\"),\n        tbl_name=\"small_table\",\n        label=\"Step reports for column data checks\"\n    )\n    .col_vals_ge(columns=\"c\", value=4, na_pass=True)                # has failing test units\n    .col_vals_regex(columns=\"b\", pattern=r\"\\d-[a-z]{3}-\\d{3}\")      # no failing test units\n    .interrogate()\n)\n\nvalidation\nvalidation.get_step_report(i=1)\nvalidation.get_step_report(i=2)\n\n\nPreview of Input Table\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows13Columns8\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05\n    6\n    8-kdg-938\n    3\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    None\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09\n    8\n    3-ldm-038\n    7\n    283.94\n    True\n    low\n  \n  \n    6\n    2016-01-11 06:15:00\n    2016-01-11\n    4\n    2-dhe-923\n    4\n    3291.03\n    True\n    mid\n  \n  \n    7\n    2016-01-15 18:46:00\n    2016-01-15\n    7\n    1-knw-093\n    3\n    843.34\n    True\n    high\n  \n  \n    8\n    2016-01-17 11:27:00\n    2016-01-17\n    4\n    5-boe-639\n    2\n    1035.64\n    False\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26\n    4\n    2-dmx-010\n    7\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28\n    2\n    7-dmx-010\n    8\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30\n    1\n    3-dka-303\n    None\n    2230.09\n    True\n    high"
  },
  {
    "objectID": "demos/check-row-column-counts/index.html",
    "href": "demos/check-row-column-counts/index.html",
    "title": "Pointblank",
    "section": "",
    "text": "Verifying Row and Column Counts\nCheck the dimensions of the table with the *_count_match() validation methods.\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:20:27DuckDB\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_count_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            col_count_match()\n        \n        \n        \n    —\n    11\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    row_count_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            row_count_match()\n        \n        \n        \n    —\n    2000\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    row_count_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            row_count_match()\n        \n        \n        \n    —\n    ≠ 0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_count_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            col_count_match()\n        \n        \n        \n    —\n    11\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:20:27 UTC&lt; 1 s2025-11-23 00:20:27 UTC\n  \n\n\n\n\n\n\n        \n\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"duckdb\")\n    )\n    .col_count_match(count=11)                       # expect 11 columns in the table\n    .row_count_match(count=2000)                     # expect 2,000 rows in the table\n    .row_count_match(count=0, inverse=True)          # expect that the table has rows\n    .col_count_match(                                # compare column count against\n        count=pb.load_dataset(                       # that of another table\n            dataset=\"game_revenue\", tbl_type=\"pandas\"\n        )\n    )\n    .interrogate()\n)\n\nvalidation\n\n\nPreview of Input Table\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    DuckDBRows2,000Columns11\n  \n\n  \n  player_idstring\n  session_idstring\n  session_starttimestamp\n  timetimestamp\n  item_typestring\n  item_namestring\n  item_revenuefloat64\n  session_durationfloat64\n  start_daydate\n  acquisitionstring\n  countrystring\n\n\n\n  \n    1\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:31:27+00:00\n    iap\n    offer2\n    8.99\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    2\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:36:57+00:00\n    iap\n    gems3\n    22.49\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    3\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:37:45+00:00\n    iap\n    gold7\n    107.99\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    4\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:42:33+00:00\n    ad\n    ad_20sec\n    0.76\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    5\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-hdu9jkls\n    2015-01-01 11:50:02+00:00\n    2015-01-01 11:55:20+00:00\n    ad\n    ad_5sec\n    0.03\n    35.2\n    2015-01-01\n    google\n    Germany\n  \n  \n    1996\n    NAOJRDMCSEBI281\n    NAOJRDMCSEBI281-j2vs9ilp\n    2015-01-21 01:57:50+00:00\n    2015-01-21 02:02:50+00:00\n    ad\n    ad_survey\n    1.332\n    25.8\n    2015-01-11\n    organic\n    Norway\n  \n  \n    1997\n    NAOJRDMCSEBI281\n    NAOJRDMCSEBI281-j2vs9ilp\n    2015-01-21 01:57:50+00:00\n    2015-01-21 02:22:14+00:00\n    ad\n    ad_survey\n    1.35\n    25.8\n    2015-01-11\n    organic\n    Norway\n  \n  \n    1998\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-vbhcsmtr\n    2015-01-21 02:39:48+00:00\n    2015-01-21 02:40:00+00:00\n    ad\n    ad_5sec\n    0.03\n    8.4\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    1999\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-vbhcsmtr\n    2015-01-21 02:39:48+00:00\n    2015-01-21 02:47:12+00:00\n    iap\n    offer5\n    26.09\n    8.4\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    2000\n    GJCXNTWEBIPQ369\n    GJCXNTWEBIPQ369-9elq67md\n    2015-01-21 03:59:23+00:00\n    2015-01-21 04:06:29+00:00\n    ad\n    ad_5sec\n    0.12\n    18.5\n    2015-01-14\n    organic\n    United States"
  },
  {
    "objectID": "demos/02-advanced/index.html",
    "href": "demos/02-advanced/index.html",
    "title": "Pointblank",
    "section": "",
    "text": "Advanced Validation\nA validation with a comprehensive set of rules.\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Comprehensive validation examplePolarsgame_revenueWARNING0.1ERROR0.25CRITICAL0.35\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    player_id\n    ^[A-Z]{12}[0-9]{3}$\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    session_duration\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    19820.99\n    180.01\n    ○\n    ○\n    ○\n    CSV\n  \n  \n    #4CA64C66\n    3\n    \n        \n            \n\n    col_vals_ge\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_ge()\n        \n        \n        \n    item_revenue\n    0.02\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    19410.97\n    590.03\n    ○\n    ○\n    ○\n    CSV\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        \n        \n    item_type\n    iap, ad\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C66\n    5\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        \n        \n    acquisition\n    google, facebook, organic, crosspromo, other_campaign\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    19750.99\n    250.01\n    ○\n    ○\n    ○\n    CSV\n  \n  \n    #AAAAAA\n    6\n    \n        \n            \n\n    col_vals_not_in_set\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_in_set()\n        \n        \n        \n    country\n    Mongolia, Germany\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    17750.89\n    2250.11\n    ●\n    ○\n    ○\n    CSV\n  \n  \n    #4CA64C\n    7\n    \n        \n            \n\n    col_vals_between\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_between()\n        \n        \n        \n    session_duration\n    [10, 50]\n    \n    \n        \n            \n            \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C66\n    8\n    \n        \n            \n\n    rows_distinct\n    \n        \n            \n            \n                \n                \n                \n            \n        \n    \n\n        \n        \n            rows_distinct()\n        \n        \n        \n    player_id, session_id, time\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    19780.99\n    220.01\n    ○\n    ○\n    ○\n    CSV\n  \n  \n    #4CA64C\n    9\n    \n        \n            \n\n    row_count_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            row_count_match()\n        \n        \n        \n    —\n    2000\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C\n    10\n    \n        \n            \n\n    col_count_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            col_count_match()\n        \n        \n        \n    —\n    11\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C\n    11\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    item_type\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C\n    12\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    item_name\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C\n    13\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    item_revenue\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C\n    14\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    start_day\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:20:17 UTC&lt; 1 s2025-11-23 00:20:17 UTC\n  \n\n\n\n\n\n\n        \n\n\nimport pointblank as pb\nimport polars as pl\n\nvalidation = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"polars\"),\n        tbl_name=\"game_revenue\",\n        label=\"Comprehensive validation example\",\n        thresholds=pb.Thresholds(warning=0.10, error=0.25, critical=0.35),\n    )\n    .col_vals_regex(columns=\"player_id\", pattern=r\"^[A-Z]{12}[0-9]{3}$\")        # STEP 1\n    .col_vals_gt(columns=\"session_duration\", value=5)                           # STEP 2\n    .col_vals_ge(columns=\"item_revenue\", value=0.02)                            # STEP 3\n    .col_vals_in_set(columns=\"item_type\", set=[\"iap\", \"ad\"])                    # STEP 4\n    .col_vals_in_set(                                                           # STEP 5\n        columns=\"acquisition\",\n        set=[\"google\", \"facebook\", \"organic\", \"crosspromo\", \"other_campaign\"]\n    )\n    .col_vals_not_in_set(columns=\"country\", set=[\"Mongolia\", \"Germany\"])        # STEP 6\n    .col_vals_between(                                                          # STEP 7\n        columns=\"session_duration\",\n        left=10, right=50,\n        pre = lambda df: df.select(pl.median(\"session_duration\"))\n    )\n    .rows_distinct(columns_subset=[\"player_id\", \"session_id\", \"time\"])          # STEP 8\n    .row_count_match(count=2000)                                                # STEP 9\n    .col_count_match(count=11)                                                  # STEP 10\n    .col_vals_not_null(columns=pb.starts_with(\"item\"))                          # STEPS 11-13\n    .col_exists(columns=\"start_day\")                                            # STEP 14\n    .interrogate()\n)\n\nvalidation\n\n\nPreview of Input Table\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows2,000Columns11\n  \n\n  \n  player_idString\n  session_idString\n  session_startDatetime\n  timeDatetime\n  item_typeString\n  item_nameString\n  item_revenueFloat64\n  session_durationFloat64\n  start_dayDate\n  acquisitionString\n  countryString\n\n\n\n  \n    1\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:31:27+00:00\n    iap\n    offer2\n    8.99\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    2\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:36:57+00:00\n    iap\n    gems3\n    22.49\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    3\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:37:45+00:00\n    iap\n    gold7\n    107.99\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    4\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:42:33+00:00\n    ad\n    ad_20sec\n    0.76\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    5\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-hdu9jkls\n    2015-01-01 11:50:02+00:00\n    2015-01-01 11:55:20+00:00\n    ad\n    ad_5sec\n    0.03\n    35.2\n    2015-01-01\n    google\n    Germany\n  \n  \n    6\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-hdu9jkls\n    2015-01-01 11:50:02+00:00\n    2015-01-01 12:08:56+00:00\n    ad\n    ad_10sec\n    0.07\n    35.2\n    2015-01-01\n    google\n    Germany\n  \n  \n    7\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-hdu9jkls\n    2015-01-01 11:50:02+00:00\n    2015-01-01 12:14:08+00:00\n    ad\n    ad_10sec\n    0.08\n    35.2\n    2015-01-01\n    google\n    Germany\n  \n  \n    8\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-hdu9jkls\n    2015-01-01 11:50:02+00:00\n    2015-01-01 12:21:44+00:00\n    ad\n    ad_30sec\n    1.17\n    35.2\n    2015-01-01\n    google\n    Germany\n  \n  \n    9\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-hdu9jkls\n    2015-01-01 11:50:02+00:00\n    2015-01-01 12:24:20+00:00\n    ad\n    ad_10sec\n    0.14\n    35.2\n    2015-01-01\n    google\n    Germany\n  \n  \n    10\n    FXWUORGYNJAE271\n    FXWUORGYNJAE271-et7bs639\n    2015-01-01 15:17:18+00:00\n    2015-01-01 15:19:36+00:00\n    ad\n    ad_5sec\n    0.08\n    30.7\n    2015-01-01\n    organic\n    Canada\n  \n  \n    1991\n    VPNRYLMBKJGT925\n    VPNRYLMBKJGT925-vt26q9gb\n    2015-01-21 01:07:24+00:00\n    2015-01-21 01:26:12+00:00\n    ad\n    ad_survey\n    0.72\n    24.9\n    2015-01-21\n    other_campaign\n    Germany\n  \n  \n    1992\n    JVBZCPKXHFMU491\n    JVBZCPKXHFMU491-wvi6hs2t\n    2015-01-21 01:49:36+00:00\n    2015-01-21 01:53:36+00:00\n    iap\n    gold6\n    41.99\n    7.1\n    2015-01-07\n    organic\n    United States\n  \n  \n    1993\n    JVBZCPKXHFMU491\n    JVBZCPKXHFMU491-wvi6hs2t\n    2015-01-21 01:49:36+00:00\n    2015-01-21 01:55:42+00:00\n    iap\n    gems3\n    17.49\n    7.1\n    2015-01-07\n    organic\n    United States\n  \n  \n    1994\n    NAOJRDMCSEBI281\n    NAOJRDMCSEBI281-j2vs9ilp\n    2015-01-21 01:57:50+00:00\n    2015-01-21 02:01:20+00:00\n    ad\n    ad_playable\n    1.116\n    25.8\n    2015-01-11\n    organic\n    Norway\n  \n  \n    1995\n    NAOJRDMCSEBI281\n    NAOJRDMCSEBI281-j2vs9ilp\n    2015-01-21 01:57:50+00:00\n    2015-01-21 02:02:14+00:00\n    ad\n    ad_15sec\n    0.225\n    25.8\n    2015-01-11\n    organic\n    Norway\n  \n  \n    1996\n    NAOJRDMCSEBI281\n    NAOJRDMCSEBI281-j2vs9ilp\n    2015-01-21 01:57:50+00:00\n    2015-01-21 02:02:50+00:00\n    ad\n    ad_survey\n    1.332\n    25.8\n    2015-01-11\n    organic\n    Norway\n  \n  \n    1997\n    NAOJRDMCSEBI281\n    NAOJRDMCSEBI281-j2vs9ilp\n    2015-01-21 01:57:50+00:00\n    2015-01-21 02:22:14+00:00\n    ad\n    ad_survey\n    1.35\n    25.8\n    2015-01-11\n    organic\n    Norway\n  \n  \n    1998\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-vbhcsmtr\n    2015-01-21 02:39:48+00:00\n    2015-01-21 02:40:00+00:00\n    ad\n    ad_5sec\n    0.03\n    8.4\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    1999\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-vbhcsmtr\n    2015-01-21 02:39:48+00:00\n    2015-01-21 02:47:12+00:00\n    iap\n    offer5\n    26.09\n    8.4\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    2000\n    GJCXNTWEBIPQ369\n    GJCXNTWEBIPQ369-9elq67md\n    2015-01-21 03:59:23+00:00\n    2015-01-21 04:06:29+00:00\n    ad\n    ad_5sec\n    0.12\n    18.5\n    2015-01-14\n    organic\n    United States"
  },
  {
    "objectID": "demos/03-data-extracts/index.html",
    "href": "demos/03-data-extracts/index.html",
    "title": "Pointblank",
    "section": "",
    "text": "Data Extracts\nPulling out data extracts that highlight rows with validation failures.\n\nValidation with failures at Step 2:\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Validation with test unit failures available as an extractPolarsgame_revenue\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    item_revenue\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_ge\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_ge()\n        \n        \n        \n    session_duration\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    19860.99\n    140.01\n    —\n    —\n    —\n    CSV\n  \n\n  \n  \n  \n    2025-11-23 00:20:09 UTC&lt; 1 s2025-11-23 00:20:09 UTC\n  \n\n\n\n\n\n\n        \n\n\n\n\nExtract from Step 2 (which has 14 failing test units):\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows14Columns12\n  \n\n  \n  player_idString\n  session_idString\n  session_startDatetime\n  timeDatetime\n  item_typeString\n  item_nameString\n  item_revenueFloat64\n  session_durationFloat64\n  start_dayDate\n  acquisitionString\n  countryString\n\n\n\n  \n    549\n    QNLVRDEOXFYJ892\n    QNLVRDEOXFYJ892-lz5fmr6k\n    2015-01-10 16:44:17+00:00\n    2015-01-10 16:45:29+00:00\n    iap\n    gold3\n    3.49\n    3.7\n    2015-01-09\n    crosspromo\n    Australia\n  \n  \n    663\n    GFLYJHAPMZWD631\n    GFLYJHAPMZWD631-i2v1bl7a\n    2015-01-11 16:13:24+00:00\n    2015-01-11 16:14:54+00:00\n    iap\n    gems2\n    3.99\n    3.6\n    2015-01-09\n    organic\n    India\n  \n  \n    772\n    BFNLURISJXTH647\n    BFNLURISJXTH647-6o5hx27z\n    2015-01-12 17:37:39+00:00\n    2015-01-12 17:39:27+00:00\n    iap\n    offer5\n    11.59\n    4.1\n    2015-01-10\n    organic\n    India\n  \n  \n    773\n    BFNLURISJXTH647\n    BFNLURISJXTH647-6o5hx27z\n    2015-01-12 17:37:39+00:00\n    2015-01-12 17:41:45+00:00\n    iap\n    gems3\n    9.99\n    4.1\n    2015-01-10\n    organic\n    India\n  \n  \n    908\n    KILWZYHRSJEG316\n    KILWZYHRSJEG316-uke7dhqj\n    2015-01-13 22:16:29+00:00\n    2015-01-13 22:17:35+00:00\n    iap\n    offer2\n    10.99\n    3.2\n    2015-01-04\n    organic\n    Denmark\n  \n  \n    1037\n    JUBDVFHCNQWT198\n    JUBDVFHCNQWT198-9h4xs2pb\n    2015-01-14 16:08:25+00:00\n    2015-01-14 16:08:43+00:00\n    iap\n    offer5\n    8.69\n    3.3\n    2015-01-14\n    organic\n    Philippines\n  \n  \n    1038\n    JUBDVFHCNQWT198\n    JUBDVFHCNQWT198-9h4xs2pb\n    2015-01-14 16:08:25+00:00\n    2015-01-14 16:11:01+00:00\n    iap\n    offer4\n    5.99\n    3.3\n    2015-01-14\n    organic\n    Philippines\n  \n  \n    1455\n    GJCXNTWEBIPQ369\n    GJCXNTWEBIPQ369-46cdjzy7\n    2015-01-17 11:25:25+00:00\n    2015-01-17 11:28:01+00:00\n    iap\n    offer4\n    13.99\n    4.6\n    2015-01-14\n    organic\n    United States\n  \n  \n    1516\n    OMCVUAIKSDTR651\n    OMCVUAIKSDTR651-yso9e1b2\n    2015-01-17 20:58:34+00:00\n    2015-01-17 21:01:34+00:00\n    iap\n    offer3\n    10.49\n    4.2\n    2015-01-07\n    other_campaign\n    United States\n  \n  \n    1517\n    OMCVUAIKSDTR651\n    OMCVUAIKSDTR651-yso9e1b2\n    2015-01-17 20:58:34+00:00\n    2015-01-17 21:02:34+00:00\n    iap\n    offer5\n    20.29\n    4.2\n    2015-01-07\n    other_campaign\n    United States\n  \n  \n    1913\n    MTCIWKOVASYP925\n    MTCIWKOVASYP925-1q3xvfmp\n    2015-01-20 12:34:43+00:00\n    2015-01-20 12:35:37+00:00\n    iap\n    offer5\n    26.09\n    3.9\n    2015-01-14\n    organic\n    Germany\n  \n  \n    1914\n    MTCIWKOVASYP925\n    MTCIWKOVASYP925-1q3xvfmp\n    2015-01-20 12:34:43+00:00\n    2015-01-20 12:37:25+00:00\n    iap\n    gold2\n    1.79\n    3.9\n    2015-01-14\n    organic\n    Germany\n  \n  \n    1919\n    BFNLURISJXTH647\n    BFNLURISJXTH647-len6vujd\n    2015-01-20 14:09:51+00:00\n    2015-01-20 14:10:03+00:00\n    iap\n    gold7\n    47.99\n    4.5\n    2015-01-10\n    organic\n    India\n  \n  \n    1920\n    BFNLURISJXTH647\n    BFNLURISJXTH647-len6vujd\n    2015-01-20 14:09:51+00:00\n    2015-01-20 14:14:21+00:00\n    iap\n    gold6\n    23.99\n    4.5\n    2015-01-10\n    organic\n    India\n  \n\n\n\n\n\n\n        \n\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\"),\n        tbl_name=\"game_revenue\",\n        label=\"Validation with test unit failures available as an extract\"\n    )\n    .col_vals_gt(columns=\"item_revenue\", value=0)      # STEP 1: no test unit failures\n    .col_vals_ge(columns=\"session_duration\", value=5)  # STEP 2: 14 test unit failures -&gt; extract\n    .interrogate()\n)\npb.preview(validation.get_data_extracts(i=2, frame=True), n_head=20, n_tail=20)\n\n\nPreview of Input Table\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows2,000Columns11\n  \n\n  \n  player_idString\n  session_idString\n  session_startDatetime\n  timeDatetime\n  item_typeString\n  item_nameString\n  item_revenueFloat64\n  session_durationFloat64\n  start_dayDate\n  acquisitionString\n  countryString\n\n\n\n  \n    1\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:31:27+00:00\n    iap\n    offer2\n    8.99\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    2\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:36:57+00:00\n    iap\n    gems3\n    22.49\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    3\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:37:45+00:00\n    iap\n    gold7\n    107.99\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    4\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:42:33+00:00\n    ad\n    ad_20sec\n    0.76\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    5\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-hdu9jkls\n    2015-01-01 11:50:02+00:00\n    2015-01-01 11:55:20+00:00\n    ad\n    ad_5sec\n    0.03\n    35.2\n    2015-01-01\n    google\n    Germany\n  \n  \n    1996\n    NAOJRDMCSEBI281\n    NAOJRDMCSEBI281-j2vs9ilp\n    2015-01-21 01:57:50+00:00\n    2015-01-21 02:02:50+00:00\n    ad\n    ad_survey\n    1.332\n    25.8\n    2015-01-11\n    organic\n    Norway\n  \n  \n    1997\n    NAOJRDMCSEBI281\n    NAOJRDMCSEBI281-j2vs9ilp\n    2015-01-21 01:57:50+00:00\n    2015-01-21 02:22:14+00:00\n    ad\n    ad_survey\n    1.35\n    25.8\n    2015-01-11\n    organic\n    Norway\n  \n  \n    1998\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-vbhcsmtr\n    2015-01-21 02:39:48+00:00\n    2015-01-21 02:40:00+00:00\n    ad\n    ad_5sec\n    0.03\n    8.4\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    1999\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-vbhcsmtr\n    2015-01-21 02:39:48+00:00\n    2015-01-21 02:47:12+00:00\n    iap\n    offer5\n    26.09\n    8.4\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    2000\n    GJCXNTWEBIPQ369\n    GJCXNTWEBIPQ369-9elq67md\n    2015-01-21 03:59:23+00:00\n    2015-01-21 04:06:29+00:00\n    ad\n    ad_5sec\n    0.12\n    18.5\n    2015-01-14\n    organic\n    United States"
  },
  {
    "objectID": "demos/apply-checks-to-several-columns/index.html",
    "href": "demos/apply-checks-to-several-columns/index.html",
    "title": "Pointblank",
    "section": "",
    "text": "Apply Validation Rules to Multiple Columns\nCreate multiple validation steps by using a list of column names with columns=.\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:20:00Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_ge\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_ge()\n        \n        \n        \n    a\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_ge\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_ge()\n        \n        \n        \n    c\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_vals_ge\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_ge()\n        \n        \n        \n    d\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    date_time\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    5\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    date\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:20:00 UTC&lt; 1 s2025-11-23 00:20:00 UTC\n  \n\n\n\n\n\n\n        \n\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\")\n    )\n    .col_vals_ge(columns=[\"a\", \"c\", \"d\"], value=0)   # check values in 'a', 'c', and 'd'\n    .col_exists(columns=[\"date_time\", \"date\"])       # check for the existence of two columns\n    .interrogate()\n)\n\nvalidation\n\n\nPreview of Input Table\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows13Columns8\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05\n    6\n    8-kdg-938\n    3\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    None\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09\n    8\n    3-ldm-038\n    7\n    283.94\n    True\n    low\n  \n  \n    6\n    2016-01-11 06:15:00\n    2016-01-11\n    4\n    2-dhe-923\n    4\n    3291.03\n    True\n    mid\n  \n  \n    7\n    2016-01-15 18:46:00\n    2016-01-15\n    7\n    1-knw-093\n    3\n    843.34\n    True\n    high\n  \n  \n    8\n    2016-01-17 11:27:00\n    2016-01-17\n    4\n    5-boe-639\n    2\n    1035.64\n    False\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26\n    4\n    2-dmx-010\n    7\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28\n    2\n    7-dmx-010\n    8\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30\n    1\n    3-dka-303\n    None\n    2230.09\n    True\n    high"
  },
  {
    "objectID": "demos/08-validation-with-final-actions/index.html",
    "href": "demos/08-validation-with-final-actions/index.html",
    "title": "Pointblank",
    "section": "",
    "text": "Validation with Final Actions\nExecute actions after validation completes, such as sending alerts or generating summary reports.\n\n\nValidation workflow completed.\n🚨 ALERT: Critical validation failures found!\n   Failed steps: 2\n\n--- Validation Summary Report ---\nTotal validation steps: 3\nPassed steps: 1\nFailed steps: 2\nHighest severity: critical\n--- End of Report ---\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Validation with final actionsPolarsWARNING0.05ERROR0.1CRITICAL0.15\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    player_id\n    [A-Z]{12}[0-9]{3}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #EBBC14\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    item_revenue\n    0.05\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    17010.85\n    2990.15\n    ●\n    ●\n    ○\n    CSV\n  \n  \n    #FF3300\n    3\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    session_duration\n    15\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    16750.84\n    3250.16\n    ●\n    ●\n    ●\n    CSV\n  \n\n  \n  \n  \n    2025-11-23 00:19:51 UTC&lt; 1 s2025-11-23 00:19:51 UTC\n  \n\n\n\n\n\n\n        \n\n\nimport pointblank as pb\n\ndef send_alert():\n    \"\"\"Check validation summary and send alert if critical failures found\"\"\"\n    summary = pb.get_validation_summary()\n    if summary and summary.get(\"highest_severity\") == \"critical\":\n        print(f\"🚨 ALERT: Critical validation failures found!\")\n        print(f\"   Failed steps: {summary['n_failing_steps']}\")\n    elif summary and summary.get(\"highest_severity\") == \"error\":\n        print(f\"⚠️  WARNING: Error-level validation failures detected.\")\n    else:\n        print(\"✅ All validation checks passed successfully!\")\n\ndef generate_summary_report():\n    \"\"\"Generate a summary report of validation results\"\"\"\n    summary = pb.get_validation_summary()\n    if summary:\n        print(\"\\n--- Validation Summary Report ---\")\n        print(f\"Total validation steps: {summary['n_steps']}\")\n        print(f\"Passed steps: {summary['n_passing_steps']}\")\n        print(f\"Failed steps: {summary['n_failing_steps']}\")\n        print(f\"Highest severity: {summary['highest_severity']}\")\n        print(\"--- End of Report ---\")\n\nvalidation = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"polars\"),\n        label=\"Validation with final actions\",\n        thresholds=pb.Thresholds(warning=0.05, error=0.10, critical=0.15),\n        final_actions=pb.FinalActions(\n            \"Validation workflow completed.\",  # String message\n            send_alert,                        # Alert function\n            generate_summary_report            # Report function\n        )\n    )\n    .col_vals_regex(columns=\"player_id\", pattern=r\"[A-Z]{12}[0-9]{3}\")\n    .col_vals_gt(columns=\"item_revenue\", value=0.05)\n    .col_vals_gt(columns=\"session_duration\", value=15)\n    .interrogate()\n)\n\nvalidation\n\n\nPreview of Input Table\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows2,000Columns11\n  \n\n  \n  player_idString\n  session_idString\n  session_startDatetime\n  timeDatetime\n  item_typeString\n  item_nameString\n  item_revenueFloat64\n  session_durationFloat64\n  start_dayDate\n  acquisitionString\n  countryString\n\n\n\n  \n    1\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:31:27+00:00\n    iap\n    offer2\n    8.99\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    2\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:36:57+00:00\n    iap\n    gems3\n    22.49\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    3\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:37:45+00:00\n    iap\n    gold7\n    107.99\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    4\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:42:33+00:00\n    ad\n    ad_20sec\n    0.76\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    5\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-hdu9jkls\n    2015-01-01 11:50:02+00:00\n    2015-01-01 11:55:20+00:00\n    ad\n    ad_5sec\n    0.03\n    35.2\n    2015-01-01\n    google\n    Germany\n  \n  \n    1996\n    NAOJRDMCSEBI281\n    NAOJRDMCSEBI281-j2vs9ilp\n    2015-01-21 01:57:50+00:00\n    2015-01-21 02:02:50+00:00\n    ad\n    ad_survey\n    1.332\n    25.8\n    2015-01-11\n    organic\n    Norway\n  \n  \n    1997\n    NAOJRDMCSEBI281\n    NAOJRDMCSEBI281-j2vs9ilp\n    2015-01-21 01:57:50+00:00\n    2015-01-21 02:22:14+00:00\n    ad\n    ad_survey\n    1.35\n    25.8\n    2015-01-11\n    organic\n    Norway\n  \n  \n    1998\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-vbhcsmtr\n    2015-01-21 02:39:48+00:00\n    2015-01-21 02:40:00+00:00\n    ad\n    ad_5sec\n    0.03\n    8.4\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    1999\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-vbhcsmtr\n    2015-01-21 02:39:48+00:00\n    2015-01-21 02:47:12+00:00\n    iap\n    offer5\n    26.09\n    8.4\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    2000\n    GJCXNTWEBIPQ369\n    GJCXNTWEBIPQ369-9elq67md\n    2015-01-21 03:59:23+00:00\n    2015-01-21 04:06:29+00:00\n    ad\n    ad_5sec\n    0.12\n    18.5\n    2015-01-14\n    organic\n    United States"
  },
  {
    "objectID": "demos/index.html",
    "href": "demos/index.html",
    "title": "Pointblank",
    "section": "",
    "text": "A Selection of Examples\n\n\n\n\n\n\nStarter Validation\n\n\n\nA validation with the basics.\n\n\n\n\n\n\nAdvanced Validation\n\n\n\nA validation with a comprehensive set of rules.\n\n\n\n\n\n\nData Extracts\n\n\n\nPulling out data extracts that highlight rows with validation failures.\n\n\n\n\n\n\nSundered Data\n\n\n\nSplitting your data into ‘pass’ and ‘fail’ subsets.\n\n\n\n\n\n\nStep Reports for Column Data Checks\n\n\n\nA step report for column checks shows what went wrong.\n\n\n\n\n\n\nStep Report for a Schema Check\n\n\n\nWhen a schema doesn’t match, a step report gives you the details.\n\n\n\n\n\n\nStep-Level Actions\n\n\n\nConfigure actions to trigger when validation thresholds are exceeded, such as logging warnings or errors.\n\n\n\n\n\n\nFinal Actions\n\n\n\nExecute actions after validation completes, such as sending alerts or generating summary reports.\n\n\n\n\n\n\n\nNumeric Comparisons Perform comparisons of values in columns to fixed values.\nComparison Checks Across Columns Perform comparisons of values in columns to values in other columns.\nApply Validation Rules to Multiple Columns Create multiple validation steps by using a list of column names with columns=.\nChecks for Missing Values Perform validations that check whether missing/NA/Null values are present.\nExpectations with a Text Pattern With col_vals_regex(), check for conformance to a regular expression.\nSet Membership Perform validations that check whether values are part of a set (or not part of one).\nExpect No Duplicate Rows We can check for duplicate rows in the table with rows_distinct().\nChecking for Duplicate Values To check for duplicate values down a column, use rows_distinct() with a columns_subset= value.\nCustom Expression for Checking Column Values A column expression can be used to check column values. Just use col_vals_expr() for this.\nMutate the Table in a Validation Step For far more specialized validations, modify the table with the pre= argument before checking it.\nVerifying Row and Column Counts Check the dimensions of the table with the *_count_match() validation methods.\nValidating Data Freshness Use date-based validations to ensure your data is current and recent.\nDate and Datetime Validations Comprehensive examples of date, datetime, and timezone-aware datetime comparisons.\nCustom Validation with specially() Create bespoke validations using specially() to implement domain-specific business rules.\nSet Failure Threshold Levels Set threshold levels to better gauge adverse data quality.\nColumn Selector Functions: Easily Pick Columns Use column selector functions in the columns= argument to conveniently choose columns.\nCheck the Schema of a Table The schema of a table can be flexibly defined with Schema and verified with col_schema_match().\nUsing Parquet Data A Parquet dataset can be used for data validation, thanks to Ibis.\nCLI Interactive Demos These CLI demos showcase practical data quality workflows that you can use!"
  },
  {
    "objectID": "demos/07-validation-with-actions/index.html",
    "href": "demos/07-validation-with-actions/index.html",
    "title": "Pointblank",
    "section": "",
    "text": "Validation with Actions\nConfigure actions to trigger when validation thresholds are exceeded, such as logging warnings or errors.\n\n\n⚠️  WARNING: Validation step '1' exceeded threshold!\n❌  ERROR: Critical validation failure in step '2'!\n    This requires immediate attention.\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Validation with actionsPolars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #AAAAAA\n    1\n    \n        \n            \n\n    col_vals_between\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_between()\n        \n        Column 'distance' range check.\n\n        \n    distance\n    [100, 2000]\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    337K\n    283K0.84\n    53.3K0.16\n    ●\n    —\n    —\n    CSV\n  \n  \n    #EBBC14\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Column 'origin' check for minimum value.\n\n        \n    air_time\n    25\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    337K\n    336K1.00\n    3590.00\n    —\n    ●\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        Column 'carrier' completeness check.\n\n        \n    carrier\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    337K\n    337K1.00\n    00.00\n    ○\n    ○\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:19:41 UTC&lt; 1 s2025-11-23 00:19:41 UTC\n  \n\n\n  \n    \nNotes\nStep 1 (local_thresholds) Step-specific thresholds set with W:0.1.\nStep 2 (local_thresholds) Step-specific thresholds set with E:200.\nStep 3 (local_thresholds) Step-specific thresholds set with W:1|E:0.05.\n  \n\n\n\n\n\n\n        \n\n\nimport pointblank as pb\n\ndef log_warning():\n    \"\"\"Custom action to log validation warnings\"\"\"\n    metadata = pb.get_action_metadata()\n    print(f\"⚠️  WARNING: Validation step '{metadata['step']}' exceeded threshold!\")\n\ndef log_error():\n    \"\"\"Custom action to log validation errors\"\"\"\n    metadata = pb.get_action_metadata()\n    print(f\"❌  ERROR: Critical validation failure in step '{metadata['step']}'!\")\n    print(f\"    This requires immediate attention.\")\n\nvalidation = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"nycflights\", tbl_type=\"polars\"),\n        label=\"Validation with actions\"\n    )\n    .col_vals_between(\n        columns=\"distance\",\n        left=100, right=2000,\n        thresholds=pb.Thresholds(warning=0.1),  # Allow 10% failures before warning\n        actions=pb.Actions(warning=log_warning),\n        brief=\"Column 'distance' range check.\"\n    )\n    .col_vals_gt(\n        columns=\"air_time\",\n        value=25,\n        na_pass=True,\n        thresholds=pb.Thresholds(error=200),  # Allow only 200 failures before error\n        actions=pb.Actions(error=log_error),\n        brief=\"Column 'origin' check for minimum value.\"\n    )\n    .col_vals_not_null(\n        columns=\"carrier\",\n        thresholds=(1, 0.05),  # No tolerance for null values\n        actions=pb.Actions(warning=log_warning, error=log_error),\n        brief=\"Column 'carrier' completeness check.\"\n    )\n    .interrogate()\n)\n\nvalidation\n\n\nPreview of Input Table\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows336,776Columns18\n  \n\n  \n  yearInt64\n  monthInt64\n  dayInt64\n  dep_timeInt64\n  sched_dep_timeInt64\n  dep_delayInt64\n  arr_timeInt64\n  sched_arr_timeInt64\n  arr_delayInt64\n  carrierString\n  flightInt64\n  tailnumString\n  originString\n  destString\n  air_timeInt64\n  distanceInt64\n  hourInt64\n  minuteInt64\n\n\n\n  \n    1\n    2013\n    1\n    1\n    517\n    515\n    2\n    830\n    819\n    11\n    UA\n    1545\n    N14228\n    EWR\n    IAH\n    227\n    1400\n    5\n    15\n  \n  \n    2\n    2013\n    1\n    1\n    533\n    529\n    4\n    850\n    830\n    20\n    UA\n    1714\n    N24211\n    LGA\n    IAH\n    227\n    1416\n    5\n    29\n  \n  \n    3\n    2013\n    1\n    1\n    542\n    540\n    2\n    923\n    850\n    33\n    AA\n    1141\n    N619AA\n    JFK\n    MIA\n    160\n    1089\n    5\n    40\n  \n  \n    4\n    2013\n    1\n    1\n    544\n    545\n    -1\n    1004\n    1022\n    -18\n    B6\n    725\n    N804JB\n    JFK\n    BQN\n    183\n    1576\n    5\n    45\n  \n  \n    5\n    2013\n    1\n    1\n    554\n    600\n    -6\n    812\n    837\n    -25\n    DL\n    461\n    N668DN\n    LGA\n    ATL\n    116\n    762\n    6\n    0\n  \n  \n    336772\n    2013\n    9\n    30\n    None\n    1455\n    None\n    None\n    1634\n    None\n    9E\n    3393\n    None\n    JFK\n    DCA\n    None\n    213\n    14\n    55\n  \n  \n    336773\n    2013\n    9\n    30\n    None\n    2200\n    None\n    None\n    2312\n    None\n    9E\n    3525\n    None\n    LGA\n    SYR\n    None\n    198\n    22\n    0\n  \n  \n    336774\n    2013\n    9\n    30\n    None\n    1210\n    None\n    None\n    1330\n    None\n    MQ\n    3461\n    N535MQ\n    LGA\n    BNA\n    None\n    764\n    12\n    10\n  \n  \n    336775\n    2013\n    9\n    30\n    None\n    1159\n    None\n    None\n    1344\n    None\n    MQ\n    3572\n    N511MQ\n    LGA\n    CLE\n    None\n    419\n    11\n    59\n  \n  \n    336776\n    2013\n    9\n    30\n    None\n    840\n    None\n    None\n    1020\n    None\n    MQ\n    3531\n    N839MQ\n    LGA\n    RDU\n    None\n    431\n    8\n    40"
  },
  {
    "objectID": "demos/comparisons-across-columns/index.html",
    "href": "demos/comparisons-across-columns/index.html",
    "title": "Pointblank",
    "section": "",
    "text": "Comparison Checks Across Columns\nPerform comparisons of values in columns to values in other columns.\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:19:32Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    a\n    c\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    60.46\n    70.54\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_between\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_between()\n        \n        \n        \n    d\n    [c, 12000]\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:19:32 UTC&lt; 1 s2025-11-23 00:19:32 UTC\n  \n\n\n\n\n\n\n        \n\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\")\n    )\n    .col_vals_lt(columns=\"a\", value=pb.col(\"c\"))     # values in 'a' &gt; values in 'c'\n    .col_vals_between(\n        columns=\"d\",                                 # values in 'd' are between values\n        left=pb.col(\"c\"),                            # in 'c' and the fixed value of 12,000;\n        right=12000,                                 # any missing values encountered result\n        na_pass=True                                 # in a passing test unit\n    )\n    .interrogate()\n)\n\nvalidation\n\n\nPreview of Input Table\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows13Columns8\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05\n    6\n    8-kdg-938\n    3\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    None\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09\n    8\n    3-ldm-038\n    7\n    283.94\n    True\n    low\n  \n  \n    6\n    2016-01-11 06:15:00\n    2016-01-11\n    4\n    2-dhe-923\n    4\n    3291.03\n    True\n    mid\n  \n  \n    7\n    2016-01-15 18:46:00\n    2016-01-15\n    7\n    1-knw-093\n    3\n    843.34\n    True\n    high\n  \n  \n    8\n    2016-01-17 11:27:00\n    2016-01-17\n    4\n    5-boe-639\n    2\n    1035.64\n    False\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26\n    4\n    2-dmx-010\n    7\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28\n    2\n    7-dmx-010\n    8\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30\n    1\n    3-dka-303\n    None\n    2230.09\n    True\n    high"
  },
  {
    "objectID": "user-guide/extracts.html",
    "href": "user-guide/extracts.html",
    "title": "Data Extracts",
    "section": "",
    "text": "When validating data, identifying exactly which rows failed is critical for diagnosing and resolving data quality issues. This is where data extracts come in. Data extracts consist of target table rows containing at least one cell that failed validation. While the validation report provides an overview of pass/fail statistics, data extracts give you the actual problematic records for deeper investigation.\nThis article will cover:",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Data Extracts"
    ]
  },
  {
    "objectID": "user-guide/extracts.html#the-validation-methods-that-work-with-data-extracts",
    "href": "user-guide/extracts.html#the-validation-methods-that-work-with-data-extracts",
    "title": "Data Extracts",
    "section": "The Validation Methods that Work with Data Extracts",
    "text": "The Validation Methods that Work with Data Extracts\nThe following validation methods operate on column values and will have rows extracted when there are failing test units in those rows:\n\ncol_vals_gt()\ncol_vals_lt()\ncol_vals_ge()\ncol_vals_le()\ncol_vals_eq()\ncol_vals_ne()\ncol_vals_between()\ncol_vals_outside()\ncol_vals_in_set()\ncol_vals_not_in_set()\ncol_vals_null()\ncol_vals_not_null()\ncol_vals_regex()\ncol_vals_expr()\nconjointly()\n\nThese row-based validation methods will also have rows extracted should there be failing rows:\n\nrows_distinct()\nrows_complete()\n\nNote that some validation methods like col_exists() and col_schema_match() don’t generate data extracts because they validate structural aspects of the table rather than checking column values.",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Data Extracts"
    ]
  },
  {
    "objectID": "user-guide/extracts.html#accessing-data-extracts",
    "href": "user-guide/extracts.html#accessing-data-extracts",
    "title": "Data Extracts",
    "section": "Accessing Data Extracts",
    "text": "Accessing Data Extracts\nThere are three primary ways to access data extracts in Pointblank:\n\nthe CSV buttons in validation reports\nthrough the get_data_extracts() method\ninspecting a subset of failed rows in step reports\n\nLet’s explore each approach using examples.\n\nCSV Data from Validation Reports\nData extracts are embedded within validation report tables. Let’s look at an example, using the small_table dataset, where data extracts are collected in a single validation step due to failing test units:\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .col_vals_lt( columns=\"d\", value=3000)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    d\n    3000\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    90.69\n    40.31\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe single validation step checks whether values in d are less than 3000. Within that column, values range from 108.34 to 9999.99 so it makes sense that we can see 4 failing test units in the FAIL column.\nIf you look at the far right of the validation report you’ll find there’s a CSV button. Pressing it initiates the download of a CSV file, and that file contains the data extract for this validation step. The CSV button only appears when:\n\nthere is a non-zero number of failing test units\nthe validation step is based on the use of a column-value or a row-based validation method (the methods outlined in the section entitled The Validation Methods that Work with Data Extracts)\n\nAccess to CSV data for the test unit errors is useful when the validation report is shared with other data quality stakeholders, since it is easily accessible and doesn’t require further use of Pointblank. The stakeholder can simply open the downloaded CSV in their preferred spreadsheet software, import it into a different analysis environment like R or Julia, or process it with any tool that supports CSV files. This cross-platform compatibility makes the CSV export particularly valuable in mixed-language data teams where different members might be working with different tools.\n\n\nget_data_extracts()\nFor programmatic access to data extracts, Pointblank provides the get_data_extracts() method. This allows you to work with extract data directly in your Python workflow:\n\n# Get data extracts from step 1\nextract_1 = validation.get_data_extracts(i=1, frame=True)\n\nextract_1\n\n\nshape: (4, 9)_row_num_date_timedateabcdefu32datetime[μs]datei64stri64f64boolstr12016-01-04 11:00:002016-01-042\"1-bcd-345\"33423.29true\"high\"22016-01-04 00:32:002016-01-043\"5-egh-163\"89999.99true\"low\"42016-01-06 17:23:002016-01-062\"5-jdo-903\"null3892.4false\"mid\"62016-01-11 06:15:002016-01-114\"2-dhe-923\"43291.03true\"mid\"\n\n\nThe extracted table is of the same type (a Polars DataFrame) as the target table. Previously we used load_dataset() with the tbl_type=\"polars\" option to fetch the dataset in that form.\nNote these important details about using get_data_extracts():\n\nthe parameter i=1 corresponds to the step number shown in the validation report (1-indexed, not 0-indexed)\nsetting frame=True returns the data as a DataFrame rather than a dictionary (only works when i is a single integer)\nthe extract includes all columns from the original data, not just the column being validated\nan additional _row_num_ column is added to identify the original row positions\n\n\n\nStep Reports\nStep reports provide another way to access and visualize failing data. When you generate a step report for a validation step that has failing rows, those failing rows are displayed directly in the report:\n\n# Get a step report for the first validation step\nstep_report = validation.get_step_report(i=1)\n\nstep_report\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 1ASSERTION d &lt; 30004 / 13 TEST UNIT FAILURES IN COLUMN 6 EXTRACT OF ALL 4 ROWS (WITH TEST UNIT FAILURES IN RED):\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    None\n    3892.4\n    False\n    mid\n  \n  \n    6\n    2016-01-11 06:15:00\n    2016-01-11\n    4\n    2-dhe-923\n    4\n    3291.03\n    True\n    mid\n  \n\n\n\n\n\n\n        \n\n\nStep reports offer several advantages for working with data extracts as they:\n\nprovide immediate visual context by highlighting the specific column being validated\nformat the data for better readability, especially useful when sharing results with colleagues\ninclude additional metadata about the validation step and failure statistics\n\nFor steps with many failures, you can customize how many rows to display:\n\n# Limit to just 2 rows of failing data\nlimited_report = validation.get_step_report(i=1, limit=2)\n\nlimited_report\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 1ASSERTION d &lt; 30004 / 13 TEST UNIT FAILURES IN COLUMN 6 EXTRACT OF FIRST 2 ROWS (WITH TEST UNIT FAILURES IN RED):\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n\n\n\n\n\n\n        \n\n\nStep reports are particularly valuable when you want to quickly inspect the failing data without extracting it into a separate DataFrame. They provide a bridge between the high-level validation report and the detailed data extracts.",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Data Extracts"
    ]
  },
  {
    "objectID": "user-guide/extracts.html#viewing-data-extracts-with-preview",
    "href": "user-guide/extracts.html#viewing-data-extracts-with-preview",
    "title": "Data Extracts",
    "section": "Viewing Data Extracts with preview()",
    "text": "Viewing Data Extracts with preview()\nTo get a consistent HTML representation of any data extract (regardless of the table type), we can use the preview() function:\n\npb.preview(data=extract_1)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows4Columns9\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    None\n    3892.4\n    False\n    mid\n  \n  \n    6\n    2016-01-11 06:15:00\n    2016-01-11\n    4\n    2-dhe-923\n    4\n    3291.03\n    True\n    mid\n  \n\n\n\n\n\n\n        \n\n\nThe view is optimized for readability, with column names and data types displayed in a compact format. Notice that the _row_num_ column is now part of the table stub and doesn’t steal focus from the table’s original columns.\nThe preview() function is designed to provide the head and tail (5 rows each) of the table so very large extracts won’t overflow the display.",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Data Extracts"
    ]
  },
  {
    "objectID": "user-guide/extracts.html#working-with-multiple-validation-steps",
    "href": "user-guide/extracts.html#working-with-multiple-validation-steps",
    "title": "Data Extracts",
    "section": "Working with Multiple Validation Steps",
    "text": "Working with Multiple Validation Steps\nWhen validating data with multiple steps, you can extract failing rows from any step or combine extracts from multiple steps:\n\n# Create a validation with multiple steps\nmulti_validation = (\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .col_vals_gt(columns=\"a\", value=3)                                  # Step 1\n    .col_vals_lt(columns=\"d\", value=3000)                               # Step 2\n    .col_vals_regex(columns=\"b\", pattern=\"^[0-9]-[a-z]{3}-[0-9]{3}$\")   # Step 3\n    .interrogate()\n)\n\nmulti_validation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    a\n    3\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    60.46\n    70.54\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    d\n    3000\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    90.69\n    40.31\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    b\n    ^[0-9]-[a-z]{3}-[0-9]{3}$\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\n\nExtracting Data from a Specific Step\nYou can access extracts from any specific validation step:\n\n# Get extracts from step 2 (`d &lt; 3000` validation)\nless_than_failures = multi_validation.get_data_extracts(i=2, frame=True)\n\nless_than_failures\n\n\nshape: (4, 9)_row_num_date_timedateabcdefu32datetime[μs]datei64stri64f64boolstr12016-01-04 11:00:002016-01-042\"1-bcd-345\"33423.29true\"high\"22016-01-04 00:32:002016-01-043\"5-egh-163\"89999.99true\"low\"42016-01-06 17:23:002016-01-062\"5-jdo-903\"null3892.4false\"mid\"62016-01-11 06:15:002016-01-114\"2-dhe-923\"43291.03true\"mid\"\n\n\nUsing frame=True means that returned value will be a DataFrame (not a dictionary that contains a single DataFrame).\nIf a step has no failing rows, an empty DataFrame will be returned:\n\n# Get extracts from step 3 (regex check)\nregex_failures = multi_validation.get_data_extracts(i=3, frame=True)\n\nregex_failures\n\n\nshape: (0, 9)_row_num_date_timedateabcdefu32datetime[μs]datei64stri64f64boolstr\n\n\n\n\nGetting All Extracts at Once\nTo retrieve extracts from all steps with failures in one command:\n\n# Get all extracts ()\nall_extracts = multi_validation.get_data_extracts()\n\n# Display the step numbers that have extracts\nprint(f\"Steps with data extracts: {list(all_extracts.keys())}\")\n\nSteps with data extracts: [1, 2, 3]\n\n\nA dictionary of DataFrames is returned and only steps with failures will appear in this dictionary.\n\n\nGetting Specific Extracts\nYou can also retrieve data extracts from several specified steps as a dictionary:\n\n# Get extracts from steps 1 and 2 as a dictionary\nextract_dict = multi_validation.get_data_extracts(i=[1, 2])\n\n# The keys are the step numbers\nprint(f\"Dictionary keys: {list(extract_dict.keys())}\")\n\n# Get the number of failing rows in each extract\nfor step, extract in extract_dict.items():\n    print(f\"Step {step}: {len(extract)} failing rows\")\n\nDictionary keys: [1, 2]\nStep 1: 7 failing rows\nStep 2: 4 failing rows\n\n\nNote that frame=True cannot be used when retrieving multiple extracts.",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Data Extracts"
    ]
  },
  {
    "objectID": "user-guide/extracts.html#applications-of-data-extracts",
    "href": "user-guide/extracts.html#applications-of-data-extracts",
    "title": "Data Extracts",
    "section": "Applications of Data Extracts",
    "text": "Applications of Data Extracts\nOnce you have extracted the failing data, there are numerous ways to analyze and use this information to improve data quality. Let’s explore some practical applications.\n\nFinding Patterns Across Validation Steps\nYou can analyze patterns across different validation steps by combining extracts:\n\n# Get a consolidated view of all rows that failed any validation\nall_failure_rows = set()\nfor step, extract in all_extracts.items():\n    if len(extract) &gt; 0:\n        all_failure_rows.update(extract[\"_row_num_\"])\n\nprint(f\"Total unique rows with failures: {len(all_failure_rows)}\")\nprint(f\"Row numbers with failures: {sorted(all_failure_rows)}\")\n\nTotal unique rows with failures: 8\nRow numbers with failures: [1, 2, 4, 6, 9, 10, 12, 13]\n\n\n\n\nIdentifying Rows with Multiple Failures\nYou might want to find rows that failed multiple validation checks, as these often represent more serious data quality issues:\n\n# Get row numbers from each extract\nstep1_rows = set(multi_validation.get_data_extracts(i=1, frame=True)[\"_row_num_\"])\nstep2_rows = set(multi_validation.get_data_extracts(i=2, frame=True)[\"_row_num_\"])\n\n# Find rows that failed both validations\ncommon_failures = step1_rows.intersection(step2_rows)\nprint(f\"Rows failing both step 1 and step 2: {common_failures}\")\n\nRows failing both step 1 and step 2: {1, 2, 4}\n\n\n\n\nStatistical Analysis of Failing Values\nOnce you have data extracts, you can perform statistical analysis to identify patterns in the failing data:\n\n# Get extracts from step 2\nd_value_failures = multi_validation.get_data_extracts(i=2, frame=True)\n\n# Basic statistical analysis of the failing values\nif len(d_value_failures) &gt; 0:\n    print(f\"Min failing value: {d_value_failures['d'].min()}\")\n    print(f\"Max failing value: {d_value_failures['d'].max()}\")\n    print(f\"Mean failing value: {d_value_failures['d'].mean()}\")\n\nMin failing value: 3291.03\nMax failing value: 9999.99\nMean failing value: 5151.6775\n\n\nThese analysis techniques help you thoroughly investigate data quality issues by examining failing data from multiple perspectives. Rather than treating failures as isolated incidents, you can identify patterns that might indicate systematic problems in your data pipeline.\n\n\nDetailed Analysis with col_summary_tbl()\nFor a more comprehensive view of the statistical properties of your extract data, you can use the col_summary_tbl() function:\n\n# Get extracts from step 2\nd_value_failures = multi_validation.get_data_extracts(i=2, frame=True)\n\n# Generate a comprehensive statistical summary of the failing data\npb.col_summary_tbl(d_value_failures)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows4Columns9\n  \n\n  \n  Column\n  NA\n  UQ\n  Mean\n  SD\n  Min\n  P5\n  Q1\n  Med\n  Q3\n  P95\n  Max\n  IQR\n\n\n\n  \n    \n    numeric\n    \n        \n            \n            \n                \n            \n        \n    \n\n    _row_num_UInt32\n    00\n    41\n    3.25\n    2.22\n    1\n    1.01\n    1.75\n    3\n    4.5\n    5.7\n    6\n    2.75\n  \n  \n    \n    date\n    \n        \n            \n            \n                \n            \n        \n    \n\n    date_timeDatetime(time_unit='us', time_zone=None)\n    00\n    41\n    -\n    -\n    20160104 00:32:00\n    -\n    -\n    -\n    -\n    -\n    20160111 06:15:00\n    -\n  \n  \n    \n    date\n    \n        \n            \n            \n                \n            \n        \n    \n\n    dateDate\n    00\n    30.75\n    -\n    -\n    20160104\n    -\n    -\n    -\n    -\n    -\n    20160111\n    -\n  \n  \n    \n    numeric\n    \n        \n            \n            \n                \n            \n        \n    \n\n    aInt64\n    00\n    30.75\n    2.75\n    0.96\n    2\n    2\n    2\n    2.5\n    3.25\n    3.85\n    4\n    1.25\n  \n  \n    \n    string\n    \n        \n            \n            \n                \n            \n        \n    \n\n    bString\n    00\n    41\n    9\n    0\n    9\n    9\n    9\n    9\n    9\n    9\n    9\n    0\n  \n  \n    \n    numeric\n    \n        \n            \n            \n                \n            \n        \n    \n\n    cInt64\n    10.25\n    41\n    5\n    2.65\n    3\n    3.01\n    3.5\n    4\n    6\n    7.6\n    8\n    2.5\n  \n  \n    \n    numeric\n    \n        \n            \n            \n                \n            \n        \n    \n\n    dFloat64\n    00\n    41\n    5,151.68\n    3,242.49\n    3291.03\n    3,293.01\n    3,390.22\n    3,657.85\n    5,419.3\n    9,083.85\n    9999.99\n    2,029.07\n  \n  \n    \n    boolean\n    \n        \n            \n            \n                \n            \n            \n                \n            \n            \n        \n    \n\n    eBoolean\n    00\n    T0.75F0.25\n    -\n    -\n    -\n    -\n    -\n    -\n    -\n    -\n    -\n    -\n  \n  \n    \n    string\n    \n        \n            \n            \n                \n            \n        \n    \n\n    fString\n    00\n    30.75\n    3.25\n    0.5\n    3\n    3\n    3\n    3\n    3.25\n    3.85\n    4\n    0.25\n  \n\n  \n  \n  \n    String columns statistics regard the string's length.\n  \n\n\n\n\n\n\n        \n\n\nThis statistical overview provides:\n\na count of values (including missing values)\ntype information for each column\ndistribution metrics like min, max, mean, and quartiles for numeric columns\nfrequency of common values for categorical columns\nmissing value counts and proportions\n\nUsing col_summary_tbl() on data extracts lets you quickly understand the characteristics of failing data without writing custom analysis code. This approach is particularly valuable when:\n\nYou need to understand the statistical properties of failing records\nYou want to compare distributions of failing vs passing data\nYou’re looking for anomalies or unexpected patterns within the failing rows\n\nFor example, if values failing a validation check are concentrated at certain quantiles or have an unusual distribution shape, this might indicate a systematic data collection or processing issue rather than random errors.",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Data Extracts"
    ]
  },
  {
    "objectID": "user-guide/extracts.html#using-extracts-for-data-quality-improvement",
    "href": "user-guide/extracts.html#using-extracts-for-data-quality-improvement",
    "title": "Data Extracts",
    "section": "Using Extracts for Data Quality Improvement",
    "text": "Using Extracts for Data Quality Improvement\nData extracts are especially valuable for:\n\nRoot Cause Analysis: examining the full context of failing rows to understand why they failed\nData Cleaning: creating targeted cleanup scripts that focus only on problematic records\nFeedback Loops: sharing specific examples with data providers to improve upstream quality\nPattern Recognition: identifying systemic issues by analyzing groups of failing records\n\nHere’s an example of using extracts to create a corrective action plan:\n\nimport polars as pl\n\n# Create a new sample of an extract DF\nsample_extract = pl.DataFrame({\n    \"id\": range(1, 11),\n    \"value\": [3500, 4200, 3800, 9800, 5500, 7200, 8300, 4100, 7600, 3200],\n    \"category\": [\"A\", \"B\", \"A\", \"C\", \"B\", \"A\", \"C\", \"B\", \"A\", \"B\"],\n    \"region\": [\n        \"South\", \"South\", \"North\", \"East\", \"South\",\n        \"South\", \"East\", \"South\", \"West\", \"South\"\n    ]\n})\n\n# Identify which regions have the most failures\nregion_counts = (\n    sample_extract\n    .group_by(\"region\")\n    .agg(pl.len().alias(\"failure_count\"))\n    .sort(\"failure_count\", descending=True)\n)\n\nregion_counts\n\n\nshape: (4, 2)regionfailure_countstru32\"South\"6\"East\"2\"North\"1\"West\"1\n\n\nAnalysis shows that 6 out of 10 failing records (60%) are from the \"South\" region, making it the highest priority area for data quality investigation. This suggests a potential systemic issue with data collection or processing in that specific region.",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Data Extracts"
    ]
  },
  {
    "objectID": "user-guide/extracts.html#best-practices-for-working-with-data-extracts",
    "href": "user-guide/extracts.html#best-practices-for-working-with-data-extracts",
    "title": "Data Extracts",
    "section": "Best Practices for Working with Data Extracts",
    "text": "Best Practices for Working with Data Extracts\nWhen incorporating data extracts into your data quality workflow:\n\nUse extracts for investigation, not just reporting: the real value is in the insights you gain from analyzing the problematic data\nCombine with other Pointblank features: data extracts work well with step reports and can inform threshold settings for future validations\nConsider sampling for very large datasets: if your extracts contain thousands of rows, focus your investigation on a representative sample\nLook beyond individual validation steps: cross-reference extracts from different steps to identify complex issues that span multiple validation rules\nDocument patterns in failing data: record and share insights about common failure modes to build organizational knowledge about data quality issues.\n\nBy integrating these practices into your data validation workflow, you’ll transform data extracts from simple error lists into powerful diagnostic tools. The most successful data quality initiatives treat extracts as the starting point for investigation rather than the end result of validation. When systematically analyzed and documented, patterns in failing data can reveal underlying issues in data systems, collection methods, or business processes that might otherwise remain hidden. Remember that the ultimate goal isn’t just to identify problematic records, but to use that information to implement targeted improvements that prevent similar issues from occurring in the future.",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Data Extracts"
    ]
  },
  {
    "objectID": "user-guide/extracts.html#conclusion",
    "href": "user-guide/extracts.html#conclusion",
    "title": "Data Extracts",
    "section": "Conclusion",
    "text": "Conclusion\nData extracts bridge the gap between high-level validation statistics and the detailed context needed to fix data quality issues. By providing access to the actual failing records, Pointblank enables you to:\n\npinpoint exactly which data points caused validation failures\nunderstand the full context around problematic values\ndevelop targeted strategies for data cleanup and quality improvement\ncommunicate specific examples to stakeholders\n\nWhether you’re accessing extracts through CSV downloads, the get_data_extracts() method, or step reports, this feature provides the detail needed to move from identifying problems to implementing solutions.",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Data Extracts"
    ]
  },
  {
    "objectID": "user-guide/preprocessing.html",
    "href": "user-guide/preprocessing.html",
    "title": "Preprocessing",
    "section": "",
    "text": "While the available validation methods can do a lot for you, there’s likewise a lot of things you can’t easily do with them. What if you wanted to validate that\nThese constitute more sophisticated validation requirements, yet such examinations are quite prevalent in practice. Rather than expanding our library to encompass every conceivable validation scenario (a pursuit that would yield an unwieldy and potentially infinite collection) we instead employ a more elegant approach. By transforming the table under examination through judicious preprocessing and exposing key metrics, we may subsequently employ the existing collection of validation methods. This compositional strategy affords us considerable analytical power while maintaining conceptual clarity and implementation parsimony.\nCentral to this approach is the idea of composability. Pointblank makes it easy to safely transform the target table for a given validation via the pre= argument. Any computed columns are available for the (short) lifetime of the validation step during interrogation. This composability means:\nThis compositional paradigm allows us to use data transformation effectively within our validation workflows, maintaining both flexibility and clarity in our data quality assessments.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Preprocessing"
    ]
  },
  {
    "objectID": "user-guide/preprocessing.html#transforming-data-with-lambda-functions",
    "href": "user-guide/preprocessing.html#transforming-data-with-lambda-functions",
    "title": "Preprocessing",
    "section": "Transforming Data with Lambda Functions",
    "text": "Transforming Data with Lambda Functions\nNow, through examples, let’s look at the process of performing the validations mentioned above. We’ll use the small_table dataset for all of the examples. Here it is in its entirety:\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows13Columns8\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05\n    6\n    8-kdg-938\n    3\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    None\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09\n    8\n    3-ldm-038\n    7\n    283.94\n    True\n    low\n  \n  \n    6\n    2016-01-11 06:15:00\n    2016-01-11\n    4\n    2-dhe-923\n    4\n    3291.03\n    True\n    mid\n  \n  \n    7\n    2016-01-15 18:46:00\n    2016-01-15\n    7\n    1-knw-093\n    3\n    843.34\n    True\n    high\n  \n  \n    8\n    2016-01-17 11:27:00\n    2016-01-17\n    4\n    5-boe-639\n    2\n    1035.64\n    False\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26\n    4\n    2-dmx-010\n    7\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28\n    2\n    7-dmx-010\n    8\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30\n    1\n    3-dka-303\n    None\n    2230.09\n    True\n    high\n  \n\n\n\n\n\n\n        \n\n\nIn getting to grips with the basics, we’ll try to validate that string lengths in the b column are less than 10 characters. We can’t directly use the col_vals_lt() validation method with that column because it is meant to be used with a column of numeric values. Let’s just give that method what it needs and create a column with string lengths!\nThe target table is a Polars DataFrame so we’ll provide a function that uses the Polars API to add in that numeric column:\n\nimport polars as pl\n\n# Define a preprocessing function that gets string lengths from column `b`\ndef add_string_length_column(df):\n    return df.with_columns(string_lengths=pl.col(\"b\").str.len_chars())\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"),\n        tbl_name=\"small_table\",\n        label=\"String lengths\"\n    )\n    .col_vals_lt(\n\n        # The generated column, via `pre=` (see below) ---\n        columns=\"string_lengths\",\n\n        # The string length value to be less than ---\n        value=10,\n\n        # The preprocessing function that modifies the table ---\n        pre=add_string_length_column\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    String lengthsPolarssmall_table\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    string_lengths\n    10\n    \n    \n        \n            \n            \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe validation was successfully constructed and we can see from the validation report table that all strings in b had lengths less than 10 characters. Also note that the icon under the TBL column is no longer a rightward-facing arrow, but one that is indicative of a transformation taking place.\nLet’s examine the transformation approach more closely. In the previous example, we’re not directly testing the b column itself. Instead, we’re validating the string_lengths column that was generated by the lambda function provided to pre=. The Polars API’s with_columns() method does the heavy lifting, creating numerical values that represent each string’s length in the original column.\nThat transformation occurs only during interrogation and only for that validation step. Any prior or subsequent steps would normally use the as-provided small_table. Having the possibility for data transformation being isolated at the step level means that you don’t have to generate separate validation plans for each form of the data, you’re free to fluidly transform the target table as necessary for perform validations on different representations of the data.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Preprocessing"
    ]
  },
  {
    "objectID": "user-guide/preprocessing.html#using-custom-functions-for-preprocessing",
    "href": "user-guide/preprocessing.html#using-custom-functions-for-preprocessing",
    "title": "Preprocessing",
    "section": "Using Custom Functions for Preprocessing",
    "text": "Using Custom Functions for Preprocessing\nWhile lambda functions work well for simple transformations, custom named functions can make your validation code more organized and reusable, especially for complex preprocessing logic. Let’s implement the same string length validation using a dedicated function:\n\ndef add_string_lengths(df):\n    # This generates string length from a column `b`; the new column with\n    # the values is called `string_lengths` (will be placed as the last column)\n    return df.with_columns(string_lengths=pl.col(\"b\").str.len_chars())\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"),\n        tbl_name=\"small_table\",\n        label=\"String lengths for column `b`.\"\n    )\n    .col_vals_lt(\n\n        # Use of a column selector function to select the last column ---\n        columns=pb.last_n(1),\n\n        # The string length to be less than ---\n        value=10,\n\n        # Custom function for generating string lengths in a new column ---\n        pre=add_string_lengths\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    String lengths for column `b`.Polarssmall_table\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    string_lengths\n    10\n    \n    \n        \n            \n            \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe column-generating logic was placed in the add_string_lengths() function, which is then passed to pre=. Notice we’re using pb.last_n(1) in the columns parameter. This is a convenient column selector that targets the last column in the DataFrame, which in our case is the newly created string_lengths column. This saves us from having to explicitly write out the column name, making our code more adaptable if column names change. Despite not specifying the name directly, you’ll still see the actual column name (string_lengths) displayed in the validation report.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Preprocessing"
    ]
  },
  {
    "objectID": "user-guide/preprocessing.html#creating-parameterized-preprocessing-functions",
    "href": "user-guide/preprocessing.html#creating-parameterized-preprocessing-functions",
    "title": "Preprocessing",
    "section": "Creating Parameterized Preprocessing Functions",
    "text": "Creating Parameterized Preprocessing Functions\nSo far we’ve used simple functions and lambdas, but sometimes you may want to create more flexible preprocessing functions that can be configured with parameters. Let’s create a reusable function that can calculate string lengths for any column:\n\ndef string_length_calculator(column_name):\n    \"\"\"Returns a preprocessing function that calculates string lengths for the specified column.\"\"\"\n    def preprocessor(df):\n        return df.with_columns(string_lengths=pl.col(column_name).str.len_chars())\n    return preprocessor\n\n# Validate string lengths in column b\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"),\n        tbl_name=\"small_table\",\n        label=\"String lengths for column `b`.\"\n    )\n    .col_vals_lt(\n        columns=pb.last_n(1),\n        value=10,\n        pre=string_length_calculator(column_name=\"b\")\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    String lengths for column `b`.Polarssmall_table\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    string_lengths\n    10\n    \n    \n        \n            \n            \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThis pattern is called a function factory, which is a function that creates and returns another function. The outer function (string_length_calculator()) accepts parameters that customize the behavior of the returned preprocessing function. The inner function (preprocessor()) is what actually gets called during validation.\nThis approach offers several benefits as it:\n\ncreates reusable, configurable preprocessing functions\nkeeps your validation code DRY\nallows you to separate configuration from implementation\nenables easy application of the same transformation to different columns\n\nYou could extend this pattern to create even more sophisticated preprocessing functions with multiple parameters, default values, and complex logic.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Preprocessing"
    ]
  },
  {
    "objectID": "user-guide/preprocessing.html#using-narwhals-to-preprocess-many-types-of-dataframes",
    "href": "user-guide/preprocessing.html#using-narwhals-to-preprocess-many-types-of-dataframes",
    "title": "Preprocessing",
    "section": "Using Narwhals to Preprocess Many Types of DataFrames",
    "text": "Using Narwhals to Preprocess Many Types of DataFrames\nIn this previous example we used a Polars table. You might have a situation where you perform data validation variously on Pandas and Polars DataFrames. This is where Narwhals becomes handy: it provides a single, consistent API that works across multiple DataFrame types, eliminating the need to learn and switch between different APIs depending on your data source.\nLet’s obtain small_table as a Pandas DataFrame. We’ll construct a validation step to verify that the median of column c is greater than the median in column a.\n\nimport narwhals as nw\n\n# Define preprocessing function using Narwhals for cross-backend compatibility\ndef get_median_columns_c_and_a(df):\n    return nw.from_native(df).select(nw.median(\"c\"), nw.median(\"a\"))\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"pandas\"),\n        tbl_name=\"small_table\",\n        label=\"Median comparison.\",\n    )\n    .col_vals_gt(\n        columns=\"c\",\n        value=pb.col(\"a\"),\n\n        # Using Narwhals to modify the table; generates table with columns `c` and `a` ---\n        pre=get_median_columns_c_and_a\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Median comparison.Pandassmall_table\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    c\n    a\n    \n    \n        \n            \n            \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe goal is to check that the median value of c is greater than the corresponding median of column a, which we set up through the columns= and value= parameters in the col_vals_gt() method.\nThere’s a bit to unpack here so let’s look at at the lambda function first. Narwhals can translate a Pandas DataFrame to a Narwhals DataFrame with its from_native() function. After that initiating step, you’re free to use the Narwhals API (which is modeled on a subset of the Polars API) to do the necessary data transformation. In this case, we are getting the medians of the c and a columns and ending up with a one-row, two-column table.\nWe should note that the transformed table is, perhaps surprisingly, a Narwhals DataFrame (we didn’t have to go back to a Pandas DataFrame by using .to_native()). Pointblank is able to work directly with the Narwhals DataFrame for validation purposes, which makes the workflow more concise.\nOne more thing to note: Pointblank provides a convenient syntactic sugar for working with Narwhals. If you name the lambda parameter dfn instead of df, the system automatically applies nw.from_native() to the input DataFrame first. This lets you write more concise code without having to explicitly convert the DataFrame to a Narwhals format.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Preprocessing"
    ]
  },
  {
    "objectID": "user-guide/preprocessing.html#swapping-in-a-totally-different-dataframe",
    "href": "user-guide/preprocessing.html#swapping-in-a-totally-different-dataframe",
    "title": "Preprocessing",
    "section": "Swapping in a Totally Different DataFrame",
    "text": "Swapping in a Totally Different DataFrame\nSometimes data validation requires looking at completely transformed versions of your data (such as aggregated summaries, pivoted views, or even reference tables). While this approach goes against the typical paradigm of validating a single target table, there are legitimate use cases where you might need to validate properties that only emerge after significant transformations.\nLet’s now try to prepare the final validation scenario, checking that there are at least three instances of every categorical value in column f (which contains string values in the set of \"low\", \"mid\", and \"high\"). This time, we’ll prepare the transformed table (transformed by Polars expressions) outside of the Pointblank code.\n\ndata_original = pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\")\ndata_transformed = data_original.group_by(\"f\").len(name=\"n\")\n\ndata_transformed\n\n\nshape: (3, 2)fnstru32\"low\"5\"high\"6\"mid\"2\n\n\nThen, we’ll plug in the data_transformed DataFrame with a preprocessing function:\n\n# Define preprocessing function to use the transformed data\ndef use_transformed_data(df):\n    return data_transformed\n\n(\n    pb.Validate(\n        data=data_original,\n        tbl_name=\"small_table\",\n        label=\"Category counts.\",\n    )\n    .col_vals_ge(\n        columns=\"n\",\n        value=3,\n        pre=use_transformed_data\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Category counts.Polarssmall_table\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_ge\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_ge()\n        \n        \n        \n    n\n    3\n    \n    \n        \n            \n            \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    20.67\n    10.33\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nWe can see from the validation report table that there are three test units. This corresponds to a row for each of the categorical value counts. From the report, we find that two of the three test units are passing test units (turns out there are only two instances of \"mid\" in column f).\nNote that the swapped-in table can be any table type that Pointblank supports, like a Polars DataFrame (as shown here), a Pandas DataFrame, a Narwhals DataFrame, or any other compatible format. This flexibility allows you to validate properties of your data that might only be apparent after significant reshaping or aggregation.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Preprocessing"
    ]
  },
  {
    "objectID": "user-guide/preprocessing.html#conclusion",
    "href": "user-guide/preprocessing.html#conclusion",
    "title": "Preprocessing",
    "section": "Conclusion",
    "text": "Conclusion\nThe preprocessing capabilities in Pointblank provide the power and flexibility for validating complex data properties beyond what’s directly possible with the standard validation methods. Through the pre= parameter, you can:\n\ntransform your data on-the-fly with computed columns\ngenerate aggregated metrics to validate statistical properties\nwork seamlessly across different DataFrame types using Narwhals\nswap in completely different tables when validating properties that emerge only after transformation\n\nBy combining these preprocessing techniques with Pointblank’s validation methods, you can create comprehensive data quality checks that address virtually any validation scenario without needing an endless library of specialized validation functions. This composable approach keeps your validation code concise while allowing you to verify even the most complex data quality requirements.\nRemember that preprocessing happens just for the specific validation step, keeping your validation plan organized and maintaining the integrity of your original data throughout the rest of the validation process.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Preprocessing"
    ]
  },
  {
    "objectID": "user-guide/installation.html",
    "href": "user-guide/installation.html",
    "title": "Installation",
    "section": "",
    "text": "Pointblank can be installed using various package managers. The base installation gives you the core validation functionality, with optional dependencies for working with different data sources.",
    "crumbs": [
      "Get Started",
      "Installation"
    ]
  },
  {
    "objectID": "user-guide/installation.html#basic-installation",
    "href": "user-guide/installation.html#basic-installation",
    "title": "Installation",
    "section": "Basic Installation",
    "text": "Basic Installation\nYou can install Pointblank using your preferred package manager:\n\npipuvcondapixi\n\n\npip install pointblank\n\n\nuv pip install pointblank\n\n\nconda install -c conda-forge pointblank\n\n\n# add pointblank to project\npixi init name-of-project\ncd name-of-project\npixi add pointblank",
    "crumbs": [
      "Get Started",
      "Installation"
    ]
  },
  {
    "objectID": "user-guide/installation.html#dataframe-libraries",
    "href": "user-guide/installation.html#dataframe-libraries",
    "title": "Installation",
    "section": "DataFrame Libraries",
    "text": "DataFrame Libraries\nPointblank requires a DataFrame library but doesn’t include one by default, giving you the flexibility to choose either Pandas or Polars:\n\nPolarsPandas\n\n\n# Using pip\npip install pointblank[pl]\n\n# Or manually\npip install polars&gt;=1.24.0\n\n\n# Using pip\npip install pointblank[pd]\n\n# Or manually\npip install pandas&gt;=2.2.3\n\n\n\nPointblank works seamlessly with both libraries, and you can choose the one that best fits your workflow and performance requirements.",
    "crumbs": [
      "Get Started",
      "Installation"
    ]
  },
  {
    "objectID": "user-guide/installation.html#optional-dependencies",
    "href": "user-guide/installation.html#optional-dependencies",
    "title": "Installation",
    "section": "Optional Dependencies",
    "text": "Optional Dependencies\n\nIbis Backends\nTo work with various database systems through Ibis, you can install additional backends:\n\npipuvcondapixi\n\n\npip install pointblank[sqlite]      # SQLite\npip install pointblank[duckdb]      # DuckDB\npip install pointblank[postgres]    # PostgreSQL\npip install pointblank[mysql]       # MySQL\npip install pointblank[mssql]       # Microsoft SQL Server\npip install pointblank[bigquery]    # BigQuery\npip install pointblank[pyspark]     # Apache Spark\npip install pointblank[databricks]  # Databricks\npip install pointblank[snowflake]   # Snowflake\n\n# Example of installing multiple backends\npip install pointblank[duckdb,postgres,sqlite]\n\n\nuv pip install pointblank[sqlite]      # SQLite\nuv pip install pointblank[duckdb]      # DuckDB\nuv pip install pointblank[postgres]    # PostgreSQL\nuv pip install pointblank[mysql]       # MySQL\nuv pip install pointblank[mssql]       # Microsoft SQL Server\nuv pip install pointblank[bigquery]    # BigQuery\nuv pip install pointblank[pyspark]     # Apache Spark\nuv pip install pointblank[databricks]  # Databricks\nuv pip install pointblank[snowflake]   # Snowflake\n\n# Example of installing multiple backends\nuv pip install pointblank[duckdb,postgres,sqlite]\n\n\nconda install -c conda-forge pointblank-sqlite      # SQLite\nconda install -c conda-forge pointblank-duckdb      # DuckDB\nconda install -c conda-forge pointblank-postgres    # PostgreSQL\nconda install -c conda-forge pointblank-mysql       # MySQL\nconda install -c conda-forge pointblank-mssql       # Microsoft SQL Server\nconda install -c conda-forge pointblank-bigquery    # BigQuery\nconda install -c conda-forge pointblank-pyspark     # Apache Spark\nconda install -c conda-forge pointblank-databricks  # Databricks\nconda install -c conda-forge pointblank-snowflake   # Snowflake\n\n# Example of installing multiple backends\nconda install -c conda-forge pointblank-duckdb pointblank-postgres pointblank-sqlite\n\n\npixi add pointblank-sqlite      # SQLite\npixi add pointblank-duckdb      # DuckDB\npixi add pointblank-postgres    # PostgreSQL\npixi add pointblank-mysql       # MySQL\npixi add pointblank-mssql       # Microsoft SQL Server\npixi add pointblank-bigquery    # BigQuery\npixi add pointblank-pyspark     # Apache Spark\npixi add pointblank-databricks  # Databricks\npixi add pointblank-snowflake   # Snowflake\n\n# Example of installing multiple backends\npixi add pointblank-duckdb pointblank-postgres pointblank-sqlite\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nEven when using exclusively Ibis backends, you still need either Pandas or Polars installed since Pointblank’s reporting functionality (powered by Great Tables) requires a DataFrame library for rendering tabular reporting results.\n\n\n\n\nAI-Assisted Validation (Experimental)\nPointblank includes experimental support for AI-assisted validation plan generation:\npip install pointblank[generate]\nThis installs the necessary dependencies for working with LLM providers to help generate validation plans. See the Draft Validation article for how to create validation plans from existing data.\n\n\nDevelopment Version\nIf you want the latest development version with the newest features, you can install directly from GitHub:\npip install git+https://github.com/posit-dev/pointblank.git",
    "crumbs": [
      "Get Started",
      "Installation"
    ]
  },
  {
    "objectID": "user-guide/installation.html#verifying-your-installation",
    "href": "user-guide/installation.html#verifying-your-installation",
    "title": "Installation",
    "section": "Verifying Your Installation",
    "text": "Verifying Your Installation\nYou can verify your installation by importing Pointblank and checking the version:\nimport pointblank as pb\nprint(pb.__version__)",
    "crumbs": [
      "Get Started",
      "Installation"
    ]
  },
  {
    "objectID": "user-guide/installation.html#system-requirements",
    "href": "user-guide/installation.html#system-requirements",
    "title": "Installation",
    "section": "System Requirements",
    "text": "System Requirements\n\nPython 3.10 or higher\na supported DataFrame library (Pandas or Polars)\noptional: Ibis (for database connectivity)",
    "crumbs": [
      "Get Started",
      "Installation"
    ]
  },
  {
    "objectID": "user-guide/installation.html#next-steps",
    "href": "user-guide/installation.html#next-steps",
    "title": "Installation",
    "section": "Next Steps",
    "text": "Next Steps\nNow that you’ve installed Pointblank, you’re ready to start validating your data. If you haven’t read the Introduction yet, consider starting there to learn the basic concepts.\nIf you encounter any installation issues, please open an issue on GitHub with details about your system and the specific error messages you’re seeing. The maintainers actively monitor these issues and can help troubleshoot problems.\nFor a quick test of your installation, try running a simple validation:\nimport pointblank as pb\n\n# Load a small dataset\ndata = pb.load_dataset(\"small_table\")\n\n# Create a simple validation\nvalidation = (\n    pb.Validate(data=data)\n    .col_exists(columns=[\"a\", \"b\", \"c\"])\n    .interrogate()\n)\n\n# Display the validation results\nvalidation",
    "crumbs": [
      "Get Started",
      "Installation"
    ]
  },
  {
    "objectID": "user-guide/installation.html#command-line-interface",
    "href": "user-guide/installation.html#command-line-interface",
    "title": "Installation",
    "section": "Command Line Interface",
    "text": "Command Line Interface\nOnce installed, Pointblank also provides a powerful command-line interface for quick data validation tasks:\n# Test the CLI with a built-in dataset\npb validate small_table --check rows-distinct\n\n# Check if a column exists\npb validate small_table --check col-exists --column a\n\n# Validate data ranges\npb validate small_table --check col-vals-lt --column a --value 10\nThe CLI is perfect for:\n\nquick data quality checks in CI/CD pipelines\nexploratory data analysis from the terminal\nintegration with shell scripts and automation workflows\n\n\n\n\n\n\n\nTipSee the CLI in Action\n\n\n\nWatch our interactive CLI demonstrations to see these commands executing in real-time with actual output formatting.\n\n\nLearn more about the CLI capabilities in the Command Line Interface guide.",
    "crumbs": [
      "Get Started",
      "Installation"
    ]
  },
  {
    "objectID": "user-guide/cli-data-validation.html",
    "href": "user-guide/cli-data-validation.html",
    "title": "Data Validation",
    "section": "",
    "text": "Validating data directly in the terminal with the Pointblank CLI offers a fast, scriptable, and repeatable way to check your data. This approach is especially useful for quick checks, CI/CD pipelines, and automation workflows, where you want immediate feedback and clear pass/fail results.\nThe CLI commands are designed for efficiency: you can run validations with a single line, integrate them easily into shell scripts or data pipelines, and benefit from clear, color-coded output that’s easy to interpret at a glance.\nThe pb validate command lets you perform common validation checks directly on your data source with a simple command-line interface. This works well both for quick, one-off checks and for use in automated pipelines.\nFor more complex validation logic, the pb run command serves as a runner for validation scripts written with the Pointblank Python API, allowing you to execute custom validation workflows from the command line.",
    "crumbs": [
      "Get Started",
      "The Pointblank CLI",
      "Data Validation"
    ]
  },
  {
    "objectID": "user-guide/cli-data-validation.html#pb-validate-quick-one-line-data-checks",
    "href": "user-guide/cli-data-validation.html#pb-validate-quick-one-line-data-checks",
    "title": "Data Validation",
    "section": "pb validate: Quick, One-Line Data Checks",
    "text": "pb validate: Quick, One-Line Data Checks\nThe pb validate command is your go-to for running common validation checks directly on your data source. It’s perfect for quick, one-off checks or for use in automated pipelines. You specify exactly which check you want to run using the --check option, making your intent clear and your validation explicit.\nHere’s how you construct a validation command:\npb validate worldcities.csv --check &lt;check-name&gt; [other options]\nYou always provide the data source first, then specify one or more checks with --check. Each check can have its own options, such as --column or --value, depending on what you want to validate.\n\nChecking for Duplicate and Complete Rows\nTo check for duplicate rows, use the rows-distinct check:\npb validate worldcities.csv --check rows-distinct\n\nThe output shows you whether your data contains any duplicate rows, how many rows were checked, and if any duplicates were found. The color-coding of the results helps you quickly interpret the results, using green for pass and red for fail. Here, no duplicate rows were detected out of the 41K rows checked.\nTo check that every row is complete (i.e., no missing values in any column), use the rows-complete check:\npb validate worldcities.csv --check rows-complete\n\nWith this check we see that the worldcities.csv dataset has 739 rows containing at least one Null/missing value. And with any dataset, it’s easy to quickly spot if there are any rows with missing data using this command.\n\n\nChecking for Nulls and Value Ranges\nYou can easily check for missing values in a column, or ensure that values fall within a certain range. Here’s how to check that all values in the population column are not null:\npb validate worldcities.csv --check col-vals-not-null --column city_name\n\nPerhaps surprisingly, we find that one row has a missing city name.\nLet’s now check whether all values in the population column are greater than zero:\npb validate worldcities.csv --check col-vals-gt --column population --value 0\n\nWith that we find that there are 741 rows where the population value is not greater than 0 (note that this check also fails when cells are null or missing).\n\n\nMultiple Checks in One Command\nYou can chain several checks together in a single command. This is handy for comprehensive data quality checks:\npb validate worldcities.csv --check rows-distinct --check col-vals-not-null --column city_name --check col-vals-gt --column population --value 0\n\nEach check is shown one after the other in the terminal output, so you can review the result of each validation step individually as the command proceeds.\n\n\nSeeing and Saving Failing Rows\nIf a check fails, you might want to see which rows caused the failure. Use the --show-extract option to display failing rows right in the terminal:\npb validate worldcities.csv --check rows-complete --show-extract\n\nOr, save the failing rows to a CSV file for further investigation:\npb validate worldcities.csv --check rows-complete --show-extract --write-extract incomplete_failing_rows\n\nNote here in the output the additional lines stating that failing rows were saved to a folder (incomplete_failing_rows) and, within that folder the step_01_rows_complete.csv file was written. Using a folder for extracts is necessary in practice since there may be multiple validations defined in a pb validate command.\n\n\nAdvanced Options and CI/CD Integration\n\nuse --exit-code to make the command exit with a non-zero code if any check fails; useful for CI/CD pipelines\nuse --limit to control how many failing rows are shown or saved\nuse --list-checks to see all available validation checks and their options\n\npb validate worldcities.csv --check col-vals-not-null --column city_name --exit-code",
    "crumbs": [
      "Get Started",
      "The Pointblank CLI",
      "Data Validation"
    ]
  },
  {
    "objectID": "user-guide/cli-data-validation.html#pb-run-custom-validation-workflows-with-python",
    "href": "user-guide/cli-data-validation.html#pb-run-custom-validation-workflows-with-python",
    "title": "Data Validation",
    "section": "pb run: Custom Validation Workflows with Python",
    "text": "pb run: Custom Validation Workflows with Python\nFor more complex validation logic, use the pb run command. This lets you execute a Python script containing Pointblank validation steps, combining the flexibility of the Python API with the convenience of the CLI.\nYou can always scaffold a template script using the pb make-template command:\npb make-template my_validation.py\n\nBut for our example, we’ll elect to make our own worldcities_validation.py file from scratch. It will:\n\nuse the worldcities.csv file\napply two thresholds (one for ‘warning’, another for ‘error’)\nhave six validation steps\n\nHere’s what it looks like:\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(\n        data=\"worldcities.csv\",\n        thresholds=pb.Thresholds(\n            warning=1,  # 1 failure\n            error=0.05,  # 5% of rows failing\n        ),\n    )\n    .col_schema_match(\n        schema=pb.Schema(\n            columns=[\n                (\"city_name\", \"object\"),\n                (\"latitude\", \"float64\"),\n                (\"longitude\", \"float64\"),\n                (\"country\", \"object\"),\n                (\"population\", \"float64\"),\n            ]\n        ),\n    )\n    .col_vals_not_null(columns=\"city_name\")\n    .col_vals_not_null(columns=\"population\")\n    .col_vals_gt(columns=\"population\", value=0, na_pass=True)\n    .col_vals_between(columns=\"latitude\", left=-90, right=90)\n    .col_vals_between(columns=\"longitude\", left=-180, right=180)\n    .interrogate()\n)\nNow, we’ll run the .py script from the terminal:\npb run worldcities_validation.py\n\nYou’ll see a summary table that lists all of the steps and their results and you can include as many steps and as much logic as you need.\n\nOutput Options\nYou could save the validation report as HTML or JSON (or both) for the purposes of sharing or for automation:\npb run worldcities_validation.py --output-html report.html --output-json report.json\n\nThere are also the options to produce extracts (subset of failing rows) with --show-extract or --write-extract (just like with pb validate). Let’s do both in the following example:\npb run worldcities_validation.py --show-extract --write-extract worldcities_failures\n\nThis shows a preview of each extract for those validation steps where extracts were produced (steps 2, 3, and 4). Individual CSV files with extracted rows for those steps were written to the worldcities_failures directory.\n\n\nControlling Failure Behavior\nIt’s possible to use the --fail-on option to control when the command should exit with an error, based on the severity of validation failures. This is especially useful for automated workflows and CI/CD pipelines.\nLet’s try that with our worldcities_validation.py validation, which we’ve seen exeeds the ‘warning’ in steps 2, 3, and 4:\npb run worldcities_validation.py --fail-on warning\n\nNotice the final line states Exiting with error due to warning, error, or critical validation failures. Because we applied --fail-on warning, any presence of `warning’ (or higher levels such as ‘error’ or ‘critical’) will yield a non-zero exit code that should stop a pipeline process. We can prove this by running the following lines in the terminal\npb run worldcities_validation.py --fail-on warning &gt; /dev/null 2&gt;&1\necho $?\nwhich returns 1.",
    "crumbs": [
      "Get Started",
      "The Pointblank CLI",
      "Data Validation"
    ]
  },
  {
    "objectID": "user-guide/cli-data-validation.html#wrapping-up",
    "href": "user-guide/cli-data-validation.html#wrapping-up",
    "title": "Data Validation",
    "section": "Wrapping Up",
    "text": "Wrapping Up\nPointblank’s CLI gives you powerful tools for validating your data, whether you need a quick check or a custom workflow. Use pb validate for fast, one-liner checks and pb run for more advanced, scriptable validation logic. With clear output and flexible options, you can catch data issues early and keep your workflows running smoothly.",
    "crumbs": [
      "Get Started",
      "The Pointblank CLI",
      "Data Validation"
    ]
  },
  {
    "objectID": "user-guide/preview.html",
    "href": "user-guide/preview.html",
    "title": "Previewing Data",
    "section": "",
    "text": "In many cases, it’s good to look at your data tables. Before validating a table, you’ll likely want to inspect a portion of it before diving into the creation of data-quality rules. This is pretty easily done with Polars and Pandas DataFrames, however, it’s not as easy with database tables and each table backend displays things differently.\nTo make this common task a little better, you can use the preview() function in Pointblank. It has been designed to work with every table that the package supports (i.e., DataFrames and Ibis-backend tables, the latter of which are largely database tables). Plus, what’s shown in the output is consistent, no matter what type of data you’re looking at.",
    "crumbs": [
      "Get Started",
      "Data Inspection",
      "Previewing Data"
    ]
  },
  {
    "objectID": "user-guide/preview.html#viewing-a-table-with-preview",
    "href": "user-guide/preview.html#viewing-a-table-with-preview",
    "title": "Previewing Data",
    "section": "Viewing a Table with preview()",
    "text": "Viewing a Table with preview()\nLet’s look at how preview() works. It requires only a table and, for this first example, let’s use the nycflights dataset:\n\nimport pointblank as pb\n\nnycflights = pb.load_dataset(dataset=\"nycflights\", tbl_type=\"polars\")\n\npb.preview(nycflights)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows336,776Columns18\n  \n\n  \n  yearInt64\n  monthInt64\n  dayInt64\n  dep_timeInt64\n  sched_dep_timeInt64\n  dep_delayInt64\n  arr_timeInt64\n  sched_arr_timeInt64\n  arr_delayInt64\n  carrierString\n  flightInt64\n  tailnumString\n  originString\n  destString\n  air_timeInt64\n  distanceInt64\n  hourInt64\n  minuteInt64\n\n\n\n  \n    1\n    2013\n    1\n    1\n    517\n    515\n    2\n    830\n    819\n    11\n    UA\n    1545\n    N14228\n    EWR\n    IAH\n    227\n    1400\n    5\n    15\n  \n  \n    2\n    2013\n    1\n    1\n    533\n    529\n    4\n    850\n    830\n    20\n    UA\n    1714\n    N24211\n    LGA\n    IAH\n    227\n    1416\n    5\n    29\n  \n  \n    3\n    2013\n    1\n    1\n    542\n    540\n    2\n    923\n    850\n    33\n    AA\n    1141\n    N619AA\n    JFK\n    MIA\n    160\n    1089\n    5\n    40\n  \n  \n    4\n    2013\n    1\n    1\n    544\n    545\n    -1\n    1004\n    1022\n    -18\n    B6\n    725\n    N804JB\n    JFK\n    BQN\n    183\n    1576\n    5\n    45\n  \n  \n    5\n    2013\n    1\n    1\n    554\n    600\n    -6\n    812\n    837\n    -25\n    DL\n    461\n    N668DN\n    LGA\n    ATL\n    116\n    762\n    6\n    0\n  \n  \n    336772\n    2013\n    9\n    30\n    None\n    1455\n    None\n    None\n    1634\n    None\n    9E\n    3393\n    None\n    JFK\n    DCA\n    None\n    213\n    14\n    55\n  \n  \n    336773\n    2013\n    9\n    30\n    None\n    2200\n    None\n    None\n    2312\n    None\n    9E\n    3525\n    None\n    LGA\n    SYR\n    None\n    198\n    22\n    0\n  \n  \n    336774\n    2013\n    9\n    30\n    None\n    1210\n    None\n    None\n    1330\n    None\n    MQ\n    3461\n    N535MQ\n    LGA\n    BNA\n    None\n    764\n    12\n    10\n  \n  \n    336775\n    2013\n    9\n    30\n    None\n    1159\n    None\n    None\n    1344\n    None\n    MQ\n    3572\n    N511MQ\n    LGA\n    CLE\n    None\n    419\n    11\n    59\n  \n  \n    336776\n    2013\n    9\n    30\n    None\n    840\n    None\n    None\n    1020\n    None\n    MQ\n    3531\n    N839MQ\n    LGA\n    RDU\n    None\n    431\n    8\n    40\n  \n\n\n\n\n\n\n        \n\n\nThis is an HTML table using the style of the other reporting tables in the library. The header is more minimal here, only showing the type of table we’re looking at (POLARS in this case) along with the table dimensions. The column headers provide both the column names and the column data types.\nBy default, we’re getting the first five rows and the last five rows. Row numbers (from the original dataset) provide an indication of which rows are the head and tail rows. The blue lines provide additional demarcation of the column containing the row numbers and the head and tail row groups. Finally, any cells with missing values are prominently styled with red lettering and a lighter red background.\nIf you’d rather not see the row numbers in the table, you can use the show_row_numbers=False option. Let’s try that with the game_revenue dataset as a DuckDB table:\n\ngame_revenue = pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"duckdb\")\n\npb.preview(game_revenue, show_row_numbers=False)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    DuckDBRows2,000Columns11\n  \n\n  player_idstring\n  session_idstring\n  session_starttimestamp\n  timetimestamp\n  item_typestring\n  item_namestring\n  item_revenuefloat64\n  session_durationfloat64\n  start_daydate\n  acquisitionstring\n  countrystring\n\n\n\n  \n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:31:27+00:00\n    iap\n    offer2\n    8.99\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:36:57+00:00\n    iap\n    gems3\n    22.49\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:37:45+00:00\n    iap\n    gold7\n    107.99\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:42:33+00:00\n    ad\n    ad_20sec\n    0.76\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-hdu9jkls\n    2015-01-01 11:50:02+00:00\n    2015-01-01 11:55:20+00:00\n    ad\n    ad_5sec\n    0.03\n    35.2\n    2015-01-01\n    google\n    Germany\n  \n  \n    NAOJRDMCSEBI281\n    NAOJRDMCSEBI281-j2vs9ilp\n    2015-01-21 01:57:50+00:00\n    2015-01-21 02:02:50+00:00\n    ad\n    ad_survey\n    1.332\n    25.8\n    2015-01-11\n    organic\n    Norway\n  \n  \n    NAOJRDMCSEBI281\n    NAOJRDMCSEBI281-j2vs9ilp\n    2015-01-21 01:57:50+00:00\n    2015-01-21 02:22:14+00:00\n    ad\n    ad_survey\n    1.35\n    25.8\n    2015-01-11\n    organic\n    Norway\n  \n  \n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-vbhcsmtr\n    2015-01-21 02:39:48+00:00\n    2015-01-21 02:40:00+00:00\n    ad\n    ad_5sec\n    0.03\n    8.4\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-vbhcsmtr\n    2015-01-21 02:39:48+00:00\n    2015-01-21 02:47:12+00:00\n    iap\n    offer5\n    26.09\n    8.4\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    GJCXNTWEBIPQ369\n    GJCXNTWEBIPQ369-9elq67md\n    2015-01-21 03:59:23+00:00\n    2015-01-21 04:06:29+00:00\n    ad\n    ad_5sec\n    0.12\n    18.5\n    2015-01-14\n    organic\n    United States\n  \n\n\n\n\n\n\n        \n\n\nWith the above preview, the row numbers are gone. The horizontal blue line still serves to divide the top and bottom rows of the table, however.",
    "crumbs": [
      "Get Started",
      "Data Inspection",
      "Previewing Data"
    ]
  },
  {
    "objectID": "user-guide/preview.html#adjusting-the-number-of-rows-shown",
    "href": "user-guide/preview.html#adjusting-the-number-of-rows-shown",
    "title": "Previewing Data",
    "section": "Adjusting the Number of Rows Shown",
    "text": "Adjusting the Number of Rows Shown\nIt could be that displaying the five top and bottom rows is not preferred. This can be changed with the n_head= and n_tail=. Maybe, you want three from the top along with the last row? Let’s try that out with the small_table dataset as a Pandas DataFrame:\n\nsmall_table = pb.load_dataset(dataset=\"small_table\", tbl_type=\"pandas\")\n\npb.preview(small_table, n_head=3, n_tail=1)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PandasRows13Columns8\n  \n\n  \n  date_timedatetime64[ns]\n  datedatetime64[ns]\n  aint64\n  bobject\n  cfloat64\n  dfloat64\n  ebool\n  fobject\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04 00:00:00\n    2\n    1-bcd-345\n    3.0\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04 00:00:00\n    3\n    5-egh-163\n    8.0\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05 00:00:00\n    6\n    8-kdg-938\n    3.0\n    2343.23\n    True\n    high\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30 00:00:00\n    1\n    3-dka-303\n    NA\n    2230.09\n    True\n    high\n  \n\n\n\n\n\n\n        \n\n\nIf you’re looking at a small table and want to see the entirety of it, you can enlarge the n_head= and n_tail= values:\n\nsmall_table = pb.load_dataset(dataset=\"small_table\", tbl_type=\"pandas\")\n\npb.preview(small_table, n_head=10, n_tail=10)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PandasRows13Columns8\n  \n\n  \n  date_timedatetime64[ns]\n  datedatetime64[ns]\n  aint64\n  bobject\n  cfloat64\n  dfloat64\n  ebool\n  fobject\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04 00:00:00\n    2\n    1-bcd-345\n    3.0\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04 00:00:00\n    3\n    5-egh-163\n    8.0\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05 00:00:00\n    6\n    8-kdg-938\n    3.0\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06 00:00:00\n    2\n    5-jdo-903\n    NA\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09 00:00:00\n    8\n    3-ldm-038\n    7.0\n    283.94\n    True\n    low\n  \n  \n    6\n    2016-01-11 06:15:00\n    2016-01-11 00:00:00\n    4\n    2-dhe-923\n    4.0\n    3291.03\n    True\n    mid\n  \n  \n    7\n    2016-01-15 18:46:00\n    2016-01-15 00:00:00\n    7\n    1-knw-093\n    3.0\n    843.34\n    True\n    high\n  \n  \n    8\n    2016-01-17 11:27:00\n    2016-01-17 00:00:00\n    4\n    5-boe-639\n    2.0\n    1035.64\n    False\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20 00:00:00\n    3\n    5-bce-642\n    9.0\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20 00:00:00\n    3\n    5-bce-642\n    9.0\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26 00:00:00\n    4\n    2-dmx-010\n    7.0\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28 00:00:00\n    2\n    7-dmx-010\n    8.0\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30 00:00:00\n    1\n    3-dka-303\n    NA\n    2230.09\n    True\n    high\n  \n\n\n\n\n\n\n        \n\n\nGiven that the table has 13 rows, asking for 20 rows to be displayed effectively shows the entire table.",
    "crumbs": [
      "Get Started",
      "Data Inspection",
      "Previewing Data"
    ]
  },
  {
    "objectID": "user-guide/preview.html#previewing-a-subset-of-columns",
    "href": "user-guide/preview.html#previewing-a-subset-of-columns",
    "title": "Previewing Data",
    "section": "Previewing a Subset of Columns",
    "text": "Previewing a Subset of Columns\nThe preview scales well to tables that have many columns by allowing for a horizontal scroll. However, previewing data from all columns can be impractical if you’re only concerned with a key set of them. To preview only a subset of a table’s columns, we can use the columns_subset= argument. Let’s do this with the nycflights dataset and provide a list of six columns from that table.\n\npb.preview(\n    nycflights,\n    columns_subset=[\"hour\", \"minute\", \"sched_dep_time\", \"year\", \"month\", \"day\"]\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows336,776Columns18\n  \n\n  \n  hourInt64\n  minuteInt64\n  sched_dep_timeInt64\n  yearInt64\n  monthInt64\n  dayInt64\n\n\n\n  \n    1\n    5\n    15\n    515\n    2013\n    1\n    1\n  \n  \n    2\n    5\n    29\n    529\n    2013\n    1\n    1\n  \n  \n    3\n    5\n    40\n    540\n    2013\n    1\n    1\n  \n  \n    4\n    5\n    45\n    545\n    2013\n    1\n    1\n  \n  \n    5\n    6\n    0\n    600\n    2013\n    1\n    1\n  \n  \n    336772\n    14\n    55\n    1455\n    2013\n    9\n    30\n  \n  \n    336773\n    22\n    0\n    2200\n    2013\n    9\n    30\n  \n  \n    336774\n    12\n    10\n    1210\n    2013\n    9\n    30\n  \n  \n    336775\n    11\n    59\n    1159\n    2013\n    9\n    30\n  \n  \n    336776\n    8\n    40\n    840\n    2013\n    9\n    30\n  \n\n\n\n\n\n\n        \n\n\nWhat we see are the six columns we specified from the nycflights dataset.\nNote that the columns are displayed in the order provided in the columns_subset= list. This can be useful for making quick, side-by-side comparisons. In the example above, we placed hour and minute next to the sched_dep_time column. In the original dataset, sched_dep_time is far apart from the other two columns, but, it’s useful to have them next to each other in the preview since hour and minute are derived from sched_dep_time (and this lets us spot check any issues).\nWe can also use column selectors within columns_subset=. Suppose we want to only see those columns that have \"dep_\" or \"arr_\" in the name. To do that, we use the matches() column selector function:\n\npb.preview(nycflights, columns_subset=pb.matches(\"dep_|arr_\"))\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows336,776Columns18\n  \n\n  \n  dep_timeInt64\n  sched_dep_timeInt64\n  dep_delayInt64\n  arr_timeInt64\n  sched_arr_timeInt64\n  arr_delayInt64\n\n\n\n  \n    1\n    517\n    515\n    2\n    830\n    819\n    11\n  \n  \n    2\n    533\n    529\n    4\n    850\n    830\n    20\n  \n  \n    3\n    542\n    540\n    2\n    923\n    850\n    33\n  \n  \n    4\n    544\n    545\n    -1\n    1004\n    1022\n    -18\n  \n  \n    5\n    554\n    600\n    -6\n    812\n    837\n    -25\n  \n  \n    336772\n    None\n    1455\n    None\n    None\n    1634\n    None\n  \n  \n    336773\n    None\n    2200\n    None\n    None\n    2312\n    None\n  \n  \n    336774\n    None\n    1210\n    None\n    None\n    1330\n    None\n  \n  \n    336775\n    None\n    1159\n    None\n    None\n    1344\n    None\n  \n  \n    336776\n    None\n    840\n    None\n    None\n    1020\n    None\n  \n\n\n\n\n\n\n        \n\n\nSeveral selectors can be combined together through use of the col() function and operators such as & (and), | (or), - (difference), and ~ (not). Let’s look at a column selection case where:\n\nthe first three columns are selected\nall columns containing \"dep_\" or \"arr_\" are selected\nany columns beginning with \"sched\" are omitted\n\nThis is how we put that together within col():\n\npb.preview(\n    nycflights,\n    columns_subset=pb.col((pb.first_n(3) | pb.matches(\"dep_|arr_\")) & ~ pb.starts_with(\"sched\"))\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows336,776Columns18\n  \n\n  \n  yearInt64\n  monthInt64\n  dayInt64\n  dep_timeInt64\n  dep_delayInt64\n  arr_timeInt64\n  arr_delayInt64\n\n\n\n  \n    1\n    2013\n    1\n    1\n    517\n    2\n    830\n    11\n  \n  \n    2\n    2013\n    1\n    1\n    533\n    4\n    850\n    20\n  \n  \n    3\n    2013\n    1\n    1\n    542\n    2\n    923\n    33\n  \n  \n    4\n    2013\n    1\n    1\n    544\n    -1\n    1004\n    -18\n  \n  \n    5\n    2013\n    1\n    1\n    554\n    -6\n    812\n    -25\n  \n  \n    336772\n    2013\n    9\n    30\n    None\n    None\n    None\n    None\n  \n  \n    336773\n    2013\n    9\n    30\n    None\n    None\n    None\n    None\n  \n  \n    336774\n    2013\n    9\n    30\n    None\n    None\n    None\n    None\n  \n  \n    336775\n    2013\n    9\n    30\n    None\n    None\n    None\n    None\n  \n  \n    336776\n    2013\n    9\n    30\n    None\n    None\n    None\n    None\n  \n\n\n\n\n\n\n        \n\n\nThis gives us a preview with only the columns that fit the specific selection rules. Incidentally, using selectors with a dataset through preview() is a good way to test out the use of selectors more generally. Since they are primarily used to select columns for validation, trying them beforehand with preview() can help verify that your selection logic is sound.",
    "crumbs": [
      "Get Started",
      "Data Inspection",
      "Previewing Data"
    ]
  },
  {
    "objectID": "user-guide/cli-reference.html",
    "href": "user-guide/cli-reference.html",
    "title": "CLI Reference",
    "section": "",
    "text": "This page provides a complete reference for all Pointblank CLI commands. Each section shows the full help text as it appears in the terminal, giving you quick access to all available options and examples.\nFor practical usage examples and workflows, see the CLI Data Validation and CLI Data Inspection guides.",
    "crumbs": [
      "Get Started",
      "The Pointblank CLI",
      "CLI Reference"
    ]
  },
  {
    "objectID": "user-guide/cli-reference.html#pb---main-command",
    "href": "user-guide/cli-reference.html#pb---main-command",
    "title": "CLI Reference",
    "section": "pb - Main Command",
    "text": "pb - Main Command\nThe main entry point for all Pointblank CLI operations:\n\nUsage: pb [OPTIONS] COMMAND [ARGS]...\n\n  Pointblank CLI: Data validation and quality tools for data engineers.\n\n  Use this CLI to validate data quality, explore datasets, and generate\n  comprehensive reports for CSV, Parquet, and database sources. Suitable for\n  data pipelines, ETL validation, and exploratory data analysis from the\n  command line.\n\n  Quick Examples:\n\n    pb preview data.csv              Preview your data\n    pb scan data.csv                 Generate data profile\n    pb validate data.csv             Run basic validation\n\n  Use pb COMMAND --help for detailed help on any command.\n\nOptions:\n  -v, --version  Show the version and exit.\n  -h, --help     Show this message and exit.\n\nCommands:\n  info           Display information about a data source.\n  preview        Preview a data table showing head and tail rows.\n  scan           Generate a data scan profile report.\n  missing        Generate a missing values report for a data table.\n  validate       Perform single or multiple data validations.\n  run            Run a Pointblank validation script or YAML configuration.\n  make-template  Create a validation script or YAML configuration template.\n  pl             Execute Polars expressions and display results.\n  datasets       List available built-in datasets.\n  requirements   Check installed dependencies and their availability.",
    "crumbs": [
      "Get Started",
      "The Pointblank CLI",
      "CLI Reference"
    ]
  },
  {
    "objectID": "user-guide/cli-reference.html#pb-info---data-source-information",
    "href": "user-guide/cli-reference.html#pb-info---data-source-information",
    "title": "CLI Reference",
    "section": "pb info - Data Source Information",
    "text": "pb info - Data Source Information\nDisplay basic information about a data source:\n\nUsage: pb info [OPTIONS] [DATA_SOURCE]\n\n  Display information about a data source.\n\n  Shows table type, dimensions, column names, and data types.\n\n  DATA_SOURCE can be:\n\n  - CSV file path (e.g., data.csv)\n  - Parquet file path or pattern (e.g., data.parquet, data/*.parquet)\n  - GitHub URL to CSV/Parquet (e.g., https://github.com/user/repo/blob/main/data.csv)\n  - Database connection string (e.g., duckdb:///path/to/db.ddb::table_name)\n  - Dataset name from pointblank (small_table, game_revenue, nycflights, global_sales)\n\nOptions:\n  --help  Show this message and exit.",
    "crumbs": [
      "Get Started",
      "The Pointblank CLI",
      "CLI Reference"
    ]
  },
  {
    "objectID": "user-guide/cli-reference.html#pb-preview---data-table-preview",
    "href": "user-guide/cli-reference.html#pb-preview---data-table-preview",
    "title": "CLI Reference",
    "section": "pb preview - Data Table Preview",
    "text": "pb preview - Data Table Preview\nPreview data showing head and tail rows:\n\nUsage: pb preview [OPTIONS] [DATA_SOURCE]\n\n  Preview a data table showing head and tail rows.\n\n  DATA_SOURCE can be:\n\n  - CSV file path (e.g., data.csv)\n  - Parquet file path or pattern (e.g., data.parquet, data/*.parquet)\n  - GitHub URL to CSV/Parquet (e.g., https://github.com/user/repo/blob/main/data.csv)\n  - Database connection string (e.g., duckdb:///path/to/db.ddb::table_name)\n  - Dataset name from pointblank (small_table, game_revenue, nycflights, global_sales)\n  - Piped data from pb pl command\n\n  COLUMN SELECTION OPTIONS:\n\n  For tables with many columns, use these options to control which columns are\n  displayed:\n\n  - --columns: Specify exact columns (e.g., --columns \"name,age,email\")\n  - --col-range: Select column range (e.g., --col-range \"1:10\", --col-range \"5:\", --col-range \":15\")\n  - --col-first: Show first N columns (e.g., --col-first 5)\n  - --col-last: Show last N columns (e.g., --col-last 3)\n\n  Tables with &gt;15 columns automatically show first 7 and last 7 columns with\n  indicators.\n\nOptions:\n  --columns TEXT             Comma-separated list of columns to display\n  --col-range TEXT           Column range like '1:10' or '5:' or ':15'\n                             (1-based indexing)\n  --col-first INTEGER        Show first N columns\n  --col-last INTEGER         Show last N columns\n  --head INTEGER             Number of rows from the top (default: 5)\n  --tail INTEGER             Number of rows from the bottom (default: 5)\n  --limit INTEGER            Maximum total rows to display (default: 50)\n  --no-row-numbers           Hide row numbers\n  --max-col-width INTEGER    Maximum column width in pixels (default: 250)\n  --min-table-width INTEGER  Minimum table width in pixels (default: 500)\n  --no-header                Hide table header\n  --output-html PATH         Save HTML output to file\n  --help                     Show this message and exit.",
    "crumbs": [
      "Get Started",
      "The Pointblank CLI",
      "CLI Reference"
    ]
  },
  {
    "objectID": "user-guide/cli-reference.html#pb-scan---data-profile-reports",
    "href": "user-guide/cli-reference.html#pb-scan---data-profile-reports",
    "title": "CLI Reference",
    "section": "pb scan - Data Profile Reports",
    "text": "pb scan - Data Profile Reports\nGenerate comprehensive data profiles:\n\nUsage: pb scan [OPTIONS] [DATA_SOURCE]\n\n  Generate a data scan profile report.\n\n  Produces a comprehensive data profile including:\n\n  - Column types and distributions\n  - Missing value patterns\n  - Basic statistics\n  - Data quality indicators\n\n  DATA_SOURCE can be:\n\n  - CSV file path (e.g., data.csv)\n  - Parquet file path or pattern (e.g., data.parquet, data/*.parquet)\n  - GitHub URL to CSV/Parquet (e.g., https://github.com/user/repo/blob/main/data.csv)\n  - Database connection string (e.g., duckdb:///path/to/db.ddb::table_name)\n  - Dataset name from pointblank (small_table, game_revenue, nycflights, global_sales)\n  - Piped data from pb pl command\n\nOptions:\n  --output-html PATH  Save HTML scan report to file\n  -c, --columns TEXT  Comma-separated list of columns to scan\n  --help              Show this message and exit.",
    "crumbs": [
      "Get Started",
      "The Pointblank CLI",
      "CLI Reference"
    ]
  },
  {
    "objectID": "user-guide/cli-reference.html#pb-missing---missing-values-reports",
    "href": "user-guide/cli-reference.html#pb-missing---missing-values-reports",
    "title": "CLI Reference",
    "section": "pb missing - Missing Values Reports",
    "text": "pb missing - Missing Values Reports\nGenerate reports focused on missing values:\n\nUsage: pb missing [OPTIONS] [DATA_SOURCE]\n\n  Generate a missing values report for a data table.\n\n  DATA_SOURCE can be:\n\n  - CSV file path (e.g., data.csv)\n  - Parquet file path or pattern (e.g., data.parquet, data/*.parquet)\n  - GitHub URL to CSV/Parquet (e.g., https://github.com/user/repo/blob/main/data.csv)\n  - Database connection string (e.g., duckdb:///path/to/db.ddb::table_name)\n  - Dataset name from pointblank (small_table, game_revenue, nycflights, global_sales)\n  - Piped data from pb pl command\n\nOptions:\n  --output-html PATH  Save HTML output to file\n  --help              Show this message and exit.",
    "crumbs": [
      "Get Started",
      "The Pointblank CLI",
      "CLI Reference"
    ]
  },
  {
    "objectID": "user-guide/cli-reference.html#pb-validate---quick-data-validations",
    "href": "user-guide/cli-reference.html#pb-validate---quick-data-validations",
    "title": "CLI Reference",
    "section": "pb validate - Quick Data Validations",
    "text": "pb validate - Quick Data Validations\nPerform single or multiple data validations:\n\nUsage: pb validate [OPTIONS] [DATA_SOURCE]\n\n  Perform single or multiple data validations.\n\n  Run one or more validation checks on your data in a single command. Use\n  multiple --check options to perform multiple validations.\n\n  DATA_SOURCE can be:\n\n  - CSV file path (e.g., data.csv)\n  - Parquet file path or pattern (e.g., data.parquet, data/*.parquet)\n  - GitHub URL to CSV/Parquet (e.g., https://github.com/user/repo/blob/main/data.csv)\n  - Database connection string (e.g., duckdb:///path/to/db.ddb::table_name)\n  - Dataset name from pointblank (small_table, game_revenue, nycflights, global_sales)\n\n  AVAILABLE CHECK_TYPES:\n\n  Require no additional options:\n\n  - rows-distinct: Check if all rows in the dataset are unique (no duplicates)\n  - rows-complete: Check if all rows are complete (no missing values in any column)\n\n  Require --column:\n\n  - col-exists: Check if a specific column exists in the dataset\n  - col-vals-not-null: Check if all values in a column are not null/missing\n\n  Require --column and --value:\n\n  - col-vals-gt: Check if column values are greater than a fixed value\n  - col-vals-ge: Check if column values are greater than or equal to a fixed value\n  - col-vals-lt: Check if column values are less than a fixed value\n  - col-vals-le: Check if column values are less than or equal to a fixed value\n\n  Require --column and --set:\n\n  - col-vals-in-set: Check if column values are in an allowed set\n\n  Use --list-checks to see all available validation methods with examples. The\n  default CHECK_TYPE is 'rows-distinct' which checks for duplicate rows.\n\n  Examples:\n\n  pb validate data.csv                               # Uses default validation (rows-distinct)\n  pb validate data.csv --list-checks                 # Show all available checks\n  pb validate data.csv --check rows-distinct\n  pb validate data.csv --check rows-distinct --show-extract\n  pb validate data.csv --check rows-distinct --write-extract failing_rows_folder\n  pb validate data.csv --check rows-distinct --exit-code\n  pb validate data.csv --check col-exists --column price\n  pb validate data.csv --check col-vals-not-null --column email\n  pb validate data.csv --check col-vals-gt --column score --value 50\n  pb validate data.csv --check col-vals-in-set --column status --set \"active,inactive,pending\"\n\n  Multiple validations in one command: pb validate data.csv --check rows-\n  distinct --check rows-complete\n\nOptions:\n  --list-checks         List available validation checks and exit\n  --check CHECK_TYPE    Type of validation check to perform. Can be used\n                        multiple times for multiple checks.\n  --column TEXT         Column name or integer position as #N (1-based index)\n                        for validation.\n  --set TEXT            Comma-separated allowed values for col-vals-in-set\n                        checks.\n  --value FLOAT         Numeric value for comparison checks.\n  --show-extract        Show extract of failing rows if validation fails\n  --write-extract TEXT  Save failing rows to folder. Provide base name for\n                        folder.\n  --limit INTEGER       Maximum number of failing rows to save to CSV\n                        (default: 500)\n  --exit-code           Exit with non-zero code if validation fails\n  --help                Show this message and exit.",
    "crumbs": [
      "Get Started",
      "The Pointblank CLI",
      "CLI Reference"
    ]
  },
  {
    "objectID": "user-guide/cli-reference.html#pb-run---validation-scripts-and-yaml",
    "href": "user-guide/cli-reference.html#pb-run---validation-scripts-and-yaml",
    "title": "CLI Reference",
    "section": "pb run - Validation Scripts and YAML",
    "text": "pb run - Validation Scripts and YAML\nRun Python validation scripts or YAML configurations:\n\nUsage: pb run [OPTIONS] [VALIDATION_FILE]\n\n  Run a Pointblank validation script or YAML configuration.\n\n  VALIDATION_FILE can be: - A Python file (.py) that defines validation logic\n  - A YAML configuration file (.yaml, .yml) that defines validation steps\n\n  Python scripts should load their own data and create validation objects.\n  YAML configurations define data sources and validation steps declaratively.\n\n  If --data is provided, it will automatically replace the data source in your\n  validation objects (Python scripts) or override the 'tbl' field (YAML\n  configs).\n\n  To get started quickly, use 'pb make-template' to create templates.\n\n  DATA can be:\n\n  - CSV file path (e.g., data.csv)\n  - Parquet file path or pattern (e.g., data.parquet, data/*.parquet)\n  - GitHub URL to CSV/Parquet (e.g., https://github.com/user/repo/blob/main/data.csv)\n  - Database connection string (e.g., duckdb:///path/to/db.ddb::table_name)\n  - Dataset name from pointblank (small_table, game_revenue, nycflights, global_sales)\n\n  Examples:\n\n  pb make-template my_validation.py  # Create a Python template\n  pb run validation_script.py\n  pb run validation_config.yaml\n  pb run validation_script.py --data data.csv\n  pb run validation_config.yaml --data small_table --output-html report.html\n  pb run validation_script.py --show-extract --fail-on error\n  pb run validation_config.yaml --write-extract extracts_folder --fail-on critical\n\nOptions:\n  --data TEXT                     Data source to replace in validation objects\n                                  (Python scripts and YAML configs)\n  --output-html PATH              Save HTML validation report to file\n  --output-json PATH              Save JSON validation summary to file\n  --show-extract                  Show extract of failing rows if validation\n                                  fails\n  --write-extract TEXT            Save failing rows to folders (one CSV per\n                                  step). Provide base name for folder.\n  --limit INTEGER                 Maximum number of failing rows to save to\n                                  CSV (default: 500)\n  --fail-on [critical|error|warning|any]\n                                  Exit with non-zero code when validation\n                                  reaches this threshold level\n  --help                          Show this message and exit.",
    "crumbs": [
      "Get Started",
      "The Pointblank CLI",
      "CLI Reference"
    ]
  },
  {
    "objectID": "user-guide/cli-reference.html#pb-make-template---template-generation",
    "href": "user-guide/cli-reference.html#pb-make-template---template-generation",
    "title": "CLI Reference",
    "section": "pb make-template - Template Generation",
    "text": "pb make-template - Template Generation\nCreate validation script or YAML configuration templates:\n\nUsage: pb make-template [OPTIONS] [OUTPUT_FILE]\n\n  Create a validation script or YAML configuration template.\n\n  Creates a sample Python script or YAML configuration with examples showing\n  how to use Pointblank for data validation. The template type is determined\n  by the file extension: - .py files create Python script templates -\n  .yaml/.yml files create YAML configuration templates\n\n  Edit the template to add your own data loading and validation rules, then\n  run it with 'pb run'.\n\n  OUTPUT_FILE is the path where the template will be created.\n\n  Examples:\n\n  pb make-template my_validation.py        # Creates Python script template\n  pb make-template my_validation.yaml      # Creates YAML config template\n  pb make-template validation_template.yml # Creates YAML config template\n\nOptions:\n  --help  Show this message and exit.",
    "crumbs": [
      "Get Started",
      "The Pointblank CLI",
      "CLI Reference"
    ]
  },
  {
    "objectID": "user-guide/cli-reference.html#pb-pl---polars-expression-execution",
    "href": "user-guide/cli-reference.html#pb-pl---polars-expression-execution",
    "title": "CLI Reference",
    "section": "pb pl - Polars Expression Execution",
    "text": "pb pl - Polars Expression Execution\nExecute Polars expressions and display results:\n\nUsage: pb pl [OPTIONS] [POLARS_EXPRESSION]\n\n  Execute Polars expressions and display results.\n\n  Execute Polars DataFrame operations from the command line and display the\n  results using Pointblank's visualization tools.\n\n  POLARS_EXPRESSION should be a valid Polars expression that returns a\n  DataFrame. The 'pl' module is automatically imported and available.\n\n  Examples:\n\n  # Direct expression\n  pb pl \"pl.read_csv('data.csv')\"\n  pb pl \"pl.read_csv('data.csv').select(['name', 'age'])\"\n  pb pl \"pl.read_csv('data.csv').filter(pl.col('age') &gt; 25)\"\n\n  # Multi-line with editor (supports multiple statements)\n  pb pl --edit\n\n  # Multi-statement code example in editor:\n  # csv = pl.read_csv('data.csv')\n  # result = csv.select(['name', 'age']).filter(pl.col('age') &gt; 25)\n\n  # Multi-line with a specific editor\n  pb pl --edit --editor nano\n  pb pl --edit --editor code\n  pb pl --edit --editor micro\n\n  # From file\n  pb pl --file query.py\n\n  Piping to other pb commands\n  pb pl \"pl.read_csv('data.csv').head(20)\" --pipe | pb validate --check rows-distinct\n  pb pl --edit --pipe | pb preview --head 10\n  pb pl --edit --pipe | pb scan --output-html report.html\n  pb pl --edit --pipe | pb missing --output-html missing_report.html\n\n  Use --output-format to change how results are displayed:\n  pb pl \"pl.read_csv('data.csv')\" --output-format scan\n  pb pl \"pl.read_csv('data.csv')\" --output-format missing\n  pb pl \"pl.read_csv('data.csv')\" --output-format info\n\n  Note: For multi-statement code, assign your final result to a variable like\n  'result', 'df', 'data', or ensure it's the last expression.\n\nOptions:\n  -e, --edit                      Open editor for multi-line input\n  -f, --file PATH                 Read query from file\n  --editor TEXT                   Editor to use for --edit mode (overrides\n                                  $EDITOR and auto-detection)\n  -o, --output-format [preview|scan|missing|info]\n                                  Output format for the result\n  --preview-head INTEGER          Number of head rows for preview\n  --preview-tail INTEGER          Number of tail rows for preview\n  --output-html PATH              Save HTML output to file\n  --pipe                          Output data in a format suitable for piping\n                                  to other pb commands\n  --pipe-format [parquet|csv]     Format for piped output (default: parquet)\n  --help                          Show this message and exit.",
    "crumbs": [
      "Get Started",
      "The Pointblank CLI",
      "CLI Reference"
    ]
  },
  {
    "objectID": "user-guide/cli-reference.html#pb-datasets---built-in-datasets",
    "href": "user-guide/cli-reference.html#pb-datasets---built-in-datasets",
    "title": "CLI Reference",
    "section": "pb datasets - Built-in Datasets",
    "text": "pb datasets - Built-in Datasets\nList available built-in datasets:\n\nUsage: pb datasets [OPTIONS]\n\n  List available built-in datasets.\n\nOptions:\n  --help  Show this message and exit.",
    "crumbs": [
      "Get Started",
      "The Pointblank CLI",
      "CLI Reference"
    ]
  },
  {
    "objectID": "user-guide/cli-reference.html#pb-requirements---dependency-check",
    "href": "user-guide/cli-reference.html#pb-requirements---dependency-check",
    "title": "CLI Reference",
    "section": "pb requirements - Dependency Check",
    "text": "pb requirements - Dependency Check\nCheck installed dependencies and their availability:\n\nUsage: pb requirements [OPTIONS]\n\n  Check installed dependencies and their availability.\n\nOptions:\n  --help  Show this message and exit.",
    "crumbs": [
      "Get Started",
      "The Pointblank CLI",
      "CLI Reference"
    ]
  },
  {
    "objectID": "user-guide/cli-reference.html#common-data-source-types",
    "href": "user-guide/cli-reference.html#common-data-source-types",
    "title": "CLI Reference",
    "section": "Common Data Source Types",
    "text": "Common Data Source Types\nAll commands that accept a DATA_SOURCE parameter support these formats:\n\nCSV files: data.csv, path/to/data.csv\nParquet files: data.parquet, data/*.parquet (patterns supported)\nGitHub URLs: https://github.com/user/repo/blob/main/data.csv\nDatabase connections: duckdb:///path/to/db.ddb::table_name\nBuilt-in datasets: small_table, game_revenue, nycflights, global_sales\nPiped data: Output from pb pl command (where supported)",
    "crumbs": [
      "Get Started",
      "The Pointblank CLI",
      "CLI Reference"
    ]
  },
  {
    "objectID": "user-guide/cli-reference.html#exit-codes-and-automation",
    "href": "user-guide/cli-reference.html#exit-codes-and-automation",
    "title": "CLI Reference",
    "section": "Exit Codes and Automation",
    "text": "Exit Codes and Automation\nMany commands support options useful for automation and CI/CD:\n\n--exit-code: Exit with non-zero code on validation failure\n--fail-on [critical|error|warning|any]: Control failure thresholds\n--output-html, --output-json: Save reports for external consumption\n--write-extract: Save failing rows for investigation\n\nThese features make Pointblank CLI commands suitable for integration into data pipelines, quality gates, and automated workflows.",
    "crumbs": [
      "Get Started",
      "The Pointblank CLI",
      "CLI Reference"
    ]
  },
  {
    "objectID": "user-guide/briefs.html",
    "href": "user-guide/briefs.html",
    "title": "Briefs",
    "section": "",
    "text": "When validating data with Pointblank, it’s often helpful to have descriptive labels for each validation step. This is where briefs come in. A brief is a short description of what a validation step is checking and it appears in the STEP column of the validation report table. Briefs make your validation reports more readable and they help others understand what each step is verifying without needing to look at the code.\nBriefs can be set in two ways:\nUnderstanding these two approaches to adding briefs gives you flexibility in how you document your validation process. Global briefs provide consistency across all steps and save time when you want similar descriptions throughout, while step-level briefs allow for precise customization when specific validations need more detailed or unique explanations. In practice, many validation workflows will combine both approaches (i.e., setting a useful global brief template while overriding it for steps that require special attention).",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Briefs"
    ]
  },
  {
    "objectID": "user-guide/briefs.html#global-briefs",
    "href": "user-guide/briefs.html#global-briefs",
    "title": "Briefs",
    "section": "Global Briefs",
    "text": "Global Briefs\nTo set a global brief that applies to all validation steps, use the Validate(brief=) parameter when creating a Validate object:\n\nimport pointblank as pb\nimport polars as pl\n\n# Sample data\ndata = pl.DataFrame({\n    \"id\": [1, 2, 3, 4, 5],\n    \"value\": [10, 20, 30, 40, 50],\n    \"category\": [\"A\", \"B\", \"C\", \"A\", \"B\"]\n})\n\n# Create a validation with a global brief\n(\n    pb.Validate(\n        data=data,\n\n        # Global brief template ---\n        brief=\"Step {step}: {auto}\"\n    )\n    .col_vals_gt(columns=\"value\", value=5)\n    .col_vals_in_set(columns=\"category\", set=[\"A\", \"B\", \"C\"])\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:18:27Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Step 1: Expect that values in value should be &gt; 5.\n\n        \n    value\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Step 2: Expect that values in category should be in the set of A, B, C.\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nIn this example, every validation step will have a brief description that follows the pattern \"Step X: [auto-generated description]\".\nThis is a simple example of template-based briefs. Later in this guide, we’ll explore the full range of templating elements available for creating custom brief descriptions that precisely communicate what each validation step is checking.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Briefs"
    ]
  },
  {
    "objectID": "user-guide/briefs.html#step-level-briefs",
    "href": "user-guide/briefs.html#step-level-briefs",
    "title": "Briefs",
    "section": "Step-level Briefs",
    "text": "Step-level Briefs\nYou can also set briefs for individual validation steps:\n\n(\n    pb.Validate(data=data)\n    .col_vals_gt(\n        columns=\"value\", value=5,\n        brief=\"Check if values exceed minimum threshold of 5\"\n    )\n    .col_vals_in_set(\n        columns=\"category\", set=[\"A\", \"B\", \"C\"],\n        brief=\"Verify categories are valid\"\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:18:28Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Check if values exceed minimum threshold of 5\n\n        \n    value\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Verify categories are valid\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nLocal briefs override any global briefs that might be set.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Briefs"
    ]
  },
  {
    "objectID": "user-guide/briefs.html#brief-templating",
    "href": "user-guide/briefs.html#brief-templating",
    "title": "Briefs",
    "section": "Brief Templating",
    "text": "Brief Templating\nBriefs support templating elements that get replaced with specific values:\n\n{auto}: an auto-generated description of the validation\n{step}: the step number in the validation plan\n{col}: the column name(s) being validated\n{value}: the comparison value used in the validation (when applicable)\n{thresholds}: a short summary of thresholds levels set (or unset) for the step\n{segment}, {segment_column}, {segment_value}: information on the step’s segment\n\nHere’s how to use these templates:\n\n(\n    pb.Validate(data=data)\n    .col_vals_gt(\n        columns=\"value\", value=5,\n        brief=\"Step {step}: Checking column '{col}' for values `&gt; 5`\"\n    )\n    .col_vals_in_set(\n        columns=\"category\", set=[\"A\", \"B\", \"C\"],\n        brief=\"{auto} **(Step {step})**\"\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:18:28Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Step 1: Checking column 'value' for values &gt; 5\n\n        \n    value\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Expect that values in category should be in the set of A, B, C. (Step 2)\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThese template elements make briefs highly flexible and customizable. You can combine multiple templating elements in a single brief to create descriptive yet concise validation step descriptions. The templates help maintain consistency across your validation reports while providing enough detail to understand what each step is checking.\nNote that not all templating elements will be relevant for every validation step. For instance, {value} is only applicable to validation functions that hold a comparison value like col_vals_gt(). If you include a templating element that isn’t relevant to a particular step, it will not be replaced with a corresponding value.\nBriefs support the use of Markdown formatting, allowing you to add emphasis with bold or italic text, include inline code formatting, or other Markdown elements to make your briefs more visually distinctive and informative. This can be especially helpful when you want certain parts of your briefs to stand out in the validation report.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Briefs"
    ]
  },
  {
    "objectID": "user-guide/briefs.html#automatic-briefs",
    "href": "user-guide/briefs.html#automatic-briefs",
    "title": "Briefs",
    "section": "Automatic Briefs",
    "text": "Automatic Briefs\nIf you want Pointblank to generate briefs for you automatically, you can set brief=True. Here, we’ll make that setting at the global level (by using Validate(brief=True)):\n\n(\n    pb.Validate(\n        data=data,\n\n        # Setting for automatically generated briefs ---\n        brief=True\n    )\n    .col_vals_gt(columns=\"value\", value=5)\n    .col_vals_in_set(columns=\"category\", set=[\"A\", \"B\", \"C\"])\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:18:28Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Expect that values in value should be &gt; 5.\n\n        \n    value\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Expect that values in category should be in the set of A, B, C.\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nAutomatic briefs are descriptive and include information about what’s being validated, including the column names and the validation conditions.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Briefs"
    ]
  },
  {
    "objectID": "user-guide/briefs.html#briefs-localized-to-a-specified-language",
    "href": "user-guide/briefs.html#briefs-localized-to-a-specified-language",
    "title": "Briefs",
    "section": "Briefs Localized to a Specified Language",
    "text": "Briefs Localized to a Specified Language\nWhen using the lang= parameter in Validate, automatically generated briefs will be created in the specified language (along with other elements of the validation report table):\n\n(\n    pb.Validate(\n        data=data,\n\n        # Setting the language as Spanish ---\n        lang=\"es\",\n\n        # Automatically generate all briefs in Spanish\n        brief=True\n    )\n    .col_vals_gt(columns=\"value\", value=5)\n    .col_vals_in_set(columns=\"category\", set=[\"A\", \"B\", \"C\"])\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Validación de Pointblank\n  \n  \n    2025-11-23|00:18:28Polars\n  \n\n  \n  \n  PASO\n  COLUMNAS\n  VALORES\n  TBL\n  EVAL\n  UNID.\n  PASA\n  FALLO\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Se espera que los valores en value sean &gt; 5.\n\n        \n    value\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51,00\n    00,00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Se espera que los valores en category estén en el conjunto de A, B, C.\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51,00\n    00,00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nWhen using the lang= parameter in combination with the {auto} templating element, the auto-generated portion of the brief will also be translated to the specified language. This makes it possible to create fully localized validation reports where both custom text and auto-generated descriptions appear in the same language.\nPointblank supports several languages for localized briefs, including French (\"fr\"), German (\"de\"), Spanish (\"es\"), Italian (\"it\"), and Portuguese (\"pt\"). For the complete list of supported languages, refer to the Validate documentation.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Briefs"
    ]
  },
  {
    "objectID": "user-guide/briefs.html#disabling-briefs",
    "href": "user-guide/briefs.html#disabling-briefs",
    "title": "Briefs",
    "section": "Disabling Briefs",
    "text": "Disabling Briefs\nIf you’ve set a global brief but want to disable it for specific validation steps, you can set brief=False:\n\n(\n    pb.Validate(\n        data=data,\n\n        # Global brief template ---\n        brief=\"Step {step}: {auto}\"\n    )\n    .col_vals_gt(columns=\"value\", value=5)  # This step uses the global brief setting\n    .col_vals_in_set(\n        columns=\"category\",\n        set=[\"A\", \"B\", \"C\"],\n\n        # No brief for this step ---\n        brief=False\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:18:28Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Step 1: Expect that values in value should be &gt; 5.\n\n        \n    value\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        \n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    —\n    —\n    —\n    —",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Briefs"
    ]
  },
  {
    "objectID": "user-guide/briefs.html#practical-example-comprehensive-validation-with-briefs",
    "href": "user-guide/briefs.html#practical-example-comprehensive-validation-with-briefs",
    "title": "Briefs",
    "section": "Practical Example: Comprehensive Validation with Briefs",
    "text": "Practical Example: Comprehensive Validation with Briefs\nIn real-world data validation scenarios, you’ll likely work with more complex datasets and apply various types of validation checks. This final example brings together many of the brief-generating techniques we’ve covered, showing how you can mix different approaches in a single validation workflow.\n\n# Create a slightly larger dataset\ndata_2 = pl.DataFrame({\n    \"id\": [1, 2, 3, 4, 5, 6, 7, 8],\n    \"value\": [10, 20, 30, 40, 50, 60, 70, 80],\n    \"ratio\": [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n    \"category\": [\"A\", \"B\", \"C\", \"A\", \"B\", \"C\", \"A\", \"B\"],\n    \"date\": [\"2023-01-01\", \"2023-01-02\", \"2023-01-03\", \"2023-01-04\",\n             \"2023-01-05\", \"2023-01-06\", \"2023-01-07\", \"2023-01-08\"]\n})\n\n(\n    pb.Validate(data=data_2)\n    .col_vals_gt(\n        columns=\"value\", value=0,\n\n        # Plaintext brief ---\n        brief=\"All values must be positive.\"\n    )\n    .col_vals_between(\n        columns=\"ratio\", left=0, right=1,\n\n        # Template-based brief ---\n        brief=\"**Step {step}**: Ratios should be between `0` and `1`.\"\n    )\n    .col_vals_in_set(\n        columns=\"category\", set=[\"A\", \"B\", \"C\"],\n\n        # Automatically generated brief ---\n        brief=True\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:18:28Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        All values must be positive.\n\n        \n    value\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    8\n    81.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_between\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_between()\n        \n        Step 2: Ratios should be between 0 and 1.\n\n        \n    ratio\n    [0, 1]\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    8\n    81.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Expect that values in category should be in the set of A, B, C.\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    8\n    81.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe example above demonstrates:\n\nplaintext briefs with direct messages\ntemplate-based briefs with Markdown formatting\nautomatically generated briefs (brief=True)\n\nBy combining these different brief styles, you can create validation reports that are informative, consistent, and tailored to your specific data quality requirements.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Briefs"
    ]
  },
  {
    "objectID": "user-guide/briefs.html#best-practices-for-using-briefs",
    "href": "user-guide/briefs.html#best-practices-for-using-briefs",
    "title": "Briefs",
    "section": "Best Practices for Using Briefs",
    "text": "Best Practices for Using Briefs\nWell-crafted briefs can significantly enhance the readability and usefulness of your validation reports. Here are some guidelines to follow:\n\nBe concise: briefs should be short and to the point; they’re meant to quickly communicate the purpose of a validation step\nBe specific: include relevant details or conditions that make the validation meaningful\nUse templates consistently: if you’re using template elements like \"{step}\" or \"{col}\", try to use them consistently across all briefs for a cleaner look\nUse auto-generated briefs as a starting point: you can start with Validate(brief=True) to see what Pointblank generates automatically, then customize as needed\nAdd custom briefs for complex validations: custom briefs are especially useful for complex validations where the purpose might not be immediately obvious from the code\n\nFollowing these best practices will help ensure your validation reports are easy to understand for everyone who needs to review them.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Briefs"
    ]
  },
  {
    "objectID": "user-guide/briefs.html#conclusion",
    "href": "user-guide/briefs.html#conclusion",
    "title": "Briefs",
    "section": "Conclusion",
    "text": "Conclusion\nBriefs help make validation reports more readable and understandable. By using global briefs, step-level briefs, or a combination of both, you can create validation reports that clearly communicate what each validation step is checking.\nWhether you want automatically generated descriptions or precisely tailored custom messages, the brief system provides the flexibility to make your data validation work more transparent and easier to interpret for all stakeholders.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Briefs"
    ]
  },
  {
    "objectID": "user-guide/thresholds.html",
    "href": "user-guide/thresholds.html",
    "title": "Thresholds",
    "section": "",
    "text": "Thresholds are a key concept in Pointblank that allow you to define acceptable limits for failing validation tests. Rather than a simple pass/fail model, thresholds enable you to signal failure at different severity levels (‘warning’, ‘error’, and ‘critical’), giving you fine-grained control over how data quality issues are reported and handled.\nWhen used with actions (covered in the next section), thresholds create a robust system for responding to data quality issues based on their severity. This approach allows you to:",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Thresholds"
    ]
  },
  {
    "objectID": "user-guide/thresholds.html#a-simple-example",
    "href": "user-guide/thresholds.html#a-simple-example",
    "title": "Thresholds",
    "section": "A Simple Example",
    "text": "A Simple Example\nLet’s start with a basic example that demonstrates how thresholds work in practice:\n\nimport pointblank as pb\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .col_vals_not_null(\n        columns=\"c\",\n\n        # Set thresholds for the validation step ---\n        thresholds=pb.Thresholds(warning=1, error=0.2)\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:18:18Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #AAAAAA\n    1\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    c\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    ●\n    ○\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nIn this example, we’re validating that column c contains no Null values. We’ve set:\n\nA ‘warning’ threshold of 1 (triggers when 1 or more values are Null)\nAn ‘error’ threshold of 0.2 (triggers when 20% or more values are Null)\n\nLooking at the results:\n\nthe FAIL column shows that 2 test units have failed\nthe W column (for ‘warning’) shows a filled gray circle, indicating the warning threshold has been exceeded\nthe E column (for ‘error’) shows an open yellow circle, indicating the error threshold has not been exceeded\nthe C column (for ‘critical’) shows a dash since we didn’t set a critical threshold",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Thresholds"
    ]
  },
  {
    "objectID": "user-guide/thresholds.html#types-of-threshold-values",
    "href": "user-guide/thresholds.html#types-of-threshold-values",
    "title": "Thresholds",
    "section": "Types of Threshold Values",
    "text": "Types of Threshold Values\nThresholds in Pointblank can be specified in two different ways:\n\nAbsolute Thresholds\nAbsolute thresholds are specified as integers and represent a fixed number of failing test units:\n# Warning threshold of exactly 5 failing test units\nthresholds_absolute = pb.Thresholds(warning=5)\nWith this configuration, the ‘warning’ threshold would be triggered if 5 or more test units fail.\n\n\nProportional Thresholds\nProportional thresholds are specified as decimals between 0 and 1, representing a percentage of the total test units:\n# Error threshold of 10% of test units failing\nthresholds_proportional = pb.Thresholds(error=0.1)\nWith this configuration, the ‘error’ threshold would be triggered if 10% or more of the test units fail.\n\n\nBoolean Shorthand\nFor cases where you want to allow exactly 1 failing test unit, you can use True as a convenient shorthand:\n# Critical threshold of exactly 1 failing test unit\nthresholds_boolean = pb.Thresholds(critical=True)\nThis is equivalent to setting critical=1 but provides a more intuitive way to express “allow at most one failure”. This shorthand is particularly useful for strict validations where any failure beyond a single edge case should trigger immediate attention.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Thresholds"
    ]
  },
  {
    "objectID": "user-guide/thresholds.html#understanding-severity-levels",
    "href": "user-guide/thresholds.html#understanding-severity-levels",
    "title": "Thresholds",
    "section": "Understanding Severity Levels",
    "text": "Understanding Severity Levels\nThe three threshold levels in Pointblank (‘warning’, ‘error’, and ‘critical’) are inspired by traditional logging levels used in software development. These names suggest a progression of severity:\n\n‘warning’ (level 30): indicates potential issues that don’t necessarily prevent normal operation\n‘error’ (level 40): suggests more serious problems that might impact data quality\n‘critical’ (level 50): represents the most severe issues that likely require immediate attention\n\nThese numerical values (30, 40, 50) are used internally by Pointblank when determining threshold hierarchy and can be accessed through the {level_num} field in action metadata (covered in the next User Guide article).\nWhile these names imply certain severity levels, they’re ultimately just convenient labels for different thresholds. You have complete flexibility in how you use them:\n\nyou could use ‘warning’ for issues that should block a pipeline\nyou might configure ‘critical’ for minor issues that just need documentation\nthe ‘error’ level could trigger informational emails rather than actual error handling\n\nThe naming is primarily a suggestion to help organize your validation strategy. What matters most is how you configure actions for each threshold level to suit your specific data quality requirements.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Thresholds"
    ]
  },
  {
    "objectID": "user-guide/thresholds.html#threshold-behavior",
    "href": "user-guide/thresholds.html#threshold-behavior",
    "title": "Thresholds",
    "section": "Threshold Behavior",
    "text": "Threshold Behavior\nIt’s important to understand a few key behaviors of thresholds:\n\nthresholds are inclusive: a value equal to or exceeding the threshold will trigger the associated level\nthresholds can be mixed: you can use absolute values for some levels and proportional for others\nthreshold levels are hierarchical: ‘critical’ is more severe than ‘error’, which is more severe than ‘warning’\nwhen a test fails, all applicable threshold levels are marked in the report (though actions may only execute for the highest level by default)",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Thresholds"
    ]
  },
  {
    "objectID": "user-guide/thresholds.html#setting-global-thresholds",
    "href": "user-guide/thresholds.html#setting-global-thresholds",
    "title": "Thresholds",
    "section": "Setting Global Thresholds",
    "text": "Setting Global Thresholds\nYou can set thresholds globally for all validation steps in a workflow using the thresholds= parameter in Validate:\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"),\n\n        # Setting thresholds for all validation steps ---\n        thresholds=pb.Thresholds(warning=1, error=0.1)\n    )\n    .col_vals_not_null(columns=\"a\")\n    .col_vals_gt(columns=\"a\", value=2)\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:18:18PolarsWARNING1ERROR0.1CRITICAL—\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    a\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    ○\n    ○\n    —\n    —\n  \n  \n    #EBBC14\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    a\n    2\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    90.69\n    40.31\n    ●\n    ●\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nWith this approach, the same thresholds are applied to every validation step in the workflow.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Thresholds"
    ]
  },
  {
    "objectID": "user-guide/thresholds.html#overriding-thresholds-for-specific-steps",
    "href": "user-guide/thresholds.html#overriding-thresholds-for-specific-steps",
    "title": "Thresholds",
    "section": "Overriding Thresholds for Specific Steps",
    "text": "Overriding Thresholds for Specific Steps\nYou can override global thresholds for specific validation steps by providing the thresholds= parameter in individual validation methods:\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"),\n\n        # Setting global thresholds ---\n        thresholds=pb.Thresholds(warning=1, error=0.1)\n    )\n    .col_vals_not_null(columns=\"a\")\n    .col_vals_gt(\n        columns=\"a\", value=2,\n\n        # Step-specific threshold that overrides global ---\n        thresholds=pb.Thresholds(warning=3)\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:18:18PolarsWARNING1ERROR0.1CRITICAL—\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    a\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    ○\n    ○\n    —\n    —\n  \n  \n    #AAAAAA\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    a\n    2\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    90.69\n    40.31\n    ●\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nIn this example, the second validation step uses its own ‘warning’ threshold of 3, overriding the global setting of 1.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Thresholds"
    ]
  },
  {
    "objectID": "user-guide/thresholds.html#ways-to-define-thresholds",
    "href": "user-guide/thresholds.html#ways-to-define-thresholds",
    "title": "Thresholds",
    "section": "Ways to Define Thresholds",
    "text": "Ways to Define Thresholds\nPointblank offers multiple ways to define thresholds to accommodate different coding styles and requirements.\n\n1. Using the Thresholds Class (Recommended)\nThe most explicit and flexible approach is using the Thresholds class:\n\n# Set individual thresholds for different levels\nthresholds_all_levels = pb.Thresholds(warning=0.05, error=0.1, critical=0.25)\n\n# Set only specific levels\nthresholds_error_only = pb.Thresholds(error=0.15)\n\nThis approach allows you to:\n\nset any combination of threshold levels\nuse descriptive parameter names for clarity\nskip levels you don’t need to set\n\n\n\n2. Using a Tuple\nFor concise code, you can use a tuple where positions represent ‘warning’, ‘error’, and ‘critical’ levels in that order:\n\n# (warning, error, critical)\nthresholds_tuple = (1, 0.1, 0.25)\n\n# Shorter tuples are also allowed\nthresholds_tuple_warning = (3,)            # Only the 'warning' threshold\nthresholds_tuple_warning_error = (3, 0.2)  # Both 'warning' and 'error' thresholds\n\nWhile concise, this approach requires you to start with the ‘warning’ level and add levels in order.\n\n\n3. Using a Dictionary\nYou can also use a dictionary with keys that match the threshold level names:\n\n# Can use any combination of threshold levels\nthresholds_dict = {\"warning\": 1, \"critical\": 0.15}\n\nThe dictionary must use the exact keys \"warning\", \"error\", and/or \"critical\".\n\n\n4. Using a Single Value\nThe simplest approach is using a single numeric value, which sets just the ‘warning’ threshold:\n\n# Sets 'warning' threshold to `5`\nthresholds_single = 5\n\nThis is equivalent to pb.Thresholds(warning=5).",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Thresholds"
    ]
  },
  {
    "objectID": "user-guide/thresholds.html#thresholds-and-validation-steps",
    "href": "user-guide/thresholds.html#thresholds-and-validation-steps",
    "title": "Thresholds",
    "section": "Thresholds and Validation Steps",
    "text": "Thresholds and Validation Steps\nLet’s look at a more complete validation workflow that demonstrates different threshold configurations:\n\n# Create a validation workflow with global and step-specific thresholds\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"),\n\n        # Global thresholds applied to all steps unless overridden ---\n        thresholds=pb.Thresholds(warning=0.05, error=0.1, critical=0.2)\n    )\n\n    # Step 1: Uses global thresholds ---\n    .col_vals_not_null(columns=\"b\")\n\n    # Step 2: Overrides with step-specific thresholds ---\n    .col_vals_gt(\n        columns=\"a\", value=2,\n        thresholds=pb.Thresholds(warning=1, critical=0.3) # No 'error' threshold\n    )\n\n    # Step 3: Uses a simplified tuple notation ---\n    .col_vals_not_null(columns=\"c\", thresholds=(2, 0.15))\n\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:18:18PolarsWARNING0.05ERROR0.1CRITICAL0.2\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    b\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #FF3300\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    a\n    2\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    90.69\n    40.31\n    ●\n    —\n    ●\n    CSV\n  \n  \n    #EBBC14\n    3\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    c\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    ●\n    ●\n    —\n    CSV",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Thresholds"
    ]
  },
  {
    "objectID": "user-guide/thresholds.html#thresholds-and-actions",
    "href": "user-guide/thresholds.html#thresholds-and-actions",
    "title": "Thresholds",
    "section": "Thresholds and Actions",
    "text": "Thresholds and Actions\nWhile thresholds by themselves provide visual indicators of validation severity in reports, their real power emerges when combined with Actions. The Actions system (covered in the next article) allows you to specify what happens when a threshold is exceeded.\nFor example, you might configure:\n\nA ‘warning’ threshold that logs a message\nAn ‘error’ threshold that sends an email notification\nA ‘critical’ threshold that blocks a data pipeline\n\nHere’s a simple preview of how thresholds and actions work together:\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"),\n\n        # Define thresholds for all three severity levels ---\n        thresholds=pb.Thresholds(warning=1, error=2, critical=3),\n\n        # Define actions for different threshold levels ---\n        actions=pb.Actions(\n            warning=\"Warning: {step} has {FAIL} failing values\",\n            error=\"ERROR: Step {step} exceeded the 'error' threshold\",\n            critical=\"CRITICAL: Data quality issue in column {col}\"\n        )\n    )\n    .col_vals_not_null(columns=\"c\")\n    .interrogate()\n)\n\nERROR: Step 1 exceeded the 'error' threshold\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:18:18PolarsWARNING1ERROR2CRITICAL3\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #EBBC14\n    1\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    c\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    ●\n    ●\n    ○\n    CSV",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Thresholds"
    ]
  },
  {
    "objectID": "user-guide/thresholds.html#conclusion",
    "href": "user-guide/thresholds.html#conclusion",
    "title": "Thresholds",
    "section": "Conclusion",
    "text": "Conclusion\nThresholds are a powerful feature that transform Pointblank from a simple validation tool into a sophisticated data quality monitoring system. By setting appropriate thresholds, you can:\n\nDefine different severity levels for data quality issues\nCustomize tolerance levels for different types of validation checks\nCreate a more nuanced approach to data validation than binary pass/fail\nEnable targeted actions based on the severity of issues detected\n\nIn the next article, we’ll explore the Actions system in depth, showing you how to define automatic responses when thresholds are exceeded.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Thresholds"
    ]
  },
  {
    "objectID": "user-guide/segmentation.html",
    "href": "user-guide/segmentation.html",
    "title": "Segmentation",
    "section": "",
    "text": "When validating data, you often need to analyze specific subsets or segments of your data separately. Maybe you want to ensure that data quality meets standards in each geographic region, for each product category, or across different time periods. This is where the segments= argument can be useful.\nData segmentation lets you split a validation step into multiple segments, with each segment receiving its own validation step. Rather than validating an entire table at once, you could instead validate different partitions separately and get separate results for each.\nThe segments= argument is available in many validation methods; typically it’s in those methods that check values within rows, and those methods that examine entire rows (rows_distinct(), rows_complete()). When you use it, Pointblank will:\nLet’s explore how to use the segments= argument through a few practical examples.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Segmentation"
    ]
  },
  {
    "objectID": "user-guide/segmentation.html#basic-segmentation-by-column-values",
    "href": "user-guide/segmentation.html#basic-segmentation-by-column-values",
    "title": "Segmentation",
    "section": "Basic Segmentation by Column Values",
    "text": "Basic Segmentation by Column Values\nThe simplest way to segment data is by the unique values in a column. For the upcoming example, we’ll use the small_table dataset, which contains a categorical-value column called f.\nFirst, let’s preview the dataset:\n\ntable = pb.load_dataset()\n\npb.preview(table)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows13Columns8\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05\n    6\n    8-kdg-938\n    3\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    None\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09\n    8\n    3-ldm-038\n    7\n    283.94\n    True\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26\n    4\n    2-dmx-010\n    7\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28\n    2\n    7-dmx-010\n    8\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30\n    1\n    3-dka-303\n    None\n    2230.09\n    True\n    high\n  \n\n\n\n\n\n\n        \n\n\nNow, let’s validate that values in column d are greater than 100, but we’ll also segment the validation by the categorical values in column f:\n\nvalidation_1 = (\n    pb.Validate(\n        data=pb.load_dataset(),\n        tbl_name=\"small_table\",\n        label=\"Segmented validation by category\"\n    )\n    .col_vals_gt(\n        columns=\"d\", value=100,\n\n        # Segment by unique values in column `f` ---\n        segments=\"f\"\n    )\n    .interrogate()\n)\n\nvalidation_1\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Segmented validation by categoryPolarssmall_table\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    SEGMENT  f / high \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    100\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    61.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    SEGMENT  f / low \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    100\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    3\n    SEGMENT  f / mid \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    100\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    2\n    21.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nIn the validation report, notice that instead of a single validation step, we have multiple steps: one for each unique value in the f column. The segmentation is clearly indicated in the STEP column with labels like SEGMENT  f / high, making it easy to identify which segment each validation result belongs to. This clear labeling helps when reviewing reports, especially with complex validations that use multiple segmentation criteria.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Segmentation"
    ]
  },
  {
    "objectID": "user-guide/segmentation.html#segmenting-on-specific-values",
    "href": "user-guide/segmentation.html#segmenting-on-specific-values",
    "title": "Segmentation",
    "section": "Segmenting on Specific Values",
    "text": "Segmenting on Specific Values\nSometimes you don’t want to segment on all unique values in a column, but only on specific ones of interest. You can do this by providing a tuple with the column name and a list of values:\n\nvalidation_2 = (\n    pb.Validate(\n        data=pb.load_dataset(),\n        tbl_name=\"small_table\",\n        label=\"Segmented validation on specific categories\"\n    )\n    .col_vals_gt(\n        columns=\"d\",\n        value=100,\n        segments=(\"f\", [\"low\", \"high\"])  # Only segment on \"low\" and \"high\" values in column `f`\n    )\n    .interrogate()\n)\n\nvalidation_2\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Segmented validation on specific categoriesPolarssmall_table\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    SEGMENT  f / low \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    100\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    SEGMENT  f / high \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    100\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    61.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nIn this example, we only create validation steps for the \"low\" and \"high\" segments, ignoring any rows with f equal to \"mid\".",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Segmentation"
    ]
  },
  {
    "objectID": "user-guide/segmentation.html#multiple-segmentation-criteria",
    "href": "user-guide/segmentation.html#multiple-segmentation-criteria",
    "title": "Segmentation",
    "section": "Multiple Segmentation Criteria",
    "text": "Multiple Segmentation Criteria\nFor more complex segmentation, you can provide a list of columns or column-value tuples. This creates segments based on combinations of criteria:\n\nvalidation_3 = (\n    pb.Validate(\n        data=pb.load_dataset(),\n        tbl_name=\"small_table\",\n        label=\"Multiple segmentation criteria\"\n    )\n    .col_vals_gt(\n        columns=\"d\",\n        value=100,\n\n        # Segment by values in `f` AND specific values in `a` ---\n        segments=[\"f\", (\"a\", [1, 2])]\n    )\n    .interrogate()\n)\n\nvalidation_3\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Multiple segmentation criteriaPolarssmall_table\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    SEGMENT  f / high \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    100\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    61.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    SEGMENT  f / low \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    100\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    3\n    SEGMENT  f / mid \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    100\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    2\n    21.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    SEGMENT  a / 1 \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    100\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    5\n    SEGMENT  a / 2 \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    100\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThis creates validation steps for each combination of values in column f and the specified values in column a.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Segmentation"
    ]
  },
  {
    "objectID": "user-guide/segmentation.html#segmentation-with-preprocessing",
    "href": "user-guide/segmentation.html#segmentation-with-preprocessing",
    "title": "Segmentation",
    "section": "Segmentation with Preprocessing",
    "text": "Segmentation with Preprocessing\nYou can combine segmentation with preprocessing for powerful and flexible validations. All preprocessing is applied before segmentation occurs, which means you can create derived columns to segment on:\n\nimport polars as pl\n\n# Define preprocessing function for creating a categorical column\ndef add_d_category_column(df):\n    return df.with_columns(\n        d_category=pl.when(pl.col(\"d\") &gt; 150).then(pl.lit(\"high\")).otherwise(pl.lit(\"low\"))\n    )\n\nvalidation_4 = (\n    pb.Validate(\n        data=pb.load_dataset(tbl_type=\"polars\"),\n        tbl_name=\"small_table\",\n        label=\"Segmentation with preprocessing\",\n    )\n    .col_vals_gt(\n        columns=\"d\", value=100,\n\n        # Create a column containing categorical values ---\n        pre=add_d_category_column,\n\n        # Segment by the computed column `d_category` generated via `pre=` ---\n        segments=\"d_category\",\n    )\n    .interrogate()\n)\n\nvalidation_4\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Segmentation with preprocessingPolarssmall_table\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    SEGMENT  d_category / high \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    100\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    12\n    121.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    SEGMENT  d_category / low \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    100\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nIn this example, we first create a derived column d_category based on whether d is greater than 150. Then, we segment our validation based on this derived column by using segments=\"d_category\".",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Segmentation"
    ]
  },
  {
    "objectID": "user-guide/segmentation.html#when-to-use-segmentation",
    "href": "user-guide/segmentation.html#when-to-use-segmentation",
    "title": "Segmentation",
    "section": "When to Use Segmentation",
    "text": "When to Use Segmentation\nSegmentation is particularly useful when:\n\nData quality standards vary by group: different regions, product lines, or customer segments might have different acceptable thresholds\nIdentifying problem areas: segmentation helps pinpoint exactly where data quality issues exist, rather than just knowing that some issue exists somewhere in the data\nGenerating detailed reports: by segmenting, you get more granular reporting that can be shared with different stakeholders responsible for different parts of the data\nTracking improvements over time: segmented validations make it easier to see if data quality is improving in specific areas that were previously problematic\n\nBy using segmentation strategically in these scenarios, you can transform your data validation from a simple pass/fail system into a much more nuanced diagnostic tool that provides actionable insights about data quality across different dimensions. This targeted approach not only helps identify issues more precisely but also enables more effective communication of data quality metrics to relevant stakeholders.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Segmentation"
    ]
  },
  {
    "objectID": "user-guide/segmentation.html#segmentation-vs.-multiple-validation-steps",
    "href": "user-guide/segmentation.html#segmentation-vs.-multiple-validation-steps",
    "title": "Segmentation",
    "section": "Segmentation vs. Multiple Validation Steps",
    "text": "Segmentation vs. Multiple Validation Steps\nSo why use segmentation instead of just creating separate validation steps for each segment using filtering in the pre= argument? Well, segmentation offers several nice advantages:\n\nConciseness: you define your validation logic once, not repeatedly for each segment\nConsistency: we can be certain that the same validation is applied uniformly across segments\nClarity: the validation report will clearly organize results by segment (with extra labeling)\nConvenience: there’s no need to manually extract and filter subsets of your data\n\nSegmentation can end of simplifying your validation code while also providing more structured and informative reporting about different portions of your data.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Segmentation"
    ]
  },
  {
    "objectID": "user-guide/segmentation.html#practical-example-validating-sales-data-by-region-and-product-type",
    "href": "user-guide/segmentation.html#practical-example-validating-sales-data-by-region-and-product-type",
    "title": "Segmentation",
    "section": "Practical Example: Validating Sales Data by Region and Product Type",
    "text": "Practical Example: Validating Sales Data by Region and Product Type\nLet’s see a more realistic example where we validate sales data segmented by both region and product type:\n\nimport pandas as pd\nimport numpy as np\n\n# Create a sample sales dataset\nnp.random.seed(123)\n\n# Create a simple sales dataset\nsales_data = pd.DataFrame({\n    \"region\": np.random.choice([\"North\", \"South\", \"East\", \"West\"], 100),\n    \"product_type\": np.random.choice([\"Electronics\", \"Clothing\", \"Food\"], 100),\n    \"units_sold\": np.random.randint(5, 100, 100),\n    \"revenue\": np.random.uniform(100, 10000, 100),\n    \"cost\": np.random.uniform(50, 5000, 100)\n})\n\n# Calculate profit\nsales_data[\"profit\"] = sales_data[\"revenue\"] - sales_data[\"cost\"]\nsales_data[\"profit_margin\"] = sales_data[\"profit\"] / sales_data[\"revenue\"]\n\n# Preview the dataset\npb.preview(sales_data)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PandasRows100Columns7\n  \n\n  \n  regionobject\n  product_typeobject\n  units_soldint64\n  revenuefloat64\n  costfloat64\n  profitfloat64\n  profit_marginfloat64\n\n\n\n  \n    1\n    East\n    Clothing\n    55\n    8428.654356103547\n    1363.5197435071943\n    7065.134612596353\n    0.8382280627607168\n  \n  \n    2\n    South\n    Electronics\n    7\n    6589.7066024003025\n    3824.069456121553\n    2765.6371462787497\n    0.41969048292246663\n  \n  \n    3\n    East\n    Food\n    23\n    4680.5819759229435\n    4122.545156369359\n    558.0368195535848\n    0.11922381071929586\n  \n  \n    4\n    East\n    Clothing\n    51\n    5693.611988153584\n    1797.3122335569797\n    3896.2997545966045\n    0.6843282897927435\n  \n  \n    5\n    North\n    Clothing\n    50\n    4296.763518753258\n    4872.448283639371\n    -575.684764886113\n    -0.13398102138354426\n  \n  \n    96\n    West\n    Clothing\n    85\n    6551.261354681658\n    936.7119894981438\n    5614.549365183515\n    0.8570180704470368\n  \n  \n    97\n    South\n    Electronics\n    29\n    9543.579639173184\n    2779.779531480257\n    6763.800107692927\n    0.7087277901396456\n  \n  \n    98\n    East\n    Food\n    20\n    4822.302251263769\n    2833.48720726181\n    1988.815044001959\n    0.41242023837903463\n  \n  \n    99\n    North\n    Clothing\n    54\n    8801.046116310079\n    2185.8559620190636\n    6615.1901542910155\n    0.7516368016788095\n  \n  \n    100\n    North\n    Clothing\n    85\n    7942.857049695305\n    1834.7969383843642\n    6108.060111310941\n    0.7690003827458094\n  \n\n\n\n\n\n\n        \n\n\nNow, let’s validate that profit margins are above 20% across different regions and product types:\n\nvalidation_5 = (\n    pb.Validate(\n        data=sales_data,\n        tbl_name=\"sales_data\",\n        label=\"Sales data validation by region and product\"\n    )\n    .col_vals_gt(\n        columns=\"profit_margin\",\n        value=0.2,\n        segments=[\"region\", \"product_type\"],\n        brief=\"Profit margin &gt; 20% check\"\n    )\n    .interrogate()\n)\n\nvalidation_5\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Sales data validation by region and productPandassales_data\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    SEGMENT  region / East \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Profit margin &gt; 20% check\n\n        \n    profit_margin\n    0.2\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    30\n    200.67\n    100.33\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    SEGMENT  region / North \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Profit margin &gt; 20% check\n\n        \n    profit_margin\n    0.2\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    25\n    170.68\n    80.32\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    3\n    SEGMENT  region / South \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Profit margin &gt; 20% check\n\n        \n    profit_margin\n    0.2\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    21\n    180.86\n    30.14\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    4\n    SEGMENT  region / West \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Profit margin &gt; 20% check\n\n        \n    profit_margin\n    0.2\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    24\n    160.67\n    80.33\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    5\n    SEGMENT  product_type / Clothing \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Profit margin &gt; 20% check\n\n        \n    profit_margin\n    0.2\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    38\n    280.74\n    100.26\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    6\n    SEGMENT  product_type / Electronics \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Profit margin &gt; 20% check\n\n        \n    profit_margin\n    0.2\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    33\n    210.64\n    120.36\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    7\n    SEGMENT  product_type / Food \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Profit margin &gt; 20% check\n\n        \n    profit_margin\n    0.2\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    29\n    220.76\n    70.24\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThis validation gives us a detailed breakdown of profit margin performance across the different regions and product types, making it easy to identify areas that need attention.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Segmentation"
    ]
  },
  {
    "objectID": "user-guide/segmentation.html#best-practices-for-segmentation",
    "href": "user-guide/segmentation.html#best-practices-for-segmentation",
    "title": "Segmentation",
    "section": "Best Practices for Segmentation",
    "text": "Best Practices for Segmentation\nEffective data segmentation requires thoughtful planning about how to divide your data in ways that make sense for your validation needs. When implementing segmentation in your data validation workflow, consider these key principles:\n\nChoose meaningful segments: select segmentation columns that align with your business logic and organizational structure\nUse preprocessing when needed: if your raw data doesn’t have good segmentation columns, create them through preprocessing (with the pre= argument)\nCombine with actions: for critical segments, define segment-specific actions using the actions= parameter to respond to validation failures.\n\nBy implementing these best practices, you’ll create more targeted, maintainable, and actionable data validations. Segmentation becomes most powerful when it aligns with natural divisions in your data and analytical processes, allowing for more precise identification of quality issues while maintaining a unified validation framework.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Segmentation"
    ]
  },
  {
    "objectID": "user-guide/segmentation.html#conclusion",
    "href": "user-guide/segmentation.html#conclusion",
    "title": "Segmentation",
    "section": "Conclusion",
    "text": "Conclusion\nData segmentation can make your validations more targeted and informative. By dividing your data into meaningful segments, you can identify quality issues with greater precision, apply appropriate validation standards to different parts of your data, and generate more actionable reports.\nThe segments= parameter transforms validation from a monolithic process into a granular assessment of data quality across various dimensions of your dataset. Whether you’re dealing with regional differences, product categories, time periods, or any other meaningful divisions in your data, segmentation makes it possible to validate each portion according to its specific requirements while maintaining the simplicity of a unified validation framework.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Segmentation"
    ]
  },
  {
    "objectID": "user-guide/quickstart.html",
    "href": "user-guide/quickstart.html",
    "title": "Quickstart",
    "section": "",
    "text": "The Pointblank library is all about assessing the state of data quality for a table. You provide the validation rules and the library will dutifully interrogate the data and provide useful reporting. We can use different types of tables like Polars and Pandas DataFrames, Parquet files, or various database tables. Let’s walk through what data validation looks like in Pointblank.",
    "crumbs": [
      "Get Started",
      "Quickstart"
    ]
  },
  {
    "objectID": "user-guide/quickstart.html#a-simple-validation-table",
    "href": "user-guide/quickstart.html#a-simple-validation-table",
    "title": "Quickstart",
    "section": "A Simple Validation Table",
    "text": "A Simple Validation Table\nThis is a validation report table that is produced from a validation of a Polars DataFrame:\n\n\nShow the code\nimport pointblank as pb\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\"), label=\"Example Validation\")\n    .col_vals_lt(columns=\"a\", value=10)\n    .col_vals_between(columns=\"d\", left=0, right=5000)\n    .col_vals_in_set(columns=\"f\", set=[\"low\", \"mid\", \"high\"])\n    .col_vals_regex(columns=\"b\", pattern=r\"^[0-9]-[a-z]{3}-[0-9]{3}$\")\n    .interrogate()\n)\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Example ValidationPolars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    a\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_between\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_between()\n        \n        \n        \n    d\n    [0, 5000]\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    120.92\n    10.08\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        \n        \n    f\n    low, mid, high\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    b\n    ^[0-9]-[a-z]{3}-[0-9]{3}$\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nEach row in this reporting table constitutes a single validation step. Roughly, the left-hand side outlines the validation rules and the right-hand side provides the results of each validation step. While simple in principle, there’s a lot of useful information packed into this validation table.\nHere’s a diagram that describes a few of the important parts of the validation table:\n\nThere are three things that should be noted here:\n\nvalidation steps: each step is a separate test on the table, focused on a certain aspect of the table\nvalidation rules: the validation type is provided here along with key constraints\nvalidation results: interrogation results are provided here, with a breakdown of test units (total, passing, and failing), threshold flags, and more\n\nThe intent is to provide the key information in one place, and have it be interpretable by data stakeholders. For example, a failure can be seen in the second row (notice there’s a CSV button). A data quality stakeholder could click this to download a CSV of the failing rows for that step.",
    "crumbs": [
      "Get Started",
      "Quickstart"
    ]
  },
  {
    "objectID": "user-guide/quickstart.html#example-code-step-by-step",
    "href": "user-guide/quickstart.html#example-code-step-by-step",
    "title": "Quickstart",
    "section": "Example Code, Step-by-Step",
    "text": "Example Code, Step-by-Step\nThis section will walk you through the example code used above.\nimport pointblank as pb\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\"))\n    .col_vals_lt(columns=\"a\", value=10)\n    .col_vals_between(columns=\"d\", left=0, right=5000)\n    .col_vals_in_set(columns=\"f\", set=[\"low\", \"mid\", \"high\"])\n    .col_vals_regex(columns=\"b\", pattern=r\"^[0-9]-[a-z]{3}-[0-9]{3}$\")\n    .interrogate()\n)\nNote these three key pieces in the code:\n\ndata: the Validate(data=) argument takes a DataFrame or database table that you want to validate\nsteps: the methods starting with col_vals_ specify validation steps that run on specific columns\nexecution: the interrogate() method executes the validation plan on the table\n\nThis common pattern is used in a validation workflow, where Validate and interrogate() bookend a validation plan generated through calling validation methods.\nIn the next few sections we’ll go a bit further by understanding how we can measure data quality and respond to failures.",
    "crumbs": [
      "Get Started",
      "Quickstart"
    ]
  },
  {
    "objectID": "user-guide/quickstart.html#understanding-test-units",
    "href": "user-guide/quickstart.html#understanding-test-units",
    "title": "Quickstart",
    "section": "Understanding Test Units",
    "text": "Understanding Test Units\nEach validation step will execute a type of validation test on the target table. For example, a col_vals_lt() validation step can test that each value in a column is less than a specified number. And the key finding that’s reported in each step is the number of test units that pass or fail.\nIn the validation report table, test unit metrics are displayed under the UNITS, PASS, and FAIL columns. This diagram explains what the tabulated values signify:\n\nTest units are dependent on the test being run. Some validation methods might test every value in a particular column, so each value will be a test unit. Others will only have a single test unit since they aren’t testing individual values but rather if the overall test passes or fails.",
    "crumbs": [
      "Get Started",
      "Quickstart"
    ]
  },
  {
    "objectID": "user-guide/quickstart.html#setting-thresholds-for-data-quality-signals",
    "href": "user-guide/quickstart.html#setting-thresholds-for-data-quality-signals",
    "title": "Quickstart",
    "section": "Setting Thresholds for Data Quality Signals",
    "text": "Setting Thresholds for Data Quality Signals\nUnderstanding test units is essential because they form the foundation of Pointblank’s threshold system. Thresholds let you define acceptable levels of data quality, triggering different severity signals (‘warning’, ‘error’, or ‘critical’) when certain failure conditions are met.\nHere’s a simple example that uses a single validation step along with thresholds set using the Thresholds class:\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\"))\n    .col_vals_lt(\n        columns=\"a\",\n        value=7,\n\n        # Set the 'warning' and 'error' thresholds ---\n        thresholds=pb.Thresholds(warning=2, error=4)\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:17:55Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #AAAAAA\n    1\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    a\n    7\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    ●\n    ○\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nIf you look at the validation report table, we can see:\n\nthe FAIL column shows that 2 tests units have failed\nthe W column (short for ‘warning’) shows a filled gray circle indicating those failing test units reached that threshold value\nthe E column (short for ‘error’) shows an open yellow circle indicating that the number of failing test units is below that threshold\n\nThe one final threshold level, C (for ‘critical’), wasn’t set so it appears on the validation table as a long dash.",
    "crumbs": [
      "Get Started",
      "Quickstart"
    ]
  },
  {
    "objectID": "user-guide/quickstart.html#taking-action-on-threshold-exceedances",
    "href": "user-guide/quickstart.html#taking-action-on-threshold-exceedances",
    "title": "Quickstart",
    "section": "Taking Action on Threshold Exceedances",
    "text": "Taking Action on Threshold Exceedances\nPointblank becomes even more powerful when you combine thresholds with actions. The Actions class lets you trigger responses when validation failures exceed threshold levels, turning passive reporting into active notifications.\nHere’s a simple example that adds an action to the previous validation:\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\"))\n    .col_vals_lt(\n        columns=\"a\",\n        value=7,\n        thresholds=pb.Thresholds(warning=2, error=4),\n\n        # Set an action for the 'warning' threshold ---\n        actions=pb.Actions(\n            warning=\"WARNING: Column 'a' has values that aren't less than 7.\"\n        )\n    )\n    .interrogate()\n)\n\nWARNING: Column 'a' has values that aren't less than 7.\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:17:55Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #AAAAAA\n    1\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    a\n    7\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    ●\n    ○\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nNotice the printed warning message: \"WARNING: Column 'a' has values that aren't less than 7.\". The warning indicator (filled gray circle) visually confirms this threshold was reached and the action should trigger.\nActions make your validation workflows more responsive and integrated with your data pipelines. For example, you can generate console messages, Slack notifications, and more.",
    "crumbs": [
      "Get Started",
      "Quickstart"
    ]
  },
  {
    "objectID": "user-guide/quickstart.html#navigating-the-user-guide",
    "href": "user-guide/quickstart.html#navigating-the-user-guide",
    "title": "Quickstart",
    "section": "Navigating the User Guide",
    "text": "Navigating the User Guide\nAs you continue exploring Pointblank’s capabilities, you’ll find the User Guide organized into sections that will help you navigate the various features.\n\nGetting Started\nThe Getting Started section introduces you to Pointblank:\n\nIntroduction: Overview of Pointblank and core concepts (this article)\nInstallation: How to install and set up Pointblank\n\n\n\nValidation Plan\nThe Validation Plan section covers everything you need to know about creating robust validation plans:\n\nOverview: Survey of validation methods and their shared parameters\nValidation Methods: A closer look at the more common validation methods\nColumn Selection Patterns: Techniques for targeting specific columns\nPreprocessing: Transform data before validation\nSegmentation: Apply validations to specific segments of your data\nThresholds: Set quality standards and trigger severity levels\nActions: Respond to threshold exceedances with notifications or custom functions\nBriefs: Add context to validation steps\n\n\n\nAdvanced Validation\nThe Advanced Validation section explores more specialized validation techniques:\n\nExpression-Based Validation: Use column expressions for advanced validation\nSchema Validation: Enforce table structure and column types\nAssertions: Raise exceptions to enforce data quality requirements\nDraft Validation: Create validation plans from existing data\n\n\n\nPost Interrogation\nAfter validating your data, the Post Interrogation section helps you analyze and respond to results:\n\nValidation Reports: Understand and customize the validation report table\nStep Reports: View detailed results for individual validation steps\nData Extracts: Extract and analyze failing data\nSundering Validated Data: Split data based on validation results\n\n\n\nData Inspection\nThe Data Inspection section provides tools to explore and understand your data:\n\nPreviewing Data: View samples of your data\nColumn Summaries: Get statistical summaries of your data\nMissing Values Reporting: Identify and visualize missing data\n\nBy following this guide, you’ll gain a comprehensive understanding of how to validate, monitor, and maintain high-quality data with Pointblank.\n\n\n\n\n\n\nNote\n\n\n\nA PDF version of the User Guide is also available for offline reading.",
    "crumbs": [
      "Get Started",
      "Quickstart"
    ]
  },
  {
    "objectID": "user-guide/validation-reports.html",
    "href": "user-guide/validation-reports.html",
    "title": "Validation Reports",
    "section": "",
    "text": "After interrogating your data with a validation plan, Pointblank automatically generates a validation report. That tabular report comprehensively summarizes the results of all validation steps. It’ll be your primary tool for understanding data quality at a glance, identifying issues, and communicating results to stakeholders.\nValidation reports are Great Tables objects that provide rich information about each validation step. It includes: identifying information for the step, pass/fail statistics, threshold exceedances, and visual status indicators. The report makes it easy to quickly assess overall data quality and pinpoint specific areas that need attention.",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Validation Reports"
    ]
  },
  {
    "objectID": "user-guide/validation-reports.html#viewing-the-validation-report",
    "href": "user-guide/validation-reports.html#viewing-the-validation-report",
    "title": "Validation Reports",
    "section": "Viewing the Validation Report",
    "text": "Viewing the Validation Report\nThe most straightforward way to view a validation report is to simply print the Validate object after calling interrogate():\n\nimport pointblank as pb\nimport polars as pl\n\n# Sample data\ndata = pl.DataFrame({\n    \"id\": range(1, 11),\n    \"value\": [120, 85, 47, 210, 30, 155, 175, 95, 205, 140],\n    \"category\": [\"A\", \"B\", \"C\", \"A\", \"D\", \"B\", \"A\", \"E\", \"A\", \"C\"],\n    \"ratio\": [0.5, 0.7, 0.3, 1.2, 0.8, 0.9, 0.4, 1.5, 0.6, 0.2],\n})\n\n# Create and interrogate a validation\nvalidation = (\n    pb.Validate(data=data, tbl_name=\"sales_data\")\n    .col_vals_gt(columns=\"value\", value=50, brief=True)\n    .col_vals_in_set(columns=\"category\", set=[\"A\", \"B\", \"C\"], brief=True)\n    .col_exists(columns=[\"id\", \"value\"], brief=True)\n    .interrogate()\n)\n\n# Display the validation report\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:17:42Polarssales_data\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Expect that values in value should be &gt; 50.\n\n        \n    value\n    50\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Expect that values in category should be in the set of A, B, C.\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column id exists.\n\n        \n    id\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column value exists.\n\n        \n    value\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:17:42 UTC&lt; 1 s2025-11-23 00:17:42 UTC\n  \n\n\n\n\n\n\n        \n\n\nIn a notebook or interactive environment, simply typing the validation object name displays the report automatically. In a script or REPL, you might need to explicitly call validation.get_tabular_report().show() to display the table.\n\n\n\n\n\n\nNote\n\n\n\nYou can display a validation report even before calling interrogate(). The report will show your validation plan with all the steps you’ve defined, but it won’t contain any interrogation results. Additionally, validation steps that use column selection patterns (like validating multiple columns at once) won’t be expanded into individual rows yet, as that expansion happens during interrogation.",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Validation Reports"
    ]
  },
  {
    "objectID": "user-guide/validation-reports.html#understanding-report-components",
    "href": "user-guide/validation-reports.html#understanding-report-components",
    "title": "Validation Reports",
    "section": "Understanding Report Components",
    "text": "Understanding Report Components\nThe validation report table consists of several key components that work together to provide a complete picture of your data quality:\n\nReport Header\nThe report header (title and subtitle area) contains important metadata about the validation:\n\nTitle: by default, shows “Pointblank Validation” but can be customized\nLabel: your custom label for the validation (if provided via the label= parameter)\nTable Information: the table name and type (Polars, Pandas, DuckDB, etc.)\nThresholds: the warning, error, and critical threshold values used\n\nThis header information provides essential context for interpreting the validation results, especially when sharing reports with stakeholders or reviewing historical validations.\n\n\nReport Footer\nThe report footer contains a timestamp showing when the interrogation was performed. This timestamp helps track when data quality checks were executed, which is especially useful when archiving reports or monitoring data quality over time.\n\n\n\n\n\n\nNote\n\n\n\nThroughout this documentation, the footer is hidden in example reports for brevity. This is controlled through a global option (see the section on controlling header and footer display later in this guide). In practice, including the footer provides valuable timestamp information for tracking when validations were executed.\n\n\n\n\nReport Columns\nThe validation report table includes the following columns, each providing specific information about the validation steps:\n\nStatus Indicator (first column, unlabeled)\nThe first column is an unlabeled vertical colored bar that provides instant visual feedback about each step’s status:\n\nGreen: all test units passed the validation\nLight green (semi-transparent): some test units failed but no thresholds were exceeded\nGray: the ‘warning’ threshold was exceeded\nYellow: the ‘error’ threshold was exceeded\nRed: the ‘critical’ threshold was exceeded\n\nThis visual indicator allows you to quickly scan the report and identify problem areas.\n\n\nStep Number (second column, unlabeled)\nThe second column is unlabeled and contains the sequential step number, starting from 1. This number is used when referencing specific steps in other methods like get_step_report(i=2) or when extracting data from specific validation steps.\n\n\nTYPE\nThe TYPE column displays the validation method name along with an icon that visually represents the type of validation being performed. The validation method indicates what aspect of data quality is being checked, such as:\n\ncol_vals_gt(): column values greater than\ncol_vals_in_set(): column values in a set\ncol_exists(): column existence check\nrows_distinct(): row uniqueness check\nand many others…\n\nWhen you provide a brief message (via brief=True for auto-generated briefs or brief=\"custom text\" for custom messages), it appears within the TYPE column below the validation method name. These briefs provide human-readable explanations of what each validation step is checking, making the report more accessible to non-technical stakeholders.\n\n# Example showing brief messages in the TYPE column\nvalidation_with_briefs = (\n    pb.Validate(data=data, tbl_name=\"sales_data\")\n    .col_vals_gt(\n        columns=\"value\",\n        value=50,\n        brief=\"Sales values should always exceed the $50 threshold\"\n    )\n    .col_vals_in_set(\n        columns=\"category\",\n        set=[\"A\", \"B\", \"C\"],\n        brief=True  # Auto-generated brief\n    )\n    .interrogate()\n)\n\nvalidation_with_briefs\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:17:43Polarssales_data\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Sales values should always exceed the $50 threshold\n\n        \n    value\n    50\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Expect that values in category should be in the set of A, B, C.\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n\n  \n  \n  \n    2025-11-23 00:17:43 UTC&lt; 1 s2025-11-23 00:17:43 UTC\n  \n\n\n\n\n\n\n        \n\n\nIn the above report, you’ll see the custom brief message appear below the col_vals_gt method name in the first step, and an automatically generated brief below col_vals_in_set in the second step.\n\n\nCOLUMNS\nThe column(s) being validated in this step. For validation methods that don’t target specific columns (like row_count_match), this will show an em dash (—).\n\n\nVALUES\nThe comparison value(s) or criteria used in the validation. For example:\n\nfor col_vals_gt(value=100), this shows 100\nfor col_vals_in_set(set=[\"A\", \"B\", \"C\"]), this shows A | B | C\nfor existence checks, this shows an em dash (—)\n\n\n\nTBL\nIcons indicating whether any preprocessing or segmentation was applied:\n\nTable icon: standard validation on the original data\nTransformation icon: preprocessing function was applied via pre=\nSegmentation icon: data was segmented via segments=\n\nThese icons help you understand if you’re validating transformed or segmented data.\n\n\nEVAL\nIndicates whether the validation step was evaluated:\n\nCheckmark: step was successfully evaluated\nError icon: an evaluation error occurred (e.g., column not found)\nInactive icon: step was marked as inactive\n\nThis column is crucial for identifying validation steps that couldn’t be executed properly.\n\n\nUNITS\nThe number of units tested in this validation step. A ‘test unit’ is the atomic unit being validated, which varies by validation type:\n\nfor column value checks: each cell in the target column(s)\nfor row checks: each row\nfor table checks: typically 1 (the table itself)\n\nThis number is formatted with locale-appropriate thousand separators for readability. Also, since space is limited, values are often abbreviated so a figure like 43,534 will appear as 43.5K.\n\n\nPASS\nThe number and fraction of test units that passed the validation, displayed as:\nn_passed\nf_passed\nFor example, the cell with\n8\n0.80\nmeans 8 test units passed out of the total, representing an 80% success rate (though f_passed is always expressed as a fractional value from 0 to 1).\n\n\nFAIL\nThe number and fraction of test units that failed the validation, displayed similarly to PASS:\nn_failed\nf_failed\nFor example, the cell with\n2\n0.20\nmeans 2 test units failed, representing a 20% failure rate from a fractional value of 0.20. Note that this fractional f_failed value is what’s used to set failure thresholds for ‘warning’, ‘error’, and ‘critical’ states.\n\n\nW, E, C (Warning, Error, Critical)\nThree columns showing whether each threshold level was exceeded for the three different states.\n\nLong dash: threshold wasn’t set for a state\nEmpty colored circle: threshold was set but wasn’t exceeded for a given state\nFilled colored circle: threshold was set and exceeded\n\nIn terms of colors, the ‘warning’ state is gray, the ‘error’ state is yellow, and the ‘critical’ state is red.\nHaving visual indicators makes it easy to identify which validation steps have crossed into warning, error, or critical territory.\n\n\nEXT\nIndicates whether failing row data was extracted for this step:\n\nEm dash (—): no extract available\nDownload button: click to download failing rows as CSV\n\nWhen extracts are available, you can download them directly from the report for further analysis or to share with data stewards who need to fix the issues.",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Validation Reports"
    ]
  },
  {
    "objectID": "user-guide/validation-reports.html#understanding-validation-status",
    "href": "user-guide/validation-reports.html#understanding-validation-status",
    "title": "Validation Reports",
    "section": "Understanding Validation Status",
    "text": "Understanding Validation Status\nThe validation report helps you quickly understand the overall status of your data:\n\nAll green status indicators: all validations passed completely\nLight green indicators: minor failures below warning threshold\nGray, yellow, or red indicators: threshold exceedances requiring attention\nError icons in EVAL column: validation steps that couldn’t be evaluated\n\nBy scanning the status indicators column, you can immediately identify which validation steps need attention and prioritize your data quality efforts accordingly.",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Validation Reports"
    ]
  },
  {
    "objectID": "user-guide/validation-reports.html#customizing-the-report-title",
    "href": "user-guide/validation-reports.html#customizing-the-report-title",
    "title": "Validation Reports",
    "section": "Customizing the Report Title",
    "text": "Customizing the Report Title\nYou can customize the validation report’s title using the title= parameter in get_tabular_report(). This is particularly useful when generating multiple reports or when you want to provide more context:\n\n# Default title\nvalidation.get_tabular_report()\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:17:42Polarssales_data\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Expect that values in value should be &gt; 50.\n\n        \n    value\n    50\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Expect that values in category should be in the set of A, B, C.\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column id exists.\n\n        \n    id\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column value exists.\n\n        \n    value\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:17:42 UTC&lt; 1 s2025-11-23 00:17:42 UTC\n  \n\n\n\n\n\n\n        \n\n\n\n# Use the table name as the title\nvalidation.get_tabular_report(title=\":tbl_name:\")\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    sales_data\n  \n  \n    2025-11-23|00:17:42Polarssales_data\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Expect that values in value should be &gt; 50.\n\n        \n    value\n    50\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Expect that values in category should be in the set of A, B, C.\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column id exists.\n\n        \n    id\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column value exists.\n\n        \n    value\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:17:42 UTC&lt; 1 s2025-11-23 00:17:42 UTC\n  \n\n\n\n\n\n\n        \n\n\n\n# Provide a custom title (supports Markdown)\nvalidation.get_tabular_report(title=\"**Sales Data** Quality Report\")\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Sales Data Quality Report\n\n  \n  \n    2025-11-23|00:17:42Polarssales_data\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Expect that values in value should be &gt; 50.\n\n        \n    value\n    50\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Expect that values in category should be in the set of A, B, C.\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column id exists.\n\n        \n    id\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column value exists.\n\n        \n    value\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:17:42 UTC&lt; 1 s2025-11-23 00:17:42 UTC\n  \n\n\n\n\n\n\n        \n\n\n\n# No title\nvalidation.get_tabular_report(title=\":none:\")\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    \n  \n  \n    2025-11-23|00:17:42Polarssales_data\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Expect that values in value should be &gt; 50.\n\n        \n    value\n    50\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Expect that values in category should be in the set of A, B, C.\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column id exists.\n\n        \n    id\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column value exists.\n\n        \n    value\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:17:42 UTC&lt; 1 s2025-11-23 00:17:42 UTC\n  \n\n\n\n\n\n\n        \n\n\nThe title customization options are:\n\n\":default:\" (default): shows \"Pointblank Validation\"\n\":tbl_name:\": uses the table name from tbl_name= parameter\n\":none:\": hides the title completely\nAny string: custom title text (Markdown is supported)",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Validation Reports"
    ]
  },
  {
    "objectID": "user-guide/validation-reports.html#customizing-with-great-tables",
    "href": "user-guide/validation-reports.html#customizing-with-great-tables",
    "title": "Validation Reports",
    "section": "Customizing with Great Tables",
    "text": "Customizing with Great Tables\nSince the validation report is a Great Tables object, you can leverage the full power of Great Tables to customize its appearance. This allows you to match your organization’s branding, highlight specific information, or adjust the presentation for different audiences.\n\nGuide to Internal Column Names\nWhen working with Great Tables methods to customize the validation report, you’ll need to use the internal column names rather than the display labels you see in the rendered table. This is because Great Tables operates on the underlying data table structure, where columns have technical names that differ from their user-facing labels.\nFor example, the column labeled \"STEP\" in the report is actually stored internally as \"i\", and the \"TYPE\" column is internally named \"type_upd\". Most Great Tables methods that target specific columns (like tab_style(), cols_width(), cols_hide(), etc.) require these internal names.\nHere’s the complete mapping from display labels to internal column names:\n\nStatus indicator (no label): \"status_color\"\nStep number (no label): \"i\"\nTYPE: \"type_upd\"\nCOLUMNS: \"columns_upd\"\nVALUES: \"values_upd\"\nTBL: \"tbl\"\nEVAL: \"eval\"\nUNITS: \"test_units\"\nPASS: \"pass\"\nFAIL: \"fail\"\nW: \"w_upd\"\nE: \"e_upd\"\nC: \"c_upd\"\nEXT: \"extract_upd\"\n\nAlways use these internal names when calling Great Tables methods. Using the display labels (like \"STEP\" or \"TYPE\") will result in errors since these labels only exist in the rendered output, not in the underlying data structure.\nIn the examples that follow, you’ll see how to use these internal column names to customize various aspects of the validation report.\n\n\nAdding Custom Styling\nYou can apply custom styles to the report table:\n\nfrom great_tables import style, loc\n\n# Get the report as a Great Tables object\nreport = validation.get_tabular_report()\n\n# Add custom styling using internal column names\nreport = (\n    report\n    .tab_style(\n        style=style.fill(color=\"#F0F8FF\"),\n        locations=loc.body(columns=\"i\")  # Internal name for step number\n    )\n    .tab_style(\n        style=style.text(weight=\"bold\"),\n        locations=loc.body(columns=\"type_upd\")  # Internal name for TYPE\n    )\n)\n\nreport\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:17:42Polarssales_data\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Expect that values in value should be &gt; 50.\n\n        \n    value\n    50\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Expect that values in category should be in the set of A, B, C.\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column id exists.\n\n        \n    id\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column value exists.\n\n        \n    value\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:17:42 UTC&lt; 1 s2025-11-23 00:17:42 UTC\n  \n\n\n\n\n\n\n        \n\n\n\n\nModifying Column Widths\nAdjust column widths to optimize the layout:\n\nreport = (\n    validation\n    .get_tabular_report()\n    .cols_width(\n        cases={\n            \"status_color\": \"20px\", # Status indicator column\n            \"i\": \"40px\",            # Step number column\n            \"type_upd\": \"170px\",    # TYPE column\n            \"columns_upd\": \"100px\", # COLUMNS column\n        }\n    )\n)\n\nreport\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:17:42Polarssales_data\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Expect that values in value should be &gt; 50.\n\n        \n    value\n    50\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Expect that values in category should be in the set of A, B, C.\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column id exists.\n\n        \n    id\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column value exists.\n\n        \n    value\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:17:42 UTC&lt; 1 s2025-11-23 00:17:42 UTC\n  \n\n\n\n\n\n\n        \n\n\n\n\nHiding Columns\nHide specific columns that aren’t relevant for your audience:\n\n# Hide the TBL and EVAL columns for a cleaner presentation (using internal names)\nreport = (\n    validation\n    .get_tabular_report()\n    .cols_hide(columns=[\"tbl\", \"eval\"])  # Use internal column names\n)\n\nreport\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:17:42Polarssales_data\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Expect that values in value should be &gt; 50.\n\n        \n    value\n    50\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Expect that values in category should be in the set of A, B, C.\n\n        \n    category\n    A, B, C\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column id exists.\n\n        \n    id\n    —\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column value exists.\n\n        \n    value\n    —\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:17:42 UTC&lt; 1 s2025-11-23 00:17:42 UTC\n  \n\n\n\n\n\n\n        \n\n\n\n\nAdding a Source Note\nAdd information about data source or validation context:\n\nreport = (\n    validation\n    .get_tabular_report()\n    .tab_source_note(\n        source_note=\"Data validated on 2025-10-10 | Production database snapshot\"\n    )\n)\n\nreport\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:17:42Polarssales_data\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Expect that values in value should be &gt; 50.\n\n        \n    value\n    50\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Expect that values in category should be in the set of A, B, C.\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column id exists.\n\n        \n    id\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column value exists.\n\n        \n    value\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:17:42 UTC&lt; 1 s2025-11-23 00:17:42 UTC\n  \n\n\n  \n    Data validated on 2025-10-10 | Production database snapshot",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Validation Reports"
    ]
  },
  {
    "objectID": "user-guide/validation-reports.html#exporting-the-report",
    "href": "user-guide/validation-reports.html#exporting-the-report",
    "title": "Validation Reports",
    "section": "Exporting the Report",
    "text": "Exporting the Report\nGreat Tables provides multiple export options for sharing validation reports:\n# Save as a standalone HTML file\nvalidation.get_tabular_report().write_raw_html(\"validation_report.html\")\n\n# Save as a PNG image\nvalidation.get_tabular_report().save(\"validation_report.png\")\n\n# Open in browser\nvalidation.get_tabular_report().show(\"browser\")",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Validation Reports"
    ]
  },
  {
    "objectID": "user-guide/validation-reports.html#controlling-header-and-footer-display",
    "href": "user-guide/validation-reports.html#controlling-header-and-footer-display",
    "title": "Validation Reports",
    "section": "Controlling Header and Footer Display",
    "text": "Controlling Header and Footer Display\nYou can control whether the header and footer appear in the validation report:\n\n# Hide the footer\nvalidation.get_tabular_report(incl_footer=False)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:17:42Polarssales_data\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Expect that values in value should be &gt; 50.\n\n        \n    value\n    50\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Expect that values in category should be in the set of A, B, C.\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column id exists.\n\n        \n    id\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column value exists.\n\n        \n    value\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\n\n# Hide the header\nvalidation.get_tabular_report(incl_header=False)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Expect that values in value should be &gt; 50.\n\n        \n    value\n    50\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Expect that values in category should be in the set of A, B, C.\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column id exists.\n\n        \n    id\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column value exists.\n\n        \n    value\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:17:42 UTC&lt; 1 s2025-11-23 00:17:42 UTC\n  \n\n\n\n\n\n\n        \n\n\n\n# Hide both\nvalidation.get_tabular_report(incl_header=False, incl_footer=False)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Expect that values in value should be &gt; 50.\n\n        \n    value\n    50\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Expect that values in category should be in the set of A, B, C.\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column id exists.\n\n        \n    id\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column value exists.\n\n        \n    value\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nYou can also set these preferences globally using pb.config():\n# Set global preferences\npb.config(report_incl_header=True, report_incl_footer=False)",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Validation Reports"
    ]
  },
  {
    "objectID": "user-guide/validation-reports.html#best-practices-for-validation-reports",
    "href": "user-guide/validation-reports.html#best-practices-for-validation-reports",
    "title": "Validation Reports",
    "section": "Best Practices for Validation Reports",
    "text": "Best Practices for Validation Reports\nHere are some guidelines for creating effective validation reports:\n\n1. Use Descriptive Table Names and Labels\nProvide meaningful names and labels to make reports self-documenting:\nvalidation = pb.Validate(\n    data=sales_df,\n    tbl_name=\"Q3_2025_sales\",\n    label=\"Quarterly sales data validation for financial reporting\"\n)\n\n\n2. Add Brief Messages for Stakeholder Reports\nWhen sharing reports with non-technical stakeholders, always include briefs:\n.col_vals_between(\n    columns=\"price\",\n    left=0, right=10000,\n    brief=\"Product prices must be between $0 and $10,000\"\n)\n\n\n3. Set Appropriate Thresholds\nConfigure thresholds that align with your data quality requirements:\nvalidation = pb.Validate(\n    data=data,\n    tbl_name=\"customer_data\",\n    thresholds=pb.Thresholds(\n        warning=0.01,  # 1% failure triggers warning\n        error=0.05,    # 5% failure triggers error\n        critical=0.10  # 10% failure triggers critical\n    )\n)\n\n\n4. Customize for Your Audience\nTailor the report presentation to your audience:\n\nTechnical teams: include all columns, show preprocessing indicators\nManagement: hide technical columns, emphasize status indicators\nData stewards: include extract download buttons, detailed briefs\n\n\n\n5. Combine with Other Reporting Tools\nUse validation reports alongside other Pointblank features:\n\nStep reports: drill down into specific failing steps with get_step_report()\nExtracts: use get_data_extracts() to get all failing data for analysis\nSundered data: use get_sundered_data() to split data into passing/failing sets\n\n\n\n6. Archive Reports for Trend Analysis\nSave validation reports over time to track data quality trends:\nfrom datetime import datetime\n\n# Save with timestamp\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nvalidation.get_tabular_report().write_raw_html(f\"validation_report_{timestamp}.html\")",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Validation Reports"
    ]
  },
  {
    "objectID": "user-guide/validation-reports.html#conclusion",
    "href": "user-guide/validation-reports.html#conclusion",
    "title": "Validation Reports",
    "section": "Conclusion",
    "text": "Conclusion\nThe validation report is your primary interface for understanding data quality after running a validation. By providing a comprehensive overview of all validation steps, visual status indicators, and detailed statistics, it enables you to:\n\nquickly assess overall data quality across multiple dimensions\nidentify specific validation steps that need attention\ncommunicate data quality status to technical and non-technical stakeholders\ntrack threshold exceedances and their severity levels\naccess failing data through extract downloads\n\nCombined with customization options from Great Tables, you can create reports that perfectly match your organization’s needs and workflows. Whether you’re validating data in an interactive notebook, generating automated quality reports, or presenting findings to stakeholders, the validation report provides the clarity and detail you need to maintain high data quality standards.",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Validation Reports"
    ]
  },
  {
    "objectID": "user-guide/mcp-quick-start.html",
    "href": "user-guide/mcp-quick-start.html",
    "title": "MCP Quick Start",
    "section": "",
    "text": "Transform your data validation workflow with conversational AI in VS Code or Positron IDE. Here are three simple steps to start validating data through conversation (and no complex configuration required).",
    "crumbs": [
      "Get Started",
      "MCP Server",
      "MCP Quick Start"
    ]
  },
  {
    "objectID": "user-guide/mcp-quick-start.html#essential-commands",
    "href": "user-guide/mcp-quick-start.html#essential-commands",
    "title": "MCP Quick Start",
    "section": "Essential Commands",
    "text": "Essential Commands\nMaster these five command patterns and you’ll be able to handle most data validation scenarios. Think of these as your fundamental vocabulary for talking to Pointblank.\n\nLoad Data\n\"Load the file /path/to/data.csv\"\n\"Load my Netflix dataset from the working directory\"\n\"Load the CSV file with sales metrics\"\n\"Load customer_data.csv as my main dataset\"\n\n\nExplore Data\n\"Analyze the data for netflix_data\"\n\"Show me a preview of the loaded data\"\n\"Create a column summary table\"\n\"Generate a missing values analysis\"\nWhat you’ll get: Comprehensive data profiling with statistics including missing values, data types, distributions, and summary statistics for each column. The preview and summary tables are automatically generated as beautiful HTML files that open in your browser. This gives you a complete picture of your dataset’s structure and characteristics before you define quality rules.\n\n\nCheck Quality\n\"Create a validator for netflix_data\"\n\"Add validation that ratings are between 0 and 10\"\n\"Check that all release years are reasonable\"\n\"Apply the basic_quality template\"\nWhat you’ll get: Actual data quality validation that checks your data against business rules and domain knowledge. This tells you if your data meets your specific quality requirements and identifies rows that fail validation criteria.\n\n\nCreate Data Validations\n\"Add validation that show_id values are unique\"\n\"Check that cast field is not empty for movies\"\n\"Ensure vote_count is greater than 0\"\n\"Validate that country field follows ISO format\"\nWhat you’ll get: Individual validation rules added to your validator. Each rule tests a specific business requirement and can be customized with thresholds and actions.\n\n\nRun and Export\n\"Run the validation and show results\"\n\"Export validation failures to CSV\"\n\"Get failed rows for step 2\"\n\"Save the validation report\"",
    "crumbs": [
      "Get Started",
      "MCP Server",
      "MCP Quick Start"
    ]
  },
  {
    "objectID": "user-guide/mcp-quick-start.html#top-three-use-cases",
    "href": "user-guide/mcp-quick-start.html#top-three-use-cases",
    "title": "MCP Quick Start",
    "section": "Top Three Use Cases",
    "text": "Top Three Use Cases\nOnce you have Pointblank set up, these scenarios show the most common and powerful ways to use natural language data validation. Each example demonstrates the conversational flow and immediate value you’ll experience.\n\n1. 📊 Quick Data Check\nWhen: You get a new dataset\n👤 \"I just got netflix_data.csv. Is it clean?\"\n🤖 \"Loading dataset... Found 16,000 movies/shows with 18 columns.\n    Quality analysis complete:\n    - ✅ No duplicate show IDs\n    - ⚠️ 466 missing countries (2.9%)\n    - ⚠️ 132 missing directors (0.8%)\n    Opening data preview in your browser...\"\n\n\n2. 🔄 Daily Validation\nWhen: Regular data quality checks\n👤 \"Apply the basic_quality template to my data\"\n🤖 \"Creating validator with basic quality checks...\n    ✅ Data types validated\n    ✅ Missing value thresholds checked\n    ✅ Duplicate detection passed\n    Validation complete! All checks passed.\"\n\n\n3. 🚨 Issue Investigation\nWhen: Something looks wrong\n👤 \"Show me movies with ratings above 9.5\"\n🤖 \"Creating validator for high ratings...\n    Found 47 entries with ratings &gt; 9.5\n    Exporting suspicious rows to CSV\n    Most are documentaries - could be valid!\"\nThese examples show how natural conversation can quickly identify and resolve data quality issues that might take hours to diagnose manually.",
    "crumbs": [
      "Get Started",
      "MCP Server",
      "MCP Quick Start"
    ]
  },
  {
    "objectID": "user-guide/mcp-quick-start.html#core-capabilities",
    "href": "user-guide/mcp-quick-start.html#core-capabilities",
    "title": "MCP Quick Start",
    "section": "Core Capabilities",
    "text": "Core Capabilities\nPointblank’s MCP server provides powerful tools for comprehensive data validation with beautiful, interactive HTML reports:\n\nData Exploration\n\nInteractive HTML previews with automatic browser opening showing head/tail rows\nColumn summary tables with detailed statistics and color-coded data types\nMissing values analysis with visual patterns and percentages\nData quality analysis with comprehensive profiling insights\n\n\n\nValidation Workflows\n\nValidator creation with flexible thresholds and configuration\nMany validation types for comprehensive data quality checking\nStep-by-step validation building with natural language commands\nTemplate-based validation for common data quality patterns\n\n\n\nHTML Reports & Analysis\n\nInteractive validation reports automatically opened in your browser\nTimestamped HTML files for easy sharing and documentation\nPython code generation for reproducible validation scripts\n\nAll interactions use natural language, making advanced data validation accessible to users at any technical level while producing publication-ready HTML reports.",
    "crumbs": [
      "Get Started",
      "MCP Server",
      "MCP Quick Start"
    ]
  },
  {
    "objectID": "user-guide/mcp-quick-start.html#common-validation-rules",
    "href": "user-guide/mcp-quick-start.html#common-validation-rules",
    "title": "MCP Quick Start",
    "section": "Common Validation Rules",
    "text": "Common Validation Rules\nUnderstanding what validation rules to ask for will help you quickly build comprehensive data quality checks. These examples cover the most frequent validation scenarios using Pointblank’s built-in validation functions.\n\nData Integrity\n\n“Check for duplicate show IDs”\n“Ensure no missing required fields like title”\n“Validate that release years are between 1900 and 2025”\n\n\n\nBusiness Logic\n\n“Ratings must be between 0 and 10”\n“Budget must be positive numbers”\n“Duration should be greater than 0”\n\n\n\nCross-Field Validation\n\n“Release year should match date_added year”\n“Vote count should correlate with popularity”\n“Movies should have directors specified”\n\n\n\nAvailable Templates\nPointblank includes pre-built validation templates:\n\nbasic_quality - Essential data quality checks\nfinancial_data - Money and numeric validations\ncustomer_data - Personal information validations\nsensor_data - Time series and measurement checks\nsurvey_data - Response and rating validations\n\nThese rule patterns can be combined and customized for your specific data and business requirements. The natural language interface makes it easy to express complex validation logic without learning technical syntax.",
    "crumbs": [
      "Get Started",
      "MCP Server",
      "MCP Quick Start"
    ]
  },
  {
    "objectID": "user-guide/mcp-quick-start.html#some-tips-and-tricks",
    "href": "user-guide/mcp-quick-start.html#some-tips-and-tricks",
    "title": "MCP Quick Start",
    "section": "Some Tips and Tricks",
    "text": "Some Tips and Tricks\nThese recommendations will help you get more value from your Pointblank MCP server and avoid some common pitfalls.\n\nTalk Naturally\n✅ Good: “Check if customer emails look valid”\n❌ Avoid: “Execute col_vals_regex on email column”\n\n\nProvide Context\n✅ Good: “This is for the board presentation”\n❌ Avoid: Just asking for validation without explanation\n\n\nBuild Incrementally\n\nStart with data profiling\nAdd basic validation rules\nCreate templates for reuse\nSet up automated checks\n\n\n\nSave Templates\n\"Save these rules as 'customer_validation'\"\n\"Apply the financial_data template\"\n\"Use our standard survey validation\"\n\n\nInteractive Visual Tables\nPointblank automatically generates beautiful, interactive HTML tables for data exploration:\n\"Show me a preview of the data\"\n\"Generate a column summary table\"\n\"Create a missing values analysis\"\nThese commands create professional HTML tables with:\n\nColor-coded data types (numeric in purple, text in yellow)\nGradient styling tailored to each table type\nAutomatic browser opening for immediate viewing\nTimestamped files for easy reference and sharing\n\nThe tables open automatically in your default browser, making it easy to share data insights with colleagues or include in presentations.\nThese practices help you build data quality workflows that scale with your needs while remaining accessible to those with varying technical backgrounds.",
    "crumbs": [
      "Get Started",
      "MCP Server",
      "MCP Quick Start"
    ]
  },
  {
    "objectID": "user-guide/mcp-quick-start.html#file-support",
    "href": "user-guide/mcp-quick-start.html#file-support",
    "title": "MCP Quick Start",
    "section": "File Support",
    "text": "File Support\nPointblank works with many major data file formats, making it easy to validate data regardless of how it’s stored. This support means you can maintain consistent validation practices across your entire data ecosystem.\n\n\n\nType\nExtensions\nExample\nBackend Support\n\n\n\n\nCSV\n.csv\nsales_data.csv\npandas, polars\n\n\nParquet\n.parquet\nbig_data.parquet\npandas, polars\n\n\nJSON\n.json\napi_response.json\npandas, polars\n\n\nJSON Lines\n.jsonl\nstreaming_data.jsonl\npandas, polars\n\n\n\nThe consistent natural language interface works the same regardless of file format, so you can focus on validation logic rather than technical details. Polars provides faster processing for large datasets, while Pandas offers broader format support.",
    "crumbs": [
      "Get Started",
      "MCP Server",
      "MCP Quick Start"
    ]
  },
  {
    "objectID": "user-guide/mcp-quick-start.html#quick-troubleshooting",
    "href": "user-guide/mcp-quick-start.html#quick-troubleshooting",
    "title": "MCP Quick Start",
    "section": "Quick Troubleshooting",
    "text": "Quick Troubleshooting\nWhen you encounter issues, these quick fixes resolve the most common problems. Furthermore, the natural language interface means you can always ask for help and explanations.\n\n\n\n\n\n\n\nProblem\nQuick Fix\n\n\n\n\n“File not found”\nUse absolute path: /Users/name/Downloads/data.csv\n\n\n“DataFrame not found”\nCheck loaded datasets with “List my loaded dataframes”\n\n\n“Validator not found”\nUse “List active validators” to see available validators\n\n\n“Validation too slow”\nTry “Use pandas backend” or sample your data first\n\n\n“HTML tables won’t open”\nCheck your default browser settings\n\n\n“Need validation ideas”\nAsk “Show me validation templates” or “Suggest validations for my data”\n\n\n\nBrowser Issues: The HTML tables automatically open in your default browser. If they don’t appear, check that your browser isn’t blocking pop-ups and that you have a default browser set in your system preferences.\nRemember, you can always ask the AI to explain what’s happening or suggest solutions when you run into problems.",
    "crumbs": [
      "Get Started",
      "MCP Server",
      "MCP Quick Start"
    ]
  },
  {
    "objectID": "user-guide/mcp-quick-start.html#now-youre-ready",
    "href": "user-guide/mcp-quick-start.html#now-youre-ready",
    "title": "MCP Quick Start",
    "section": "Now You’re Ready!",
    "text": "Now You’re Ready!\nYou now have everything needed to start validating data through conversation. The beauty of Pointblank’s MCP server is that it grows with your expertise: start simple and gradually build more sophisticated validation workflows as you become comfortable with the interface.\nStart with simple commands and build up to more complex validation workflows. The AI will guide you through the process and help you create robust data quality checks!",
    "crumbs": [
      "Get Started",
      "MCP Server",
      "MCP Quick Start"
    ]
  },
  {
    "objectID": "user-guide/assertions.html",
    "href": "user-guide/assertions.html",
    "title": "Assertions",
    "section": "",
    "text": "In addition to validation steps that create reports, Pointblank provides assertions. This is a lightweight way to confirm data quality by raising exceptions when validation conditions aren’t met. Assertions are particularly useful in:",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Assertions"
    ]
  },
  {
    "objectID": "user-guide/assertions.html#basic-assertion-workflow",
    "href": "user-guide/assertions.html#basic-assertion-workflow",
    "title": "Assertions",
    "section": "Basic Assertion Workflow",
    "text": "Basic Assertion Workflow\nThe assertion workflow uses your familiar validation steps with assertion methods to check that validations meet your requirements:\n\nimport pointblank as pb\nimport polars as pl\n\n# Create sample data\nsample_data = pl.DataFrame({\n    \"id\": [1, 2, 3, 4, 5],\n    \"value\": [10.5, 8.3, -2.1, 15.7, 7.2]\n})\n\n# Create a validation plan and assert that all steps pass\n(\n    pb.Validate(data=sample_data)\n    .col_vals_gt(columns=\"id\", value=0, brief=\"IDs must be positive\")\n    .col_vals_gt(columns=\"value\", value=-5, brief=\"Values should exceed -5\")\n\n    # Will automatically `interrogate()` and raise an AssertionError if any validation fails ---\n    .assert_passing()\n)\n\nThis simple pattern allows you to integrate data quality checks into your data pipelines. With it, you can create clear stopping points when data doesn’t meet specified criteria.",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Assertions"
    ]
  },
  {
    "objectID": "user-guide/assertions.html#assertion-methods",
    "href": "user-guide/assertions.html#assertion-methods",
    "title": "Assertions",
    "section": "Assertion Methods",
    "text": "Assertion Methods\nPointblank offers two types of assertions:\n\nFull Passing Assertions: using assert_passing() to verify that every single test unit passes\nThreshold-Based Assertions: using assert_below_threshold() to verify that failure rates stay within acceptable thresholds\n\n\nassert_passing()\nThe assert_passing() method is the strictest form of assertion, requiring every single validation test unit to pass:\n\ntry:\n    (\n        pb.Validate(data=sample_data)\n        .col_vals_gt(columns=\"value\", value=0)\n\n        # Direct assertion: automatically interrogates ---\n        .assert_passing()\n    )\nexcept AssertionError as e:\n    print(\"AssertionError:\", str(e))\n\nAssertionError: The following assertions failed:\n- Step 1: Expect that values in `value` should be &gt; `0`.\n\n\n\n\nassert_below_threshold()\nThe assert_below_threshold() method is more flexible as it allows some failures as long as they stay below specified threshold levels. Pointblank uses three severity thresholds that increase in order of seriousness:\n\n‘warning’ (least severe): the first threshold that gets triggered when failures exceed this level\n‘error’ (more severe): the middle threshold indicating more serious data quality issues\n‘critical’ (most severe): the highest threshold indicating critical data quality problems\n\n\n# Create a two-column DataFrame for this example\ntbl_pl = pl.DataFrame({\n    \"a\": [4, 6, 9, 7, 12, 8, 7, 12, 10, 7],\n    \"b\": [9, 8, 10, 5, 10, 9, 14, 6, 6, 8],\n\n})\n\n# Set thresholds: warning=0.2 (20%), error=0.3 (30%), critical=0.4 (40%)\nvalidation = (\n    pb.Validate(data=tbl_pl, thresholds=(0.2, 0.3, 0.4))\n    .col_vals_gt(columns=\"b\", value=5)   # 1/10 failing (10% failure rate)\n    .col_vals_lt(columns=\"a\", value=11)  # 2/10 failing (20% failure rate)\n    .col_vals_ge(columns=\"b\", value=8)   # 3/10 failing (30% failure rate)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:17:23PolarsWARNING0.2ERROR0.3CRITICAL0.4\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    b\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    90.90\n    10.10\n    ○\n    ○\n    ○\n    CSV\n  \n  \n    #AAAAAA\n    2\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    a\n    11\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    ●\n    ○\n    ○\n    CSV\n  \n  \n    #EBBC14\n    3\n    \n        \n            \n\n    col_vals_ge\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_ge()\n        \n        \n        \n    b\n    8\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    70.70\n    30.30\n    ●\n    ●\n    ○\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe validation report above visually indicates threshold levels with colored circles:\n\ngray circles in the W column indicate the ‘warning’ threshold\nyellow circles in the E column indicate the ‘error’ threshold\nred circles in the C column indicate the ‘critical’ threshold\n\nThis won’t pass the assert_below_threshold() assertion for the ‘error’ level because step 3 exceeds this threshold (30% failure rate matches the error threshold):\n\ntry:\n    validation.assert_below_threshold(level=\"error\")\nexcept AssertionError as e:\n    print(\"AssertionError:\", str(e))\n\nAssertionError: The following steps exceeded the error threshold level:\nStep 3: Expect that values in `b` should be &gt;= `8`.\n\n\nWe can check against the ‘error’ threshold for specific steps with the i= parameter:\n\nvalidation.assert_below_threshold(level=\"error\", i=[1, 2])\n\nThis passes because the highest threshold exceeded in steps 1 and 2 is ‘warning’.\nThe assert_below_threshold() method takes these parameters:\n\nlevel=: threshold level to check against (\"warning\", \"error\", or \"critical\")\ni=: optional specific step number(s) to check\nmessage=: optional custom error message\n\nThis is particularly useful when:\n\nworking with real-world data where some percentage of failures is acceptable\nimplementing different severity levels for data quality rules\ngradually improving data quality with stepped thresholds\n\n\n\n\n\n\n\nNote\n\n\n\nAssertion methods like assert_passing() and assert_below_threshold() will automatically call interrogate() if needed, so you don’t have to explicitly include this step when using assertions directly.",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Assertions"
    ]
  },
  {
    "objectID": "user-guide/assertions.html#using-status-check-methods",
    "href": "user-guide/assertions.html#using-status-check-methods",
    "title": "Assertions",
    "section": "Using Status Check Methods",
    "text": "Using Status Check Methods\nIn addition to assertion methods that raise exceptions, Pointblank provides status check methods that return boolean values:\n\nall_passed()\nThe all_passed() method will return True only if every single test unit in every validation step passed:\n\nvalidation = (\n    pb.Validate(data=sample_data)\n    .col_vals_gt(columns=\"value\", value=0)\n    .interrogate()\n)\n\nif not validation.all_passed():\n    print(\"Validation failed: some values are not positive\")\n\nValidation failed: some values are not positive\n\n\n\n\nwarning(), error(), and critical()\nThe methods warning(), error(), and critical() all return information about whether validation steps exceeded that specific threshold level.\nWhile assertion methods raise exceptions to halt execution when thresholds are exceeded, these status methods give you fine-grained control to implement custom logic based on different validation quality levels.\n\nvalidation = (\n    pb.Validate(data=sample_data, thresholds=(0.05, 0.10, 0.20))\n    .col_vals_gt(columns=\"value\", value=0)  # Some values are negative\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:17:23PolarsWARNING0.05ERROR0.1CRITICAL0.2\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #FF3300\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    value\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    40.80\n    10.20\n    ●\n    ●\n    ●\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe warning() method returns a dictionary mapping step numbers to boolean values. A True value means that step exceeds the warning threshold:\n\n# Get dictionary of warning status for each step\nwarning_status = validation.warning()\nprint(f\"Warning status: {warning_status}\")  # {1: True} means step 1 exceeds warning threshold\n\nWarning status: {1: True}\n\n\nYou can check a specific step using the i= parameter, and get a single boolean with scalar=True:\n\n# Check error threshold for specific step\nhas_errors = validation.error(i=1, scalar=True)\n\nif has_errors:\n    print(\"Step 1 exceeded the error threshold.\")\n\nStep 1 exceeded the error threshold.\n\n\nSimilarly, we can check if any steps exceed the ‘critical’ threshold:\n\n# Check against critical threshold\ncritical_status = validation.critical()\nprint(f\"Critical status: {critical_status}\")\n\nCritical status: {1: True}\n\n\nThese methods are particularly useful for:\n\nConditional logic: taking different actions based on threshold severity\nReporting: generating summary reports about validation quality\nMonitoring: tracking data quality trends over time\nGraceful degradation: implementing fallback logic when quality decreases\n\nEach method has these options:\n\nwithout parameters: returns a dictionary mapping step numbers to boolean status values\nwith i=: check specific step(s)\nwith scalar=True: return a single boolean instead of a dictionary (when checking a specific step)\n\nWhile assertion methods raise exceptions to halt execution when thresholds are exceeded, these methods give you fine-grained control to implement custom logic based on different validation quality levels.",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Assertions"
    ]
  },
  {
    "objectID": "user-guide/assertions.html#customizing-error-messages",
    "href": "user-guide/assertions.html#customizing-error-messages",
    "title": "Assertions",
    "section": "Customizing Error Messages",
    "text": "Customizing Error Messages\nYou can provide custom error messages when assertions fail to make them more meaningful in your specific workflow context:\n\n# Create a validation with potential failures\nvalidation = (\n    pb.Validate(data=sample_data, thresholds=(0.2, 0.3, 0.4))\n    .col_vals_gt(columns=\"value\", value=0)\n    .interrogate()\n)\n\n# Display the validation results\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:17:24PolarsWARNING0.2ERROR0.3CRITICAL0.4\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #AAAAAA\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    value\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    40.80\n    10.20\n    ●\n    ○\n    ○\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nWhen you need to customize the error message that appears when an assertion fails, use the message= parameter:\n\ntry:\n    # Custom message for threshold assertion\n    validation.assert_below_threshold(\n        level=\"warning\",\n        message=\"Data quality too low for processing!\"\n    )\nexcept AssertionError as e:\n    print(f\"Custom handling of failure: {e}\")\n\nCustom handling of failure: Data quality too low for processing!\n\n\nDescriptive error messages are essential in production systems where multiple team members might need to interpret validation failures. The custom message lets you provide context appropriate to your specific workflow or data pipeline stage.",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Assertions"
    ]
  },
  {
    "objectID": "user-guide/assertions.html#combining-assertions-with-actions",
    "href": "user-guide/assertions.html#combining-assertions-with-actions",
    "title": "Assertions",
    "section": "Combining Assertions with Actions",
    "text": "Combining Assertions with Actions\nActions and assertions serve complementary but distinct purposes in data validation workflows:\n\nActions trigger during validation but shouldn’t raise errors (as this would halt report generation)\nAssertions are designed to raise errors based on specific conditions, making them ideal for flow control after validation completes\n\nHere’s a simplified example showing how to use them together. The print statements simulate logging or monitoring that would be valuable in production data pipelines:\n\n# Define a simple action function (won't raise errors)\ndef notify_quality_issue(message=\"Data quality issue detected\"):\n    print(f\"ACTION TRIGGERED: {message}\")\n\n# Create data with known failures\nproblem_data = pl.DataFrame({\n    \"id\": [1, 2, 3, -4, 5],  # One negative ID\n    \"value\": [10.5, 8.3, -2.1, 15.7, 7.2]  # One negative value\n})\n\n# First use actions for automated responses during validation\nprint(\"Running validation with actions...\")\nvalidation = (\n    pb.Validate(data=problem_data, thresholds=(0.1, 0.2, 0.3))\n    .col_vals_gt(\n        columns=\"id\", value=0,\n        brief=\"IDs must be positive\",\n        actions=pb.Actions(warning=notify_quality_issue)\n    )\n    .interrogate()  # Actions trigger here but won't stop report generation\n)\n\n# Then use assertions after validation for workflow control\nprint(\"\\nNow using assertion for flow control...\")\ntry:\n    validation.assert_below_threshold(level=\"warning\")\n    print(\"This line won't execute if the assertion fails\")\nexcept AssertionError as e:\n    print(f\"Validation failed threshold check: {e}\")\n    print(\"Implementing fallback process...\")\n\nRunning validation with actions...\nACTION TRIGGERED: Data quality issue detected\n\nNow using assertion for flow control...\nValidation failed threshold check: The following steps exceeded the warning threshold level:\nStep 1: Expect that values in `id` should be &gt; `0`.\nImplementing fallback process...\n\n\nThis approach gives you the best of both worlds:\n\nActions provide immediate notification during validation without interrupting the process\nAssertions control workflow execution after validation when important thresholds are exceeded\n\nThis pattern works well in data pipelines where you want both: (1) automated responses during validation and (2) clear decision points after validation is complete.",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Assertions"
    ]
  },
  {
    "objectID": "user-guide/assertions.html#best-practices-for-assertions",
    "href": "user-guide/assertions.html#best-practices-for-assertions",
    "title": "Assertions",
    "section": "Best Practices for Assertions",
    "text": "Best Practices for Assertions\nWhen using assertions in your data workflows, consider these best practices:\n\nChoose the right assertion type:\n\nuse assert_passing() for critical validations where any failure is unacceptable\nuse assert_below_threshold() for validations where some failure rate is acceptable\n\nSet appropriate thresholds that match your data quality requirements:\n# Example threshold strategy\nvalidation = pb.Validate(\n    data=sample_data,\n    # warning at 1%, error at 5%, critical at 10%\n    thresholds=pb.Thresholds(warning=0.01, error=0.05, critical=0.10)\n)\nUse a graduated approach to validation severity:\n# Critical validations: must be perfect\nvalidation_1.assert_passing()\n\n# Important validations: must be below error threshold\nvalidation_2.assert_below_threshold(level=\"error\")\n\n# Monitor-only validations: check warning status\nwarning_status = validation_3.warning()\nPlacement in pipelines: place assertions at critical points where data quality is essential\nError handling: wrap assertions in try-except blocks for better error handling in production systems\nCombine with reporting: use both assertions and reporting approaches for comprehensive quality control",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Assertions"
    ]
  },
  {
    "objectID": "user-guide/assertions.html#conclusion",
    "href": "user-guide/assertions.html#conclusion",
    "title": "Assertions",
    "section": "Conclusion",
    "text": "Conclusion\nPointblank’s assertion methods give you flexible options for enforcing data quality requirements:\n\nassert_passing() for strict validation where every test unit must pass\nassert_below_threshold() for more flexible validation where some failures are tolerable\nStatus methods (warning(), error(), and critical()) for programmatic threshold checking\n\nBy using these assertion methods appropriately, you can build robust data pipelines with different levels of quality enforcement (from strict validation of critical data properties to more lenient checks for less critical aspects). This graduated approach to data quality helps create systems that are both reliable and practical in real-world data environments.",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Assertions"
    ]
  },
  {
    "objectID": "user-guide/sundering.html",
    "href": "user-guide/sundering.html",
    "title": "Sundering Validated Data",
    "section": "",
    "text": "Sundering data? First off, let’s get the correct meaning across here. Sundering is really just splitting, dividing, cutting into two pieces. And it’s a useful thing we can do in Pointblank to any data that we are validating. When you interrogate the data, you learn about which rows have test failures within them. With more validation steps, we get an even better picture of this simply by virtue of more testing.\nThe power of sundering lies in its ability to separate your data into two distinct categories:\nThis approach allows you to:\nLet’s use the small_table in our examples to show just how sundering is done. Here’s that table:\nPolarsRows13Columns8\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05\n    6\n    8-kdg-938\n    3\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    None\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09\n    8\n    3-ldm-038\n    7\n    283.94\n    True\n    low\n  \n  \n    6\n    2016-01-11 06:15:00\n    2016-01-11\n    4\n    2-dhe-923\n    4\n    3291.03\n    True\n    mid\n  \n  \n    7\n    2016-01-15 18:46:00\n    2016-01-15\n    7\n    1-knw-093\n    3\n    843.34\n    True\n    high\n  \n  \n    8\n    2016-01-17 11:27:00\n    2016-01-17\n    4\n    5-boe-639\n    2\n    1035.64\n    False\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26\n    4\n    2-dmx-010\n    7\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28\n    2\n    7-dmx-010\n    8\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30\n    1\n    3-dka-303\n    None\n    2230.09\n    True\n    high",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Sundering Validated Data"
    ]
  },
  {
    "objectID": "user-guide/sundering.html#a-simple-example-where-data-is-torn-asunder",
    "href": "user-guide/sundering.html#a-simple-example-where-data-is-torn-asunder",
    "title": "Sundering Validated Data",
    "section": "A Simple Example Where Data is Torn Asunder",
    "text": "A Simple Example Where Data is Torn Asunder\nWe’ll begin with a very simple validation plan, having only a single step. There will be failing test units here.\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\"))\n    .col_vals_ge(columns=\"d\", value=1000)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_ge\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_ge()\n        \n        \n        \n    d\n    1000\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    70.54\n    60.46\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nWe see six failing test units in FAIL column of the above validation report table. There is a data extract (collection of failing rows) available. Let’s use the get_data_extracts() method to have a look at it.\n\nvalidation.get_data_extracts(i=1, frame=True)\n\n\nshape: (6, 9)_row_num_date_timedateabcdefu32datetime[μs]datei64stri64f64boolstr52016-01-09 12:36:002016-01-098\"3-ldm-038\"7283.94true\"low\"72016-01-15 18:46:002016-01-157\"1-knw-093\"3843.34true\"high\"92016-01-20 04:30:002016-01-203\"5-bce-642\"9837.93false\"high\"102016-01-20 04:30:002016-01-203\"5-bce-642\"9837.93false\"high\"112016-01-26 20:07:002016-01-264\"2-dmx-010\"7833.98true\"low\"122016-01-28 02:51:002016-01-282\"7-dmx-010\"8108.34false\"low\"\n\n\nThis is six rows of data that had failing test units in column d. Indeed we can see that all values in that column are less than 1000 (and we asserted that values should be greater than or equal to 1000). This is the ‘bad’ data, if you will. Using the get_sundered_data() method, we get the ‘good’ part:\n\nvalidation.get_sundered_data()\n\n\nshape: (7, 8)date_timedateabcdefdatetime[μs]datei64stri64f64boolstr2016-01-04 11:00:002016-01-042\"1-bcd-345\"33423.29true\"high\"2016-01-04 00:32:002016-01-043\"5-egh-163\"89999.99true\"low\"2016-01-05 13:32:002016-01-056\"8-kdg-938\"32343.23true\"high\"2016-01-06 17:23:002016-01-062\"5-jdo-903\"null3892.4false\"mid\"2016-01-11 06:15:002016-01-114\"2-dhe-923\"43291.03true\"mid\"2016-01-17 11:27:002016-01-174\"5-boe-639\"21035.64false\"low\"2016-01-30 11:23:002016-01-301\"3-dka-303\"null2230.09true\"high\"\n\n\nThis is a Polars DataFrame of seven rows. All values in d were passing test units (i.e., fulfilled the expectation outlined in the validation step) and, in many ways, this is like a ‘good extract’.\nYou can always collect the failing rows with get_sundered_data() by using the type=\"fail\" option. Let’s try that here:\n\nvalidation.get_sundered_data(type=\"fail\")\n\n\nshape: (6, 8)date_timedateabcdefdatetime[μs]datei64stri64f64boolstr2016-01-09 12:36:002016-01-098\"3-ldm-038\"7283.94true\"low\"2016-01-15 18:46:002016-01-157\"1-knw-093\"3843.34true\"high\"2016-01-20 04:30:002016-01-203\"5-bce-642\"9837.93false\"high\"2016-01-20 04:30:002016-01-203\"5-bce-642\"9837.93false\"high\"2016-01-26 20:07:002016-01-264\"2-dmx-010\"7833.98true\"low\"2016-01-28 02:51:002016-01-282\"7-dmx-010\"8108.34false\"low\"\n\n\nIt gives us the same rows as in the DataFrame obtained from using validation.get_data_extracts(i=1, frame=True). Two important things to know about get_sundered_data() are that the table rows returned from type=pass (the default) and type=fail are:\n\nthe sum of rows across these returned tables will be equal to that of the original table\nthe rows in each split table are mutually exclusive (i.e., you won’t find the same row in both)\n\nYou can think of sundered data as a filtered version of the original dataset based on validation results. While the simple example illustrates how this process works on a basic level, the value of the method is better seen in a slightly more complex example.",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Sundering Validated Data"
    ]
  },
  {
    "objectID": "user-guide/sundering.html#using-get_sundered_data-with-a-more-comprehensive-validation",
    "href": "user-guide/sundering.html#using-get_sundered_data-with-a-more-comprehensive-validation",
    "title": "Sundering Validated Data",
    "section": "Using get_sundered_data() with a More Comprehensive Validation",
    "text": "Using get_sundered_data() with a More Comprehensive Validation\nThe previous example used exactly one validation step. You’re likely to use more than that in standard practice so let’s see how get_sundered_data() works in those common situations. Here’s a validation with three steps:\n\nvalidation_2 = (\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\"))\n    .col_vals_ge(\n        columns=\"d\",\n        value=1000\n    )\n    .col_vals_not_null(columns=\"c\")\n    .col_vals_gt(\n        columns=\"a\",\n        value=2\n    )\n    .interrogate()\n)\n\nvalidation_2\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_ge\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_ge()\n        \n        \n        \n    d\n    1000\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    70.54\n    60.46\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    c\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    3\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    a\n    2\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    90.69\n    40.31\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThere are quite a few failures here across the three validation steps. In the FAIL column of the validation report table, there are 12 failing test units if we were to tally them up. So if the input table has 13 rows in total, does this mean there would be one row in the table returned by get_sundered_data()? Not so:\n\nvalidation_2.get_sundered_data()\n\n\nshape: (4, 8)date_timedateabcdefdatetime[μs]datei64stri64f64boolstr2016-01-04 00:32:002016-01-043\"5-egh-163\"89999.99true\"low\"2016-01-05 13:32:002016-01-056\"8-kdg-938\"32343.23true\"high\"2016-01-11 06:15:002016-01-114\"2-dhe-923\"43291.03true\"mid\"2016-01-17 11:27:002016-01-174\"5-boe-639\"21035.64false\"low\"\n\n\nThere are four rows. This is because the different validation steps tested values in different columns of the table. Some of the failing test units had to have occurred in more than once in certain rows. The rows that didn’t have any failing test units across the three different tests (in three different columns) are the ones seen above. This brings us to the third important thing about the sundering process:\n\nthe absence of test-unit failures in a row across all validation steps means those rows are returned as the ‘passing’ set, all others are placed in the ‘failing’ set\n\nIn validations where many validation steps are used, we can be more confident about the level of data quality for those rows returned in the passing set. But not every type of validation step is considered within this splitting procedure. The next section will explain the rules on that.",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Sundering Validated Data"
    ]
  },
  {
    "objectID": "user-guide/sundering.html#the-validation-methods-considered-when-sundering",
    "href": "user-guide/sundering.html#the-validation-methods-considered-when-sundering",
    "title": "Sundering Validated Data",
    "section": "The Validation Methods Considered When Sundering",
    "text": "The Validation Methods Considered When Sundering\nThe sundering procedure relies on row-level validation types to be used. This makes sense as it’s impossible to judge the quality of a row when using the col_exists() validation method, for example. Luckily, we have many row-level validation methods; here’s a list:\n\ncol_vals_gt()\ncol_vals_lt()\ncol_vals_ge()\ncol_vals_le()\ncol_vals_eq()\ncol_vals_ne()\ncol_vals_between()\ncol_vals_outside()\ncol_vals_in_set()\ncol_vals_not_in_set()\ncol_vals_null()\ncol_vals_not_null()\ncol_vals_regex()\ncol_vals_expr()\nrows_distinct()\nrows_complete()\nconjointly()\n\nThis is the same list of validation methods that are considered when creating data extracts.\nThere are some additional caveats though. Even if using a validation method drawn from the set above, the validation step won’t be used for sundering if:\n\nthe active= parameter for that step has been set to False\nthe pre= parameter has been used\n\nThe first one makes intuitive sense (you decided to skip this validation step entirely), the second one requires some explanation. Using pre= allows you to modify the target table, there’s no easy or practical way to compare rows in a mutated table compared to the original table (e.g., a mutation may drastically reduce the number of rows).",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Sundering Validated Data"
    ]
  },
  {
    "objectID": "user-guide/sundering.html#practical-applications-of-sundering",
    "href": "user-guide/sundering.html#practical-applications-of-sundering",
    "title": "Sundering Validated Data",
    "section": "Practical Applications of Sundering",
    "text": "Practical Applications of Sundering\n\n1. Creating Clean Datasets for Analysis\nOne of the most common use cases for sundering is preparing validated data for downstream analysis:\n\n# Comprehensive validation for analysis-ready data\nanalysis_validation = (\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\"))\n    .col_vals_not_null(columns=[\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"])  # No missing values\n    .col_vals_gt(columns=\"a\", value=0)                          # Positive values only\n    .col_vals_lt(columns=\"d\", value=10000)                      # No extreme outliers\n    .interrogate()\n)\n\n# Extract only the clean data that passed all checks\nclean_data = analysis_validation.get_sundered_data(type=\"pass\")\n\n# Use the clean data for your analysis\npb.preview(clean_data)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows11Columns8\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05\n    6\n    8-kdg-938\n    3\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-09 12:36:00\n    2016-01-09\n    8\n    3-ldm-038\n    7\n    283.94\n    True\n    low\n  \n  \n    5\n    2016-01-11 06:15:00\n    2016-01-11\n    4\n    2-dhe-923\n    4\n    3291.03\n    True\n    mid\n  \n  \n    7\n    2016-01-17 11:27:00\n    2016-01-17\n    4\n    5-boe-639\n    2\n    1035.64\n    False\n    low\n  \n  \n    8\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-26 20:07:00\n    2016-01-26\n    4\n    2-dmx-010\n    7\n    833.98\n    True\n    low\n  \n  \n    11\n    2016-01-28 02:51:00\n    2016-01-28\n    2\n    7-dmx-010\n    8\n    108.34\n    False\n    low\n  \n\n\n\n\n\n\n        \n\n\nThis approach ensures that any subsequent analysis is based on data that meets your quality standards, reducing the risk of misleading results or spurious conclusions due to problematic records. By making validation an explicit step in your analytical workflow, you create a natural quality gate that prevents invalid data from influencing your findings.\n\n\n2. Creating Parallel Workflows for Clean and Problematic Data\nYou can use sundering to create parallel processing paths:\n\n# Get both clean and problematic data\nclean_data = analysis_validation.get_sundered_data(type=\"pass\")\nproblem_data = analysis_validation.get_sundered_data(type=\"fail\")\n\n# Process clean data (in real applications, you'd do more here)\nprint(f\"Clean data size: {len(clean_data)} rows\")\n\n# Log problematic data for investigation\nprint(f\"Problematic data size: {len(problem_data)} rows\")\n\nClean data size: 11 rows\nProblematic data size: 2 rows\n\n\nThis approach enables you to build robust data processing pathways with separate handling for clean and problematic data. In production environments, you could save problematic records to a separate location for further investigation, generate detailed logs of validation failures, and trigger automated notifications to data stewards when issues arise. By establishing clear protocols for handling both data streams, you create a systematic approach to data quality that balances immediate analytical needs with longer-term data improvement goals.\n\n\n3. Data Quality Monitoring and Improvement\nTracking the ratio of passing to failing rows over time can help monitor data quality trends:\n\n# Calculate data quality metrics\ntotal_rows = len(pb.load_dataset(dataset=\"small_table\"))\npassing_rows = len(clean_data)\nquality_score = passing_rows / total_rows\n\nprint(f\"Data quality score: {quality_score:.2%}\")\nprint(f\"Passing rows: {passing_rows} out of {total_rows}\")\n\nData quality score: 84.62%\nPassing rows: 11 out of 13\n\n\nBy tracking these metrics over time, you can measure the impact of your data quality improvement efforts and communicate progress to stakeholders. This approach transforms sundering from a one-time filtering tool into an ongoing data quality management system, where improving the ratio of passing rows becomes a measurable business objective aligned with broader data governance goals.",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Sundering Validated Data"
    ]
  },
  {
    "objectID": "user-guide/sundering.html#best-practices-for-using-sundered-data",
    "href": "user-guide/sundering.html#best-practices-for-using-sundered-data",
    "title": "Sundering Validated Data",
    "section": "Best Practices for Using Sundered Data",
    "text": "Best Practices for Using Sundered Data\nWhen incorporating data sundering into your workflow, consider these best practices:\n\nBe comprehensive in your validation: the more validation steps you include (assuming they’re meaningful), the more confidence you can have in your passing dataset\nDocument your validation criteria: when sharing sundered data with others, always document the criteria used to determine passing rows\nConsider traceability: for audit purposes, it may be valuable to add a column indicating whether a record was originally in the passing or failing set\nBalance strictness and practicality: if you’re too strict with validation rules, you might end up with very few passing rows; consider the appropriate level of strictness for your use case\nUse sundering as part of a pipeline: automate the process of validation, sundering, and subsequent handling of the two resulting datasets\nContinually refine validation rules: as you learn more about your data and domain, update your validation rules to improve the accuracy of your sundering process\n\nBy following these best practices, data scientists and engineers can transform sundering from a simple utility into a strategic component of their data quality framework. When implemented thoughtfully, sundering enables a shift from reactive data cleaning to proactive quality management, where validation criteria evolve alongside your understanding of the data.\nThe ultimate goal isn’t just to separate good data from bad, but to gradually improve your entire dataset over time by addressing the root causes of validation failures that appear in the failing set. This approach turns data validation from a gatekeeper function into a continuous improvement process.",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Sundering Validated Data"
    ]
  },
  {
    "objectID": "user-guide/sundering.html#conclusion",
    "href": "user-guide/sundering.html#conclusion",
    "title": "Sundering Validated Data",
    "section": "Conclusion",
    "text": "Conclusion\nData sundering provides a powerful way to separate your data based on validation results. While the concept is simple (splitting data into passing and failing sets) the feature can very useful in many data workflows. By integrating sundering into your data pipeline, you can:\n\nensure that downstream analysis only works with validated data\ncreate focused datasets for different purposes\nimprove overall data quality through systematic identification and isolation of problematic records\nbuild more robust data pipelines that explicitly handle data quality issues\n\nSo long as you’re aware of the rules and limitations of sundering, you’re likely to find it to be a simple and useful way to filter your input table on the basis of a validation plan, turning data validation from a passive reporting tool into an active component of your data processing workflow.",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Sundering Validated Data"
    ]
  },
  {
    "objectID": "user-guide/validation-methods.html",
    "href": "user-guide/validation-methods.html",
    "title": "Validation Methods",
    "section": "",
    "text": "Pointblank provides a comprehensive suite of validation methods to verify different aspects of your data. Each method creates a validation step that becomes part of your validation plan.\nThese validation methods cover everything from checking column values against thresholds to validating the table structure and detecting duplicates. Combined into validation steps, they form the foundation of your data quality workflow.\nPointblank provides over 25 validation methods to handle diverse data quality requirements. These are grouped into three main categories:\nWithin each of these categories, we’ll walk through several examples showing how each validation method creates steps in your validation plan.\nAnd we’ll use the small_table dataset for all of our examples. Here’s a preview of it:\nPolarsRows13Columns8\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05\n    6\n    8-kdg-938\n    3\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    None\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09\n    8\n    3-ldm-038\n    7\n    283.94\n    True\n    low\n  \n  \n    6\n    2016-01-11 06:15:00\n    2016-01-11\n    4\n    2-dhe-923\n    4\n    3291.03\n    True\n    mid\n  \n  \n    7\n    2016-01-15 18:46:00\n    2016-01-15\n    7\n    1-knw-093\n    3\n    843.34\n    True\n    high\n  \n  \n    8\n    2016-01-17 11:27:00\n    2016-01-17\n    4\n    5-boe-639\n    2\n    1035.64\n    False\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26\n    4\n    2-dmx-010\n    7\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28\n    2\n    7-dmx-010\n    8\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30\n    1\n    3-dka-303\n    None\n    2230.09\n    True\n    high",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Validation Methods"
    ]
  },
  {
    "objectID": "user-guide/validation-methods.html#validation-methods-to-validation-steps",
    "href": "user-guide/validation-methods.html#validation-methods-to-validation-steps",
    "title": "Validation Methods",
    "section": "Validation Methods to Validation Steps",
    "text": "Validation Methods to Validation Steps\nIn Pointblank, validation methods become validation steps when you add them to a validation plan. Each method creates a distinct step that performs a specific check on your data.\nHere’s a simple example showing how three validation methods create three validation steps:\n\nimport pointblank as pb\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n\n    # Step 1: Check that values in column `a` are greater than 2 ---\n    .col_vals_gt(columns=\"a\", value=2, brief=\"Values in 'a' must exceed 2.\")\n\n    # Step 2: Check that column 'date' exists in the table ---\n    .col_exists(columns=\"date\", brief=\"Column 'date' must exist.\")\n\n    # Step 3: Check that the table has exactly 13 rows ---\n    .row_count_match(count=13, brief=\"Table should have exactly 13 rows.\")\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Values in 'a' must exceed 2.\n\n        \n    a\n    2\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    90.69\n    40.31\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Column 'date' must exist.\n\n        \n    date\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    row_count_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            row_count_match()\n        \n        Table should have exactly 13 rows.\n\n        \n    —\n    13\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nEach validation method produces one step in the validation report above. When combined, these steps form a complete validation plan that systematically checks different aspects of your data quality.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Validation Methods"
    ]
  },
  {
    "objectID": "user-guide/validation-methods.html#common-arguments",
    "href": "user-guide/validation-methods.html#common-arguments",
    "title": "Validation Methods",
    "section": "Common Arguments",
    "text": "Common Arguments\nMost validation methods in Pointblank share a set of common arguments that provide consistency and flexibility across different validation types:\n\ncolumns=: specifies which column(s) to validate (used in column-based validations)\npre=: allows data transformation before validation\nsegments=: enables validation across different data subsets\nthresholds=: sets acceptable failure thresholds\nactions=: defines actions to take when validations fail\nbrief=: provides a description of what the validation is checking\nactive=: determines if the validation step should be executed (default is True)\nna_pass=: controls how missing values are handled (only for column value validation methods)\n\nFor column validation methods, the na_pass= parameter determines whether missing values (Null/None/NA) should pass validation (this parameter is covered in a later section).\nThese arguments follow a consistent pattern across validation methods, so you don’t need to memorize different parameter sets for each function. This systematic approach makes Pointblank more intuitive to work with as you build increasingly complex validation plans.\nWe’ll cover most of these common arguments in their own dedicated sections later in the User Guide, as some of them represent a deeper topic worthy of focused attention.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Validation Methods"
    ]
  },
  {
    "objectID": "user-guide/validation-methods.html#column-value-validations",
    "href": "user-guide/validation-methods.html#column-value-validations",
    "title": "Validation Methods",
    "section": "1. Column Value Validations",
    "text": "1. Column Value Validations\nThese methods check individual values within columns against specific criteria:\n\nComparison checks (col_vals_gt(), col_vals_lt(), etc.) for comparing values to thresholds or other columns\nRange checks (col_vals_between(), col_vals_outside()) for verifying that values fall within or outside specific ranges\nSet membership checks (col_vals_in_set(), col_vals_not_in_set()) for validating values against predefined sets\nNull value checks (col_vals_null(), col_vals_not_null()) for testing presence or absence of null values\nPattern matching checks (col_vals_regex(), col_vals_within_spec()) for validating text patterns with regular expressions or against standard specifications\nTrending value checks (col_vals_increasing(), col_vals_decreasing()) for verifying that values increase or decrease as you move down the rows\nCustom expression checks (col_vals_expr()) for complex validations using custom expressions\n\nNow let’s look at some key examples from select categories of column value validations.\n\nComparison Checks\nLet’s start with a simple example of how col_vals_gt() might be used to check if the values in a column are greater than a specified value.\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .col_vals_gt(columns=\"a\", value=5)\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    a\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    30.23\n    100.77\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nIf you’re checking data in a column that contains Null/None/NA values and you’d like to disregard those values (i.e., let them pass validation), you can use na_pass=True. The following example checks values in column c of small_table, which contains two None values:\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .col_vals_le(columns=\"c\", value=10, na_pass=True)\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_le\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_le()\n        \n        \n        \n    c\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nIn the above validation table, we see that all test units passed. If we didn’t use na_pass=True there would be 2 failing test units, one for each None value in the c column.\nIt’s possible to check against column values against values in an adjacent column. To do this, supply the value= argument with the column name within the col() helper function. Here’s an example of that:\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .col_vals_lt(columns=\"a\", value=pb.col(\"c\"))\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    a\n    c\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    60.46\n    70.54\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThis validation checks that values in column a are less than values in column c.\n\n\nChecking of Missing Values\nA very common thing to validate is that there are no Null/NA/missing values in a column. The col_vals_not_null() method checks for the presence of missing values:\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .col_vals_not_null(columns=\"a\")\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    a\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nColumn a has no missing values and the above validation proves this.\n\n\nChecking Strings with Regexes\nA regular expression (regex) validation via the col_vals_regex() validation method checks if values in a column match a specified pattern. Here’s an example with two validation steps, each checking text values in a column:\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .col_vals_regex(columns=\"b\", pattern=r\"^\\d-[a-z]{3}-\\d{3}$\")\n    .col_vals_regex(columns=\"f\", pattern=r\"high|low|mid\")\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    b\n    ^\\d-[a-z]{3}-\\d{3}$\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    f\n    high|low|mid\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\n\n\nChecking Strings Against Specifications\nThe col_vals_within_spec() method validates column values against common data specifications like email addresses, URLs, postal codes, credit card numbers, ISBNs, VINs, and IBANs. This is particularly useful when you need to validate that text data conforms to standard formats:\n\nimport polars as pl\n\n# Create a sample table with various data types\nsample_data = pl.DataFrame({\n    \"isbn\": [\"978-0-306-40615-7\", \"0-306-40615-2\", \"invalid\"],\n    \"email\": [\"test@example.com\", \"user@domain.co.uk\", \"not-an-email\"],\n    \"zip\": [\"12345\", \"90210\", \"invalid\"]\n})\n\n(\n    pb.Validate(data=sample_data)\n    .col_vals_within_spec(columns=\"isbn\", spec=\"isbn\")\n    .col_vals_within_spec(columns=\"email\", spec=\"email\")\n    .col_vals_within_spec(columns=\"zip\", spec=\"postal_code[US]\")\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_within_spec\n    \n        \n            \n            \n                \n            \n        \n    \n\n        \n        \n            col_vals_within_spec()\n        \n        \n        \n    isbn\n    isbn\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    20.67\n    10.33\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_within_spec\n    \n        \n            \n            \n                \n            \n        \n    \n\n        \n        \n            col_vals_within_spec()\n        \n        \n        \n    email\n    email\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    20.67\n    10.33\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    3\n    \n        \n            \n\n    col_vals_within_spec\n    \n        \n            \n            \n                \n            \n        \n    \n\n        \n        \n            col_vals_within_spec()\n        \n        \n        \n    zip\n    postal_code[US]\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    20.67\n    10.33\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\n\n\nChecking for Trending Values\nThe col_vals_increasing() and col_vals_decreasing() validation methods check whether column values are increasing or decreasing as you move down the rows. These are useful for validating time series data, sequential identifiers, or any data where you expect monotonic trends:\n\nimport polars as pl\n\n# Create a sample table with increasing and decreasing values\ntrend_data = pl.DataFrame({\n    \"id\": [1, 2, 3, 4, 5],\n    \"temperature\": [20, 22, 25, 28, 30],\n    \"countdown\": [100, 80, 60, 40, 20]\n})\n\n(\n    pb.Validate(data=trend_data)\n    .col_vals_increasing(columns=\"id\")\n    .col_vals_increasing(columns=\"temperature\")\n    .col_vals_decreasing(columns=\"countdown\")\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_increasing\n    \n        \n            \n            \n                \n            \n        \n    \n\n        \n        \n            col_vals_increasing()\n        \n        \n        \n    id\n    \n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_increasing\n    \n        \n            \n            \n                \n            \n        \n    \n\n        \n        \n            col_vals_increasing()\n        \n        \n        \n    temperature\n    \n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_vals_decreasing\n    \n        \n            \n            \n                \n            \n        \n    \n\n        \n        \n            col_vals_decreasing()\n        \n        \n        \n    countdown\n    \n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe allow_stationary= parameter lets you control whether consecutive identical values should pass validation. By default, stationary values (e.g., [1, 2, 2, 3]) will fail the increasing check, but setting allow_stationary=True will allow them to pass.\n\n\nHandling Missing Values with na_pass=\nWhen validating columns containing Null/None/NA values, you can control how these missing values are treated with the na_pass= parameter:\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .col_vals_le(columns=\"c\", value=10, na_pass=True)\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_le\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_le()\n        \n        \n        \n    c\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nIn the above example, column c contains two None values, but all test units pass because we set na_pass=True. Without this setting, those two values would fail the validation.\nIn summary, na_pass= works like this:\n\nna_pass=True: missing values pass validation regardless of the condition being tested\nna_pass=False (the default): missing values fail validation",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Validation Methods"
    ]
  },
  {
    "objectID": "user-guide/validation-methods.html#row-based-validations",
    "href": "user-guide/validation-methods.html#row-based-validations",
    "title": "Validation Methods",
    "section": "2. Row-based Validations",
    "text": "2. Row-based Validations\nRow-based validations focus on examining properties that span across entire rows rather than individual columns. These are essential for detecting issues that can’t be found by looking at columns in isolation:\n\nrows_distinct(): ensures no duplicate rows exist in the table\nrows_complete(): verifies that no rows contain any missing values\n\nThese row-level validations are particularly valuable for ensuring data integrity and completeness at the record level, which is crucial for many analytical and operational data applications.\n\nChecking Row Distinctness\nHere’s an example where we check for duplicate rows with rows_distinct():\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .rows_distinct()\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    rows_distinct\n    \n        \n            \n            \n                \n                \n                \n            \n        \n    \n\n        \n        \n            rows_distinct()\n        \n        \n        \n    ALL COLUMNS\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    90.69\n    20.15\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nWe can also adapt the rows_distinct() check to use a single column or a subset of columns. To do that, we need to use the columns_subset= parameter. Here’s an example of that:\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .rows_distinct(columns_subset=\"b\")\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    rows_distinct\n    \n        \n            \n            \n                \n                \n                \n            \n        \n    \n\n        \n        \n            rows_distinct()\n        \n        \n        \n    b\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\n\n\nChecking Row Completeness\nAnother important validation is checking for complete rows: rows that have no missing values across all columns or a specified subset of columns. The rows_complete() validation method performs this check.\nHere’s an example checking if all rows in the table are complete (have no missing values in any column):\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .rows_complete()\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    rows_complete\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            rows_complete()\n        \n        \n        \n    ALL COLUMNS\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nAs the report indicates, there are some incomplete rows in the table.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Validation Methods"
    ]
  },
  {
    "objectID": "user-guide/validation-methods.html#table-structure-validations",
    "href": "user-guide/validation-methods.html#table-structure-validations",
    "title": "Validation Methods",
    "section": "3. Table Structure Validations",
    "text": "3. Table Structure Validations\nTable structure validations ensure that the overall architecture of your data meets expectations. These structural checks form a foundation for more detailed data quality assessments:\n\ncol_exists(): verifies a column exists in the table\ncol_schema_match(): ensures table matches a defined schema\ncol_count_match(): confirms the table has the expected number of columns\nrow_count_match(): verifies the table has the expected number of rows\ntbl_match(): validates that the target table matches a comparison table\n\nThese structural validations provide essential checks on the fundamental organization of your data tables, ensuring they have the expected dimensions and components needed for reliable data analysis.\n\nChecking Column Presence\nIf you need to check for the presence of individual columns, the Validate.col_exists() validation method is useful. In this example, we check whether the date column is present in the table:\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .col_exists(columns=\"date\")\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    date\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThat column is present, so the single test unit of this validation step is a passing one.\n\n\nChecking the Table Schema\nFor deeper checks of table structure, a schema validation can be performed with the col_schema_match() validation method, where the goal is to check whether the structure of a table matches an expected schema. To define an expected table schema, we need to use the Schema class. Here is a simple example that (1) prepares a schema consisting of column names, (2) uses that schema object in a col_schema_match() validation step:\n\nschema = pb.Schema(columns=[\"date_time\", \"date\", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\"])\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .col_schema_match(schema=schema)\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_schema_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            col_schema_match()\n        \n        \n        \n    —\n    SCHEMA\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe col_schema_match() validation step will only have a single test unit (signifying pass or fail). We can see in the above validation report that the column schema validation passed.\nMore often, a schema will be defined using column names and column types. We can do that by using a list of tuples in the columns= parameter of Schema. Here’s an example of that approach in action:\n\nschema = pb.Schema(\n    columns=[\n        (\"date_time\", \"Datetime(time_unit='us', time_zone=None)\"),\n        (\"date\", \"Date\"),\n        (\"a\", \"Int64\"),\n        (\"b\", \"String\"),\n        (\"c\", \"Int64\"),\n        (\"d\", \"Float64\"),\n        (\"e\", \"Boolean\"),\n        (\"f\", \"String\"),\n    ]\n)\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .col_schema_match(schema=schema)\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_schema_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            col_schema_match()\n        \n        \n        \n    —\n    SCHEMA\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe col_schema_match() validation method has several boolean parameters for making the checks less stringent:\n\ncomplete=: requires exact column matching (all expected columns must exist, no extra columns allowed)\nin_order=: enforces that columns appear in the same order as defined in the schema\ncase_sensitive_colnames=: column names must match with exact letter case\ncase_sensitive_dtypes=: data type strings must match with exact letter case\n\nThese parameters all default to True, providing strict schema validation. Setting any to False relaxes the validation requirements, making the checks more flexible when exact matching isn’t necessary or practical for your use case.\n\n\nComparing Tables with tbl_match()\nThe tbl_match() validation method provides a comprehensive way to verify that two tables are identical. It performs a progressive series of checks, from least to most stringent:\n\nColumn count match\nRow count match\nSchema match (loose - case-insensitive, any order)\nSchema match (order - columns in correct order)\nSchema match (exact - case-sensitive, correct order)\nData match (cell-by-cell comparison)\n\nThis progressive approach helps identify exactly where tables differ. Here’s an example comparing the small_table dataset with itself:\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .tbl_match(tbl_compare=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    tbl_match\n    \n        \n            \n            \n                \n                \n            \n            \n                \n                \n            \n            \n            \n        \n    \n\n        \n        \n            tbl_match()\n        \n        \n        \n    None\n    EXTERNAL TABLE\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThis validation method is especially useful for:\n\nVerifying that data transformations preserve expected properties\nComparing production data against a golden dataset\nEnsuring data consistency across different environments\nValidating that imported data matches source data\n\n\n\nChecking Counts of Row and Columns\nRow and column count validations check the number of rows and columns in a table.\nUsing row_count_match() checks whether the number of rows in a table matches a specified count.\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .row_count_match(count=13)\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    row_count_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            row_count_match()\n        \n        \n        \n    —\n    13\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe col_count_match() validation method checks if the number of columns in a table matches a specified count.\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .col_count_match(count=8)\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_count_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            col_count_match()\n        \n        \n        \n    —\n    8\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nExpectations on column and row counts can be useful in certain situations and they align nicely with schema checks.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Validation Methods"
    ]
  },
  {
    "objectID": "user-guide/validation-methods.html#ai-powered-validations",
    "href": "user-guide/validation-methods.html#ai-powered-validations",
    "title": "Validation Methods",
    "section": "4. AI-Powered Validations",
    "text": "4. AI-Powered Validations\nAI-powered validations use Large Language Models (LLMs) to validate data based on natural language criteria. This opens up new possibilities for complex validation rules that are difficult to express with traditional programmatic methods.\n\nValidating with Natural Language Prompts\nThe prompt() validation method allows you to describe validation criteria in plain language. The LLM interprets your prompt and evaluates each row, producing pass/fail results just like other Pointblank validation methods.\nThis is particularly useful for:\n\nSemantic checks (e.g., “descriptions should mention a product name”)\nContext-dependent validation (e.g., “prices should be reasonable for the product category”)\nSubjective quality assessments (e.g., “comments should be professional and constructive”)\nComplex rules that would require extensive regex patterns or custom functions\n\nHere’s a simple example that validates whether text descriptions contain specific information:\n\nimport polars as pl\n\n# Create sample data with product descriptions\nproducts = pl.DataFrame({\n    \"product\": [\"Widget A\", \"Gadget B\", \"Tool C\"],\n    \"description\": [\n        \"High-quality widget made in USA\",\n        \"Innovative gadget with warranty\",\n        \"Professional tool\"\n    ],\n    \"price\": [29.99, 49.99, 19.99]\n})\n\n# Validate that descriptions mention quality or features\n(\n    pb.Validate(data=products)\n    .prompt(\n        prompt=\"Each description should mention either quality, features, or warranty\",\n        columns_subset=[\"description\"],\n        model=\"anthropic:claude-sonnet-4-5\"\n    )\n    .interrogate()\n)\n\nThe columns_subset= parameter lets you specify which columns to include in the validation, improving performance and reducing API costs by only sending relevant data to the LLM.\nNote: To use prompt(), you need to have the appropriate API credentials configured for your chosen LLM provider (Anthropic, OpenAI, Ollama, or AWS Bedrock).",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Validation Methods"
    ]
  },
  {
    "objectID": "user-guide/validation-methods.html#conclusion",
    "href": "user-guide/validation-methods.html#conclusion",
    "title": "Validation Methods",
    "section": "Conclusion",
    "text": "Conclusion\nIn this article, we’ve explored the various types of validation methods that Pointblank offers for ensuring data quality. These methods provide a framework for validating column values, checking row properties, verifying table structures, and even using AI for complex semantic validations. By combining these validation methods into comprehensive plans, you can systematically test your data against business rules and quality expectations. And this all helps to ensure your data remains reliable and trustworthy.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Validation Methods"
    ]
  },
  {
    "objectID": "blog/intro-pointblank/index.html",
    "href": "blog/intro-pointblank/index.html",
    "title": "Introducing Pointblank",
    "section": "",
    "text": "If you have tabular data (and who doesn’t?) this is the package for you! I’ve long been interested in data quality and so I’ve spent a lot of time building tooling that makes it possible to perform data quality checks. And there’s so many reasons to care about data quality. If I were to put down just one good reason for why data quality is worth your time it is because having good data quality strongly determines the quality of decisions.\nHaving the ability to distinguish bad data from good data is the first step in solving DQ issues, and the sustained practice of doing data validation will guard against intrusions of poor-quality data. Pointblank has been designed to really help here. Though it’s a fairly new package it is currently quite capable. And it’s available in PyPI, so you can install it by using:"
  },
  {
    "objectID": "blog/intro-pointblank/index.html#how-pointblank-transforms-your-data-validation-workflow",
    "href": "blog/intro-pointblank/index.html#how-pointblank-transforms-your-data-validation-workflow",
    "title": "Introducing Pointblank",
    "section": "How Pointblank Transforms Your Data Validation Workflow",
    "text": "How Pointblank Transforms Your Data Validation Workflow\nWhat sets Pointblank apart is its intuitive, expressive approach to data validation. Rather than writing dozens of ad-hoc checks scattered throughout your codebase, Pointblank lets you define a comprehensive validation plan with just a few lines of code. The fluent API makes your validation intentions crystal clear, whether you’re ensuring numeric values fall within expected ranges, text fields match specific patterns, or relationships between columns remain consistent.\nBut say you find problems. What are you gonna do about it? Well, Pointblank wants to help at not just finding problems but helping you understand them. When validation failures occur, the detailed reporting capabilities (in the form of beautiful, sharable tables) show you exactly where issues are. Right down to the specific rows and columns. This transforms data validation from a binary pass/fail exercise into a super-insightful diagnostic tool.\n\nHere’s the the best part: Pointblank is designed to work with your existing data stack. Whether you’re using Polars, Pandas, DuckDB, or other database systems, Pointblank tries hard to integrate without forcing you to change your workflow. We also have international spoken language support for reporting, meaning that validation reports can be localized to your team’s preferred language. This making data quality accessible to everyone in your organization (like a team sport!).\n\nAlright! Let’s look at a few demonstrations of Pointblank’s capabilities for data validation."
  },
  {
    "objectID": "blog/intro-pointblank/index.html#the-data-validation-workflow",
    "href": "blog/intro-pointblank/index.html#the-data-validation-workflow",
    "title": "Introducing Pointblank",
    "section": "The Data Validation Workflow",
    "text": "The Data Validation Workflow\nLet’s get right to performing a basic check of a Polars DataFrame. We’ll make use of the included small_table dataset.\n\nimport pointblank as pb\n\nsmall_table = pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\")\n\nvalidation_1 = (\n    pb.Validate(\n        data=small_table,\n        tbl_name=\"small_table\",\n        label=\"Example Validation\"\n    )\n    .col_vals_lt(columns=\"a\", value=10)\n    .col_vals_between(columns=\"d\", left=0, right=5000)\n    .col_vals_in_set(columns=\"f\", set=[\"low\", \"mid\", \"high\"])\n    .col_vals_regex(columns=\"b\", pattern=r\"^[0-9]-[a-z]{3}-[0-9]{3}$\")\n    .interrogate()\n)\n\nvalidation_1\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Example ValidationPolarssmall_table\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    a\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_between\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_between()\n        \n        \n        \n    d\n    [0, 5000]\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    120.92\n    10.08\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        \n        \n    f\n    low, mid, high\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    b\n    ^[0-9]-[a-z]{3}-[0-9]{3}$\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:16:50 UTC&lt; 1 s2025-11-23 00:16:50 UTC\n  \n\n\n\n\n\n\n        \n\n\nThere’s a lot to take in here so let’s break down the code first! Note these three key pieces:\n\nthe Validate(data=...) argument takes a DataFrame (or database table) that you want to validate\nthe methods starting with col_* specify validation steps that run on specific columns\nthe interrogate() method executes the validation plan on the table (it’s the finishing step)\n\nThis common pattern is used in a validation workflow, where Validate and interrogate() bookend a validation plan generated through calling validation methods.\nNow, onto the result: it’s a table! Naturally, we’re using the awesome Great Tables package here in Pointblank to really give you the goods on how the validation went down. Each row in this reporting table represents a single validation step (one for each invocation of a col_vals_*() validation method). Generally speaking, the left side of the validation report tables outlines the key validation rules, and the right side provides the results of each validation step.\nWe tried to keep it simple in principle, but a lot of useful information can be packed into this validation table. Here’s a diagram that describes a few of the important parts of the validation report table:\n\nAll of those numbers under the UNITS, PASS, and FAIL columns have to do with test units, a measure of central importance in Pointblank. Each validation step will execute a type of validation test on the target table. For example, a col_vals_lt() validation step can test that each value in a column is less than a specified number. The key finding that’s reported as a result of this test is the number of test units that pass or fail. This little diagram explains what those numbers mean:\n\nFailing test units can be tied to threshold levels, which can provide a better indication of whether failures should raise some basic awareness or spur you into action. Here’s a validation workflow that sets three failure threshold levels that signal the severity of data quality problems:\n\nimport pointblank as pb\nimport polars as pl\n\nvalidation_2 = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"polars\"),\n        tbl_name=\"game_revenue\",\n        label=\"Data validation with threshold levels set.\",\n        thresholds=pb.Thresholds(warning=1, error=20, critical=0.10),\n    )\n    .col_vals_regex(columns=\"player_id\", pattern=r\"^[A-Z]{12}[0-9]{3}$\")        # STEP 1\n    .col_vals_gt(columns=\"session_duration\", value=5)                           # STEP 2\n    .col_vals_ge(columns=\"item_revenue\", value=0.02)                            # STEP 3\n    .col_vals_in_set(columns=\"item_type\", set=[\"iap\", \"ad\"])                    # STEP 4\n    .col_vals_in_set(                                                           # STEP 5\n        columns=\"acquisition\",\n        set=[\"google\", \"facebook\", \"organic\", \"crosspromo\", \"other_campaign\"]\n    )\n    .col_vals_not_in_set(columns=\"country\", set=[\"Mongolia\", \"Germany\"])        # STEP 6\n    .col_vals_between(                                                          # STEP 7\n        columns=\"session_duration\",\n        left=10, right=50,\n        pre = lambda df: df.select(pl.median(\"session_duration\"))\n    )\n    .rows_distinct(columns_subset=[\"player_id\", \"session_id\", \"time\"])          # STEP 8\n    .row_count_match(count=2000)                                                # STEP 9\n    .col_exists(columns=\"start_day\")                                            # STEP 10\n    .interrogate()\n)\n\nvalidation_2\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Data validation with threshold levels set.Polarsgame_revenueWARNING1ERROR20CRITICAL0.1\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    player_id\n    ^[A-Z]{12}[0-9]{3}$\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #AAAAAA\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    session_duration\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    19820.99\n    180.01\n    ●\n    ○\n    ○\n    CSV\n  \n  \n    #EBBC14\n    3\n    \n        \n            \n\n    col_vals_ge\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_ge()\n        \n        \n        \n    item_revenue\n    0.02\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    19410.97\n    590.03\n    ●\n    ●\n    ○\n    CSV\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        \n        \n    item_type\n    iap, ad\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #EBBC14\n    5\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        \n        \n    acquisition\n    google, facebook, organic, crosspromo, other_campaign\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    19750.99\n    250.01\n    ●\n    ●\n    ○\n    CSV\n  \n  \n    #FF3300\n    6\n    \n        \n            \n\n    col_vals_not_in_set\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_in_set()\n        \n        \n        \n    country\n    Mongolia, Germany\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    17750.89\n    2250.11\n    ●\n    ●\n    ●\n    CSV\n  \n  \n    #4CA64C\n    7\n    \n        \n            \n\n    col_vals_between\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_between()\n        \n        \n        \n    session_duration\n    [10, 50]\n    \n    \n        \n            \n            \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #EBBC14\n    8\n    \n        \n            \n\n    rows_distinct\n    \n        \n            \n            \n                \n                \n                \n            \n        \n    \n\n        \n        \n            rows_distinct()\n        \n        \n        \n    player_id, session_id, time\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    19780.99\n    220.01\n    ●\n    ●\n    ○\n    CSV\n  \n  \n    #4CA64C\n    9\n    \n        \n            \n\n    row_count_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            row_count_match()\n        \n        \n        \n    —\n    2000\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C\n    10\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    start_day\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:16:50 UTC&lt; 1 s2025-11-23 00:16:50 UTC\n  \n\n\n\n\n\n\n        \n\n\nThis data validation makes use of the many validation methods available in the library. Because thresholds have been set at the Validate(thresholds=) parameter, we can now see where certain validation steps have greater amounts of failures. Any validation steps with green indicators passed with flying colors, whereas: (1) gray indicates the ‘warning’ condition was met (at least one test unit failing), (2) yellow is for the ‘error’ condition (20 or more test units failing), and (3) red means ‘critical’ and that’s tripped when 10% of all test units are failing ones.\nReporting tables are essential to the package and they help communicate what went wrong (or well) in a validation workflow. Now let’s look at some additional reporting that Pointblank can give you to better understand where things might’ve gone wrong."
  },
  {
    "objectID": "blog/intro-pointblank/index.html#reporting-for-individual-validation-steps",
    "href": "blog/intro-pointblank/index.html#reporting-for-individual-validation-steps",
    "title": "Introducing Pointblank",
    "section": "Reporting for Individual Validation Steps",
    "text": "Reporting for Individual Validation Steps\nThe second validation step of the previous data validation showed 18 failing test units. That translates to 18 spots in a 2,000 row DataFrame where a data quality assertion failed. We often would like to know exactly what that failing data is; it’s usually the next step toward addressing data quality issues.\nPointblank offers a method that gives you a tabular report on a specific step: get_step_report(). The previous tables you’ve seen (the validation report table) dealt with providing a summary of all validation steps. In contrast, a focused report on a single step can help to get to the heart of a data quality issue. Here’s how that looks for Step 2:\n\nvalidation_2.get_step_report(i=2)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 2ASSERTION session_duration &gt; 518 / 2000 TEST UNIT FAILURES IN COLUMN 8 EXTRACT OF FIRST 10 ROWS (WITH TEST UNIT FAILURES IN RED):\n  \n\n  \n  player_idString\n  session_idString\n  session_startDatetime\n  timeDatetime\n  item_typeString\n  item_nameString\n  item_revenueFloat64\n  session_durationFloat64\n  start_dayDate\n  acquisitionString\n  countryString\n\n\n\n  \n    549\n    QNLVRDEOXFYJ892\n    QNLVRDEOXFYJ892-lz5fmr6k\n    2015-01-10 16:44:17+00:00\n    2015-01-10 16:45:29+00:00\n    iap\n    gold3\n    3.49\n    3.7\n    2015-01-09\n    crosspromo\n    Australia\n  \n  \n    620\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-t4y8bjcu\n    2015-01-11 07:24:24+00:00\n    2015-01-11 07:25:18+00:00\n    iap\n    offer4\n    17.991\n    5.0\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    621\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-t4y8bjcu\n    2015-01-11 07:24:24+00:00\n    2015-01-11 07:26:24+00:00\n    iap\n    offer5\n    26.09\n    5.0\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    622\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-t4y8bjcu\n    2015-01-11 07:24:24+00:00\n    2015-01-11 07:28:36+00:00\n    ad\n    ad_15sec\n    0.53\n    5.0\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    663\n    GFLYJHAPMZWD631\n    GFLYJHAPMZWD631-i2v1bl7a\n    2015-01-11 16:13:24+00:00\n    2015-01-11 16:14:54+00:00\n    iap\n    gems2\n    3.99\n    3.6\n    2015-01-09\n    organic\n    India\n  \n  \n    772\n    BFNLURISJXTH647\n    BFNLURISJXTH647-6o5hx27z\n    2015-01-12 17:37:39+00:00\n    2015-01-12 17:39:27+00:00\n    iap\n    offer5\n    11.59\n    4.1\n    2015-01-10\n    organic\n    India\n  \n  \n    773\n    BFNLURISJXTH647\n    BFNLURISJXTH647-6o5hx27z\n    2015-01-12 17:37:39+00:00\n    2015-01-12 17:41:45+00:00\n    iap\n    gems3\n    9.99\n    4.1\n    2015-01-10\n    organic\n    India\n  \n  \n    908\n    KILWZYHRSJEG316\n    KILWZYHRSJEG316-uke7dhqj\n    2015-01-13 22:16:29+00:00\n    2015-01-13 22:17:35+00:00\n    iap\n    offer2\n    10.99\n    3.2\n    2015-01-04\n    organic\n    Denmark\n  \n  \n    1037\n    JUBDVFHCNQWT198\n    JUBDVFHCNQWT198-9h4xs2pb\n    2015-01-14 16:08:25+00:00\n    2015-01-14 16:08:43+00:00\n    iap\n    offer5\n    8.69\n    3.3\n    2015-01-14\n    organic\n    Philippines\n  \n  \n    1038\n    JUBDVFHCNQWT198\n    JUBDVFHCNQWT198-9h4xs2pb\n    2015-01-14 16:08:25+00:00\n    2015-01-14 16:11:01+00:00\n    iap\n    offer4\n    5.99\n    3.3\n    2015-01-14\n    organic\n    Philippines\n  \n\n\n\n\n\n\n        \n\n\nThis report provides the 18 rows where the failure occurred. If you scroll the table to the right you’ll see the column that underwent testing (session_duration) is highlighted in red. All of these values are 5.0 or less, which is in violation of the assertion (in the header) that session_duration &gt; 5.\nThese types of bespoke reports are useful for finding a needle in a haystack. Another good use for a step report is when validating a table schema. Using the col_schema_match() validation method with a table schema prepared with the Schema class allows us to verify our understanding of the table structure. Here is a validation that performs a schema validation with the small_table dataset prepared as a DuckDB table:\n\nimport pointblank as pb\n\n# Create a schema for the target table (`small_table` as a DuckDB table)\nschema = pb.Schema(\n    columns=[\n        (\"date_time\", \"timestamp(6)\"),\n        (\"dates\", \"date\"),\n        (\"a\", \"int64\"),\n        (\"b\",),\n        (\"c\",),\n        (\"d\", \"float64\"),\n        (\"e\", [\"bool\", \"boolean\"]),\n        (\"f\", \"str\"),\n    ]\n)\n\n# Use the `col_schema_match()` validation method to perform a schema check\nvalidation_3 = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"duckdb\"),\n        tbl_name=\"small_table\",\n        label=\"Schema check\"\n    )\n    .col_schema_match(schema=schema)\n    .interrogate()\n)\n\nvalidation_3\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Schema checkDuckDBsmall_table\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_schema_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            col_schema_match()\n        \n        \n        \n    —\n    SCHEMA\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    00.00\n    11.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:16:51 UTC&lt; 1 s2025-11-23 00:16:51 UTC\n  \n\n\n  \n    \nNotes\nStep 1 (schema_check) ✗ Schema validation failed: 1 unmatched column(s), 1 dtype mismatch(es).\n\nSchema Comparison\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n  \n    TARGET\n  \n  \n    EXPECTED\n  \n\n\n  \n  COLUMN\n  DATA TYPE\n  \n  COLUMN\n  \n  DATA TYPE\n  \n\n\n\n  \n    1\n    date_time\n    timestamp(6)\n    1\n    date_time\n    ✓\n    timestamp(6)\n    ✓\n  \n  \n    2\n    date\n    date\n    2\n    dates\n    ✗\n    date\n    —\n  \n  \n    3\n    a\n    int64\n    3\n    a\n    ✓\n    int64\n    ✓\n  \n  \n    4\n    b\n    string\n    4\n    b\n    ✓\n    —\n    \n  \n  \n    5\n    c\n    int64\n    5\n    c\n    ✓\n    —\n    \n  \n  \n    6\n    d\n    float64\n    6\n    d\n    ✓\n    float64\n    ✓\n  \n  \n    7\n    e\n    boolean\n    7\n    e\n    ✓\n    bool | boolean\n    ✓\n  \n  \n    8\n    f\n    string\n    8\n    f\n    ✓\n    str\n    ✗\n  \n\n  \n  \n    Supplied Column Schema:[('date_time', 'timestamp(6)'), ('dates', 'date'), ('a', 'int64'), ('b',), ('c',), ('d', 'float64'), ('e', ['bool', 'boolean']), ('f', 'str')]\n  \n  \n    \nSchema Match Settings\nCOMPLETEIN ORDERCOLUMN ≠ columnDTYPE ≠ dtypefloat ≠ float64\n\n  \n\n\n\n\n\n\n  \n\n\n\n\n\n\n        \n\n\nThis step fails, but the validation report table doesn’t tell us how (or where). Using `get_step_report() will show us what the underlying issues are:\n\nvalidation_3.get_step_report(i=1)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 1 ✗COLUMN SCHEMA MATCHCOMPLETEIN ORDERCOLUMN ≠ columnDTYPE ≠ dtypefloat ≠ float64\n  \n\n  \n    TARGET\n  \n  \n    EXPECTED\n  \n\n\n  \n  COLUMN\n  DATA TYPE\n  \n  COLUMN\n  \n  DATA TYPE\n  \n\n\n\n  \n    1\n    date_time\n    timestamp(6)\n    1\n    date_time\n    ✓\n    timestamp(6)\n    ✓\n  \n  \n    2\n    date\n    date\n    2\n    dates\n    ✗\n    date\n    —\n  \n  \n    3\n    a\n    int64\n    3\n    a\n    ✓\n    int64\n    ✓\n  \n  \n    4\n    b\n    string\n    4\n    b\n    ✓\n    —\n    \n  \n  \n    5\n    c\n    int64\n    5\n    c\n    ✓\n    —\n    \n  \n  \n    6\n    d\n    float64\n    6\n    d\n    ✓\n    float64\n    ✓\n  \n  \n    7\n    e\n    boolean\n    7\n    e\n    ✓\n    bool | boolean\n    ✓\n  \n  \n    8\n    f\n    string\n    8\n    f\n    ✓\n    str\n    ✗\n  \n\n  \n  \n  \n    Supplied Column Schema:[('date_time', 'timestamp(6)'), ('dates', 'date'), ('a', 'int64'), ('b',), ('c',), ('d', 'float64'), ('e', ['bool', 'boolean']), ('f', 'str')]\n  \n\n\n\n\n\n\n        \n\n\nThe step report here shows the target table’s schema on the left side and the expectation of the schema on the right side. There appears to be two problems with our supplied schema:\n\nthe second column is actually date instead of dates\nthe dtype of the f column is \"string\" and not \"str\"\n\nThe convenience of this step report means we only have to look at one display of information, rather than having to collect up the individual pieces and make careful comparisons."
  },
  {
    "objectID": "blog/intro-pointblank/index.html#much-more-in-store",
    "href": "blog/intro-pointblank/index.html#much-more-in-store",
    "title": "Introducing Pointblank",
    "section": "Much More in Store",
    "text": "Much More in Store\nPointblank tries really hard to make it easy for you to test your data. All sorts of input tables are supported since we integrate with the brilliant Narwhals and Ibis libraries. And even through the project has only started four months ago, we already have an extensive catalog of well-tested validation methods.\nWe care a great deal about documentation so much recent effort has been placed on getting the User Guide written. We hope it provides for gentle introduction to the major features of the library. If you want some quick examples to get your imagination going, check out our gallery of examples.\nWe really care about what you want in a validation package, so talk to us :) We just started a Discord so feel free to hop on and ask us anything. Alternatively, we always like to get issues so don’t be shy in letting us know how we could improve!"
  },
  {
    "objectID": "blog/all-about-actions/index.html",
    "href": "blog/all-about-actions/index.html",
    "title": "Level Up Your Data Validation with Actions and FinalActions",
    "section": "",
    "text": "Data validation is only useful if you can respond appropriately when problems arise. That’s why Pointblank’s recent v0.8.0 and v0.8.1 releases have significantly enhanced our action framework, allowing you to create sophisticated, automated responses to validation failures.\nIn this post, we’ll explore how to use:\nLet’s dive into how these features can transform your data validation process from passive reporting to active response."
  },
  {
    "objectID": "blog/all-about-actions/index.html#from-passive-validation-to-active-response",
    "href": "blog/all-about-actions/index.html#from-passive-validation-to-active-response",
    "title": "Level Up Your Data Validation with Actions and FinalActions",
    "section": "From Passive Validation to Active Response",
    "text": "From Passive Validation to Active Response\nTraditional data validation simply reports problems: “Column X has invalid values.” But what if you want to:\n\nsend a Slack message when critical errors occur?\nlog detailed diagnostics about failing data?\ntrigger automatic data cleaning processes?\ngenerate custom reports for stakeholders?\n\nThis is where Pointblank’s action system can help. By pairing thresholds with actions, you can create automated responses that trigger exactly when needed."
  },
  {
    "objectID": "blog/all-about-actions/index.html#getting-started-with-actions",
    "href": "blog/all-about-actions/index.html#getting-started-with-actions",
    "title": "Level Up Your Data Validation with Actions and FinalActions",
    "section": "Getting Started with Actions",
    "text": "Getting Started with Actions\nActions are executed when validation steps fail to meet certain thresholds. Let’s start with a simple example:\n\nimport pointblank as pb\n\nvalidation_1 = (\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\"))\n    .col_vals_gt(\n        columns=\"d\",\n        value=1000,\n        thresholds=pb.Thresholds(warning=1, error=5),\n        actions=pb.Actions(\n            warning=\"⚠️ WARNING: Some values in column 'd' are below the minimum threshold!\"\n        )\n    )\n    .interrogate()\n)\n\nvalidation_1\n\n⚠️ WARNING: Some values in column 'd' are below the minimum threshold!\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:16:40Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #EBBC14\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    1000\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    70.54\n    60.46\n    ●\n    ●\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nIn this example:\n\nwe’re validating that values in column “d” are greater than 1000\nwe set a warning threshold of 1 (triggers if any values fail)\nwe define an action that prints a warning message when the threshold is exceeded\n\nSince several values in column d are below 1000, our ‘warning’ action is triggered and the message appears above the validation report."
  },
  {
    "objectID": "blog/all-about-actions/index.html#the-anatomy-of-actions",
    "href": "blog/all-about-actions/index.html#the-anatomy-of-actions",
    "title": "Level Up Your Data Validation with Actions and FinalActions",
    "section": "The Anatomy of Actions",
    "text": "The Anatomy of Actions\nThe Actions class is a very important piece of Pointblank’s response system. Actions can be defined in several ways:\n\nString messages: simple text output to the console\nCallable functions: custom Python functions that execute when triggered\nLists of strings/callables: multiple actions that execute in sequence\n\nActions can be paired with different severity levels:\n\n‘warning’: for minor issues that need attention\n‘error’: for more significant problems\n‘critical’: for severe issues that require immediate action\n\nThe v0.8.0 release added two (very) useful new parameters:\n\ndefault=: apply the same action to all threshold levels\nhighest_only=: only trigger the action for the highest threshold level reached (True by default)\n\nLet’s see how these work in practice:\n\ndef log_problem():\n    # Simple action that runs when thresholds are exceeded\n    print(\"A validation threshold has been exceeded!\")\n\nvalidation_2 = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\"),\n        thresholds=pb.Thresholds(warning=0.05, error=0.10, critical=0.15),\n        actions=pb.Actions(default=log_problem)  # Apply this action to all threshold levels\n    )\n    .col_vals_regex(\n        columns=\"player_id\",\n        pattern=r\"[A-Z]{12}\\d{3}\"\n    )\n    .col_vals_gt(\n        columns=\"item_revenue\",\n        value=0.10\n    )\n    .interrogate()\n)\n\nvalidation_2\n\nA validation threshold has been exceeded!\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:16:40PolarsWARNING0.05ERROR0.1CRITICAL0.15\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    player_id\n    [A-Z]{12}\\d{3}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #FF3300\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    item_revenue\n    0.1\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    14400.72\n    5600.28\n    ●\n    ●\n    ●\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nIn this example, we’re using a simple function that prints a generic message whenever any threshold is exceeded. By using the Actions(default=) parameter, this same function gets applied to all threshold levels (‘warning’, ‘error’, and ‘critical’). This saves you from having to define separate actions for each level when you want the same behavior for all of them. The highest_only= parameter (True by default, so not shown here) is complementary and it ensures that only the action for the highest threshold level reached will be triggered, preventing multiple notifications for the same validation failure."
  },
  {
    "objectID": "blog/all-about-actions/index.html#dynamic-messages-with-templating",
    "href": "blog/all-about-actions/index.html#dynamic-messages-with-templating",
    "title": "Level Up Your Data Validation with Actions and FinalActions",
    "section": "Dynamic Messages with Templating",
    "text": "Dynamic Messages with Templating\nActions don’t have to be static messages. With Pointblank’s templating system, you can create context-aware notifications that include details about the specific validation failure.\nAvailable placeholders include:\n\n{type}: the validation step type (e.g., \"col_vals_gt\")\n{level}: the threshold level (‘warning’, ‘error’, ‘critical’)\n{step} or {i}: the step number in the validation workflow\n{col} or {column}: the column name being validated\n{val} or {value}: the comparison value used in the validation\n{time}: when the action was executed\n\nYou can also capitalize placeholders (like {LEVEL}) to get uppercase text.\n\naction_template = \"[{LEVEL}] Step {step}: Values in '{column}' failed validation against {value}.\"\n\nvalidation_3 = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\"),\n        thresholds=pb.Thresholds(warning=1, error=4, critical=10),\n        actions=pb.Actions(default=action_template)\n    )\n    .col_vals_lt(\n        columns=\"d\",\n        value=3000\n    )\n    .interrogate()\n)\n\nvalidation_3\n\n[ERROR] Step 1: Values in 'd' failed validation against 3000.\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:16:41PolarsWARNING1ERROR4CRITICAL10\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #EBBC14\n    1\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    d\n    3000\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    90.69\n    40.31\n    ●\n    ●\n    ○\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThis templating approach is a great way to create context-aware notifications that adapt to the specific validation failures occurring. As the example shows, when values in column d fail validation against the limit of 3000, the template automatically generates a meaningful error message showing exactly which step, column, and threshold value was involved."
  },
  {
    "objectID": "blog/all-about-actions/index.html#accessing-metadata-in-custom-action-functions",
    "href": "blog/all-about-actions/index.html#accessing-metadata-in-custom-action-functions",
    "title": "Level Up Your Data Validation with Actions and FinalActions",
    "section": "Accessing Metadata in Custom Action Functions",
    "text": "Accessing Metadata in Custom Action Functions\nFor more sophisticated actions, you often need access to details about the validation failure. The get_action_metadata() function provides this context when called inside an action function:\n\ndef send_detailed_alert():\n    # Get metadata about the validation failure\n    metadata = pb.get_action_metadata()\n\n    # Create a customized alert message\n    print(f\"\"\"\n    VALIDATION FAILURE DETAILS\n    -------------------------\n    Step: {metadata['step']}\n    Column: {metadata['column']}\n    Validation type: {metadata['type']}\n    Severity: {metadata['level']} (level {metadata['level_num']})\n    Time: {metadata['time']}\n\n    Explanation: {metadata['failure_text']}\n    \"\"\")\n\nvalidation_4 = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\"),\n        thresholds=pb.Thresholds(critical=1),\n        actions=pb.Actions(critical=send_detailed_alert)\n    )\n    .col_vals_gt(\n        columns=\"d\",\n        value=5000\n    )\n    .interrogate()\n)\n\nvalidation_4\n\n\n    VALIDATION FAILURE DETAILS\n    -------------------------\n    Step: 1\n    Column: d\n    Validation type: col_vals_gt\n    Severity: critical (level 50)\n    Time: 2025-11-23 00:16:41.159327+00:00\n\n    Explanation: Exceedance of failed test units where values in `d` should have been &gt; `5000`.\n    \n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:16:41PolarsWARNING—ERROR—CRITICAL1\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #FF3300\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    5000\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    10.08\n    120.92\n    —\n    —\n    ●\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe metadata dictionary contains essential fields for a given validation step, including the step number, column name, validation type, severity level, and failure explanation. This gives you complete flexibility to create highly customized responses based on the specific nature of the validation failure."
  },
  {
    "objectID": "blog/all-about-actions/index.html#final-actions-with-finalactions",
    "href": "blog/all-about-actions/index.html#final-actions-with-finalactions",
    "title": "Level Up Your Data Validation with Actions and FinalActions",
    "section": "Final Actions with FinalActions",
    "text": "Final Actions with FinalActions\nWhile regular Actions are great for responding to individual validation steps, sometimes you need to take action based on the overall validation results. This is where the new FinalActions feature from v0.8.1 comes in.\nUnlike regular Actions that trigger during validation, FinalActions execute after all validation steps are complete. FinalActions accepts any number of actions (strings or callables) and executes them in sequence. Each argument can be a string message to display in the console, a callable function, or a list of strings/callables for multiple actions to execute in sequence.\nThe real power of FinalActions comes from the ability to access comprehensive information about your validation results using get_validation_summary(). When called inside a function passed to FinalActions, this function provides a dictionary containing counts of passing/failing steps and test units, threshold levels exceeded, and much more:\n\ndef generate_summary():\n    # Access comprehensive validation results\n    summary = pb.get_validation_summary()\n\n    print(\"\\n=== VALIDATION SUMMARY ===\")\n    print(f\"Total steps: {summary['n_steps']}\")\n    print(f\"Passing steps: {summary['n_passing_steps']}\")\n    print(f\"Failing steps: {summary['n_failing_steps']}\")\n\n    if summary['highest_severity'] == \"critical\":\n        print(\"\\n⚠️ CRITICAL FAILURES DETECTED - immediate action required!\")\n    elif summary['highest_severity'] == \"error\":\n        print(\"\\n⚠️ ERRORS DETECTED - review needed\")\n    elif summary['highest_severity'] == \"warning\":\n        print(\"\\n⚠️ WARNINGS DETECTED - please investigate\")\n    else:\n        print(\"\\n✅ All validations passed!\")\n\nvalidation_5 = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\"),\n        tbl_name=\"small_table\",\n        thresholds=pb.Thresholds(warning=1, error=5, critical=10),\n        final_actions=pb.FinalActions(\n            \"Validation process complete.\",  # A simple string message\n            generate_summary               # Our function using get_validation_summary()\n        )\n    )\n    .col_vals_gt(columns=\"a\", value=1)\n    .col_vals_lt(columns=\"d\", value=10000)\n    .interrogate()\n)\n\nvalidation_5\n\nValidation process complete.\n\n=== VALIDATION SUMMARY ===\nTotal steps: 2\nPassing steps: 1\nFailing steps: 1\n\n⚠️ WARNINGS DETECTED - please investigate\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:16:41Polarssmall_tableWARNING1ERROR5CRITICAL10\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #AAAAAA\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    a\n    1\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    120.92\n    10.08\n    ●\n    ○\n    ○\n    CSV\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    d\n    10000\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe get_validation_summary() function is only available within functions passed to FinalActions. It gives you access to these key dictionary fields:\n\ntbl_name: name of the validated table\nn_steps: total number of validation steps\nn_passing_steps, n_failing_steps: count of passing/failing steps\nn, n_passed, n_failed: total test units and their pass/fail counts\nhighest_severity: the most severe threshold level reached (‘warning’, ‘error’, ‘critical’)\nand many more detailed statistics\n\nThis information allows you to create detailed and specific final actions that can respond appropriately to the overall validation results."
  },
  {
    "objectID": "blog/all-about-actions/index.html#combining-regular-and-final-actions",
    "href": "blog/all-about-actions/index.html#combining-regular-and-final-actions",
    "title": "Level Up Your Data Validation with Actions and FinalActions",
    "section": "Combining Regular and Final Actions",
    "text": "Combining Regular and Final Actions\nYou can use both Actions and FinalActions together for comprehensive control over your validation workflow:\n\ndef step_alert():\n    metadata = pb.get_action_metadata()\n    print(f\"Step {metadata['step']} failed with {metadata['level']} severity\")\n\n\ndef final_summary():\n    summary = pb.get_validation_summary()\n\n    # Get counts by checking each step's status in the dictionaries\n    steps = range(1, summary['n_steps'] + 1)\n    n_critical = sum(1 for step in steps if summary['dict_critical'].get(step, False))\n    n_error = sum(1 for step in steps if summary['dict_error'].get(step, False))\n    n_warning = sum(1 for step in steps if summary['dict_warning'].get(step, False))\n\n    print(f\"\\nValidation complete with:\")\n    print(f\"- {n_critical} critical issues\")\n    print(f\"- {n_error} errors\")\n    print(f\"- {n_warning} warnings\")\n\n\nvalidation_6 = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\"),\n        thresholds=pb.Thresholds(warning=1, error=5, critical=10),\n        actions=pb.Actions(default=step_alert),\n        final_actions=pb.FinalActions(final_summary),\n    )\n    .col_vals_gt(columns=\"a\", value=5)\n    .col_vals_lt(columns=\"d\", value=1000)\n    .interrogate()\n)\n\nvalidation_6\n\nStep 1 failed with critical severity\nStep 2 failed with error severity\n\nValidation complete with:\n- 1 critical issues\n- 2 errors\n- 2 warnings\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:16:41PolarsWARNING1ERROR5CRITICAL10\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #FF3300\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    a\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    30.23\n    100.77\n    ●\n    ●\n    ●\n    CSV\n  \n  \n    #EBBC14\n    2\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    d\n    1000\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    60.46\n    70.54\n    ●\n    ●\n    ○\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThis approach allows you to log individual step failures during the validation process using Actions and generate a comprehensive report after all validation steps are complete using FinalActions. Using both action types gives you fine-grained control over when and how notifications and other actions are triggered in your validation workflow."
  },
  {
    "objectID": "blog/all-about-actions/index.html#real-world-example-building-an-automated-validation-pipeline",
    "href": "blog/all-about-actions/index.html#real-world-example-building-an-automated-validation-pipeline",
    "title": "Level Up Your Data Validation with Actions and FinalActions",
    "section": "Real-World Example: Building an Automated Validation Pipeline",
    "text": "Real-World Example: Building an Automated Validation Pipeline\nLet’s put everything together in a more realistic example. Imagine you’re validating a gaming revenue dataset and want to:\n\nlog detailed information about each failure\nsend a Slack notification if critical failures occur\ngenerate a comprehensive report after validation completes\n\n\ndef log_step_failure():\n    metadata = pb.get_action_metadata()\n    print(f\"[{metadata['level'].upper()}] Step {metadata['step']}: {metadata['failure_text']}\")\n\ndef analyze_results():\n    summary = pb.get_validation_summary()\n\n    # Calculate overall pass rate\n    pass_rate = (summary['n_passing_steps'] / summary['n_steps']) * 100\n\n    print(f\"\\n==== VALIDATION RESULTS ====\")\n    print(f\"Table: {summary['tbl_name']}\")\n    print(f\"Pass rate: {pass_rate:.2f}%\")\n    print(f\"Failing steps: {summary['n_failing_steps']} of {summary['n_steps']}\")\n\n    # In a real scenario, here you might:\n    # 1. Save results to a database\n    # 2. Generate and email an HTML report\n    # 3. Trigger data cleansing workflows\n\n    # Simulate a Slack notification\n    if summary['highest_severity'] == \"critical\":\n        print(\"\\n🚨 [SLACK NOTIFICATION] Critical data quality issues detected!\")\n        print(\"@data-team Please investigate immediately.\")\n\n# Create our validation workflow with actions\nvalidation_7 = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\"),\n        tbl_name=\"game_revenue\",\n        thresholds=pb.Thresholds(warning=0.05, error=0.10, critical=0.15),\n        actions=pb.Actions(default=log_step_failure, highest_only=True),\n        final_actions=pb.FinalActions(analyze_results),\n        brief=True  # Add automatically-generated briefs\n    )\n    .col_vals_regex(\n        columns=\"player_id\",\n        pattern=r\"[A-Z]{12}\\d{3}\",\n        brief=\"Player IDs must follow standard format\"  # Custom brief text\n    )\n    .col_vals_gt(\n        columns=\"item_revenue\",\n        value=0.10\n    )\n    .col_vals_gt(\n        columns=\"session_duration\",\n        value=15\n    )\n    .interrogate()\n)\n\nvalidation_7\n\n[CRITICAL] Step 2: Exceedance of failed test units where values in `item_revenue` should have been &gt; `0.1`.\n[CRITICAL] Step 3: Exceedance of failed test units where values in `session_duration` should have been &gt; `15`.\n\n==== VALIDATION RESULTS ====\nTable: game_revenue\nPass rate: 33.33%\nFailing steps: 2 of 3\n\n🚨 [SLACK NOTIFICATION] Critical data quality issues detected!\n@data-team Please investigate immediately.\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:16:41Polarsgame_revenueWARNING0.05ERROR0.1CRITICAL0.15\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        Player IDs must follow standard format\n\n        \n    player_id\n    [A-Z]{12}\\d{3}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #FF3300\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Expect that values in item_revenue should be &gt; 0.1.\n\n        \n    item_revenue\n    0.1\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    14400.72\n    5600.28\n    ●\n    ●\n    ●\n    CSV\n  \n  \n    #FF3300\n    3\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Expect that values in session_duration should be &gt; 15.\n\n        \n    session_duration\n    15\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    16750.84\n    3250.16\n    ●\n    ●\n    ●\n    CSV"
  },
  {
    "objectID": "blog/all-about-actions/index.html#wrapping-up-from-passive-validation-to-active-data-quality-management",
    "href": "blog/all-about-actions/index.html#wrapping-up-from-passive-validation-to-active-data-quality-management",
    "title": "Level Up Your Data Validation with Actions and FinalActions",
    "section": "Wrapping Up: from Passive Validation to Active Data Quality Management",
    "text": "Wrapping Up: from Passive Validation to Active Data Quality Management\nWith Actions and FinalActions, Pointblank is now more of a complete data quality management system. Instead of just detecting problems, you can now:\n\nrespond immediately to validation failures\ncustomize responses based on severity level\ngenerate comprehensive reports after validation completes\nintegrate with other systems through custom action functions\nautomate workflows based on validation results\n\nThese capabilities transform data validation from a passive reporting activity into an active component of your data pipeline, helping ensure that data quality issues are detected, reported, and addressed efficiently.\nAs we continue to enhance Pointblank, we’d love to hear how you’re using Actions and FinalActions in your workflows. Share your experiences or suggestions with us on Discord or file an issue on GitHub."
  },
  {
    "objectID": "blog/all-about-actions/index.html#learn-more",
    "href": "blog/all-about-actions/index.html#learn-more",
    "title": "Level Up Your Data Validation with Actions and FinalActions",
    "section": "Learn More",
    "text": "Learn More\nExplore our documentation to learn more about Pointblank’s action capabilities:\n\nActions documentation\nFinalActions documentation\nUser Guide on Triggering Actions"
  },
  {
    "objectID": "blog/validation-libs-2025/index.html",
    "href": "blog/validation-libs-2025/index.html",
    "title": "Data Validation Libraries for Polars (2025 Edition)",
    "section": "",
    "text": "Data validation is a very important part of any data pipeline. And with Polars gaining popularity as a superfast and feature-packed DataFrame library, developers need validation tools that work seamlessly with it. But here’s the thing: not all validation libraries are created equal, and choosing the wrong one can lead to frustration, technical debt, or validation gaps that could bite you later.\nIn this survey (conducted halfway through 2025) we’ll explore five Python validation libraries that support Polars DataFrames, each bringing distinct strengths to different validation challenges."
  },
  {
    "objectID": "blog/validation-libs-2025/index.html#recommendations",
    "href": "blog/validation-libs-2025/index.html#recommendations",
    "title": "Data Validation Libraries for Polars (2025 Edition)",
    "section": "Recommendations",
    "text": "Recommendations\nHere are the unique strengths for each library:\n\n\n\n\n\n\n\n\n  Library\n  ⭐\n  Best Features\n\n\n\n  \n    Pandera\n    3,838\n    Statistical testing, schema-centric validation, mypy integration\n  \n  \n    Patito\n    468\n    Pydantic integration, model-based validation, row-level objects\n  \n  \n    Pointblank\n    173\n    Interactive reports, threshold management, stakeholder communication\n  \n  \n    Validoopsie\n    63\n    Built-in logging, composable validation, impact levels, lightweight Great Expectations alternative\n  \n  \n    Dataframely\n    319\n    Collection validation, advanced type safety, failure analysis\n  \n\n\n\n\n\n\n        \n\n\nBased on these strengths, here are my recommendations for which libraries to use according to use case:\n\n\n\n\n\n\n\n\n  Use Case\n  Best Libraries\n  Description\n\n\n\n  \n    Type-safe pipelines\n    Pandera, Dataframely, Patito\n    Static type checking and compile-time validation\n  \n  \n    Stakeholder reporting\n    Pointblank\n    Sharing validation results with non-technical teams\n  \n  \n    Row-level object modeling\n    Patito\n    Converting DataFrame rows to Python objects with business logic\n  \n  \n    Statistical validation\n    Pandera\n    Testing data distributions and statistical properties\n  \n  \n    Data quality improvement\n    Pointblank, Validoopsie\n    Gradual quality improvement with threshold tracking"
  },
  {
    "objectID": "blog/validation-libs-2025/index.html#setup",
    "href": "blog/validation-libs-2025/index.html#setup",
    "title": "Data Validation Libraries for Polars (2025 Edition)",
    "section": "Setup",
    "text": "Setup\nWe are going to run through examples with Pandera, Patito, Pointblank, Validoopsie, and Dataframely, using this Polars DataFrame as our test case:\n\nimport polars as pl\n\n# Standard dataset for all validation examples\nuser_data = pl.DataFrame({\n    \"user_id\": [1, 2, 3, 4, 5],\n    \"age\": [25, 30, 22, 45, 95],  # &lt;- includes a very high age\n    \"email\": [\n        \"user1@example.com\", \"user2@example.com\", \"invalid-email\",  # &lt;- has an invalid email\n        \"user4@example.com\", \"user5@example.com\"\n    ],\n    \"score\": [85.5, 92.0, 78.3, 88.7, 95.2]\n})\n\nWe’ll try to run the same data validation across the surveyed libraries, so we’ll check:\n\nschema validation (correct column types)\nuser_id values greater than 0\nage values between 18 and 80 (inclusive)\nemail strings matching a basic email regex pattern\nscore values between 0 and 100 (inclusive)\n\nNow let’s dive into each library, starting with the statistically-focused Pandera."
  },
  {
    "objectID": "blog/validation-libs-2025/index.html#pandera-schema-first-validation-with-statistical-checks",
    "href": "blog/validation-libs-2025/index.html#pandera-schema-first-validation-with-statistical-checks",
    "title": "Data Validation Libraries for Polars (2025 Edition)",
    "section": "1. Pandera: Schema-First Validation with Statistical Checks",
    "text": "1. Pandera: Schema-First Validation with Statistical Checks\nPandera is a statistical data validation toolkit designed to provide a flexible and expressive API for performing data validation on dataframe-like objects. The library centers on schema-centric validation, where you define the expected structure and constraints of your data upfront. You can enable both runtime validation and static type checking integration. Pandera added Polars support in version 0.19.0 (early 2024).\n\nExample\n\nimport pandera.polars as pa\n\n# Define schema using our standard dataset\nschema = pa.DataFrameSchema({\n    \"user_id\": pa.Column(pl.Int64, checks=pa.Check.gt(0)),\n    \"age\": pa.Column(pl.Int64, checks=[pa.Check.ge(18), pa.Check.le(80)]),\n    \"email\": pa.Column(pl.Utf8, checks=pa.Check.str_matches(r\"^[^@]+@[^@]+\\.[^@]+$\")),\n    \"score\": pa.Column(pl.Float64, checks=pa.Check.in_range(0, 100))\n})\n\n# Validate the schema\ntry:\n    validated_data = schema.validate(user_data)\n    print(\"Validation successful!\")\nexcept pa.errors.SchemaError as e:\n    print(f\"Validation failed: {e}\")\n\nValidation failed: Column 'age' failed validator number 1: &lt;Check less_than_or_equal_to: less_than_or_equal_to(80)&gt; failure case examples: [{'age': 95}]\n\n\nThis example demonstrates Pandera’s declarative approach, where you define what your data should look like rather than writing imperative validation logic. The schema acts as both documentation and as a validation contract. Notice how multiple checks can be applied to a single column (here, the age column receives two checks), and the validation either succeeds completely or provides error information about what failed.\n\n\nComparisons\nBoth Pandera and Patito use declarative, schema-centric approaches, but differ in their design philosophies:\n\nPandera uses a dictionary-like schema structure with Column objects for defining validation rules\nPatito uses Pydantic model classes with familiar Field syntax for validation constraints\nPandera focuses heavily on statistical validation capabilities like hypothesis testing\nPatito emphasizes integration with existing Pydantic workflows and object modeling\na key behavioral difference: Patito reports all validation errors in a single pass, while Pandera stops at the first failure\n\nThe choice between them often comes down to whether you prefer Pandera’s statistical focus or Patito’s Pydantic integration.\nUnlike Pointblank’s step-by-step validation reporting, Pandera validates the entire schema at once. Compared to Patito’s model-based approach, Pandera focuses more on statistical validation capabilities. Unlike Validoopsie’s and Pointblank’s method chaining style, Pandera uses a more declarative, schema-centric approach.\n\n\nUnique Strengths and When to Use\nHere are some of stand-out features that Pandera has:\n\ntype-safe schema definitions with mypy integration\nstatistical hypothesis testing for data distributions: perform t-tests, chi-square tests, and custom statistical tests directly in your validation schema\nexcellent integration with Pandas, Polars, and Arrow support\ndeclarative schema syntax that serves as documentation\nbuilt-in support for data coercion and transformation\n\nThis statistical validation capability goes beyond basic type and range checking to test actual data relationships and distributional assumptions. For example, you can validate that the mean height of group \"M\" is significantly greater than group \"F\" using a two-sample t-test, or test whether a column follows a normal distribution. This makes Pandera uniquely powerful for data science workflows where the statistical properties of your data are as important as individual data points meeting basic constraints.\nData practitioners should choose Pandera when building type-safe data pipelines where schema validation is critical, especially in data science workflows that require statistical validation. It’s ideal for users that value static type checking, need to validate statistical properties of their data, or want schemas that double as documentation.\nPandera also excels in environments where data contracts between teams are important and where the statistical properties of data matter as much as basic type checking."
  },
  {
    "objectID": "blog/validation-libs-2025/index.html#patito-pydantic-style-data-models-for-dataframes",
    "href": "blog/validation-libs-2025/index.html#patito-pydantic-style-data-models-for-dataframes",
    "title": "Data Validation Libraries for Polars (2025 Edition)",
    "section": "2. Patito: Pydantic-Style Data Models for DataFrames",
    "text": "2. Patito: Pydantic-Style Data Models for DataFrames\nPatito brings Pydantic’s well-received model-based validation approach to DataFrame validation, creating a bridge between Pydantic-style data validation and DataFrame processing. The library’s primary goal is to provide a familiar, Pydantic-style interface for defining and validating DataFrame schemas, making it particularly appealing to developers already using Pydantic in their applications.\nPatito launched with Polars support from the beginning (in late 2022). Native Polars integration is touted as one of its core features, reflecting the growing adoption of Polars in the Python ecosystem.\n\nExample\n\nimport patito as pt\nfrom typing import Annotated\n\nclass UserModel(pt.Model):\n    user_id: int = pt.Field(gt=0)\n    age: Annotated[int, pt.Field(ge=18, le=80)]\n    email: str = pt.Field(pattern=r\"^[^@]+@[^@]+\\.[^@]+$\")\n    score: float = pt.Field(ge=0.0, le=100.0)\n\n# Validate using the model\ntry:\n    UserModel.validate(user_data)\n    print(\"Validation successful!\")\nexcept pt.exceptions.DataFrameValidationError as e:\n    print(f\"Validation failed: {e}\")\n\nValidation failed: 2 validation errors for UserModel\nage\n  1 row with out of bound values. (type=value_error.rowvalue)\nemail\n  1 row with out of bound values. (type=value_error.rowvalue)\n\n\nThis example showcases Patito’s model-centric approach where validation rules are embedded in class definitions. The use of Python’s type hints and Pydantic’s Field syntax makes the validation rules self-documenting. Notably, Patito reports all validation errors at once, providing a fairly comprehensive view of data quality issues, whereas other libraries (e.g., Pandera) stop at the first failure.\n\n\nColumn Validation Approaches: Pandera vs Patito\nPandera offers a much more extensive and flexible system for column validation compared to Patito’s field-based approach. While Patito provides a solid set of built-in field constraints (like gt, le, regex, unique, etc.) that cover common validation scenarios, Pandera’s Check system is designed for both simple and highly sophisticated validation logic.\nThe key architectural difference seems to lie in extensibility and complexity. Pandera’s Check objects accept arbitrary functions, allowing you to write custom validation logic that can be as simple as lambda s: s &gt; 0 or as complex as statistical hypothesis tests using scipy. You can create vectorized checks that operate on entire Series objects for performance, element-wise checks for atomic validation, and even grouped checks that validate subsets of data based on other columns. Patito’s Field constraints, while clean and declarative, are more limited to the predefined validation types that Pydantic and Patito provide.\nPandera also supports advanced validation patterns that Patito doesn’t directly offer, such as wide-form data checks (validating relationships across multiple columns), grouped validation (where checks are applied to subsets of data based on grouping columns), and the ability to raise warnings instead of errors for non-critical validation failures. While Patito does support custom constraints through Polars expressions via the constraints parameter, this requires knowledge of Polars expression syntax and, depending on where you’re coming from, could be less intuitive than Pandera’s function-based approach.\nFor most common validation scenarios, Patito’s field-based validation is simpler and more readable, especially for teams already familiar with Pydantic. However, for complex data validation requirements, statistical validation, or when you need maximum flexibility in defining validation logic, Pandera’s Check system provides significantly more power and extensibility.\n\n\nUnique Strengths and When to Use\n\nPydantic-style model definitions with familiar syntax for Pydantic users\nrich type system integration with Python’s typing system\nmodel inheritance and composition for complex data structures\nseamless integration with existing Pydantic-based applications\nrow-level object modeling for converting DataFrame rows to Python objects with methods\nmock data generation for testing with .examples() method\n\nPeople should choose Patito when they’re already using Pydantic in their applications and want consistent validation patterns across data processing and application logic. It’s great when you need to validate DataFrames and then work with individual rows as rich Python objects with embedded business logic and methods (e.g., a Product row that has a .url property or .calculate_discount() method). Patito is also good when you need to generate realistic test data and want object-oriented interfaces for their data models."
  },
  {
    "objectID": "blog/validation-libs-2025/index.html#pointblank-comprehensive-validation-with-beautiful-reports",
    "href": "blog/validation-libs-2025/index.html#pointblank-comprehensive-validation-with-beautiful-reports",
    "title": "Data Validation Libraries for Polars (2025 Edition)",
    "section": "3. Pointblank: Comprehensive Validation with Beautiful Reports",
    "text": "3. Pointblank: Comprehensive Validation with Beautiful Reports\nPointblank is a comprehensive data validation framework designed to make data quality assessment both thorough and accessible to stakeholders. Originally inspired by the R package of the same name, Pointblank’s primary mission is to provide validation workflows that generate beautiful, interactive reports that can be shared with both technical and non-technical team members.\nPointblank launched with Polars support as a core feature from its initial Python release in late 2024, built on top of the Narwhals and Ibis compatibility layers to provide consistent DataFrame operations across multiple backends including Polars, Pandas, and database connections.\n\nExample\n\nimport pointblank as pb\n\nschema = pb.Schema(\n    columns=[(\"user_id\", \"Int64\"), (\"age\", \"Int64\"), (\"email\", \"String\"), (\"score\", \"Float64\")]\n)\n\nvalidation = (\n    pb.Validate(data=user_data, label=\"An example.\", tbl_name=\"users\", thresholds=(0.1, 0.2, 0.3))\n    .col_vals_gt(columns=\"user_id\", value=0)\n    .col_vals_between(columns=\"age\", left=18, right=80)\n    .col_vals_regex(columns=\"email\", pattern=r\"^[^@]+@[^@]+\\.[^@]+$\")\n    .col_vals_between(columns=\"score\", left=0, right=100)\n    .col_schema_match(schema=schema)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    An example.PolarsusersWARNING0.1ERROR0.2CRITICAL0.3\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    user_id\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #EBBC14\n    2\n    \n        \n            \n\n    col_vals_between\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_between()\n        \n        \n        \n    age\n    [18, 80]\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    40.80\n    10.20\n    ●\n    ●\n    ○\n    CSV\n  \n  \n    #EBBC14\n    3\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    email\n    ^[^@]+@[^@]+\\.[^@]+$\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    40.80\n    10.20\n    ●\n    ●\n    ○\n    CSV\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_vals_between\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_between()\n        \n        \n        \n    score\n    [0, 100]\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C\n    5\n    \n        \n            \n\n    col_schema_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            col_schema_match()\n        \n        \n        \n    —\n    SCHEMA\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:16:34 UTC&lt; 1 s2025-11-23 00:16:34 UTC\n  \n\n\n  \n    \nNotes\nStep 5 (schema_check) ✓ Schema validation passed.\n\nSchema Comparison\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n  \n    TARGET\n  \n  \n    EXPECTED\n  \n\n\n  \n  COLUMN\n  DATA TYPE\n  \n  COLUMN\n  \n  DATA TYPE\n  \n\n\n\n  \n    1\n    user_id\n    Int64\n    1\n    user_id\n    ✓\n    Int64\n    ✓\n  \n  \n    2\n    age\n    Int64\n    2\n    age\n    ✓\n    Int64\n    ✓\n  \n  \n    3\n    email\n    String\n    3\n    email\n    ✓\n    String\n    ✓\n  \n  \n    4\n    score\n    Float64\n    4\n    score\n    ✓\n    Float64\n    ✓\n  \n\n  \n  \n    Supplied Column Schema:[('user_id', 'Int64'), ('age', 'Int64'), ('email', 'String'), ('score', 'Float64')]\n  \n  \n    \nSchema Match Settings\nCOMPLETEIN ORDERCOLUMN ≠ columnDTYPE ≠ dtypefloat ≠ float64\n\n  \n\n\n\n\n\n\n  \n\n\n\n\n\n\n        \n\n\nThis example demonstrates Pointblank’s chainable validation approach where each validation step is clearly defined and can be configured with different threshold levels. The resulting validation object provides rich, interactive reporting that shows not just what passed or failed, but detailed statistics about the validation process. The threshold system allows for nuanced responses to data quality issues.\n\n\nComparisons\nUnlike Pandera’s schema-first approach, Pointblank focuses on step-by-step validation with detailed reporting and flexible failure thresholds that can be set at both the global and individual validation step level. Both Pointblank and Validoopsie use numeric threshold values for granular control over acceptable failure rates, but they differ in their primary focus: Pointblank emphasizes comprehensive reporting and stakeholder communication, while Validoopsie prioritizes operational resilience through its impact level system (low/medium/high) that controls whether threshold breaches are logged, reported, or raise exceptions.\nWhile both libraries support custom validation logic, Pointblank’s specially() method integrates seamlessly with its reporting system, whereas Validoopsie provides a structured framework for creating custom validation classes that fit into its modular validation catalog.\n\n\nUnique Strengths and When to Use\n\nbeautiful, interactive HTML reports perfect for sharing with stakeholders\nthreshold-based alerting system with configurable actions\nsegmented validation for analyzing subsets of data\nLLM-powered validation suggestions via DraftValidation\ncomprehensive data inspection tools and summary tables\nstep-by-step validation reporting with detailed failure analysis (via .get_step_report())\n\nData practitioners might want to choose Pointblank when stakeholder communication and comprehensive data quality reporting are priorities. Because of the reporting tables it can generate, it’s well-suited for data teams that need to regularly report on data quality to relevant stakeholders. Pointblank also excels in production data monitoring scenarios, data observability workflows, and situations where understanding the nuances of data quality issues matters more than simple pass/fail validation."
  },
  {
    "objectID": "blog/validation-libs-2025/index.html#validoopsie-composable-checks-with-smart-failure-handling",
    "href": "blog/validation-libs-2025/index.html#validoopsie-composable-checks-with-smart-failure-handling",
    "title": "Data Validation Libraries for Polars (2025 Edition)",
    "section": "4. Validoopsie: Composable Checks with Smart Failure Handling",
    "text": "4. Validoopsie: Composable Checks with Smart Failure Handling\nValidoopsie is built around composable validation principles, providing a toolkit for creating reusable validation functions organized into logical modules. Drawing inspiration from Great Expectations but with a much lighter footprint, Validoopsie emphasizes building validation logic from modular, testable components that can be combined in flexible ways to create complex validation workflows. The library had Polars support from its very first release (early-2025).\nWhat sets Validoopsie apart is its sophisticated approach to handling validation failures through impact levels and threshold tolerances. These features that give you fine-grained control over how your validation pipeline behaves when things go wrong.\n\nExample\n\nfrom validoopsie import Validate\nfrom narwhals.dtypes import Int64, Float64, String\n\n# Composable validation checks with impact levels and thresholds\nvalidation = (\n    Validate(user_data)\n    .ValuesValidation.ColumnValuesToBeBetween(\n        column=\"user_id\",\n        min_value=0,\n        impact=\"high\"  # Critical - will raise exception\n    )\n    .ValuesValidation.ColumnValuesToBeBetween(\n        column=\"age\",\n        min_value=18,\n        max_value=80,\n        threshold=0.1,  # Allow 10% failures\n        impact=\"medium\"  # Important but not critical\n    )\n    .StringValidation.PatternMatch(\n        column=\"email\",\n        pattern=r\"^[^@]+@[^@]+\\.[^@]+$\",\n        threshold=0.05,  # Allow 5% malformed emails\n        impact=\"low\"  # Record but don't interrupt\n    )\n    .ValuesValidation.ColumnValuesToBeBetween(\n        column=\"score\",\n        min_value=0,\n        max_value=100,\n        impact=\"medium\"\n    )\n    .TypeValidation.TypeCheck(\n        frame_schema_definition={\n            \"user_id\": Int64,\n            \"age\": Int64,\n            \"email\": String,\n            \"score\": Float64\n        },\n        impact=\"high\"  # Schema compliance is critical\n    )\n)\n\n# Get validation results\nvalidation.validate()\n\n# Access detailed results for analysis\nprint(\"Validation results:\", validation.results)\n\n\n2025-11-23 00:16:35.206 | INFO     | validoopsie.validate:validate:313 - Passed validation: {'validation': 'ColumnValuesToBeBetween', 'impact': 'high', 'timestamp': '2025-11-23T00:16:35.193687+00:00', 'column': 'user_id', 'result': {'status': 'Success', 'threshold_pass': True, 'message': 'All items passed the validation.', 'frame_row_number': 5, 'threshold': 0.0}}\n\n2025-11-23 00:16:35.206 | ERROR    | validoopsie.validate:validate:305 - Failed validation: ColumnValuesToBeBetween_age - The column 'age' has values that are not between 18 and 80.\n\n2025-11-23 00:16:35.207 | WARNING  | validoopsie.validate:validate:307 - Failed validation: PatternMatch_email - The column 'email' has entries that do not match the pattern '^[^@]+@[^@]+\\.[^@]+$'.\n\n2025-11-23 00:16:35.207 | INFO     | validoopsie.validate:validate:313 - Passed validation: {'validation': 'ColumnValuesToBeBetween', 'impact': 'medium', 'timestamp': '2025-11-23T00:16:35.198421+00:00', 'column': 'score', 'result': {'status': 'Success', 'threshold_pass': True, 'message': 'All items passed the validation.', 'frame_row_number': 5, 'threshold': 0.0}}\n\n2025-11-23 00:16:35.207 | INFO     | validoopsie.validate:validate:313 - Passed validation: {'validation': 'TypeCheck', 'impact': 'high', 'timestamp': '2025-11-23T00:16:35.199517+00:00', 'column': 'DataTypeColumnValidation', 'result': {'status': 'Success', 'threshold_pass': True, 'message': 'All items passed the validation.', 'frame_row_number': 4, 'threshold': 0.0}}\n\n\n\n\nValidation results: {'Summary': {'passed': False, 'validations': ['ColumnValuesToBeBetween_user_id', 'ColumnValuesToBeBetween_age', 'PatternMatch_email', 'ColumnValuesToBeBetween_score', 'TypeCheck_DataTypeColumnValidation'], 'failed_validation': ['ColumnValuesToBeBetween_age', 'PatternMatch_email']}, 'ColumnValuesToBeBetween_user_id': {'validation': 'ColumnValuesToBeBetween', 'impact': 'high', 'timestamp': '2025-11-23T00:16:35.193687+00:00', 'column': 'user_id', 'result': {'status': 'Success', 'threshold_pass': True, 'message': 'All items passed the validation.', 'frame_row_number': 5, 'threshold': 0.0}}, 'ColumnValuesToBeBetween_age': {'validation': 'ColumnValuesToBeBetween', 'impact': 'medium', 'timestamp': '2025-11-23T00:16:35.195861+00:00', 'column': 'age', 'result': {'status': 'Fail', 'threshold_pass': False, 'message': \"The column 'age' has values that are not between 18 and 80.\", 'failing_items': [95], 'failed_number': 1, 'frame_row_number': 5, 'threshold': 0.1, 'failed_percentage': 0.2}}, 'PatternMatch_email': {'validation': 'PatternMatch', 'impact': 'low', 'timestamp': '2025-11-23T00:16:35.197062+00:00', 'column': 'email', 'result': {'status': 'Fail', 'threshold_pass': False, 'message': \"The column 'email' has entries that do not match the pattern '^[^@]+@[^@]+\\\\.[^@]+$'.\", 'failing_items': ['invalid-email'], 'failed_number': 1, 'frame_row_number': 5, 'threshold': 0.05, 'failed_percentage': 0.2}}, 'ColumnValuesToBeBetween_score': {'validation': 'ColumnValuesToBeBetween', 'impact': 'medium', 'timestamp': '2025-11-23T00:16:35.198421+00:00', 'column': 'score', 'result': {'status': 'Success', 'threshold_pass': True, 'message': 'All items passed the validation.', 'frame_row_number': 5, 'threshold': 0.0}}, 'TypeCheck_DataTypeColumnValidation': {'validation': 'TypeCheck', 'impact': 'high', 'timestamp': '2025-11-23T00:16:35.199517+00:00', 'column': 'DataTypeColumnValidation', 'result': {'status': 'Success', 'threshold_pass': True, 'message': 'All items passed the validation.', 'frame_row_number': 4, 'threshold': 0.0}}}\n\n\nThis example showcases Validoopsie’s key differentiators: modular validation categories (ValuesValidation, StringValidation, TypeValidation) combined with impact levels that control failure behavior and thresholds that allow controlled tolerance for data quality issues. Unlike other libraries that treat all validation failures equally, Validoopsie lets you specify which validations are critical (“high” impact raises exceptions) versus informational (“low” impact just logs results).\nValidoopsie’s most powerful feature is its three-tier impact= system combined with threshold= tolerance:\n\n# Example showing sophisticated failure handling\nvalidation = (\n    Validate(user_data)\n    # Critical validation - no tolerance\n    .NullValidation.ColumnNotBeNull(\n        column=\"user_id\",\n        impact=\"high\"    # Will raise an exception if any Null values found\n    )\n    # Important validation with tolerance\n    .StringValidation.PatternMatch(\n        column=\"email\",\n        pattern=r\"^[^@]+@[^@]+\\.[^@]+$\",\n        threshold=0.15,  # Allow up to 15% malformed emails\n        impact=\"medium\"  # Log failures but don't stop processing\n    )\n    # Informational validation\n    .ValuesValidation.ColumnValuesToBeBetween(\n        column=\"score\",\n        min_value=90,\n        max_value=100,\n        threshold=0.8,  # Allow 80% to be outside \"excellent\" range\n        impact=\"low\"    # Just track high performers\n    )\n)\n\nvalidation.validate()\n\n\n2025-11-23 00:16:35.221 | INFO     | validoopsie.validate:validate:313 - Passed validation: {'validation': 'ColumnNotBeNull', 'impact': 'high', 'timestamp': '2025-11-23T00:16:35.217466+00:00', 'column': 'user_id', 'result': {'status': 'Success', 'threshold_pass': True, 'message': 'All items passed the validation.', 'frame_row_number': 5, 'threshold': 0.0}}\n\n2025-11-23 00:16:35.221 | ERROR    | validoopsie.validate:validate:305 - Failed validation: PatternMatch_email - The column 'email' has entries that do not match the pattern '^[^@]+@[^@]+\\.[^@]+$'.\n\n2025-11-23 00:16:35.222 | INFO     | validoopsie.validate:validate:313 - Passed validation: {'validation': 'ColumnValuesToBeBetween', 'impact': 'low', 'timestamp': '2025-11-23T00:16:35.220062+00:00', 'column': 'score', 'result': {'status': 'Success', 'threshold_pass': True, 'message': \"The column 'score' has values that are not between 90 and 100.\", 'failing_items': [78.3, 85.5, 88.7], 'failed_number': 3, 'frame_row_number': 5, 'threshold': 0.8, 'failed_percentage': 0.6}}\n\n\n\n\nValidoopsie strikes a unique balance between operational flexibility and production reliability, making it an excellent choice for teams that need sophisticated failure handling without the complexity of larger validation frameworks.\n\n\nComparisons\nValidoopsie’s functional approach contrasts with Pandera’s schema-centric methodology and Patito’s object-oriented models. While Pandera focuses on statistical validation and Patito emphasizes Pydantic integration, Validoopsie prioritizes flexibility and operational robustness.\nCompared to Pointblank, both libraries offer sophisticated threshold-based failure handling using numeric values (e.g., 0.1 for 10% tolerance), but they differ in their architectural approach: Validoopsie combines numeric thresholds with impact levels (low/medium/high) that control the behavioral response to threshold breaches, while Pointblank integrates thresholds directly into its comprehensive reporting and alerting system. Both support custom validation, but Validoopsie uses a modular validation catalog approach while Pointblank’s specially() method integrates seamlessly with its step-by-step reporting workflow.\nValidoopsie is the only library in this survey that provides built-in logging capabilities, making it particularly valuable for production environments where validation events need to be tracked and monitored.\nThe library’s Great Expectations inspiration is evident in its modular design, but Validoopsie delivers this functionality with a much lighter dependency footprint and simpler API. Teams familiar with Great Expectations will find Validoopsie’s approach familiar but more streamlined.\n\n\nUnique Strengths and When to Use\nValidoopsie’s standout features include:\n\ngraduated failure handling through impact levels (low/medium/high) combined with numeric thresholds that control both tolerance levels and behavioral responses to failures\nnumeric threshold tolerance allowing controlled acceptance of data quality issues (e.g., “allow 10% email format failures” with threshold=0.1)\nbuilt-in structured logging using loguru allows for automatic logging of validation results, failures, and performance metrics (unique among these libraries)\nbeing a lightweight Great Expectations alternative with similar composability but minimal dependencies\nan extensive validation catalog organized into logical namespaces (Date, String, Null, Values, etc.)\ncustom validation framework with consistent patterns for creating domain-specific rules\n\nChoose Validoopsie when you need:\n\noperational resilience in production pipelines where partial data quality issues shouldn’t stop processing\ncomprehensive validation logging and monitoring for observability in production environments\nfine-grained control over validation failure behavior with different criticality levels\nlightweight Great Expectations functionality without the complexity and dependencies\ncustom validation development with a clear, consistent framework\nmodular validation design that promotes reusability across projects\n\nValidoopsie is particularly well-suited for data engineering teams building robust production pipelines where data quality monitoring is important but pipeline availability is critical. Its impact/threshold system makes it uniquely powerful for environments where you need to distinguish between “nice to have” and “must have” data quality requirements."
  },
  {
    "objectID": "blog/validation-libs-2025/index.html#dataframely-type-safe-schema-validation-with-advanced-features",
    "href": "blog/validation-libs-2025/index.html#dataframely-type-safe-schema-validation-with-advanced-features",
    "title": "Data Validation Libraries for Polars (2025 Edition)",
    "section": "5. Dataframely: Type-Safe Schema Validation with Advanced Features",
    "text": "5. Dataframely: Type-Safe Schema Validation with Advanced Features\nDataframely is a comprehensive data validation framework that brings type-safe schema validation to Polars DataFrames with some of the most advanced features in the ecosystem. The library focuses on providing both runtime validation and static type checking, with particular strengths in collection validation for related DataFrames and extensive integration capabilities with external tools.\nDataframely launched in early 2025 with native Polars support as a core feature, built specifically for the modern data ecosystem with first-class support for complex validation scenarios.\n\nExample\n\nimport polars as pl\nimport dataframely as dy\n\nclass UserSchema(dy.Schema):\n    user_id = dy.Int64(primary_key=True, min=1, nullable=False)\n    age = dy.Int64(nullable=False)\n    email = dy.String(nullable=False, regex=r\"^[^@]+@[^@]+\\.[^@]+$\")\n    score = dy.Float64(nullable=False, min=0.0, max=100.0)\n\n    # Use @dy.rule() for age range validation\n    @dy.rule()\n    def age_in_range(cls) -&gt; pl.Expr:\n        return pl.col(\"age\").is_between(18, 80, closed=\"both\")\n\n# Validate using the schema\ntry:\n    validated_data = UserSchema.validate(user_data, cast=True)\n    print(\"Validation successful!\")\n    print(validated_data)\nexcept Exception as e:\n    print(f\"Validation failed: {e}\")\n\nValidation failed: 2 rules failed validation:\n - 'age_in_range' failed for 1 rows\n * Column 'email' failed validation for 1 rules:\n   - 'regex' failed for 1 rows\n\n\nThis example showcases Dataframely’s class-based schema approach with several notable features: primary key constraints, comprehensive type validation with bounds, regex pattern matching, and custom validation rules using the @dy.rule() decorator (used here for age range checking).\nThe cast=True parameter automatically coerces column types to match the schema definitions. This is really useful when working with data from external sources where column types might not exactly match your schema expectations (e.g., integers loaded as strings from CSV files).\nDataframely features soft validation and failure introspection. As one of Dataframely’s standout features, it brings a fairly sophisticated approach to validation failures. Rather than just raising exceptions, it provides detailed failure analysis:\n\n# Soft validation: separate valid and invalid rows\ngood_data, failure_info = UserSchema.filter(user_data, cast=True)\n\nprint(\"Valid rows:\", len(good_data))\nprint(\"Failure counts:\", failure_info.counts())\nprint(\"Co-occurrence analysis:\", failure_info.cooccurrence_counts())\n\n# Inspect the actual failed rows\nfailed_rows = failure_info.invalid()\nprint(\"Failed data:\", failed_rows)\n\nValid rows: 3\nFailure counts: {'age_in_range': 1, 'email|regex': 1}\nCo-occurrence analysis: {frozenset({'email|regex'}): 1, frozenset({'age_in_range'}): 1}\nFailed data: shape: (2, 4)\n┌─────────┬─────┬───────────────────┬───────┐\n│ user_id ┆ age ┆ email             ┆ score │\n│ ---     ┆ --- ┆ ---               ┆ ---   │\n│ i64     ┆ i64 ┆ str               ┆ f64   │\n╞═════════╪═════╪═══════════════════╪═══════╡\n│ 3       ┆ 22  ┆ invalid-email     ┆ 78.3  │\n│ 5       ┆ 95  ┆ user5@example.com ┆ 95.2  │\n└─────────┴─────┴───────────────────┴───────┘\n\n\n\n\nComparisons\nWhile both Dataframely and Pandera offer schema-centric validation approaches, they serve different validation philosophies. Pandera excels in statistical validation with hypothesis testing and distribution checks, making it ideal for data science workflows where statistical properties matter. Dataframely, by contrast, emphasizes relational data integrity and type safety, providing more sophisticated failure analysis and collection-level validation capabilities that Pandera doesn’t offer.\nThe relationship between Dataframely and Patito is particularly interesting since both use class-based schema definitions. However, Dataframely extends far beyond Patito’s Pydantic-focused approach. Where Patito provides clean, simple validation with excellent Pydantic integration, Dataframely offers advanced features like collection validation, group rules, and comprehensive failure introspection. Teams already invested in Pydantic workflows might prefer Patito’s simplicity, while those building complex data systems will appreciate Dataframely’s feature set.\nDataframely and Pointblank represent two different approaches to comprehensive data validation. Pointblank shines in stakeholder communication with its beautiful interactive reports and threshold-based alerting systems, making it perfect for data quality reporting. Dataframely focuses instead on type safety and complex validation logic, with unique collection validation capabilities that no other library in this survey provides. The choice between these two will comes down to whether your priority is communicating validation results or ensuring complex data relationships remain consistent.\nWhen compared to Validoopsie’s method chaining approach, Dataframely offers a more structured, schema-centric methodology with advanced type safety features that Validoopsie doesn’t provide. While Validoopsie excels in operational flexibility and lightweight design for building reusable validation components, Dataframely’s strength lies in its comprehensive type system integration, collection validation capabilities, and sophisticated failure analysis. And that makes it ideal for complex data engineering workflows where relationships between multiple DataFrames matter as much as individual DataFrame validation.\n\n\nUnique Strengths and When to Use\nDataframely’s standout features include:\n\nadvanced type safety with full mypy integration and generic DataFrame types\ncollection validation for ensuring consistency across related DataFrames\ngroup-based validation rules using @dy.rule(group_by=[...]) for aggregate constraints\nschema inheritance for reducing code duplication in related schemas\nproduction-ready soft validation that separates valid and invalid data\n\nOne might choose Dataframely when building complex data systems where:\n\ntype safety and static analysis are critical for code quality\nyou need to validate relationships between multiple related DataFrames\nyou’re working with production pipelines that need to handle partial data quality issues gracefully\nschema reuse and inheritance would benefit your codebase organization\n\nDataframely is particularly well-suited for data engineering teams building robust, type-safe data pipelines where the relationships between different data entities are as important as the validation of individual DataFrames. Its collection validation capabilities make it uniquely powerful for ensuring referential integrity in complex data workflows."
  },
  {
    "objectID": "blog/validation-libs-2025/index.html#choosing-the-right-library",
    "href": "blog/validation-libs-2025/index.html#choosing-the-right-library",
    "title": "Data Validation Libraries for Polars (2025 Edition)",
    "section": "Choosing the Right Library",
    "text": "Choosing the Right Library\nWith five solid validation libraries to choose from, the decision often comes down to your team’s specific workflow, existing tech stack, and validation requirements. Here are some practical considerations to help guide your choice:\nStart with your existing tools\nIf you’re already using Pydantic extensively, Patito will feel natural. Teams that are heavily invested in type checking and statistical analysis should probably gravitate toward Pandera. If you’re building data products that need stakeholder buy-in, Pointblank’s reporting capabilities become incredibly useful in that context. For teams already committed to strong typing and static analysis workflows, Dataframely’s advanced type safety features will feel like a natural extension of your existing practices.\nConsider your validation complexity\nFor straightforward schema validation and type checking, any of these libraries will work well. But if you need statistical hypothesis testing, Pandera is your best bet. For highly custom validation logic that needs to be composed and reused, Validoopsie shines. When validation results need to be communicated to non-technical stakeholders, Pointblank’s interactive reports are basically unmatched. If you’re dealing with complex relational data where multiple DataFrames need to maintain consistency with each other, Dataframely’s collection validation capabilities are unique in the ecosystem.\nThink about failure tolerance requirements\nOne of the most important architectural differences among these libraries is how they handle validation failures. Only Pointblank and Validoopsie offer numeric threshold-based failure tolerance. This is the ability to accept a controlled percentage of validation failures without treating the entire validation as failed.\nThis distinction can be crucial for production environments where some level of data quality issues is acceptable and you need fine-grained control over when validations should fail versus warn. In many real-world scenarios, poor data quality is a given reality, and the goal becomes gradually improving quality over time rather than enforcing perfection. Thresholds can then be seen not as simple failure tolerances but more like data quality metrics and improvement goals (e.g., you might start with threshold=0.15 for email validation and progressively tighten to 0.05 as upstream systems improve).\nThink about your team’s preferences\nThere’s a human dimension here. Some data teams might prefer the declarative, schema-first approach of Pandera, Patito, and Dataframely, whereas others like the step-by-step, method-chaining style of Pointblank and Validoopsie. There’s really no right or wrong choice here. It’s all about what feels right and most natural for your team’s coding style and mental model.\nDon’t feel locked into one choice\nMy hunch is that many teams already successfully use different libraries for different parts of their data pipeline. They’re leveraging each tool’s strengths where they matter most. So you could conceivably use Patito for Pydantic-style validation, Pandera for statistical checks in your analysis pipeline, Pointblank for generating stakeholder reports, and Dataframely for complex data engineering workflows (use ’em all!). This multi-library approach can be particularly effective in larger organizations with diverse validation needs.\nI suppose the key is to start with one library that fits your immediate needs, learn it well, and then consider expanding your toolkit as your validation requirements evolve."
  },
  {
    "objectID": "blog/validation-libs-2025/index.html#summary-and-wrapping-up",
    "href": "blog/validation-libs-2025/index.html#summary-and-wrapping-up",
    "title": "Data Validation Libraries for Polars (2025 Edition)",
    "section": "Summary and Wrapping Up",
    "text": "Summary and Wrapping Up\nThe Python ecosystem offers truly excellent options for validating Polars DataFrames! Choosing is always tough but this is how one could make the decision based on specific needs:\n\nfor type-safe pipelines, Pandera, Dataframely, or Patito are ideal\nfor stakeholder reporting, Pointblank is a great choice\nfor row-level object modeling, go with Patito\nfor statistical validation, Pandera is perfect\nfor data quality improvement, Pointblank or Validoopsie fit well\n\nEach library has evolved to serve different aspects of the data validation ecosystem. Try them all and, with a little understanding of their strengths, you’ll get good at picking the right data validation tool for your specific use case.\nThis survey represents our understanding of these libraries as of mid-2025. Given the rapid pace of development in the Python data ecosystem, some details may become outdated or contain inaccuracies (we may have even gotten things wrong at the outset). If you notice any errors or have updates to share, we’d love to hear from you! Please reach out through:\n\nGitHub Issues\nGitHub Discussions\nOur Discord Server\n\nAny feedback you provide helps keep this resource accurate and useful for the community!"
  },
  {
    "objectID": "reference/Validate.col_vals_eq.html",
    "href": "reference/Validate.col_vals_eq.html",
    "title": "Validate.col_vals_eq",
    "section": "",
    "text": "Validate.col_vals_eq(\n    columns,\n    value,\n    na_pass=False,\n    pre=None,\n    segments=None,\n    thresholds=None,\n    actions=None,\n    brief=None,\n    active=True,\n)\nAre column data equal to a fixed value or data in another column?\nThe col_vals_eq() validation method checks whether column values in a table are equal to a specified value= (the exact comparison used in this function is col_val == value). The value= can be specified as a single, literal value or as a column name given in col(). This validation will operate over the number of test units that is equal to the number of rows in the table (determined after any pre= mutation has been applied)."
  },
  {
    "objectID": "reference/Validate.col_vals_eq.html#parameters",
    "href": "reference/Validate.col_vals_eq.html#parameters",
    "title": "Validate.col_vals_eq",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns : str | list[str] | Column | ColumnSelector | ColumnSelectorNarwhals\n\nA single column or a list of columns to validate. Can also use col() with column selectors to specify one or more columns. If multiple columns are supplied or resolved, there will be a separate validation step generated for each column.\n\nvalue : float | int | Column\n\nThe value to compare against. This can be a single value or a single column name given in col(). The latter option allows for a column-to-column comparison. For more information on which types of values are allowed, see the What Can Be Used in value=? section.\n\nna_pass : bool = False\n\nShould any encountered None, NA, or Null values be considered as passing test units? By default, this is False. Set to True to pass test units with missing values.\n\npre : Callable | None = None\n\nAn optional preprocessing function or lambda to apply to the data table during interrogation. This function should take a table as input and return a modified table. Have a look at the Preprocessing section for more information on how to use this argument.\n\nsegments : SegmentSpec | None = None\n\nAn optional directive on segmentation, which serves to split a validation step into multiple (one step per segment). Can be a single column name, a tuple that specifies a column name and its corresponding values to segment on, or a combination of both (provided as a list). Read the Segmentation section for usage information.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nSet threshold failure levels for reporting and reacting to exceedences of the levels. The thresholds are set at the step level and will override any global thresholds set in Validate(thresholds=...). The default is None, which means that no thresholds will be set locally and global thresholds (if any) will take effect. Look at the Thresholds section for information on how to set threshold levels.\n\nactions : Actions | None = None\n\nOptional actions to take when the validation step(s) meets or exceeds any set threshold levels. If provided, the Actions class should be used to define the actions.\n\nbrief : str | bool | None = None\n\nAn optional brief description of the validation step that will be displayed in the reporting table. You can use the templating elements like \"{step}\" to insert the step number, or \"{auto}\" to include an automatically generated brief. If True the entire brief will be automatically generated. If None (the default) then there won’t be a brief.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.col_vals_eq.html#returns",
    "href": "reference/Validate.col_vals_eq.html#returns",
    "title": "Validate.col_vals_eq",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.col_vals_eq.html#what-can-be-used-in-value",
    "href": "reference/Validate.col_vals_eq.html#what-can-be-used-in-value",
    "title": "Validate.col_vals_eq",
    "section": "What Can Be Used in value=?",
    "text": "What Can Be Used in value=?\nThe value= argument allows for a variety of input types. The most common are:\n\na single numeric value\na single date or datetime value\nA col() object that represents a column name\n\nWhen supplying a number as the basis of comparison, keep in mind that all resolved columns must also be numeric. Should you have columns that are of the date or datetime types, you can supply a date or datetime value as the value= argument. There is flexibility in how you provide the date or datetime value, as it can be:\n\na string-based date or datetime (e.g., \"2023-10-01\", \"2023-10-01 13:45:30\", etc.)\na date or datetime object using the datetime module (e.g., datetime.date(2023, 10, 1), datetime.datetime(2023, 10, 1, 13, 45, 30), etc.)\n\nFinally, when supplying a column name in the value= argument, it must be specified within col(). This is a column-to-column comparison and, crucially, the columns being compared must be of the same type (e.g., both numeric, both date, etc.)."
  },
  {
    "objectID": "reference/Validate.col_vals_eq.html#preprocessing",
    "href": "reference/Validate.col_vals_eq.html#preprocessing",
    "title": "Validate.col_vals_eq",
    "section": "Preprocessing",
    "text": "Preprocessing\nThe pre= argument allows for a preprocessing function or lambda to be applied to the data table during interrogation. This function should take a table as input and return a modified table. This is useful for performing any necessary transformations or filtering on the data before the validation step is applied.\nThe preprocessing function can be any callable that takes a table as input and returns a modified table. For example, you could use a lambda function to filter the table based on certain criteria or to apply a transformation to the data. Note that you can refer to columns via columns= and value=col(...) that are expected to be present in the transformed table, but may not exist in the table before preprocessing. Regarding the lifetime of the transformed table, it only exists during the validation step and is not stored in the Validate object or used in subsequent validation steps."
  },
  {
    "objectID": "reference/Validate.col_vals_eq.html#segmentation",
    "href": "reference/Validate.col_vals_eq.html#segmentation",
    "title": "Validate.col_vals_eq",
    "section": "Segmentation",
    "text": "Segmentation\nThe segments= argument allows for the segmentation of a validation step into multiple segments. This is useful for applying the same validation step to different subsets of the data. The segmentation can be done based on a single column or specific fields within a column.\nProviding a single column name will result in a separate validation step for each unique value in that column. For example, if you have a column called \"region\" with values \"North\", \"South\", and \"East\", the validation step will be applied separately to each region.\nAlternatively, you can provide a tuple that specifies a column name and its corresponding values to segment on. For example, if you have a column called \"date\" and you want to segment on only specific dates, you can provide a tuple like (\"date\", [\"2023-01-01\", \"2023-01-02\"]). Any other values in the column will be disregarded (i.e., no validation steps will be created for them).\nA list with a combination of column names and tuples can be provided as well. This allows for more complex segmentation scenarios. The following inputs are both valid:\n# Segments from all unique values in the `region` column\n# and specific dates in the `date` column\nsegments=[\"region\", (\"date\", [\"2023-01-01\", \"2023-01-02\"])]\n\n# Segments from all unique values in the `region` and `date` columns\nsegments=[\"region\", \"date\"]\nThe segmentation is performed during interrogation, and the resulting validation steps will be numbered sequentially. Each segment will have its own validation step, and the results will be reported separately. This allows for a more granular analysis of the data and helps identify issues within specific segments.\nImportantly, the segmentation process will be performed after any preprocessing of the data table. Because of this, one can conceivably use the pre= argument to generate a column that can be used for segmentation. For example, you could create a new column called \"segment\" through use of pre= and then use that column for segmentation."
  },
  {
    "objectID": "reference/Validate.col_vals_eq.html#thresholds",
    "href": "reference/Validate.col_vals_eq.html#thresholds",
    "title": "Validate.col_vals_eq",
    "section": "Thresholds",
    "text": "Thresholds\nThe thresholds= parameter is used to set the failure-condition levels for the validation step. If they are set here at the step level, these thresholds will override any thresholds set at the global level in Validate(thresholds=...).\nThere are three threshold levels: ‘warning’, ‘error’, and ‘critical’. The threshold values can either be set as a proportion failing of all test units (a value between 0 to 1), or, the absolute number of failing test units (as integer that’s 1 or greater).\nThresholds can be defined using one of these input schemes:\n\nuse the Thresholds class (the most direct way to create thresholds)\nprovide a tuple of 1-3 values, where position 0 is the ‘warning’ level, position 1 is the ‘error’ level, and position 2 is the ‘critical’ level\ncreate a dictionary of 1-3 value entries; the valid keys: are ‘warning’, ‘error’, and ‘critical’\na single integer/float value denoting absolute number or fraction of failing test units for the ‘warning’ level only\n\nIf the number of failing test units exceeds set thresholds, the validation step will be marked as ‘warning’, ‘error’, or ‘critical’. All of the threshold levels don’t need to be set, you’re free to set any combination of them.\nAside from reporting failure conditions, thresholds can be used to determine the actions to take for each level of failure (using the actions= parameter)."
  },
  {
    "objectID": "reference/Validate.col_vals_eq.html#examples",
    "href": "reference/Validate.col_vals_eq.html#examples",
    "title": "Validate.col_vals_eq",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with two numeric columns (a and b). The table is shown below:\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [5, 5, 5, 5, 5, 5],\n        \"b\": [5, 5, 5, 6, 5, 4],\n    }\n)\n\npb.preview(tbl)\n\n\n\n\n\n  \n  \n  \n\n\n\n\n\n  \n  aInt64\n  bInt64\n\n\n\n  \n    1\n    5\n    5\n  \n  \n    2\n    5\n    5\n  \n  \n    3\n    5\n    5\n  \n  \n    4\n    5\n    6\n  \n  \n    5\n    5\n    5\n  \n  \n    6\n    5\n    4\n  \n\n\n\n\n\n\n        \n\n\nLet’s validate that values in column a are all equal to the value of 5. We’ll determine if this validation had any failing test units (there are six test units, one for each row).\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_eq(columns=\"a\", value=5)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_eq\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_eq()\n        \n        \n        \n    a\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    61.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nPrinting the validation object shows the validation table in an HTML viewing environment. The validation table shows the single entry that corresponds to the validation step created by using col_vals_eq(). All test units passed, and there are no failing test units.\nAside from checking a column against a literal value, we can also use a column name in the value= argument (with the helper function col() to perform a column-to-column comparison. For the next example, we’ll use col_vals_eq() to check whether the values in column a are equal to the values in column b.\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_eq(columns=\"a\", value=pb.col(\"b\"))\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_eq\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_eq()\n        \n        \n        \n    a\n    b\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    40.67\n    20.33\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe validation table reports two failing test units. The specific failing cases are:\n\nRow 3: a is 5 and b is 6.\nRow 5: a is 5 and b is 4."
  },
  {
    "objectID": "reference/yaml_to_python.html",
    "href": "reference/yaml_to_python.html",
    "title": "yaml_to_python",
    "section": "",
    "text": "yaml_to_python(yaml)\nConvert YAML validation configuration to equivalent Python code.\nThis function takes a YAML validation configuration and generates the equivalent Python code that would produce the same validation workflow. This is useful for documentation, code generation, or learning how to translate YAML workflows into programmatic workflows.\nThe generated Python code includes all necessary imports, data loading, validation steps, and interrogation execution, formatted as executable Python code."
  },
  {
    "objectID": "reference/yaml_to_python.html#parameters",
    "href": "reference/yaml_to_python.html#parameters",
    "title": "yaml_to_python",
    "section": "Parameters",
    "text": "Parameters\n\nyaml : Union[str, Path]\n\nYAML configuration as string or file path. Can be: (1) a YAML string containing the validation configuration, or (2) a Path object or string path to a YAML file."
  },
  {
    "objectID": "reference/yaml_to_python.html#returns",
    "href": "reference/yaml_to_python.html#returns",
    "title": "yaml_to_python",
    "section": "Returns",
    "text": "Returns\n\n : str\n\nA formatted Python code string enclosed in markdown code blocks that replicates the YAML workflow. The code includes import statements, data loading, validation method calls, and interrogation execution."
  },
  {
    "objectID": "reference/yaml_to_python.html#raises",
    "href": "reference/yaml_to_python.html#raises",
    "title": "yaml_to_python",
    "section": "Raises",
    "text": "Raises\n\n: YAMLValidationError\n\nIf the YAML is invalid, malformed, or contains unknown validation methods."
  },
  {
    "objectID": "reference/yaml_to_python.html#examples",
    "href": "reference/yaml_to_python.html#examples",
    "title": "yaml_to_python",
    "section": "Examples",
    "text": "Examples\nConvert a basic YAML configuration to Python code:\n\nimport pointblank as pb\n\n# Define a YAML validation workflow\nyaml_config = '''\ntbl: small_table\ntbl_name: Data Quality Check\nsteps:\n- col_vals_not_null:\n    columns: [a, b]\n- col_vals_gt:\n    columns: [c]\n    value: 0\n'''\n\n# Generate equivalent Python code\npython_code = pb.yaml_to_python(yaml_config)\nprint(python_code)\n\n```python\nimport pointblank as pb\n\n(\n    pb.Validate(\n        data=pb.load_dataset(\"small_table\", tbl_type=\"polars\"),\n        tbl_name=\"Data Quality Check\",\n    )\n    .col_vals_not_null(columns=[\"a\", \"b\"])\n    .col_vals_gt(columns=\"c\", value=0)\n    .interrogate()\n)\n```\n\n\nThe generated Python code shows exactly how to replicate the YAML workflow programmatically. This is particularly useful when transitioning from YAML-based workflows to code-based workflows, or when generating documentation that shows both YAML and Python approaches.\nFor more complex workflows with thresholds and metadata:\n\n# Advanced YAML configuration\nyaml_config = '''\ntbl: small_table\ntbl_name: Advanced Validation\nlabel: Production data check\nthresholds:\n  warning: 0.1\n  error: 0.2\nsteps:\n- col_vals_between:\n    columns: [c]\n    left: 1\n    right: 10\n- col_vals_regex:\n    columns: [b]\n    pattern: '[0-9]-[a-z]{3}-[0-9]{3}'\n'''\n\n# Generate the equivalent Python code\npython_code = pb.yaml_to_python(yaml_config)\nprint(python_code)\n\n```python\nimport pointblank as pb\n\n(\n    pb.Validate(\n        data=pb.load_dataset(\"small_table\", tbl_type=\"polars\"),\n        tbl_name=\"Advanced Validation\",\n        label=\"Production data check\",\n        thresholds=pb.Thresholds(warning=0.1, error=0.2),\n    )\n    .col_vals_between(columns=\"c\", left=1, right=10)\n    .col_vals_regex(columns=\"b\", pattern=\"[0-9]-[a-z]{3}-[0-9]{3}\")\n    .interrogate()\n)\n```\n\n\nThe generated code includes all configuration parameters, thresholds, and maintains the exact same validation logic as the original YAML workflow.\nThis function is also useful for educational purposes, helping users understand how YAML configurations map to the underlying Python API calls."
  },
  {
    "objectID": "reference/read_file.html",
    "href": "reference/read_file.html",
    "title": "read_file",
    "section": "",
    "text": "read_file(filepath)\nRead a Validate object from disk that was previously saved with write_file().\nThis function loads a validation object that was previously serialized to disk using the write_file() function. The validation object will be restored with all its validation results, metadata, and optionally the source data (if it was saved with keep_tbl=True).\n\n\n\n\n\n\nWarning\n\n\n\nThe read_file() function is currently experimental. Please report any issues you encounter in the Pointblank issue tracker.\n\n\n\n\n\nfilepath : str | Path\n\nThe path to the saved validation file. Can be a string or Path object.\n\n\n\n\n\n\n : Validate\n\nThe restored validation object with all its original state, validation results, and metadata.\n\n\n\n\n\nLoad a validation object that was previously saved:\nimport pointblank as pb\n\n# Load a validation object from disk\nvalidation = pb.read_file(\"my_validation.pkl\")\n\n# View the validation results\nvalidation\nYou can also load using just the filename (without extension):\n# This will automatically look for \"my_validation.pkl\"\nvalidation = pb.read_file(\"my_validation\")\nThe loaded validation object retains all its functionality:\n# Get validation summary\nsummary = validation.get_json_report()\n\n# Get sundered data (if original table was saved)\nif validation.data is not None:\n    failing_rows = validation.get_sundered_data(type=\"fail\")\n\n\n\nUse the write_file() method to save a validation object to disk for later retrieval with this function."
  },
  {
    "objectID": "reference/read_file.html#parameters",
    "href": "reference/read_file.html#parameters",
    "title": "read_file",
    "section": "",
    "text": "filepath : str | Path\n\nThe path to the saved validation file. Can be a string or Path object."
  },
  {
    "objectID": "reference/read_file.html#returns",
    "href": "reference/read_file.html#returns",
    "title": "read_file",
    "section": "",
    "text": ": Validate\n\nThe restored validation object with all its original state, validation results, and metadata."
  },
  {
    "objectID": "reference/read_file.html#examples",
    "href": "reference/read_file.html#examples",
    "title": "read_file",
    "section": "",
    "text": "Load a validation object that was previously saved:\nimport pointblank as pb\n\n# Load a validation object from disk\nvalidation = pb.read_file(\"my_validation.pkl\")\n\n# View the validation results\nvalidation\nYou can also load using just the filename (without extension):\n# This will automatically look for \"my_validation.pkl\"\nvalidation = pb.read_file(\"my_validation\")\nThe loaded validation object retains all its functionality:\n# Get validation summary\nsummary = validation.get_json_report()\n\n# Get sundered data (if original table was saved)\nif validation.data is not None:\n    failing_rows = validation.get_sundered_data(type=\"fail\")"
  },
  {
    "objectID": "reference/read_file.html#see-also",
    "href": "reference/read_file.html#see-also",
    "title": "read_file",
    "section": "",
    "text": "Use the write_file() method to save a validation object to disk for later retrieval with this function."
  },
  {
    "objectID": "reference/Validate.col_vals_increasing.html",
    "href": "reference/Validate.col_vals_increasing.html",
    "title": "Validate.col_vals_increasing",
    "section": "",
    "text": "Validate.col_vals_increasing(\n    columns,\n    allow_stationary=False,\n    decreasing_tol=None,\n    na_pass=False,\n    pre=None,\n    segments=None,\n    thresholds=None,\n    actions=None,\n    brief=None,\n    active=True,\n)\nAre column data increasing by row?\nThe col_vals_increasing() validation method checks whether column values in a table are increasing when moving down a table. There are options for allowing missing values in the target column, allowing stationary phases (where consecutive values don’t change), and even one for allowing decreasing movements up to a certain threshold. This validation will operate over the number of test units that is equal to the number of rows in the table (determined after any pre= mutation has been applied)."
  },
  {
    "objectID": "reference/Validate.col_vals_increasing.html#parameters",
    "href": "reference/Validate.col_vals_increasing.html#parameters",
    "title": "Validate.col_vals_increasing",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns : str | list[str] | Column | ColumnSelector | ColumnSelectorNarwhals\n\nA single column or a list of columns to validate. Can also use col() with column selectors to specify one or more columns. If multiple columns are supplied or resolved, there will be a separate validation step generated for each column.\n\nallow_stationary : bool = False\n\nAn option to allow pauses in increasing values. For example, if the values for the test units are [80, 82, 82, 85, 88] then the third unit (82, appearing a second time) would be marked as failing when allow_stationary is False. Using allow_stationary=True will result in all the test units in [80, 82, 82, 85, 88] to be marked as passing.\n\ndecreasing_tol : float | None = None\n\nAn optional threshold value that allows for movement of numerical values in the negative direction. By default this is None but using a numerical value will set the absolute threshold of negative travel allowed across numerical test units. Note that setting a value here also has the effect of setting allow_stationary to True.\n\nna_pass : bool = False\n\nShould any encountered None, NA, or Null values be considered as passing test units? By default, this is False. Set to True to pass test units with missing values.\n\npre : Callable | None = None\n\nAn optional preprocessing function or lambda to apply to the data table during interrogation. This function should take a table as input and return a modified table. Have a look at the Preprocessing section for more information on how to use this argument.\n\nsegments : SegmentSpec | None = None\n\nAn optional directive on segmentation, which serves to split a validation step into multiple (one step per segment). Can be a single column name, a tuple that specifies a column name and its corresponding values to segment on, or a combination of both (provided as a list). Read the Segmentation section for usage information.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nSet threshold failure levels for reporting and reacting to exceedences of the levels. The thresholds are set at the step level and will override any global thresholds set in Validate(thresholds=...). The default is None, which means that no thresholds will be set locally and global thresholds (if any) will take effect. Look at the Thresholds section for information on how to set threshold levels.\n\nactions : Actions | None = None\n\nOptional actions to take when the validation step(s) meets or exceeds any set threshold levels. If provided, the Actions class should be used to define the actions.\n\nbrief : str | bool | None = None\n\nAn optional brief description of the validation step that will be displayed in the reporting table. You can use the templating elements like \"{step}\" to insert the step number, or \"{auto}\" to include an automatically generated brief. If True the entire brief will be automatically generated. If None (the default) then there won’t be a brief.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.col_vals_increasing.html#returns",
    "href": "reference/Validate.col_vals_increasing.html#returns",
    "title": "Validate.col_vals_increasing",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.col_vals_increasing.html#examples",
    "href": "reference/Validate.col_vals_increasing.html#examples",
    "title": "Validate.col_vals_increasing",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with a numeric column (a). The table is shown below:\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [1, 2, 3, 4, 5, 6],\n        \"b\": [1, 2, 2, 3, 4, 5],\n        \"c\": [1, 2, 1, 3, 4, 5],\n    }\n)\n\npb.preview(tbl)\n\n\n\n\n\n  \n  \n  \n  \n\n\n\n\n\n  \n  aInt64\n  bInt64\n  cInt64\n\n\n\n  \n    1\n    1\n    1\n    1\n  \n  \n    2\n    2\n    2\n    2\n  \n  \n    3\n    3\n    2\n    1\n  \n  \n    4\n    4\n    3\n    3\n  \n  \n    5\n    5\n    4\n    4\n  \n  \n    6\n    6\n    5\n    5\n  \n\n\n\n\n\n\n        \n\n\nLet’s validate that values in column a are increasing. We’ll determine if this validation had any failing test units (there are six test units, one for each row).\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_increasing(columns=\"a\")\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_increasing\n    \n        \n            \n            \n                \n            \n        \n    \n\n        \n        \n            col_vals_increasing()\n        \n        \n        \n    a\n    \n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    61.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe validation passed as all values in column a are increasing. Now let’s check column b which has a stationary value:\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_increasing(columns=\"b\")\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_increasing\n    \n        \n            \n            \n                \n            \n        \n    \n\n        \n        \n            col_vals_increasing()\n        \n        \n        \n    b\n    \n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    50.83\n    10.17\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThis validation fails at the third row because the value 2 is repeated. If we want to allow stationary values, we can use allow_stationary=True:\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_increasing(columns=\"b\", allow_stationary=True)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_increasing\n    \n        \n            \n            \n                \n            \n        \n    \n\n        \n        \n            col_vals_increasing()\n        \n        \n        \n    b\n    \n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    61.00\n    00.00\n    —\n    —\n    —\n    —"
  },
  {
    "objectID": "reference/get_row_count.html",
    "href": "reference/get_row_count.html",
    "title": "get_row_count",
    "section": "",
    "text": "get_row_count(data)\nGet the number of rows in a table.\nThe get_row_count() function returns the number of rows in a table. The function works with any table that is supported by the pointblank library, including Pandas, Polars, and Ibis backend tables (e.g., DuckDB, MySQL, PostgreSQL, SQLite, Parquet, etc.). It also supports direct input of CSV files, Parquet files, and database connection strings."
  },
  {
    "objectID": "reference/get_row_count.html#parameters",
    "href": "reference/get_row_count.html#parameters",
    "title": "get_row_count",
    "section": "Parameters",
    "text": "Parameters\n\ndata : FrameT | Any\n\nThe table for which to get the row count, which could be a DataFrame object, an Ibis table object, a CSV file path, a Parquet file path, or a database connection string. Read the Supported Input Table Types section for details on the supported table types."
  },
  {
    "objectID": "reference/get_row_count.html#returns",
    "href": "reference/get_row_count.html#returns",
    "title": "get_row_count",
    "section": "Returns",
    "text": "Returns\n\n : int\n\nThe number of rows in the table."
  },
  {
    "objectID": "reference/get_row_count.html#supported-input-table-types",
    "href": "reference/get_row_count.html#supported-input-table-types",
    "title": "get_row_count",
    "section": "Supported Input Table Types",
    "text": "Supported Input Table Types\nThe data= parameter can be given any of the following table types:\n\nPolars DataFrame (\"polars\")\nPandas DataFrame (\"pandas\")\nPySpark table (\"pyspark\")\nDuckDB table (\"duckdb\")*\nMySQL table (\"mysql\")*\nPostgreSQL table (\"postgresql\")*\nSQLite table (\"sqlite\")*\nMicrosoft SQL Server table (\"mssql\")*\nSnowflake table (\"snowflake\")*\nDatabricks table (\"databricks\")*\nBigQuery table (\"bigquery\")*\nParquet table (\"parquet\")*\nCSV files (string path or pathlib.Path object with .csv extension)\nParquet files (string path, pathlib.Path object, glob pattern, directory with .parquet extension, or partitioned dataset)\nGitHub URLs (direct links to CSV or Parquet files on GitHub)\nDatabase connection strings (URI format with optional table specification)\n\nThe table types marked with an asterisk need to be prepared as Ibis tables (with type of ibis.expr.types.relations.Table). Furthermore, using get_row_count() with these types of tables requires the Ibis library (v9.5.0 or above) to be installed. If the input table is a Polars or Pandas DataFrame, the availability of Ibis is not needed.\nTo use a CSV file, ensure that a string or pathlib.Path object with a .csv extension is provided. The file will be automatically detected and loaded using the best available DataFrame library. The loading preference is Polars first, then Pandas as a fallback.\nGitHub URLs pointing to CSV or Parquet files are automatically detected and converted to raw content URLs for downloading. The URL format should be: https://github.com/user/repo/blob/branch/path/file.csv or https://github.com/user/repo/blob/branch/path/file.parquet\nConnection strings follow database URL formats and must also specify a table using the ::table_name suffix. Examples include:\n\"duckdb:///path/to/database.ddb::table_name\"\n\"sqlite:///path/to/database.db::table_name\"\n\"postgresql://user:password@localhost:5432/database::table_name\"\n\"mysql://user:password@localhost:3306/database::table_name\"\n\"bigquery://project/dataset::table_name\"\n\"snowflake://user:password@account/database/schema::table_name\"\nWhen using connection strings, the Ibis library with the appropriate backend driver is required."
  },
  {
    "objectID": "reference/get_row_count.html#examples",
    "href": "reference/get_row_count.html#examples",
    "title": "get_row_count",
    "section": "Examples",
    "text": "Examples\nGetting the number of rows in a table is easily done by using the get_row_count() function. Here’s an example using the game_revenue dataset (itself loaded using the load_dataset() function):\n\nimport pointblank as pb\n\ngame_revenue_polars = pb.load_dataset(\"game_revenue\")\n\npb.get_row_count(game_revenue_polars)\n\n2000\n\n\nThis table is a Polars DataFrame, but the get_row_count() function works with any table supported by pointblank, including Pandas DataFrames and Ibis backend tables. Here’s an example using a DuckDB table handled by Ibis:\n\ngame_revenue_duckdb = pb.load_dataset(\"game_revenue\", tbl_type=\"duckdb\")\n\npb.get_row_count(game_revenue_duckdb)\n\n2000\n\n\n\nWorking with CSV Files\nThe get_row_count() function can directly accept CSV file paths:\n\n# Get a path to a CSV file from the package data\ncsv_path = pb.get_data_path(\"global_sales\", \"csv\")\n\npb.get_row_count(csv_path)\n\n50000\n\n\n\n\nWorking with Parquet Files\nThe function supports various Parquet input formats:\n\n# Single Parquet file from package data\nparquet_path = pb.get_data_path(\"nycflights\", \"parquet\")\n\npb.get_row_count(parquet_path)\n\n336776\n\n\nYou can also use glob patterns and directories:\n# Multiple Parquet files with glob patterns\npb.get_row_count(\"data/sales_*.parquet\")\n\n# Directory containing Parquet files\npb.get_row_count(\"parquet_data/\")\n\n# Partitioned Parquet dataset\npb.get_row_count(\"sales_data/\")  # Auto-discovers partition columns\n\n\nWorking with Database Connection Strings\nThe function supports database connection strings for direct access to database tables:\n\n# Get path to a DuckDB database file from package data\nduckdb_path = pb.get_data_path(\"game_revenue\", \"duckdb\")\n\npb.get_row_count(f\"duckdb:///{duckdb_path}::game_revenue\")\n\n2000\n\n\nThe function always returns the number of rows in the table as an integer value, which is 2000 for the game_revenue dataset."
  },
  {
    "objectID": "reference/Validate.rows_complete.html",
    "href": "reference/Validate.rows_complete.html",
    "title": "Validate.rows_complete",
    "section": "",
    "text": "Validate.rows_complete(\n    columns_subset=None,\n    pre=None,\n    segments=None,\n    thresholds=None,\n    actions=None,\n    brief=None,\n    active=True,\n)\nValidate whether row data are complete by having no missing values.\nThe rows_complete() method checks whether rows in the table are complete. Completeness of a row means that there are no missing values within the row. This validation will operate over the number of test units that is equal to the number of rows in the table (determined after any pre= mutation has been applied). A subset of columns can be specified for the completeness check. If no subset is provided, all columns in the table will be used."
  },
  {
    "objectID": "reference/Validate.rows_complete.html#parameters",
    "href": "reference/Validate.rows_complete.html#parameters",
    "title": "Validate.rows_complete",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns_subset : str | list[str] | None = None\n\nA single column or a list of columns to use as a subset for the completeness check. If None (the default), then all columns in the table will be used.\n\npre : Callable | None = None\n\nAn optional preprocessing function or lambda to apply to the data table during interrogation. This function should take a table as input and return a modified table. Have a look at the Preprocessing section for more information on how to use this argument.\n\nsegments : SegmentSpec | None = None\n\nAn optional directive on segmentation, which serves to split a validation step into multiple (one step per segment). Can be a single column name, a tuple that specifies a column name and its corresponding values to segment on, or a combination of both (provided as a list). Read the Segmentation section for usage information.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nSet threshold failure levels for reporting and reacting to exceedences of the levels. The thresholds are set at the step level and will override any global thresholds set in Validate(thresholds=...). The default is None, which means that no thresholds will be set locally and global thresholds (if any) will take effect. Look at the Thresholds section for information on how to set threshold levels.\n\nactions : Actions | None = None\n\nOptional actions to take when the validation step meets or exceeds any set threshold levels. If provided, the Actions class should be used to define the actions.\n\nbrief : str | bool | None = None\n\nAn optional brief description of the validation step that will be displayed in the reporting table. You can use the templating elements like \"{step}\" to insert the step number, or \"{auto}\" to include an automatically generated brief. If True the entire brief will be automatically generated. If None (the default) then there won’t be a brief.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.rows_complete.html#returns",
    "href": "reference/Validate.rows_complete.html#returns",
    "title": "Validate.rows_complete",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.rows_complete.html#preprocessing",
    "href": "reference/Validate.rows_complete.html#preprocessing",
    "title": "Validate.rows_complete",
    "section": "Preprocessing",
    "text": "Preprocessing\nThe pre= argument allows for a preprocessing function or lambda to be applied to the data table during interrogation. This function should take a table as input and return a modified table. This is useful for performing any necessary transformations or filtering on the data before the validation step is applied.\nThe preprocessing function can be any callable that takes a table as input and returns a modified table. For example, you could use a lambda function to filter the table based on certain criteria or to apply a transformation to the data. Note that you can refer to columns via columns_subset= that are expected to be present in the transformed table, but may not exist in the table before preprocessing. Regarding the lifetime of the transformed table, it only exists during the validation step and is not stored in the Validate object or used in subsequent validation steps."
  },
  {
    "objectID": "reference/Validate.rows_complete.html#segmentation",
    "href": "reference/Validate.rows_complete.html#segmentation",
    "title": "Validate.rows_complete",
    "section": "Segmentation",
    "text": "Segmentation\nThe segments= argument allows for the segmentation of a validation step into multiple segments. This is useful for applying the same validation step to different subsets of the data. The segmentation can be done based on a single column or specific fields within a column.\nProviding a single column name will result in a separate validation step for each unique value in that column. For example, if you have a column called \"region\" with values \"North\", \"South\", and \"East\", the validation step will be applied separately to each region.\nAlternatively, you can provide a tuple that specifies a column name and its corresponding values to segment on. For example, if you have a column called \"date\" and you want to segment on only specific dates, you can provide a tuple like (\"date\", [\"2023-01-01\", \"2023-01-02\"]). Any other values in the column will be disregarded (i.e., no validation steps will be created for them).\nA list with a combination of column names and tuples can be provided as well. This allows for more complex segmentation scenarios. The following inputs are both valid:\n# Segments from all unique values in the `region` column\n# and specific dates in the `date` column\nsegments=[\"region\", (\"date\", [\"2023-01-01\", \"2023-01-02\"])]\n\n# Segments from all unique values in the `region` and `date` columns\nsegments=[\"region\", \"date\"]\nThe segmentation is performed during interrogation, and the resulting validation steps will be numbered sequentially. Each segment will have its own validation step, and the results will be reported separately. This allows for a more granular analysis of the data and helps identify issues within specific segments.\nImportantly, the segmentation process will be performed after any preprocessing of the data table. Because of this, one can conceivably use the pre= argument to generate a column that can be used for segmentation. For example, you could create a new column called \"segment\" through use of pre= and then use that column for segmentation."
  },
  {
    "objectID": "reference/Validate.rows_complete.html#thresholds",
    "href": "reference/Validate.rows_complete.html#thresholds",
    "title": "Validate.rows_complete",
    "section": "Thresholds",
    "text": "Thresholds\nThe thresholds= parameter is used to set the failure-condition levels for the validation step. If they are set here at the step level, these thresholds will override any thresholds set at the global level in Validate(thresholds=...).\nThere are three threshold levels: ‘warning’, ‘error’, and ‘critical’. The threshold values can either be set as a proportion failing of all test units (a value between 0 to 1), or, the absolute number of failing test units (as integer that’s 1 or greater).\nThresholds can be defined using one of these input schemes:\n\nuse the Thresholds class (the most direct way to create thresholds)\nprovide a tuple of 1-3 values, where position 0 is the ‘warning’ level, position 1 is the ‘error’ level, and position 2 is the ‘critical’ level\ncreate a dictionary of 1-3 value entries; the valid keys: are ‘warning’, ‘error’, and ‘critical’\na single integer/float value denoting absolute number or fraction of failing test units for the ‘warning’ level only\n\nIf the number of failing test units exceeds set thresholds, the validation step will be marked as ‘warning’, ‘error’, or ‘critical’. All of the threshold levels don’t need to be set, you’re free to set any combination of them.\nAside from reporting failure conditions, thresholds can be used to determine the actions to take for each level of failure (using the actions= parameter)."
  },
  {
    "objectID": "reference/Validate.rows_complete.html#examples",
    "href": "reference/Validate.rows_complete.html#examples",
    "title": "Validate.rows_complete",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with three string columns (col_1, col_2, and col_3). The table is shown below:\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"col_1\": [\"a\", None, \"c\", \"d\"],\n        \"col_2\": [\"a\", \"a\", \"c\", None],\n        \"col_3\": [\"a\", \"a\", \"d\", None],\n    }\n)\n\npb.preview(tbl)\n\n\n\n\n\n  \n  \n  \n  \n\n\n\n\n\n  \n  col_1String\n  col_2String\n  col_3String\n\n\n\n  \n    1\n    a\n    a\n    a\n  \n  \n    2\n    None\n    a\n    a\n  \n  \n    3\n    c\n    c\n    d\n  \n  \n    4\n    d\n    None\n    None\n  \n\n\n\n\n\n\n        \n\n\nLet’s validate that the rows in the table are complete with rows_complete(). We’ll determine if this validation had any failing test units (there are four test units, one for each row). A failing test units means that a given row is not complete (i.e., has at least one missing value).\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .rows_complete()\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    rows_complete\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            rows_complete()\n        \n        \n        \n    ALL COLUMNS\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    20.50\n    20.50\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nFrom this validation table we see that there are two failing test units. This is because two rows in the table have at least one missing value (the second row and the last row).\nWe can also use a subset of columns to determine completeness. Let’s specify the subset using columns col_2 and col_3 for the next validation.\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .rows_complete(columns_subset=[\"col_2\", \"col_3\"])\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    rows_complete\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            rows_complete()\n        \n        \n        \n    col_2, col_3\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    30.75\n    10.25\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe validation table reports a single failing test units. The last row contains missing values in both the col_2 and col_3 columns. others."
  },
  {
    "objectID": "reference/Validate.get_sundered_data.html",
    "href": "reference/Validate.get_sundered_data.html",
    "title": "Validate.get_sundered_data",
    "section": "",
    "text": "Validate.get_sundered_data(type='pass')\nGet the data that passed or failed the validation steps.\nValidation of the data is one thing but, sometimes, you want to use the best part of the input dataset for something else. The get_sundered_data() method works with a Validate object that has been interrogated (i.e., the interrogate() method was used). We can get either the ‘pass’ data piece (rows with no failing test units across all column-value based validation functions), or, the ‘fail’ data piece (rows with at least one failing test unit across the same series of validations)."
  },
  {
    "objectID": "reference/Validate.get_sundered_data.html#details",
    "href": "reference/Validate.get_sundered_data.html#details",
    "title": "Validate.get_sundered_data",
    "section": "Details",
    "text": "Details\nThere are some caveats to sundering. The validation steps considered for this splitting will only involve steps where:\n\nof certain check types, where test units are cells checked down a column (e.g., the col_vals_*() methods)\nactive= is not set to False\npre= has not been given an expression for modifying the input table\n\nSo long as these conditions are met, the data will be split into two constituent tables: one with the rows that passed all validation steps and another with the rows that failed at least one validation step."
  },
  {
    "objectID": "reference/Validate.get_sundered_data.html#parameters",
    "href": "reference/Validate.get_sundered_data.html#parameters",
    "title": "Validate.get_sundered_data",
    "section": "Parameters",
    "text": "Parameters\n\ntype :  = 'pass'\n\nThe type of data to return. Options are \"pass\" or \"fail\", where the former returns a table only containing rows where test units always passed validation steps, and the latter returns a table only containing rows had test units that failed in at least one validation step."
  },
  {
    "objectID": "reference/Validate.get_sundered_data.html#returns",
    "href": "reference/Validate.get_sundered_data.html#returns",
    "title": "Validate.get_sundered_data",
    "section": "Returns",
    "text": "Returns\n\n : FrameT\n\nA table containing the data that passed or failed the validation steps."
  },
  {
    "objectID": "reference/Validate.get_sundered_data.html#examples",
    "href": "reference/Validate.get_sundered_data.html#examples",
    "title": "Validate.get_sundered_data",
    "section": "Examples",
    "text": "Examples\nLet’s create a Validate object with three validation steps and then interrogate the data.\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [7, 6, 9, 7, 3, 2],\n        \"b\": [9, 8, 10, 5, 10, 6],\n        \"c\": [\"c\", \"d\", \"a\", \"b\", \"a\", \"b\"]\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(columns=\"a\", value=5)\n    .col_vals_in_set(columns=\"c\", set=[\"a\", \"b\"])\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:15:33Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    a\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    40.67\n    20.33\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        \n        \n    c\n    a, b\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    40.67\n    20.33\n    —\n    —\n    —\n    CSV\n  \n\n  \n  \n  \n    2025-11-23 00:15:33 UTC&lt; 1 s2025-11-23 00:15:33 UTC\n  \n\n\n\n\n\n\n        \n\n\nFrom the validation table, we can see that the first and second steps each had 4 passing test units. A failing test unit will mark the entire row as failing in the context of the get_sundered_data() method. We can use this method to get the rows of data that passed the during interrogation.\n\npb.preview(validation.get_sundered_data())\n\n\n\n\n\n  \n  \n  \n  \n\n\n\n\n\n  \n  aInt64\n  bInt64\n  cString\n\n\n\n  \n    1\n    9\n    10\n    a\n  \n  \n    2\n    7\n    5\n    b\n  \n\n\n\n\n\n\n        \n\n\nThe returned DataFrame contains the rows that passed all validation steps (we passed this object to preview() to show it in an HTML view). From the six-row input DataFrame, the first two rows and the last two rows had test units that failed validation. Thus the middle two rows are the only ones that passed all validation steps and that’s what we see in the returned DataFrame."
  },
  {
    "objectID": "reference/contains.html",
    "href": "reference/contains.html",
    "title": "contains",
    "section": "",
    "text": "contains(text, case_sensitive=False)\nSelect columns that contain specified text.\nMany validation methods have a columns= argument that can be used to specify the columns for validation (e.g., col_vals_gt(), col_vals_regex(), etc.). The contains() selector function can be used to select one or more columns that contain some specified text. So if the set of table columns consists of\n[profit, conv_first, conv_last, highest_conv, age]\nand you want to validate columns that have \"conv\" in the name, you can use columns=contains(\"conv\"). This will select the conv_first, conv_last, and highest_conv columns.\nThere will be a validation step created for every resolved column. Note that if there aren’t any columns resolved from using contains() (or any other expression using selector functions), the validation step will fail to be evaluated during the interrogation process. Such a failure to evaluate will be reported in the validation results but it won’t affect the interrogation process overall (i.e., the process won’t be halted)."
  },
  {
    "objectID": "reference/contains.html#parameters",
    "href": "reference/contains.html#parameters",
    "title": "contains",
    "section": "Parameters",
    "text": "Parameters\n\ntext : str\n\nThe text that the column name should contain.\n\ncase_sensitive : bool = False\n\nWhether column names should be treated as case-sensitive. The default is False."
  },
  {
    "objectID": "reference/contains.html#returns",
    "href": "reference/contains.html#returns",
    "title": "contains",
    "section": "Returns",
    "text": "Returns\n\n : Contains\n\nA Contains object, which can be used to select columns that contain the specified text."
  },
  {
    "objectID": "reference/contains.html#relevant-validation-methods-where-contains-can-be-used",
    "href": "reference/contains.html#relevant-validation-methods-where-contains-can-be-used",
    "title": "contains",
    "section": "Relevant Validation Methods where contains() can be Used",
    "text": "Relevant Validation Methods where contains() can be Used\nThis selector function can be used in the columns= argument of the following validation methods:\n\ncol_vals_gt()\ncol_vals_lt()\ncol_vals_ge()\ncol_vals_le()\ncol_vals_eq()\ncol_vals_ne()\ncol_vals_between()\ncol_vals_outside()\ncol_vals_in_set()\ncol_vals_not_in_set()\ncol_vals_increasing()\ncol_vals_decreasing()\ncol_vals_null()\ncol_vals_not_null()\ncol_vals_regex()\ncol_vals_within_spec()\ncol_exists()\n\nThe contains() selector function doesn’t need to be used in isolation. Read the next section for information on how to compose it with other column selectors for more refined ways to select columns."
  },
  {
    "objectID": "reference/contains.html#additional-flexibilty-through-composition-with-other-column-selectors",
    "href": "reference/contains.html#additional-flexibilty-through-composition-with-other-column-selectors",
    "title": "contains",
    "section": "Additional Flexibilty through Composition with Other Column Selectors",
    "text": "Additional Flexibilty through Composition with Other Column Selectors\nThe contains() function can be composed with other column selectors to create fine-grained column selections. For example, to select columns that have the text \"_n\" and start with \"item\", you can use the contains() and starts_with() functions together. The only condition is that the expressions are wrapped in the col() function, like this:\ncol(contains(\"_n\") & starts_with(\"item\"))\nThere are four operators that can be used to compose column selectors:\n\n& (and)\n| (or)\n- (difference)\n~ (not)\n\nThe & operator is used to select columns that satisfy both conditions. The | operator is used to select columns that satisfy either condition. The - operator is used to select columns that satisfy the first condition but not the second. The ~ operator is used to select columns that don’t satisfy the condition. As many selector functions can be used as needed and the operators can be combined to create complex column selection criteria (parentheses can be used to group conditions and control the order of evaluation)."
  },
  {
    "objectID": "reference/contains.html#examples",
    "href": "reference/contains.html#examples",
    "title": "contains",
    "section": "Examples",
    "text": "Examples\nSuppose we have a table with columns name, 2021_pay_total, 2022_pay_total, and person_id and we’d like to validate that the values in columns having \"pay\" in the name are greater than 10. We can use the contains() column selector function to specify the column names that contain \"pay\" as the columns to validate.\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n        \"2021_pay_total\": [16.32, 16.25, 15.75],\n        \"2022_pay_total\": [18.62, 16.95, 18.25],\n        \"person_id\": [\"A123\", \"B456\", \"C789\"],\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(columns=pb.contains(\"pay\"), value=10)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    2021_pay_total\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    2022_pay_total\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nFrom the results of the validation table we get two validation steps, one for 2021_pay_total and one for 2022_pay_total. The values in both columns were all greater than 10.\nWe can also use the contains() function in combination with other column selectors (within col()) to create more complex column selection criteria (i.e., to select columns that satisfy multiple conditions). For example, to select columns that contain \"pay\" and match the text \"2023\" or \"2024\", we can use the & operator to combine column selectors.\n\ntbl = pl.DataFrame(\n    {\n        \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n        \"2022_hours\": [160, 180, 160],\n        \"2023_hours\": [182, 168, 175],\n        \"2024_hours\": [200, 165, 190],\n        \"2022_pay_total\": [18.62, 16.95, 18.25],\n        \"2023_pay_total\": [19.29, 17.75, 18.35],\n        \"2024_pay_total\": [20.73, 18.35, 20.10],\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(\n        columns=pb.col(pb.contains(\"pay\") & pb.matches(\"2023|2024\")),\n        value=10\n    )\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    2023_pay_total\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    2024_pay_total\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nFrom the results of the validation table we get two validation steps, one for 2023_pay_total and one for 2024_pay_total."
  },
  {
    "objectID": "reference/send_slack_notification.html",
    "href": "reference/send_slack_notification.html",
    "title": "send_slack_notification",
    "section": "",
    "text": "send_slack_notification(\n    webhook_url=None,\n    step_msg=None,\n    summary_msg=None,\n    debug=False,\n)\nCreate a Slack notification function using a webhook URL.\nThis function can be used in two ways:\n\nWith Actions to notify about individual validation step failures\nWith FinalActions to provide a summary notification after all validation steps have undergone interrogation\n\nThe function creates a callable that sends notifications through a Slack webhook. Message formatting can be customized using templates for both individual steps and summary reports.\n\n\n\nwebhook_url : str | None = None\n\nThe Slack webhook URL. If None (and debug=True), a dry run is performed (see the Offline Testing section below for information on this).\n\nstep_msg : str | None = None\n\nTemplate string for step notifications. Some of the available variables include: \"{step}\", \"{column}\", \"{value}\", \"{type}\", \"{time}\", \"{level}\", etc. See the Available Template Variables for Step Notifications section below for more details. If not provided, a default step message template will be used.\n\nsummary_msg : str | None = None\n\nTemplate string for summary notifications. Some of the available variables are: \"{n_steps}\", \"{n_passing_steps}\", \"{n_failing_steps}\", \"{all_passed}\", \"{highest_severity}\", etc. See the Available Template Variables for Summary Notifications section below for more details. If not provided, a default summary message template will be used.\n\ndebug : bool = False\n\nPrint debug information if True. This includes the message content and the response from Slack. This is useful for testing and debugging the notification function. If webhook_url is None, the function will print the message to the console instead of sending it to Slack. This is useful for debugging and ensuring that your templates are formatted correctly.\n\n\n\n\n\n\n : Callable\n\nA function that sends notifications to Slack.\n\n\n\n\n\nWhen creating a custom template for validation step alerts (step_msg=), the following templating strings can be used:\n\n\"{step}\": The step number.\n\"{column}\": The column name.\n\"{value}\": The value being compared (only available in certain validation steps).\n\"{type}\": The assertion type (e.g., \"col_vals_gt\", etc.).\n\"{level}\": The severity level (\"warning\", \"error\", or \"critical\").\n\"{level_num}\": The severity level as a numeric value (30, 40, or 50).\n\"{autobrief}\": A localized and brief statement of the expectation for the step.\n\"{failure_text}\": Localized text that explains how the validation step failed.\n\"{time}\": The time of the notification.\n\nHere’s an example of how to construct a step_msg= template:\nstep_msg = '''🚨 *Validation Step Alert*\n• Step Number: {step}\n• Column: {column}\n• Test Type: {type}\n• Value Tested: {value}\n• Severity: {level} (level {level_num})\n• Brief: {autobrief}\n• Details: {failure_text}\n• Time: {time}'''\nThis template will be filled with the relevant information when a validation step fails. The placeholders will be replaced with actual values when the Slack notification is sent.\n\n\n\nWhen creating a custom template for a validation summary (summary_msg=), the following templating strings can be used:\n\n\"{n_steps}\": The total number of validation steps.\n\"{n_passing_steps}\": The number of validation steps where all test units passed.\n\"{n_failing_steps}\": The number of validation steps that had some failing test units.\n\"{n_warning_steps}\": The number of steps that exceeded a ‘warning’ threshold.\n\"{n_error_steps}\": The number of steps that exceeded an ‘error’ threshold.\n\"{n_critical_steps}\": The number of steps that exceeded a ‘critical’ threshold.\n\"{all_passed}\": Whether or not every validation step had no failing test units.\n\"{highest_severity}\": The highest severity level encountered during validation. This can be one of the following: \"warning\", \"error\", or \"critical\", \"some failing\", or \"all passed\".\n\"{tbl_row_count}\": The number of rows in the target table.\n\"{tbl_column_count}\": The number of columns in the target table.\n\"{tbl_name}\": The name of the target table.\n\"{validation_duration}\": The duration of the validation in seconds.\n\"{time}\": The time of the notification.\n\nHere’s an example of how to put together a summary_msg= template:\nsummary_msg = '''📊 *Validation Summary Report*\n*Overview*\n• Status: {highest_severity}\n• All Passed: {all_passed}\n• Total Steps: {n_steps}\n\n*Step Results*\n• Passing Steps: {n_passing_steps}\n• Failing Steps: {n_failing_steps}\n• Warning Level: {n_warning_steps}\n• Error Level: {n_error_steps}\n• Critical Level: {n_critical_steps}\n\n*Table Info*\n• Table Name: {tbl_name}\n• Row Count: {tbl_row_count}\n• Column Count: {tbl_column_count}\n\n*Timing*\n• Duration: {validation_duration}s\n• Completed: {time}'''\nThis template will be filled with the relevant information when the validation summary is generated. The placeholders will be replaced with actual values when the Slack notification is sent.\n\n\n\nIf you want to test the function without sending actual notifications, you can leave the webhook_url= as None and set debug=True. This will print the message to the console instead of sending it to Slack. This is useful for debugging and ensuring that your templates are formatted correctly. Furthermore, the function could be run globally (i.e., outside of the context of a validation plan) to show the message templates with all possible variables. Here’s an example of how to do this:\nimport pointblank as pb\n\n# Create a Slack notification function\nnotify_slack = pb.send_slack_notification(\n    webhook_url=None,  # Leave as None for dry run\n    debug=True,  # Enable debug mode to print message previews\n)\n# Call the function to see the message previews\nnotify_slack()\nThis will print the step and summary message previews to the console, allowing you to see how the templates will look when filled with actual data. You can then adjust your templates as needed before using them in a real validation plan.\nWhen step_msg= and summary_msg= are not provided, the function will use default templates. However, you can customize the templates to include additional information or change the format to better suit your needs. Iterating on the templates can help you create more informative and visually appealing messages. Here’s an example of that:\nimport pointblank as pb\n\n# Create a Slack notification function with custom templates\nnotify_slack = pb.send_slack_notification(\n    webhook_url=None, # Leave as None for dry run\n    step_msg='''*Data Validation Alert*\n    • Type: {type}\n    • Level: {level}\n    • Step: {step}\n    • Column: {column}\n    • Time: {time}''',\n    summary_msg='''*Data Validation Summary*\n    • Highest Severity: {highest_severity}\n    • Total Steps: {n_steps}\n    • Failed Steps: {n_failing_steps}\n    • Time: {time}''',\n    debug=True,  # Enable debug mode to print message previews\n)\nThese templates will be used with sample data when the function is called. The combination of webhook_url=None and debug=True allows you to test your custom templates without having to send actual notifications to Slack.\n\n\n\nWhen using an action with one or more validation steps, you typically provide callables that fire when a matched threshold of failed test units is exceeded. The callable can be a function or a lambda. The send_slack_notification() function creates a callable that sends a Slack notification when the validation step fails. Here is how it can be set up to work for multiple validation steps by using of Actions:\nimport pointblank as pb\n\n# Create a Slack notification function\nnotify_slack = pb.send_slack_notification(\n    webhook_url=\"https://hooks.slack.com/services/your/webhook/url\"\n)\n# Create a validation plan\nvalidation = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"duckdb\"),\n        thresholds=pb.Thresholds(warning=0.05, error=0.10, critical=0.15),\n        actions=pb.Actions(critical=notify_slack),\n    )\n    .col_vals_regex(columns=\"player_id\", pattern=r\"[A-Z]{12}[0-9]{3}\")\n    .col_vals_gt(columns=\"item_revenue\", value=0.05)\n    .col_vals_gt(columns=\"session_duration\", value=15)\n    .interrogate()\n)\n\nvalidation\nBy placing the notify_slack() function in the Validate(actions=Actions(critical=)) argument, you can ensure that the notification is sent whenever the ‘critical’ threshold is reached (as set here, when 15% or more of the test units fail). The notification will include information about the validation step that triggered the alert.\nWhen using a FinalActions object, the notification will be sent after all validation steps have been completed. This is useful for providing a summary of the validation process. Here is an example of how to set up a summary notification:\nimport pointblank as pb\n\n# Create a Slack notification function\nnotify_slack = pb.send_slack_notification(\n    webhook_url=\"https://hooks.slack.com/services/your/webhook/url\"\n)\n# Create a validation plan\nvalidation = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"duckdb\"),\n        thresholds=pb.Thresholds(warning=0.05, error=0.10, critical=0.15),\n        final_actions=pb.FinalActions(notify_slack),\n    )\n    .col_vals_regex(columns=\"player_id\", pattern=r\"[A-Z]{12}[0-9]{3}\")\n    .col_vals_gt(columns=\"item_revenue\", value=0.05)\n    .col_vals_gt(columns=\"session_duration\", value=15)\n    .interrogate()\n)\nIn this case, the same notify_slack() function is used, but it is placed in Validate(final_actions=FinalActions()). This results in the summary notification being sent after all validation steps are completed, regardless of whether any steps failed or not.\nThis simplicity is possible because the send_slack_notification() function creates a callable that can be used in both contexts. The function will automatically determine whether to send a step notification or a summary notification based on the context in which it is called.\nWe can customize the message templates for both step and summary notifications. In that way, it’s possible to create a more informative and visually appealing message. For example, we can use Markdown formatting to make the message more readable and visually appealing. Here is an example of how to customize the templates:\nimport pointblank as pb\n# Create a Slack notification function\n\nnotify_slack = pb.send_slack_notification(\n    webhook_url=\"https://hooks.slack.com/services/your/webhook/url\",\n    step_msg='''\n    🚨 *Validation Step Alert*\n    • Step Number: {step}\n    • Column: {column}\n    • Test Type: {type}\n    • Value Tested: {value}\n    • Severity: {level} (level {level_num})\n    • Brief: {autobrief}\n    • Details: {failure_text}\n    • Time: {time}''',\n    summary_msg='''\n    📊 *Validation Summary Report*\n    *Overview*\n    • Status: {highest_severity}\n    • All Passed: {all_passed}\n    • Total Steps: {n_steps}\n\n    *Step Results*\n    • Passing Steps: {n_passing_steps}\n    • Failing Steps: {n_failing_steps}\n    • Warning Level: {n_warning_steps}\n    • Error Level: {n_error_steps}\n    • Critical Level: {n_critical_steps}\n\n    *Table Info*\n    • Table Name: {tbl_name}\n    • Row Count: {tbl_row_count}\n    • Column Count: {tbl_column_count}\n\n    *Timing*\n    • Duration: {validation_duration}s\n    • Completed: {time}''',\n)\n\n# Create a validation plan\nvalidation = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"duckdb\"),\n        thresholds=pb.Thresholds(warning=0.05, error=0.10, critical=0.15),\n        actions=pb.Actions(default=notify_slack),\n        final_actions=pb.FinalActions(notify_slack),\n    )\n    .col_vals_regex(columns=\"player_id\", pattern=r\"[A-Z]{12}[0-9]{3}\")\n    .col_vals_gt(columns=\"item_revenue\", value=0.05)\n    .col_vals_gt(columns=\"session_duration\", value=15)\n    .interrogate()\n)\nIn this example, we have customized the templates for both step and summary notifications. The step notification includes details about the validation step, including the step number, column name, test type, value tested, severity level, brief description, and time of the notification. The summary notification includes an overview of the validation process, including the status, number of steps, passing and failing steps, table information, and timing details."
  },
  {
    "objectID": "reference/send_slack_notification.html#parameters",
    "href": "reference/send_slack_notification.html#parameters",
    "title": "send_slack_notification",
    "section": "",
    "text": "webhook_url : str | None = None\n\nThe Slack webhook URL. If None (and debug=True), a dry run is performed (see the Offline Testing section below for information on this).\n\nstep_msg : str | None = None\n\nTemplate string for step notifications. Some of the available variables include: \"{step}\", \"{column}\", \"{value}\", \"{type}\", \"{time}\", \"{level}\", etc. See the Available Template Variables for Step Notifications section below for more details. If not provided, a default step message template will be used.\n\nsummary_msg : str | None = None\n\nTemplate string for summary notifications. Some of the available variables are: \"{n_steps}\", \"{n_passing_steps}\", \"{n_failing_steps}\", \"{all_passed}\", \"{highest_severity}\", etc. See the Available Template Variables for Summary Notifications section below for more details. If not provided, a default summary message template will be used.\n\ndebug : bool = False\n\nPrint debug information if True. This includes the message content and the response from Slack. This is useful for testing and debugging the notification function. If webhook_url is None, the function will print the message to the console instead of sending it to Slack. This is useful for debugging and ensuring that your templates are formatted correctly."
  },
  {
    "objectID": "reference/send_slack_notification.html#returns",
    "href": "reference/send_slack_notification.html#returns",
    "title": "send_slack_notification",
    "section": "",
    "text": ": Callable\n\nA function that sends notifications to Slack."
  },
  {
    "objectID": "reference/send_slack_notification.html#available-template-variables-for-step-notifications",
    "href": "reference/send_slack_notification.html#available-template-variables-for-step-notifications",
    "title": "send_slack_notification",
    "section": "",
    "text": "When creating a custom template for validation step alerts (step_msg=), the following templating strings can be used:\n\n\"{step}\": The step number.\n\"{column}\": The column name.\n\"{value}\": The value being compared (only available in certain validation steps).\n\"{type}\": The assertion type (e.g., \"col_vals_gt\", etc.).\n\"{level}\": The severity level (\"warning\", \"error\", or \"critical\").\n\"{level_num}\": The severity level as a numeric value (30, 40, or 50).\n\"{autobrief}\": A localized and brief statement of the expectation for the step.\n\"{failure_text}\": Localized text that explains how the validation step failed.\n\"{time}\": The time of the notification.\n\nHere’s an example of how to construct a step_msg= template:\nstep_msg = '''🚨 *Validation Step Alert*\n• Step Number: {step}\n• Column: {column}\n• Test Type: {type}\n• Value Tested: {value}\n• Severity: {level} (level {level_num})\n• Brief: {autobrief}\n• Details: {failure_text}\n• Time: {time}'''\nThis template will be filled with the relevant information when a validation step fails. The placeholders will be replaced with actual values when the Slack notification is sent."
  },
  {
    "objectID": "reference/send_slack_notification.html#available-template-variables-for-summary-notifications",
    "href": "reference/send_slack_notification.html#available-template-variables-for-summary-notifications",
    "title": "send_slack_notification",
    "section": "",
    "text": "When creating a custom template for a validation summary (summary_msg=), the following templating strings can be used:\n\n\"{n_steps}\": The total number of validation steps.\n\"{n_passing_steps}\": The number of validation steps where all test units passed.\n\"{n_failing_steps}\": The number of validation steps that had some failing test units.\n\"{n_warning_steps}\": The number of steps that exceeded a ‘warning’ threshold.\n\"{n_error_steps}\": The number of steps that exceeded an ‘error’ threshold.\n\"{n_critical_steps}\": The number of steps that exceeded a ‘critical’ threshold.\n\"{all_passed}\": Whether or not every validation step had no failing test units.\n\"{highest_severity}\": The highest severity level encountered during validation. This can be one of the following: \"warning\", \"error\", or \"critical\", \"some failing\", or \"all passed\".\n\"{tbl_row_count}\": The number of rows in the target table.\n\"{tbl_column_count}\": The number of columns in the target table.\n\"{tbl_name}\": The name of the target table.\n\"{validation_duration}\": The duration of the validation in seconds.\n\"{time}\": The time of the notification.\n\nHere’s an example of how to put together a summary_msg= template:\nsummary_msg = '''📊 *Validation Summary Report*\n*Overview*\n• Status: {highest_severity}\n• All Passed: {all_passed}\n• Total Steps: {n_steps}\n\n*Step Results*\n• Passing Steps: {n_passing_steps}\n• Failing Steps: {n_failing_steps}\n• Warning Level: {n_warning_steps}\n• Error Level: {n_error_steps}\n• Critical Level: {n_critical_steps}\n\n*Table Info*\n• Table Name: {tbl_name}\n• Row Count: {tbl_row_count}\n• Column Count: {tbl_column_count}\n\n*Timing*\n• Duration: {validation_duration}s\n• Completed: {time}'''\nThis template will be filled with the relevant information when the validation summary is generated. The placeholders will be replaced with actual values when the Slack notification is sent."
  },
  {
    "objectID": "reference/send_slack_notification.html#offline-testing",
    "href": "reference/send_slack_notification.html#offline-testing",
    "title": "send_slack_notification",
    "section": "",
    "text": "If you want to test the function without sending actual notifications, you can leave the webhook_url= as None and set debug=True. This will print the message to the console instead of sending it to Slack. This is useful for debugging and ensuring that your templates are formatted correctly. Furthermore, the function could be run globally (i.e., outside of the context of a validation plan) to show the message templates with all possible variables. Here’s an example of how to do this:\nimport pointblank as pb\n\n# Create a Slack notification function\nnotify_slack = pb.send_slack_notification(\n    webhook_url=None,  # Leave as None for dry run\n    debug=True,  # Enable debug mode to print message previews\n)\n# Call the function to see the message previews\nnotify_slack()\nThis will print the step and summary message previews to the console, allowing you to see how the templates will look when filled with actual data. You can then adjust your templates as needed before using them in a real validation plan.\nWhen step_msg= and summary_msg= are not provided, the function will use default templates. However, you can customize the templates to include additional information or change the format to better suit your needs. Iterating on the templates can help you create more informative and visually appealing messages. Here’s an example of that:\nimport pointblank as pb\n\n# Create a Slack notification function with custom templates\nnotify_slack = pb.send_slack_notification(\n    webhook_url=None, # Leave as None for dry run\n    step_msg='''*Data Validation Alert*\n    • Type: {type}\n    • Level: {level}\n    • Step: {step}\n    • Column: {column}\n    • Time: {time}''',\n    summary_msg='''*Data Validation Summary*\n    • Highest Severity: {highest_severity}\n    • Total Steps: {n_steps}\n    • Failed Steps: {n_failing_steps}\n    • Time: {time}''',\n    debug=True,  # Enable debug mode to print message previews\n)\nThese templates will be used with sample data when the function is called. The combination of webhook_url=None and debug=True allows you to test your custom templates without having to send actual notifications to Slack."
  },
  {
    "objectID": "reference/send_slack_notification.html#examples",
    "href": "reference/send_slack_notification.html#examples",
    "title": "send_slack_notification",
    "section": "",
    "text": "When using an action with one or more validation steps, you typically provide callables that fire when a matched threshold of failed test units is exceeded. The callable can be a function or a lambda. The send_slack_notification() function creates a callable that sends a Slack notification when the validation step fails. Here is how it can be set up to work for multiple validation steps by using of Actions:\nimport pointblank as pb\n\n# Create a Slack notification function\nnotify_slack = pb.send_slack_notification(\n    webhook_url=\"https://hooks.slack.com/services/your/webhook/url\"\n)\n# Create a validation plan\nvalidation = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"duckdb\"),\n        thresholds=pb.Thresholds(warning=0.05, error=0.10, critical=0.15),\n        actions=pb.Actions(critical=notify_slack),\n    )\n    .col_vals_regex(columns=\"player_id\", pattern=r\"[A-Z]{12}[0-9]{3}\")\n    .col_vals_gt(columns=\"item_revenue\", value=0.05)\n    .col_vals_gt(columns=\"session_duration\", value=15)\n    .interrogate()\n)\n\nvalidation\nBy placing the notify_slack() function in the Validate(actions=Actions(critical=)) argument, you can ensure that the notification is sent whenever the ‘critical’ threshold is reached (as set here, when 15% or more of the test units fail). The notification will include information about the validation step that triggered the alert.\nWhen using a FinalActions object, the notification will be sent after all validation steps have been completed. This is useful for providing a summary of the validation process. Here is an example of how to set up a summary notification:\nimport pointblank as pb\n\n# Create a Slack notification function\nnotify_slack = pb.send_slack_notification(\n    webhook_url=\"https://hooks.slack.com/services/your/webhook/url\"\n)\n# Create a validation plan\nvalidation = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"duckdb\"),\n        thresholds=pb.Thresholds(warning=0.05, error=0.10, critical=0.15),\n        final_actions=pb.FinalActions(notify_slack),\n    )\n    .col_vals_regex(columns=\"player_id\", pattern=r\"[A-Z]{12}[0-9]{3}\")\n    .col_vals_gt(columns=\"item_revenue\", value=0.05)\n    .col_vals_gt(columns=\"session_duration\", value=15)\n    .interrogate()\n)\nIn this case, the same notify_slack() function is used, but it is placed in Validate(final_actions=FinalActions()). This results in the summary notification being sent after all validation steps are completed, regardless of whether any steps failed or not.\nThis simplicity is possible because the send_slack_notification() function creates a callable that can be used in both contexts. The function will automatically determine whether to send a step notification or a summary notification based on the context in which it is called.\nWe can customize the message templates for both step and summary notifications. In that way, it’s possible to create a more informative and visually appealing message. For example, we can use Markdown formatting to make the message more readable and visually appealing. Here is an example of how to customize the templates:\nimport pointblank as pb\n# Create a Slack notification function\n\nnotify_slack = pb.send_slack_notification(\n    webhook_url=\"https://hooks.slack.com/services/your/webhook/url\",\n    step_msg='''\n    🚨 *Validation Step Alert*\n    • Step Number: {step}\n    • Column: {column}\n    • Test Type: {type}\n    • Value Tested: {value}\n    • Severity: {level} (level {level_num})\n    • Brief: {autobrief}\n    • Details: {failure_text}\n    • Time: {time}''',\n    summary_msg='''\n    📊 *Validation Summary Report*\n    *Overview*\n    • Status: {highest_severity}\n    • All Passed: {all_passed}\n    • Total Steps: {n_steps}\n\n    *Step Results*\n    • Passing Steps: {n_passing_steps}\n    • Failing Steps: {n_failing_steps}\n    • Warning Level: {n_warning_steps}\n    • Error Level: {n_error_steps}\n    • Critical Level: {n_critical_steps}\n\n    *Table Info*\n    • Table Name: {tbl_name}\n    • Row Count: {tbl_row_count}\n    • Column Count: {tbl_column_count}\n\n    *Timing*\n    • Duration: {validation_duration}s\n    • Completed: {time}''',\n)\n\n# Create a validation plan\nvalidation = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"duckdb\"),\n        thresholds=pb.Thresholds(warning=0.05, error=0.10, critical=0.15),\n        actions=pb.Actions(default=notify_slack),\n        final_actions=pb.FinalActions(notify_slack),\n    )\n    .col_vals_regex(columns=\"player_id\", pattern=r\"[A-Z]{12}[0-9]{3}\")\n    .col_vals_gt(columns=\"item_revenue\", value=0.05)\n    .col_vals_gt(columns=\"session_duration\", value=15)\n    .interrogate()\n)\nIn this example, we have customized the templates for both step and summary notifications. The step notification includes details about the validation step, including the step number, column name, test type, value tested, severity level, brief description, and time of the notification. The summary notification includes an overview of the validation process, including the status, number of steps, passing and failing steps, table information, and timing details."
  },
  {
    "objectID": "reference/Validate.col_vals_decreasing.html",
    "href": "reference/Validate.col_vals_decreasing.html",
    "title": "Validate.col_vals_decreasing",
    "section": "",
    "text": "Validate.col_vals_decreasing(\n    columns,\n    allow_stationary=False,\n    increasing_tol=None,\n    na_pass=False,\n    pre=None,\n    segments=None,\n    thresholds=None,\n    actions=None,\n    brief=None,\n    active=True,\n)\nAre column data decreasing by row?\nThe col_vals_decreasing() validation method checks whether column values in a table are decreasing when moving down a table. There are options for allowing missing values in the target column, allowing stationary phases (where consecutive values don’t change), and even one for allowing increasing movements up to a certain threshold. This validation will operate over the number of test units that is equal to the number of rows in the table (determined after any pre= mutation has been applied)."
  },
  {
    "objectID": "reference/Validate.col_vals_decreasing.html#parameters",
    "href": "reference/Validate.col_vals_decreasing.html#parameters",
    "title": "Validate.col_vals_decreasing",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns : str | list[str] | Column | ColumnSelector | ColumnSelectorNarwhals\n\nA single column or a list of columns to validate. Can also use col() with column selectors to specify one or more columns. If multiple columns are supplied or resolved, there will be a separate validation step generated for each column.\n\nallow_stationary : bool = False\n\nAn option to allow pauses in decreasing values. For example, if the values for the test units are [88, 85, 85, 82, 80] then the third unit (85, appearing a second time) would be marked as failing when allow_stationary is False. Using allow_stationary=True will result in all the test units in [88, 85, 85, 82, 80] to be marked as passing.\n\nincreasing_tol : float | None = None\n\nAn optional threshold value that allows for movement of numerical values in the positive direction. By default this is None but using a numerical value will set the absolute threshold of positive travel allowed across numerical test units. Note that setting a value here also has the effect of setting allow_stationary to True.\n\nna_pass : bool = False\n\nShould any encountered None, NA, or Null values be considered as passing test units? By default, this is False. Set to True to pass test units with missing values.\n\npre : Callable | None = None\n\nAn optional preprocessing function or lambda to apply to the data table during interrogation. This function should take a table as input and return a modified table. Have a look at the Preprocessing section for more information on how to use this argument.\n\nsegments : SegmentSpec | None = None\n\nAn optional directive on segmentation, which serves to split a validation step into multiple (one step per segment). Can be a single column name, a tuple that specifies a column name and its corresponding values to segment on, or a combination of both (provided as a list). Read the Segmentation section for usage information.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nSet threshold failure levels for reporting and reacting to exceedences of the levels. The thresholds are set at the step level and will override any global thresholds set in Validate(thresholds=...). The default is None, which means that no thresholds will be set locally and global thresholds (if any) will take effect. Look at the Thresholds section for information on how to set threshold levels.\n\nactions : Actions | None = None\n\nOptional actions to take when the validation step(s) meets or exceeds any set threshold levels. If provided, the Actions class should be used to define the actions.\n\nbrief : str | bool | None = None\n\nAn optional brief description of the validation step that will be displayed in the reporting table. You can use the templating elements like \"{step}\" to insert the step number, or \"{auto}\" to include an automatically generated brief. If True the entire brief will be automatically generated. If None (the default) then there won’t be a brief.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.col_vals_decreasing.html#returns",
    "href": "reference/Validate.col_vals_decreasing.html#returns",
    "title": "Validate.col_vals_decreasing",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.col_vals_decreasing.html#examples",
    "href": "reference/Validate.col_vals_decreasing.html#examples",
    "title": "Validate.col_vals_decreasing",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with a numeric column (a). The table is shown below:\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [6, 5, 4, 3, 2, 1],\n        \"b\": [5, 4, 4, 3, 2, 1],\n        \"c\": [5, 4, 5, 3, 2, 1],\n    }\n)\n\npb.preview(tbl)\n\n\n\n\n\n  \n  \n  \n  \n\n\n\n\n\n  \n  aInt64\n  bInt64\n  cInt64\n\n\n\n  \n    1\n    6\n    5\n    5\n  \n  \n    2\n    5\n    4\n    4\n  \n  \n    3\n    4\n    4\n    5\n  \n  \n    4\n    3\n    3\n    3\n  \n  \n    5\n    2\n    2\n    2\n  \n  \n    6\n    1\n    1\n    1\n  \n\n\n\n\n\n\n        \n\n\nLet’s validate that values in column a are decreasing. We’ll determine if this validation had any failing test units (there are six test units, one for each row).\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_decreasing(columns=\"a\")\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_decreasing\n    \n        \n            \n            \n                \n            \n        \n    \n\n        \n        \n            col_vals_decreasing()\n        \n        \n        \n    a\n    \n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    61.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe validation passed as all values in column a are decreasing. Now let’s check column b which has a stationary value:\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_decreasing(columns=\"b\")\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_decreasing\n    \n        \n            \n            \n                \n            \n        \n    \n\n        \n        \n            col_vals_decreasing()\n        \n        \n        \n    b\n    \n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    50.83\n    10.17\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThis validation fails at the third row because the value 4 is repeated. If we want to allow stationary values, we can use allow_stationary=True:\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_decreasing(columns=\"b\", allow_stationary=True)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_decreasing\n    \n        \n            \n            \n                \n            \n        \n    \n\n        \n        \n            col_vals_decreasing()\n        \n        \n        \n    b\n    \n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    61.00\n    00.00\n    —\n    —\n    —\n    —"
  },
  {
    "objectID": "reference/get_validation_summary.html",
    "href": "reference/get_validation_summary.html",
    "title": "get_validation_summary",
    "section": "",
    "text": "get_validation_summary()\nAccess validation summary information when authoring final actions.\nThis function provides a convenient way to access summary information about the validation process within a final action. It returns a dictionary with key metrics from the validation process. This function can only be used within callables crafted for the FinalActions class.\n\n\n\n : dict | None\n\nA dictionary containing validation metrics. If called outside of an final action context, this function will return None.\n\n\n\n\n\nThe summary dictionary contains the following fields:\n\nn_steps (int): The total number of validation steps.\nn_passing_steps (int): The number of validation steps where all test units passed.\nn_failing_steps (int): The number of validation steps that had some failing test units.\nn_warning_steps (int): The number of steps that exceeded a ‘warning’ threshold.\nn_error_steps (int): The number of steps that exceeded an ‘error’ threshold.\nn_critical_steps (int): The number of steps that exceeded a ‘critical’ threshold.\nlist_passing_steps (list[int]): List of step numbers where all test units passed.\nlist_failing_steps (list[int]): List of step numbers for steps having failing test units.\ndict_n (dict): The number of test units for each validation step.\ndict_n_passed (dict): The number of test units that passed for each validation step.\ndict_n_failed (dict): The number of test units that failed for each validation step.\ndict_f_passed (dict): The fraction of test units that passed for each validation step.\ndict_f_failed (dict): The fraction of test units that failed for each validation step.\ndict_warning (dict): The ‘warning’ level status for each validation step.\ndict_error (dict): The ‘error’ level status for each validation step.\ndict_critical (dict): The ‘critical’ level status for each validation step.\nall_passed (bool): Whether or not every validation step had no failing test units.\nhighest_severity (str): The highest severity level encountered during validation. This can be one of the following: \"warning\", \"error\", or \"critical\", \"some failing\", or \"all passed\".\ntbl_row_count (int): The number of rows in the target table.\ntbl_column_count (int): The number of columns in the target table.\ntbl_name (str): The name of the target table.\nvalidation_duration (float): The duration of the validation in seconds.\n\nNote that the summary dictionary is only available within the context of a final action. If called outside of a final action (i.e., when no final action is being executed), this function will return None.\n\n\n\nFinal actions are executed after the completion of all validation steps. They provide an opportunity to take appropriate actions based on the overall validation results. Here’s an example of a final action function (send_report()) that sends an alert when critical validation failures are detected:\nimport pointblank as pb\n\ndef send_report():\n    summary = pb.get_validation_summary()\n    if summary[\"highest_severity\"] == \"critical\":\n        # Send an alert email\n        send_alert_email(\n            subject=f\"CRITICAL validation failures in {summary['tbl_name']}\",\n            body=f\"{summary['n_critical_steps']} steps failed with critical severity.\"\n        )\n\nvalidation = (\n    pb.Validate(\n        data=my_data,\n        final_actions=pb.FinalActions(send_report)\n    )\n    .col_vals_gt(columns=\"revenue\", value=0)\n    .interrogate()\n)\nNote that send_alert_email() in the example above is a placeholder function that would be implemented by the user to send email alerts. This function is not provided by the Pointblank package.\nThe get_validation_summary() function can also be used to create custom reporting for validation results:\ndef log_validation_results():\n    summary = pb.get_validation_summary()\n\n    print(f\"Validation completed with status: {summary['highest_severity'].upper()}\")\n    print(f\"Steps: {summary['n_steps']} total\")\n    print(f\"  - {summary['n_passing_steps']} passing, {summary['n_failing_steps']} failing\")\n    print(\n        f\"  - Severity: {summary['n_warning_steps']} warnings, \"\n        f\"{summary['n_error_steps']} errors, \"\n        f\"{summary['n_critical_steps']} critical\"\n    )\n\n    if summary['highest_severity'] in [\"error\", \"critical\"]:\n        print(\"⚠️ Action required: Please review failing validation steps!\")\nFinal actions work well with both simple logging and more complex notification systems, allowing you to integrate validation results into your broader data quality workflows.\n\n\n\nHave a look at FinalActions for more information on how to create custom actions that are executed after all validation steps have been completed."
  },
  {
    "objectID": "reference/get_validation_summary.html#returns",
    "href": "reference/get_validation_summary.html#returns",
    "title": "get_validation_summary",
    "section": "",
    "text": ": dict | None\n\nA dictionary containing validation metrics. If called outside of an final action context, this function will return None."
  },
  {
    "objectID": "reference/get_validation_summary.html#description-of-the-summary-fields",
    "href": "reference/get_validation_summary.html#description-of-the-summary-fields",
    "title": "get_validation_summary",
    "section": "",
    "text": "The summary dictionary contains the following fields:\n\nn_steps (int): The total number of validation steps.\nn_passing_steps (int): The number of validation steps where all test units passed.\nn_failing_steps (int): The number of validation steps that had some failing test units.\nn_warning_steps (int): The number of steps that exceeded a ‘warning’ threshold.\nn_error_steps (int): The number of steps that exceeded an ‘error’ threshold.\nn_critical_steps (int): The number of steps that exceeded a ‘critical’ threshold.\nlist_passing_steps (list[int]): List of step numbers where all test units passed.\nlist_failing_steps (list[int]): List of step numbers for steps having failing test units.\ndict_n (dict): The number of test units for each validation step.\ndict_n_passed (dict): The number of test units that passed for each validation step.\ndict_n_failed (dict): The number of test units that failed for each validation step.\ndict_f_passed (dict): The fraction of test units that passed for each validation step.\ndict_f_failed (dict): The fraction of test units that failed for each validation step.\ndict_warning (dict): The ‘warning’ level status for each validation step.\ndict_error (dict): The ‘error’ level status for each validation step.\ndict_critical (dict): The ‘critical’ level status for each validation step.\nall_passed (bool): Whether or not every validation step had no failing test units.\nhighest_severity (str): The highest severity level encountered during validation. This can be one of the following: \"warning\", \"error\", or \"critical\", \"some failing\", or \"all passed\".\ntbl_row_count (int): The number of rows in the target table.\ntbl_column_count (int): The number of columns in the target table.\ntbl_name (str): The name of the target table.\nvalidation_duration (float): The duration of the validation in seconds.\n\nNote that the summary dictionary is only available within the context of a final action. If called outside of a final action (i.e., when no final action is being executed), this function will return None."
  },
  {
    "objectID": "reference/get_validation_summary.html#examples",
    "href": "reference/get_validation_summary.html#examples",
    "title": "get_validation_summary",
    "section": "",
    "text": "Final actions are executed after the completion of all validation steps. They provide an opportunity to take appropriate actions based on the overall validation results. Here’s an example of a final action function (send_report()) that sends an alert when critical validation failures are detected:\nimport pointblank as pb\n\ndef send_report():\n    summary = pb.get_validation_summary()\n    if summary[\"highest_severity\"] == \"critical\":\n        # Send an alert email\n        send_alert_email(\n            subject=f\"CRITICAL validation failures in {summary['tbl_name']}\",\n            body=f\"{summary['n_critical_steps']} steps failed with critical severity.\"\n        )\n\nvalidation = (\n    pb.Validate(\n        data=my_data,\n        final_actions=pb.FinalActions(send_report)\n    )\n    .col_vals_gt(columns=\"revenue\", value=0)\n    .interrogate()\n)\nNote that send_alert_email() in the example above is a placeholder function that would be implemented by the user to send email alerts. This function is not provided by the Pointblank package.\nThe get_validation_summary() function can also be used to create custom reporting for validation results:\ndef log_validation_results():\n    summary = pb.get_validation_summary()\n\n    print(f\"Validation completed with status: {summary['highest_severity'].upper()}\")\n    print(f\"Steps: {summary['n_steps']} total\")\n    print(f\"  - {summary['n_passing_steps']} passing, {summary['n_failing_steps']} failing\")\n    print(\n        f\"  - Severity: {summary['n_warning_steps']} warnings, \"\n        f\"{summary['n_error_steps']} errors, \"\n        f\"{summary['n_critical_steps']} critical\"\n    )\n\n    if summary['highest_severity'] in [\"error\", \"critical\"]:\n        print(\"⚠️ Action required: Please review failing validation steps!\")\nFinal actions work well with both simple logging and more complex notification systems, allowing you to integrate validation results into your broader data quality workflows."
  },
  {
    "objectID": "reference/get_validation_summary.html#see-also",
    "href": "reference/get_validation_summary.html#see-also",
    "title": "get_validation_summary",
    "section": "",
    "text": "Have a look at FinalActions for more information on how to create custom actions that are executed after all validation steps have been completed."
  },
  {
    "objectID": "reference/Validate.col_schema_match.html",
    "href": "reference/Validate.col_schema_match.html",
    "title": "Validate.col_schema_match",
    "section": "",
    "text": "Validate.col_schema_match(\n    schema,\n    complete=True,\n    in_order=True,\n    case_sensitive_colnames=True,\n    case_sensitive_dtypes=True,\n    full_match_dtypes=True,\n    pre=None,\n    thresholds=None,\n    actions=None,\n    brief=None,\n    active=True,\n)\nDo columns in the table (and their types) match a predefined schema?\nThe col_schema_match() method works in conjunction with an object generated by the Schema class. That class object is the expectation for the actual schema of the target table. The validation step operates over a single test unit, which is whether the schema matches that of the table (within the constraints enforced by the complete=, and in_order= options)."
  },
  {
    "objectID": "reference/Validate.col_schema_match.html#parameters",
    "href": "reference/Validate.col_schema_match.html#parameters",
    "title": "Validate.col_schema_match",
    "section": "Parameters",
    "text": "Parameters\n\nschema : Schema\n\nA Schema object that represents the expected schema of the table. This object is generated by the Schema class.\n\ncomplete : bool = True\n\nShould the schema match be complete? If True, then the target table must have all columns specified in the schema. If False, then the table can have additional columns not in the schema (i.e., the schema is a subset of the target table’s columns).\n\nin_order : bool = True\n\nShould the schema match be in order? If True, then the columns in the schema must appear in the same order as they do in the target table. If False, then the order of columns in the schema and the target table can differ.\n\ncase_sensitive_colnames : bool = True\n\nShould the schema match be case-sensitive with regard to column names? If True, then the column names in the schema and the target table must match exactly. If False, then the column names are compared in a case-insensitive manner.\n\ncase_sensitive_dtypes : bool = True\n\nShould the schema match be case-sensitive with regard to column data types? If True, then the column data types in the schema and the target table must match exactly. If False, then the column data types are compared in a case-insensitive manner.\n\nfull_match_dtypes : bool = True\n\nShould the schema match require a full match of data types? If True, then the column data types in the schema and the target table must match exactly. If False then substring matches are allowed, so a schema data type of Int would match a target table data type of Int64.\n\npre : Callable | None = None\n\nAn optional preprocessing function or lambda to apply to the data table during interrogation. This function should take a table as input and return a modified table. Have a look at the Preprocessing section for more information on how to use this argument.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nSet threshold failure levels for reporting and reacting to exceedences of the levels. The thresholds are set at the step level and will override any global thresholds set in Validate(thresholds=...). The default is None, which means that no thresholds will be set locally and global thresholds (if any) will take effect. Look at the Thresholds section for information on how to set threshold levels.\n\nactions : Actions | None = None\n\nOptional actions to take when the validation step meets or exceeds any set threshold levels. If provided, the Actions class should be used to define the actions.\n\nbrief : str | bool | None = None\n\nAn optional brief description of the validation step that will be displayed in the reporting table. You can use the templating elements like \"{step}\" to insert the step number, or \"{auto}\" to include an automatically generated brief. If True the entire brief will be automatically generated. If None (the default) then there won’t be a brief.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.col_schema_match.html#returns",
    "href": "reference/Validate.col_schema_match.html#returns",
    "title": "Validate.col_schema_match",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.col_schema_match.html#preprocessing",
    "href": "reference/Validate.col_schema_match.html#preprocessing",
    "title": "Validate.col_schema_match",
    "section": "Preprocessing",
    "text": "Preprocessing\nThe pre= argument allows for a preprocessing function or lambda to be applied to the data table during interrogation. This function should take a table as input and return a modified table. This is useful for performing any necessary transformations or filtering on the data before the validation step is applied.\nThe preprocessing function can be any callable that takes a table as input and returns a modified table. Regarding the lifetime of the transformed table, it only exists during the validation step and is not stored in the Validate object or used in subsequent validation steps."
  },
  {
    "objectID": "reference/Validate.col_schema_match.html#thresholds",
    "href": "reference/Validate.col_schema_match.html#thresholds",
    "title": "Validate.col_schema_match",
    "section": "Thresholds",
    "text": "Thresholds\nThe thresholds= parameter is used to set the failure-condition levels for the validation step. If they are set here at the step level, these thresholds will override any thresholds set at the global level in Validate(thresholds=...).\nThere are three threshold levels: ‘warning’, ‘error’, and ‘critical’. The threshold values can either be set as a proportion failing of all test units (a value between 0 to 1), or, the absolute number of failing test units (as integer that’s 1 or greater).\nThresholds can be defined using one of these input schemes:\n\nuse the Thresholds class (the most direct way to create thresholds)\nprovide a tuple of 1-3 values, where position 0 is the ‘warning’ level, position 1 is the ‘error’ level, and position 2 is the ‘critical’ level\ncreate a dictionary of 1-3 value entries; the valid keys: are ‘warning’, ‘error’, and ‘critical’\na single integer/float value denoting absolute number or fraction of failing test units for the ‘warning’ level only\n\nIf the number of failing test units exceeds set thresholds, the validation step will be marked as ‘warning’, ‘error’, or ‘critical’. All of the threshold levels don’t need to be set, you’re free to set any combination of them.\nAside from reporting failure conditions, thresholds can be used to determine the actions to take for each level of failure (using the actions= parameter)."
  },
  {
    "objectID": "reference/Validate.col_schema_match.html#examples",
    "href": "reference/Validate.col_schema_match.html#examples",
    "title": "Validate.col_schema_match",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with three columns (string, integer, and float). The table is shown below:\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [\"apple\", \"banana\", \"cherry\", \"date\"],\n        \"b\": [1, 6, 3, 5],\n        \"c\": [1.1, 2.2, 3.3, 4.4],\n    }\n)\n\npb.preview(tbl)\n\n\n\n\n\n  \n  \n  \n  \n\n\n\n\n\n  \n  aString\n  bInt64\n  cFloat64\n\n\n\n  \n    1\n    apple\n    1\n    1.1\n  \n  \n    2\n    banana\n    6\n    2.2\n  \n  \n    3\n    cherry\n    3\n    3.3\n  \n  \n    4\n    date\n    5\n    4.4\n  \n\n\n\n\n\n\n        \n\n\nLet’s validate that the columns in the table match a predefined schema. A schema can be defined using the Schema class.\n\nschema = pb.Schema(\n    columns=[(\"a\", \"String\"), (\"b\", \"Int64\"), (\"c\", \"Float64\")]\n)\n\nYou can print the schema object to verify that the expected schema is as intended.\n\nprint(schema)\n\nPointblank Schema\n  a: String\n  b: Int64\n  c: Float64\n\n\nNow, we’ll use the col_schema_match() method to validate the table against the expected schema object. There is a single test unit for this validation step (whether the schema matches the table or not).\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_schema_match(schema=schema)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_schema_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            col_schema_match()\n        \n        \n        \n    —\n    SCHEMA\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe validation table shows that the schema matches the table. The single test unit passed since the table columns and their types match the schema."
  },
  {
    "objectID": "reference/Validate.col_vals_in_set.html",
    "href": "reference/Validate.col_vals_in_set.html",
    "title": "Validate.col_vals_in_set",
    "section": "",
    "text": "Validate.col_vals_in_set(\n    columns,\n    set,\n    pre=None,\n    segments=None,\n    thresholds=None,\n    actions=None,\n    brief=None,\n    active=True,\n)\nValidate whether column values are in a set of values.\nThe col_vals_in_set() validation method checks whether column values in a table are part of a specified set= of values. This validation will operate over the number of test units that is equal to the number of rows in the table (determined after any pre= mutation has been applied)."
  },
  {
    "objectID": "reference/Validate.col_vals_in_set.html#parameters",
    "href": "reference/Validate.col_vals_in_set.html#parameters",
    "title": "Validate.col_vals_in_set",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns : str | list[str] | Column | ColumnSelector | ColumnSelectorNarwhals\n\nA single column or a list of columns to validate. Can also use col() with column selectors to specify one or more columns. If multiple columns are supplied or resolved, there will be a separate validation step generated for each column.\n\nset : Collection[Any]\n\nA collection of values to compare against. Can be a list of values, a Python Enum class, or a collection containing Enum instances. When an Enum class is provided, all enum values will be used. When a collection contains Enum instances, their values will be extracted automatically.\n\npre : Callable | None = None\n\nAn optional preprocessing function or lambda to apply to the data table during interrogation. This function should take a table as input and return a modified table. Have a look at the Preprocessing section for more information on how to use this argument.\n\nsegments : SegmentSpec | None = None\n\nAn optional directive on segmentation, which serves to split a validation step into multiple (one step per segment). Can be a single column name, a tuple that specifies a column name and its corresponding values to segment on, or a combination of both (provided as a list). Read the Segmentation section for usage information.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nSet threshold failure levels for reporting and reacting to exceedences of the levels. The thresholds are set at the step level and will override any global thresholds set in Validate(thresholds=...). The default is None, which means that no thresholds will be set locally and global thresholds (if any) will take effect. Look at the Thresholds section for information on how to set threshold levels.\n\nactions : Actions | None = None\n\nOptional actions to take when the validation step(s) meets or exceeds any set threshold levels. If provided, the Actions class should be used to define the actions.\n\nbrief : str | bool | None = None\n\nAn optional brief description of the validation step that will be displayed in the reporting table. You can use the templating elements like \"{step}\" to insert the step number, or \"{auto}\" to include an automatically generated brief. If True the entire brief will be automatically generated. If None (the default) then there won’t be a brief.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.col_vals_in_set.html#returns",
    "href": "reference/Validate.col_vals_in_set.html#returns",
    "title": "Validate.col_vals_in_set",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.col_vals_in_set.html#preprocessing",
    "href": "reference/Validate.col_vals_in_set.html#preprocessing",
    "title": "Validate.col_vals_in_set",
    "section": "Preprocessing",
    "text": "Preprocessing\nThe pre= argument allows for a preprocessing function or lambda to be applied to the data table during interrogation. This function should take a table as input and return a modified table. This is useful for performing any necessary transformations or filtering on the data before the validation step is applied.\nThe preprocessing function can be any callable that takes a table as input and returns a modified table. For example, you could use a lambda function to filter the table based on certain criteria or to apply a transformation to the data. Note that you can refer to a column via columns= that is expected to be present in the transformed table, but may not exist in the table before preprocessing. Regarding the lifetime of the transformed table, it only exists during the validation step and is not stored in the Validate object or used in subsequent validation steps."
  },
  {
    "objectID": "reference/Validate.col_vals_in_set.html#segmentation",
    "href": "reference/Validate.col_vals_in_set.html#segmentation",
    "title": "Validate.col_vals_in_set",
    "section": "Segmentation",
    "text": "Segmentation\nThe segments= argument allows for the segmentation of a validation step into multiple segments. This is useful for applying the same validation step to different subsets of the data. The segmentation can be done based on a single column or specific fields within a column.\nProviding a single column name will result in a separate validation step for each unique value in that column. For example, if you have a column called \"region\" with values \"North\", \"South\", and \"East\", the validation step will be applied separately to each region.\nAlternatively, you can provide a tuple that specifies a column name and its corresponding values to segment on. For example, if you have a column called \"date\" and you want to segment on only specific dates, you can provide a tuple like (\"date\", [\"2023-01-01\", \"2023-01-02\"]). Any other values in the column will be disregarded (i.e., no validation steps will be created for them).\nA list with a combination of column names and tuples can be provided as well. This allows for more complex segmentation scenarios. The following inputs are both valid:\n# Segments from all unique values in the `region` column\n# and specific dates in the `date` column\nsegments=[\"region\", (\"date\", [\"2023-01-01\", \"2023-01-02\"])]\n\n# Segments from all unique values in the `region` and `date` columns\nsegments=[\"region\", \"date\"]\nThe segmentation is performed during interrogation, and the resulting validation steps will be numbered sequentially. Each segment will have its own validation step, and the results will be reported separately. This allows for a more granular analysis of the data and helps identify issues within specific segments.\nImportantly, the segmentation process will be performed after any preprocessing of the data table. Because of this, one can conceivably use the pre= argument to generate a column that can be used for segmentation. For example, you could create a new column called \"segment\" through use of pre= and then use that column for segmentation."
  },
  {
    "objectID": "reference/Validate.col_vals_in_set.html#thresholds",
    "href": "reference/Validate.col_vals_in_set.html#thresholds",
    "title": "Validate.col_vals_in_set",
    "section": "Thresholds",
    "text": "Thresholds\nThe thresholds= parameter is used to set the failure-condition levels for the validation step. If they are set here at the step level, these thresholds will override any thresholds set at the global level in Validate(thresholds=...).\nThere are three threshold levels: ‘warning’, ‘error’, and ‘critical’. The threshold values can either be set as a proportion failing of all test units (a value between 0 to 1), or, the absolute number of failing test units (as integer that’s 1 or greater).\nThresholds can be defined using one of these input schemes:\n\nuse the Thresholds class (the most direct way to create thresholds)\nprovide a tuple of 1-3 values, where position 0 is the ‘warning’ level, position 1 is the ‘error’ level, and position 2 is the ‘critical’ level\ncreate a dictionary of 1-3 value entries; the valid keys: are ‘warning’, ‘error’, and ‘critical’\na single integer/float value denoting absolute number or fraction of failing test units for the ‘warning’ level only\n\nIf the number of failing test units exceeds set thresholds, the validation step will be marked as ‘warning’, ‘error’, or ‘critical’. All of the threshold levels don’t need to be set, you’re free to set any combination of them.\nAside from reporting failure conditions, thresholds can be used to determine the actions to take for each level of failure (using the actions= parameter)."
  },
  {
    "objectID": "reference/Validate.col_vals_in_set.html#examples",
    "href": "reference/Validate.col_vals_in_set.html#examples",
    "title": "Validate.col_vals_in_set",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with two numeric columns (a and b). The table is shown below:\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [5, 2, 4, 6, 2, 5],\n        \"b\": [5, 8, 2, 6, 5, 1],\n    }\n)\n\npb.preview(tbl)\n\n\n\n\n\n  \n  \n  \n\n\n\n\n\n  \n  aInt64\n  bInt64\n\n\n\n  \n    1\n    5\n    5\n  \n  \n    2\n    2\n    8\n  \n  \n    3\n    4\n    2\n  \n  \n    4\n    6\n    6\n  \n  \n    5\n    2\n    5\n  \n  \n    6\n    5\n    1\n  \n\n\n\n\n\n\n        \n\n\nLet’s validate that values in column a are all in the set of [2, 3, 4, 5, 6]. We’ll determine if this validation had any failing test units (there are six test units, one for each row).\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_in_set(columns=\"a\", set=[2, 3, 4, 5, 6])\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        \n        \n    a\n    2, 3, 4, 5, 6\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    61.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nPrinting the validation object shows the validation table in an HTML viewing environment. The validation table shows the single entry that corresponds to the validation step created by using col_vals_in_set(). All test units passed, and there are no failing test units.\nNow, let’s use that same set of values for a validation on column b.\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_in_set(columns=\"b\", set=[2, 3, 4, 5, 6])\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        \n        \n    b\n    2, 3, 4, 5, 6\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    40.67\n    20.33\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe validation table reports two failing test units. The specific failing cases are for the column b values of 8 and 1, which are not in the set of [2, 3, 4, 5, 6].\nUsing Python Enums\nThe col_vals_in_set() method also supports Python Enum classes and instances, which can make validations more readable and maintainable:\n\nfrom enum import Enum\n\nclass Color(Enum):\n    RED = \"red\"\n    GREEN = \"green\"\n    BLUE = \"blue\"\n\n# Create a table with color data\ntbl_colors = pl.DataFrame({\n    \"product\": [\"shirt\", \"pants\", \"hat\", \"shoes\"],\n    \"color\": [\"red\", \"blue\", \"green\", \"yellow\"]\n})\n\n# Validate using an Enum class (all enum values are allowed)\nvalidation = (\n    pb.Validate(data=tbl_colors)\n    .col_vals_in_set(columns=\"color\", set=Color)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        \n        \n    color\n    red, green, blue\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    30.75\n    10.25\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThis validation will fail for the \"yellow\" value since it’s not in the Color enum.\nYou can also use specific Enum instances or mix them with regular values:\n\n# Validate using specific Enum instances\nvalidation = (\n    pb.Validate(data=tbl_colors)\n    .col_vals_in_set(columns=\"color\", set=[Color.RED, Color.BLUE])\n    .interrogate()\n)\n\n# Mix Enum instances with regular values\nvalidation = (\n    pb.Validate(data=tbl_colors)\n    .col_vals_in_set(columns=\"color\", set=[Color.RED, Color.BLUE, \"yellow\"])\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        \n        \n    color\n    red, blue, yellow\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    30.75\n    10.25\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nIn this case, the \"green\" value will cause a failing test unit since it’s not part of the specified set."
  },
  {
    "objectID": "reference/Validate.get_data_extracts.html",
    "href": "reference/Validate.get_data_extracts.html",
    "title": "Validate.get_data_extracts",
    "section": "",
    "text": "Validate.get_data_extracts(i=None, frame=False)\nGet the rows that failed for each validation step.\nAfter the interrogate() method has been called, the get_data_extracts() method can be used to extract the rows that failed in each column-value or row-based validation step (e.g., col_vals_gt(), rows_distinct(), etc.). The method returns a dictionary of tables containing the rows that failed in every validation step. If frame=True and i= is a scalar, the value is conveniently returned as a table (forgoing the dictionary structure)."
  },
  {
    "objectID": "reference/Validate.get_data_extracts.html#parameters",
    "href": "reference/Validate.get_data_extracts.html#parameters",
    "title": "Validate.get_data_extracts",
    "section": "Parameters",
    "text": "Parameters\n\ni : int | list[int] | None = None\n\nThe validation step number(s) from which the failed rows are obtained. Can be provided as a list of integers or a single integer. If None, all steps are included.\n\nframe : bool = False\n\nIf True and i= is a scalar, return the value as a DataFrame instead of a dictionary."
  },
  {
    "objectID": "reference/Validate.get_data_extracts.html#returns",
    "href": "reference/Validate.get_data_extracts.html#returns",
    "title": "Validate.get_data_extracts",
    "section": "Returns",
    "text": "Returns\n\n : dict[int, FrameT | None] | FrameT | None\n\nA dictionary of tables containing the rows that failed in every compatible validation step. Alternatively, it can be a DataFrame if frame=True and i= is a scalar."
  },
  {
    "objectID": "reference/Validate.get_data_extracts.html#compatible-validation-methods-for-yielding-extracted-rows",
    "href": "reference/Validate.get_data_extracts.html#compatible-validation-methods-for-yielding-extracted-rows",
    "title": "Validate.get_data_extracts",
    "section": "Compatible Validation Methods for Yielding Extracted Rows",
    "text": "Compatible Validation Methods for Yielding Extracted Rows\nThe following validation methods operate on column values and will have rows extracted when there are failing test units.\n\ncol_vals_gt()\ncol_vals_ge()\ncol_vals_lt()\ncol_vals_le()\ncol_vals_eq()\ncol_vals_ne()\ncol_vals_between()\ncol_vals_outside()\ncol_vals_in_set()\ncol_vals_not_in_set()\ncol_vals_increasing()\ncol_vals_decreasing()\ncol_vals_null()\ncol_vals_not_null()\ncol_vals_regex()\ncol_vals_within_spec()\ncol_vals_expr()\nconjointly()\nprompt()\n\nAn extracted row for these validation methods means that a test unit failed for that row in the validation step.\nThese row-based validation methods will also have rows extracted should there be failing rows:\n\nrows_distinct()\nrows_complete()\n\nThe extracted rows are a subset of the original table and are useful for further analysis or for understanding the nature of the failing test units."
  },
  {
    "objectID": "reference/Validate.get_data_extracts.html#examples",
    "href": "reference/Validate.get_data_extracts.html#examples",
    "title": "Validate.get_data_extracts",
    "section": "Examples",
    "text": "Examples\nLet’s perform a series of validation steps on a Polars DataFrame. We’ll use the col_vals_gt() in the first step, col_vals_lt() in the second step, and col_vals_ge() in the third step. The interrogate() method executes the validation; then, we can extract the rows that failed for each validation step.\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [5, 6, 5, 3, 6, 1],\n        \"b\": [1, 2, 1, 5, 2, 6],\n        \"c\": [3, 7, 2, 6, 3, 1],\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(columns=\"a\", value=4)\n    .col_vals_lt(columns=\"c\", value=5)\n    .col_vals_ge(columns=\"b\", value=1)\n    .interrogate()\n)\n\nvalidation.get_data_extracts()\n\n{1: shape: (2, 4)\n ┌───────────┬─────┬─────┬─────┐\n │ _row_num_ ┆ a   ┆ b   ┆ c   │\n │ ---       ┆ --- ┆ --- ┆ --- │\n │ u32       ┆ i64 ┆ i64 ┆ i64 │\n ╞═══════════╪═════╪═════╪═════╡\n │ 4         ┆ 3   ┆ 5   ┆ 6   │\n │ 6         ┆ 1   ┆ 6   ┆ 1   │\n └───────────┴─────┴─────┴─────┘,\n 2: shape: (2, 4)\n ┌───────────┬─────┬─────┬─────┐\n │ _row_num_ ┆ a   ┆ b   ┆ c   │\n │ ---       ┆ --- ┆ --- ┆ --- │\n │ u32       ┆ i64 ┆ i64 ┆ i64 │\n ╞═══════════╪═════╪═════╪═════╡\n │ 2         ┆ 6   ┆ 2   ┆ 7   │\n │ 4         ┆ 3   ┆ 5   ┆ 6   │\n └───────────┴─────┴─────┴─────┘,\n 3: shape: (0, 4)\n ┌───────────┬─────┬─────┬─────┐\n │ _row_num_ ┆ a   ┆ b   ┆ c   │\n │ ---       ┆ --- ┆ --- ┆ --- │\n │ u32       ┆ i64 ┆ i64 ┆ i64 │\n ╞═══════════╪═════╪═════╪═════╡\n └───────────┴─────┴─────┴─────┘}\n\n\nThe get_data_extracts() method returns a dictionary of tables, where each table contains a subset of rows from the table. These are the rows that failed for each validation step.\nIn the first step, thecol_vals_gt() method was used to check if the values in column a were greater than 4. The extracted table shows the rows where this condition was not met; look at the a column: all values are less than 4.\nIn the second step, the col_vals_lt() method was used to check if the values in column c were less than 5. In the extracted two-row table, we see that the values in column c are greater than 5.\nThe third step (col_vals_ge()) checked if the values in column b were greater than or equal to 1. There were no failing test units, so the extracted table is empty (i.e., has columns but no rows).\nThe i= argument can be used to narrow down the extraction to one or more steps. For example, to extract the rows that failed in the first step only:\n\nvalidation.get_data_extracts(i=1)\n\n{1: shape: (2, 4)\n ┌───────────┬─────┬─────┬─────┐\n │ _row_num_ ┆ a   ┆ b   ┆ c   │\n │ ---       ┆ --- ┆ --- ┆ --- │\n │ u32       ┆ i64 ┆ i64 ┆ i64 │\n ╞═══════════╪═════╪═════╪═════╡\n │ 4         ┆ 3   ┆ 5   ┆ 6   │\n │ 6         ┆ 1   ┆ 6   ┆ 1   │\n └───────────┴─────┴─────┴─────┘}\n\n\nNote that the first validation step is indexed at 1 (not 0). This 1-based indexing is in place here to match the step numbers reported in the validation table. What we get back is still a dictionary, but it only contains one table (the one for the first step).\nIf you want to get the extracted table as a DataFrame, set frame=True and provide a scalar value for i. For example, to get the extracted table for the second step as a DataFrame:\n\npb.preview(validation.get_data_extracts(i=2, frame=True))\n\n\n\n\n\n  \n  \n  \n  \n\n\n\n\n\n  \n  aInt64\n  bInt64\n  cInt64\n\n\n\n  \n    2\n    6\n    2\n    7\n  \n  \n    4\n    3\n    5\n    6\n  \n\n\n\n\n\n\n        \n\n\nThe extracted table is now a DataFrame, which can serve as a more convenient format for further analysis or visualization. We further used the preview() function to show the DataFrame in an HTML view."
  },
  {
    "objectID": "reference/Validate.assert_passing.html",
    "href": "reference/Validate.assert_passing.html",
    "title": "Validate.assert_passing",
    "section": "",
    "text": "Validate.assert_passing()\nRaise an AssertionError if all tests are not passing.\nThe assert_passing() method will raise an AssertionError if a test does not pass. This method simply wraps all_passed for more ready use in test suites. The step number and assertion made is printed in the AssertionError message if a failure occurs, ensuring some details are preserved.\nIf the validation has not yet been interrogated, this method will automatically call interrogate() with default parameters before checking for passing tests."
  },
  {
    "objectID": "reference/Validate.assert_passing.html#raises",
    "href": "reference/Validate.assert_passing.html#raises",
    "title": "Validate.assert_passing",
    "section": "Raises",
    "text": "Raises\n\n: AssertionError\n\nIf any validation step has failing test units."
  },
  {
    "objectID": "reference/Validate.assert_passing.html#examples",
    "href": "reference/Validate.assert_passing.html#examples",
    "title": "Validate.assert_passing",
    "section": "Examples",
    "text": "Examples\nIn the example below, we’ll use a simple Polars DataFrame with three columns (a, b, and c). There will be three validation steps, and the second step will have a failing test unit (the value 10 isn’t less than 9). The assert_passing() method is used to assert that all validation steps passed perfectly, automatically performing the interrogation if needed.\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n    \"a\": [1, 2, 9, 5],\n    \"b\": [5, 6, 10, 3],\n    \"c\": [\"a\", \"b\", \"a\", \"a\"],\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(columns=\"a\", value=0)\n    .col_vals_lt(columns=\"b\", value=9) # this assertion is false\n    .col_vals_in_set(columns=\"c\", set=[\"a\", \"b\"])\n)\n\n# No need to call [`interrogate()`](`pointblank.Validate.interrogate`) explicitly\nvalidation.assert_passing()\n\n\n---------------------------------------------------------------------------\nAssertionError                            Traceback (most recent call last)\n/tmp/ipykernel_4884/2424908189.py in ?()\n     16     .col_vals_in_set(columns=\"c\", set=[\"a\", \"b\"])\n     17 )\n     18 \n     19 # No need to call [`interrogate()`](`pointblank.Validate.interrogate`) explicitly\n---&gt; 20 validation.assert_passing()\n\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pointblank/validate.py in ?(self)\n  13197             ]\n  13198             msg = \"The following assertions failed:\\n\" + \"\\n\".join(\n  13199                 [f\"- Step {i + 1}: {autobrief}\" for i, autobrief in failed_steps]\n  13200             )\n&gt; 13201             raise AssertionError(msg)\n\nAssertionError: The following assertions failed:\n- Step 2: Expect that values in `b` should be &lt; `9`."
  },
  {
    "objectID": "reference/Validate.set_tbl.html",
    "href": "reference/Validate.set_tbl.html",
    "title": "Validate.set_tbl",
    "section": "",
    "text": "Validate.set_tbl(tbl, tbl_name=None, label=None)\nSet or replace the table associated with the Validate object.\nThis method allows you to replace the table associated with a Validate object with a different (but presumably similar) table. This is useful when you want to apply the same validation plan to multiple tables or when you have a validation workflow defined but want to swap in a different data source."
  },
  {
    "objectID": "reference/Validate.set_tbl.html#parameters",
    "href": "reference/Validate.set_tbl.html#parameters",
    "title": "Validate.set_tbl",
    "section": "Parameters",
    "text": "Parameters\n\ntbl : FrameT | Any\n\nThe table to replace the existing table with. This can be any supported table type including DataFrame objects, Ibis table objects, CSV file paths, Parquet file paths, GitHub URLs, or database connection strings. The same table type constraints apply as in the Validate constructor.\n\ntbl_name : str | None = None\n\nAn optional name to assign to the new input table object. If no value is provided, the existing table name will be retained.\n\nlabel : str | None = None\n\nAn optional label for the validation plan. If no value is provided, the existing label will be retained."
  },
  {
    "objectID": "reference/Validate.set_tbl.html#returns",
    "href": "reference/Validate.set_tbl.html#returns",
    "title": "Validate.set_tbl",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nA new Validate object with the replacement table."
  },
  {
    "objectID": "reference/Validate.set_tbl.html#when-to-use",
    "href": "reference/Validate.set_tbl.html#when-to-use",
    "title": "Validate.set_tbl",
    "section": "When to Use",
    "text": "When to Use\nThe set_tbl() method is particularly useful in scenarios where you have:\n\nmultiple similar tables that need the same validation checks\na template validation workflow that should be applied to different data sources\nYAML-defined validations where you want to override the table specified in the YAML\n\nThe set_tbl() method creates a copy of the validation object with the new table, so the original validation object remains unchanged. This allows you to reuse validation plans across multiple tables without interference."
  },
  {
    "objectID": "reference/Validate.set_tbl.html#examples",
    "href": "reference/Validate.set_tbl.html#examples",
    "title": "Validate.set_tbl",
    "section": "Examples",
    "text": "Examples\nWe will first create two similar tables for our future validation plans.\n\nimport pointblank as pb\nimport polars as pl\n\n# Create two similar tables\ntable_1 = pl.DataFrame({\n    \"x\": [1, 2, 3, 4, 5],\n    \"y\": [5, 4, 3, 2, 1],\n    \"z\": [\"a\", \"b\", \"c\", \"d\", \"e\"]\n})\n\ntable_2 = pl.DataFrame({\n    \"x\": [2, 4, 6, 8, 10],\n    \"y\": [10, 8, 6, 4, 2],\n    \"z\": [\"f\", \"g\", \"h\", \"i\", \"j\"]\n})\n\nCreate a validation plan with the first table.\n\nvalidation_table_1 = (\n    pb.Validate(\n        data=table_1,\n        tbl_name=\"Table 1\",\n        label=\"Validation applied to the first table\"\n    )\n    .col_vals_gt(columns=\"x\", value=0)\n    .col_vals_lt(columns=\"y\", value=10)\n)\n\nNow apply the same validation plan to the second table.\n\nvalidation_table_2 = (\n    validation_table_1\n    .set_tbl(\n        tbl=table_2,\n        tbl_name=\"Table 2\",\n        label=\"Validation applied to the second table\"\n    )\n)\n\nHere is the interrogation of the first table:\n\nvalidation_table_1.interrogate()\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    x\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    y\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nAnd the second table:\n\nvalidation_table_2.interrogate()\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    x\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    y\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    40.80\n    10.20\n    —\n    —\n    —\n    CSV"
  },
  {
    "objectID": "reference/load_dataset.html",
    "href": "reference/load_dataset.html",
    "title": "load_dataset",
    "section": "",
    "text": "load_dataset(dataset='small_table', tbl_type='polars')\nLoad a dataset hosted in the library as specified table type.\nThe Pointblank library includes several datasets that can be loaded using the load_dataset() function. The datasets can be loaded as a Polars DataFrame, a Pandas DataFrame, or as a DuckDB table (which uses the Ibis library backend). These datasets are used throughout the documentation’s examples to demonstrate the functionality of the library. They’re also useful for experimenting with the library and trying out different validation scenarios."
  },
  {
    "objectID": "reference/load_dataset.html#parameters",
    "href": "reference/load_dataset.html#parameters",
    "title": "load_dataset",
    "section": "Parameters",
    "text": "Parameters\n\ndataset : Literal['small_table', 'game_revenue', 'nycflights', 'global_sales'] = 'small_table'\n\nThe name of the dataset to load. Current options are \"small_table\", \"game_revenue\", \"nycflights\", and \"global_sales\".\n\ntbl_type : Literal['polars', 'pandas', 'duckdb'] = 'polars'\n\nThe type of table to generate from the dataset. The named options are \"polars\", \"pandas\", and \"duckdb\"."
  },
  {
    "objectID": "reference/load_dataset.html#returns",
    "href": "reference/load_dataset.html#returns",
    "title": "load_dataset",
    "section": "Returns",
    "text": "Returns\n\n : FrameT | Any\n\nThe dataset for the Validate object. This could be a Polars DataFrame, a Pandas DataFrame, or a DuckDB table as an Ibis table."
  },
  {
    "objectID": "reference/load_dataset.html#included-datasets",
    "href": "reference/load_dataset.html#included-datasets",
    "title": "load_dataset",
    "section": "Included Datasets",
    "text": "Included Datasets\nThere are three included datasets that can be loaded using the load_dataset() function:\n\n\"small_table\": A small dataset with 13 rows and 8 columns. This dataset is useful for testing and demonstration purposes.\n\"game_revenue\": A dataset with 2000 rows and 11 columns. Provides revenue data for a game development company. For the particular game, there are records of player sessions, the items they purchased, ads viewed, and the revenue generated.\n\"nycflights\": A dataset with 336,776 rows and 18 columns. This dataset provides information about flights departing from New York City airports (JFK, LGA, or EWR) in 2013.\n\"global_sales\": A dataset with 50,000 rows and 20 columns. Provides information about global sales of products across different regions and countries."
  },
  {
    "objectID": "reference/load_dataset.html#supported-dataframe-types",
    "href": "reference/load_dataset.html#supported-dataframe-types",
    "title": "load_dataset",
    "section": "Supported DataFrame Types",
    "text": "Supported DataFrame Types\nThe tbl_type= parameter can be set to one of the following:\n\n\"polars\": A Polars DataFrame.\n\"pandas\": A Pandas DataFrame.\n\"duckdb\": An Ibis table for a DuckDB database."
  },
  {
    "objectID": "reference/load_dataset.html#examples",
    "href": "reference/load_dataset.html#examples",
    "title": "load_dataset",
    "section": "Examples",
    "text": "Examples\nLoad the \"small_table\" dataset as a Polars DataFrame by calling load_dataset() with dataset=\"small_table\" and tbl_type=\"polars\":\n\nimport pointblank as pb\n\nsmall_table = pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\")\n\npb.preview(small_table)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows13Columns8\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05\n    6\n    8-kdg-938\n    3\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    None\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09\n    8\n    3-ldm-038\n    7\n    283.94\n    True\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26\n    4\n    2-dmx-010\n    7\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28\n    2\n    7-dmx-010\n    8\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30\n    1\n    3-dka-303\n    None\n    2230.09\n    True\n    high\n  \n\n\n\n\n\n\n        \n\n\nNote that the \"small_table\" dataset is a Polars DataFrame and using the preview() function will display the table in an HTML viewing environment.\nThe \"game_revenue\" dataset can be loaded as a Pandas DataFrame by specifying the dataset name and setting tbl_type=\"pandas\":\n\ngame_revenue = pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"pandas\")\n\npb.preview(game_revenue)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PandasRows2,000Columns11\n  \n\n  \n  player_idobject\n  session_idobject\n  session_startdatetime64[ns, UTC]\n  timedatetime64[ns, UTC]\n  item_typeobject\n  item_nameobject\n  item_revenuefloat64\n  session_durationfloat64\n  start_daydatetime64[ns]\n  acquisitionobject\n  countryobject\n\n\n\n  \n    1\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:31:27+00:00\n    iap\n    offer2\n    8.99\n    16.3\n    2015-01-01 00:00:00\n    google\n    Germany\n  \n  \n    2\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:36:57+00:00\n    iap\n    gems3\n    22.49\n    16.3\n    2015-01-01 00:00:00\n    google\n    Germany\n  \n  \n    3\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:37:45+00:00\n    iap\n    gold7\n    107.99\n    16.3\n    2015-01-01 00:00:00\n    google\n    Germany\n  \n  \n    4\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:42:33+00:00\n    ad\n    ad_20sec\n    0.76\n    16.3\n    2015-01-01 00:00:00\n    google\n    Germany\n  \n  \n    5\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-hdu9jkls\n    2015-01-01 11:50:02+00:00\n    2015-01-01 11:55:20+00:00\n    ad\n    ad_5sec\n    0.03\n    35.2\n    2015-01-01 00:00:00\n    google\n    Germany\n  \n  \n    1996\n    NAOJRDMCSEBI281\n    NAOJRDMCSEBI281-j2vs9ilp\n    2015-01-21 01:57:50+00:00\n    2015-01-21 02:02:50+00:00\n    ad\n    ad_survey\n    1.332\n    25.8\n    2015-01-11 00:00:00\n    organic\n    Norway\n  \n  \n    1997\n    NAOJRDMCSEBI281\n    NAOJRDMCSEBI281-j2vs9ilp\n    2015-01-21 01:57:50+00:00\n    2015-01-21 02:22:14+00:00\n    ad\n    ad_survey\n    1.35\n    25.8\n    2015-01-11 00:00:00\n    organic\n    Norway\n  \n  \n    1998\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-vbhcsmtr\n    2015-01-21 02:39:48+00:00\n    2015-01-21 02:40:00+00:00\n    ad\n    ad_5sec\n    0.03\n    8.4\n    2015-01-10 00:00:00\n    other_campaign\n    France\n  \n  \n    1999\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-vbhcsmtr\n    2015-01-21 02:39:48+00:00\n    2015-01-21 02:47:12+00:00\n    iap\n    offer5\n    26.09\n    8.4\n    2015-01-10 00:00:00\n    other_campaign\n    France\n  \n  \n    2000\n    GJCXNTWEBIPQ369\n    GJCXNTWEBIPQ369-9elq67md\n    2015-01-21 03:59:23+00:00\n    2015-01-21 04:06:29+00:00\n    ad\n    ad_5sec\n    0.12\n    18.5\n    2015-01-14 00:00:00\n    organic\n    United States\n  \n\n\n\n\n\n\n        \n\n\nThe \"game_revenue\" dataset is a more real-world dataset with a mix of data types, and it’s significantly larger than the small_table dataset at 2000 rows and 11 columns.\nThe \"nycflights\" dataset can be loaded as a DuckDB table by specifying the dataset name and setting tbl_type=\"duckdb\":\n\nnycflights = pb.load_dataset(dataset=\"nycflights\", tbl_type=\"duckdb\")\n\npb.preview(nycflights)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    DuckDBRows336,776Columns18\n  \n\n  \n  yearint64\n  monthint64\n  dayint64\n  dep_timeint64\n  sched_dep_timeint64\n  dep_delayint64\n  arr_timeint64\n  sched_arr_timeint64\n  arr_delayint64\n  carrierstring\n  flightint64\n  tailnumstring\n  originstring\n  deststring\n  air_timeint64\n  distanceint64\n  hourint64\n  minuteint64\n\n\n\n  \n    1\n    2013\n    1\n    1\n    517\n    515\n    2\n    830\n    819\n    11\n    UA\n    1545\n    N14228\n    EWR\n    IAH\n    227\n    1400\n    5\n    15\n  \n  \n    2\n    2013\n    1\n    1\n    533\n    529\n    4\n    850\n    830\n    20\n    UA\n    1714\n    N24211\n    LGA\n    IAH\n    227\n    1416\n    5\n    29\n  \n  \n    3\n    2013\n    1\n    1\n    542\n    540\n    2\n    923\n    850\n    33\n    AA\n    1141\n    N619AA\n    JFK\n    MIA\n    160\n    1089\n    5\n    40\n  \n  \n    4\n    2013\n    1\n    1\n    544\n    545\n    -1\n    1004\n    1022\n    -18\n    B6\n    725\n    N804JB\n    JFK\n    BQN\n    183\n    1576\n    5\n    45\n  \n  \n    5\n    2013\n    1\n    1\n    554\n    600\n    -6\n    812\n    837\n    -25\n    DL\n    461\n    N668DN\n    LGA\n    ATL\n    116\n    762\n    6\n    0\n  \n  \n    336772\n    2013\n    9\n    30\n    NULL\n    1455\n    NULL\n    NULL\n    1634\n    NULL\n    9E\n    3393\n    NULL\n    JFK\n    DCA\n    NULL\n    213\n    14\n    55\n  \n  \n    336773\n    2013\n    9\n    30\n    NULL\n    2200\n    NULL\n    NULL\n    2312\n    NULL\n    9E\n    3525\n    NULL\n    LGA\n    SYR\n    NULL\n    198\n    22\n    0\n  \n  \n    336774\n    2013\n    9\n    30\n    NULL\n    1210\n    NULL\n    NULL\n    1330\n    NULL\n    MQ\n    3461\n    N535MQ\n    LGA\n    BNA\n    NULL\n    764\n    12\n    10\n  \n  \n    336775\n    2013\n    9\n    30\n    NULL\n    1159\n    NULL\n    NULL\n    1344\n    NULL\n    MQ\n    3572\n    N511MQ\n    LGA\n    CLE\n    NULL\n    419\n    11\n    59\n  \n  \n    336776\n    2013\n    9\n    30\n    NULL\n    840\n    NULL\n    NULL\n    1020\n    NULL\n    MQ\n    3531\n    N839MQ\n    LGA\n    RDU\n    NULL\n    431\n    8\n    40\n  \n\n\n\n\n\n\n        \n\n\nThe \"nycflights\" dataset is a large dataset with 336,776 rows and 18 columns. This dataset is truly a real-world dataset and provides information about flights originating from New York City airports in 2013.\nFinally, the \"global_sales\" dataset can be loaded as a Polars table by specifying the dataset name. Since tbl_type= is set to \"polars\" by default, we don’t need to specify it:\n\nglobal_sales = pb.load_dataset(dataset=\"global_sales\")\n\npb.preview(global_sales)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows50,000Columns20\n  \n\n  \n  product_idString\n  product_categoryString\n  customer_idString\n  customer_segmentString\n  regionString\n  countryString\n  cityString\n  timestampDatetime\n  quarterString\n  monthInt64\n  yearInt64\n  priceFloat64\n  quantityInt64\n  statusString\n  emailString\n  revenueFloat64\n  taxFloat64\n  totalFloat64\n  payment_methodString\n  sales_channelString\n\n\n\n  \n    1\n    98b70df0\n    Manufacturing\n    cf3b13c7\n    Government\n    Asia Pacific\n    Australia\n    Melbourne\n    2021-12-25 19:00:00\n    2021-Q4\n    12\n    2021\n    186.0\n    7\n    returned\n    user1651@test.org\n    1302.0\n    127.45\n    1429.45\n    Apple Pay\n    Partner\n  \n  \n    2\n    9d09fef5\n    Manufacturing\n    08b5db12\n    Consumer\n    Europe\n    France\n    Nice\n    2022-06-12 17:25:00\n    2022-Q2\n    6\n    2022\n    137.03\n    8\n    returned\n    user5200@company.io\n    1096.24\n    222.52\n    1318.76\n    PayPal\n    Distributor\n  \n  \n    3\n    8ac6b077\n    Retail\n    41079b2e\n    Consumer\n    Europe\n    France\n    Toulouse\n    2023-05-06 09:09:00\n    2023-Q2\n    5\n    2023\n    330.08\n    4\n    shipped\n    user9180@mockdata.com\n    1320.32\n    260.89\n    1581.21\n    PayPal\n    Phone\n  \n  \n    4\n    13d2df9d\n    Healthcare\n    b421eece\n    Consumer\n    North America\n    USA\n    Miami\n    2023-10-11 16:53:00\n    2023-Q4\n    10\n    2023\n    420.09\n    3\n    shipped\n    user1636@example.com\n    1260.27\n    103.99\n    1364.26\n    Bank Transfer\n    Phone\n  \n  \n    5\n    98b70df0\n    Manufacturing\n    5906a04f\n    SMB\n    North America\n    Canada\n    Calgary\n    2022-05-05 01:53:00\n    2022-Q2\n    5\n    2022\n    187.77\n    3\n    delivered\n    user9971@mockdata.com\n    563.31\n    75.73\n    639.04\n    Credit Card\n    Phone\n  \n  \n    49996\n    53a36468\n    Finance\n    966a8bbe\n    Government\n    Asia Pacific\n    Australia\n    Melbourne\n    2023-11-04 14:45:00\n    2023-Q4\n    11\n    2023\n    198.18\n    1\n    pending\n    user8593@test.org\n    198.18\n    18.3\n    216.48\n    Google Pay\n    Partner\n  \n  \n    49997\n    a42fd1ff\n    Healthcare\n    ff8933e4\n    SMB\n    Asia Pacific\n    Japan\n    Kyoto\n    2023-04-27 17:27:00\n    2023-Q2\n    4\n    2023\n    419.72\n    2\n    returned\n    user5448@company.io\n    839.44\n    90.49\n    929.93\n    Google Pay\n    Partner\n  \n  \n    49998\n    bbf158d2\n    Technology\n    f0c0af3f\n    Enterprise\n    North America\n    USA\n    Los Angeles\n    2021-04-24 23:15:00\n    2021-Q2\n    4\n    2021\n    302.52\n    1\n    pending\n    user1463@test.org\n    302.52\n    21.68\n    324.2\n    Bank Transfer\n    Online\n  \n  \n    49999\n    2a0866de\n    Healthcare\n    5b27ba59\n    SMB\n    Europe\n    France\n    Nice\n    2023-12-30 19:44:00\n    2023-Q4\n    12\n    2023\n    433.82\n    5\n    pending\n    user4167@test.org\n    2169.1\n    448.87\n    2617.97\n    Credit Card\n    Online\n  \n  \n    50000\n    6260f67c\n    Technology\n    482c1d84\n    Consumer\n    Asia Pacific\n    Japan\n    Kyoto\n    2021-12-05 09:49:00\n    2021-Q4\n    12\n    2021\n    400.31\n    8\n    returned\n    user4238@example.com\n    3202.48\n    339.84\n    3542.32\n    Apple Pay\n    Distributor\n  \n\n\n\n\n\n\n        \n\n\nThe \"global_sales\" dataset is a large dataset with 50,000 rows and 20 columns. Each record describes the sales of a particular product to a customer located in one of three global regions: North America, Europe, or Asia."
  },
  {
    "objectID": "reference/Validate.get_tabular_report.html",
    "href": "reference/Validate.get_tabular_report.html",
    "title": "Validate.get_tabular_report",
    "section": "",
    "text": "Validate.get_tabular_report(\n    title=':default:',\n    incl_header=None,\n    incl_footer=None,\n)\nValidation report as a GT table.\nThe get_tabular_report() method returns a GT table object that represents the validation report. This validation table provides a summary of the validation results, including the validation steps, the number of test units, the number of failing test units, and the fraction of failing test units. The table also includes status indicators for the ‘warning’, ‘error’, and ‘critical’ levels.\nYou could simply display the validation table without the use of the get_tabular_report() method. However, the method provides a way to customize the title of the report. In the future this method may provide additional options for customizing the report."
  },
  {
    "objectID": "reference/Validate.get_tabular_report.html#parameters",
    "href": "reference/Validate.get_tabular_report.html#parameters",
    "title": "Validate.get_tabular_report",
    "section": "Parameters",
    "text": "Parameters\n\ntitle : str | None = ':default:'\n\nOptions for customizing the title of the report. The default is the \":default:\" value which produces a generic title. Another option is \":tbl_name:\", and that presents the name of the table as the title for the report. If no title is wanted, then \":none:\" can be used. Aside from keyword options, text can be provided for the title. This will be interpreted as Markdown text and transformed internally to HTML."
  },
  {
    "objectID": "reference/Validate.get_tabular_report.html#returns",
    "href": "reference/Validate.get_tabular_report.html#returns",
    "title": "Validate.get_tabular_report",
    "section": "Returns",
    "text": "Returns\n\n : GT\n\nA GT table object that represents the validation report."
  },
  {
    "objectID": "reference/Validate.get_tabular_report.html#examples",
    "href": "reference/Validate.get_tabular_report.html#examples",
    "title": "Validate.get_tabular_report",
    "section": "Examples",
    "text": "Examples\nLet’s create a Validate object with a few validation steps and then interrogate the data table to see how it performs against the validation plan. We can then generate a tabular report to get a summary of the results.\n\nimport pointblank as pb\nimport polars as pl\n\n# Create a Polars DataFrame\ntbl_pl = pl.DataFrame({\"x\": [1, 2, 3, 4], \"y\": [4, 5, 6, 7]})\n\n# Validate data using Polars DataFrame\nvalidation = (\n    pb.Validate(data=tbl_pl, tbl_name=\"tbl_xy\", thresholds=(2, 3, 4))\n    .col_vals_gt(columns=\"x\", value=1)\n    .col_vals_lt(columns=\"x\", value=3)\n    .col_vals_le(columns=\"y\", value=7)\n    .interrogate()\n)\n\n# Look at the validation table\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:14:03Polarstbl_xyWARNING2ERROR3CRITICAL4\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    x\n    1\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    30.75\n    10.25\n    ○\n    ○\n    ○\n    CSV\n  \n  \n    #AAAAAA\n    2\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    x\n    3\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    20.50\n    20.50\n    ●\n    ○\n    ○\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_vals_le\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_le()\n        \n        \n        \n    y\n    7\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    41.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:14:03 UTC&lt; 1 s2025-11-23 00:14:03 UTC\n  \n\n\n\n\n\n\n        \n\n\nThe validation table is displayed with a default title (‘Validation Report’). We can use the get_tabular_report() method to customize the title of the report. For example, we can set the title to the name of the table by using the title=\":tbl_name:\" option. This will use the string provided in the tbl_name= argument of the Validate object.\n\nvalidation.get_tabular_report(title=\":tbl_name:\")\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    tbl_xy\n  \n  \n    2025-11-23|00:14:03Polarstbl_xyWARNING2ERROR3CRITICAL4\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    x\n    1\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    30.75\n    10.25\n    ○\n    ○\n    ○\n    CSV\n  \n  \n    #AAAAAA\n    2\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    x\n    3\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    20.50\n    20.50\n    ●\n    ○\n    ○\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_vals_le\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_le()\n        \n        \n        \n    y\n    7\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    41.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:14:03 UTC&lt; 1 s2025-11-23 00:14:03 UTC\n  \n\n\n\n\n\n\n        \n\n\nThe title of the report is now set to the name of the table, which is ‘tbl_xy’. This can be useful if you have multiple tables and want to keep track of which table the validation report is for.\nAlternatively, you can provide your own title for the report.\n\nvalidation.get_tabular_report(title=\"Report for Table XY\")\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Table XY\n\n  \n  \n    2025-11-23|00:14:03Polarstbl_xyWARNING2ERROR3CRITICAL4\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    x\n    1\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    30.75\n    10.25\n    ○\n    ○\n    ○\n    CSV\n  \n  \n    #AAAAAA\n    2\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    x\n    3\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    20.50\n    20.50\n    ●\n    ○\n    ○\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_vals_le\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_le()\n        \n        \n        \n    y\n    7\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    41.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:14:03 UTC&lt; 1 s2025-11-23 00:14:03 UTC\n  \n\n\n\n\n\n\n        \n\n\nThe title of the report is now set to ‘Report for Table XY’. This can be useful if you want to provide a more descriptive title for the report."
  },
  {
    "objectID": "reference/everything.html",
    "href": "reference/everything.html",
    "title": "everything",
    "section": "",
    "text": "everything()\nSelect all columns.\nMany validation methods have a columns= argument that can be used to specify the columns for validation (e.g., col_vals_gt(), col_vals_regex(), etc.). The everything() selector function can be used to select every column in the table. If you have a table with six columns and they’re all suitable for a specific type of validation, you can use columns=everything()) and all six columns will be selected for validation."
  },
  {
    "objectID": "reference/everything.html#returns",
    "href": "reference/everything.html#returns",
    "title": "everything",
    "section": "Returns",
    "text": "Returns\n\n : Everything\n\nAn Everything object, which can be used to select all columns."
  },
  {
    "objectID": "reference/everything.html#relevant-validation-methods-where-everything-can-be-used",
    "href": "reference/everything.html#relevant-validation-methods-where-everything-can-be-used",
    "title": "everything",
    "section": "Relevant Validation Methods where everything() can be Used",
    "text": "Relevant Validation Methods where everything() can be Used\nThis selector function can be used in the columns= argument of the following validation methods:\n\ncol_vals_gt()\ncol_vals_lt()\ncol_vals_ge()\ncol_vals_le()\ncol_vals_eq()\ncol_vals_ne()\ncol_vals_between()\ncol_vals_outside()\ncol_vals_in_set()\ncol_vals_not_in_set()\ncol_vals_increasing()\ncol_vals_decreasing()\ncol_vals_null()\ncol_vals_not_null()\ncol_vals_regex()\ncol_vals_within_spec()\ncol_exists()\n\nThe everything() selector function doesn’t need to be used in isolation. Read the next section for information on how to compose it with other column selectors for more refined ways to select columns."
  },
  {
    "objectID": "reference/everything.html#additional-flexibilty-through-composition-with-other-column-selectors",
    "href": "reference/everything.html#additional-flexibilty-through-composition-with-other-column-selectors",
    "title": "everything",
    "section": "Additional Flexibilty through Composition with Other Column Selectors",
    "text": "Additional Flexibilty through Composition with Other Column Selectors\nThe everything() function can be composed with other column selectors to create fine-grained column selections. For example, to select all column names except those having starting with “id_”, you can use the everything() and starts_with() functions together. The only condition is that the expressions are wrapped in the col() function, like this:\ncol(everything() - starts_with(\"id_\"))\nThere are four operators that can be used to compose column selectors:\n\n& (and)\n| (or)\n- (difference)\n~ (not)\n\nThe & operator is used to select columns that satisfy both conditions. The | operator is used to select columns that satisfy either condition. The - operator is used to select columns that satisfy the first condition but not the second. The ~ operator is used to select columns that don’t satisfy the condition. As many selector functions can be used as needed and the operators can be combined to create complex column selection criteria (parentheses can be used to group conditions and control the order of evaluation)."
  },
  {
    "objectID": "reference/everything.html#examples",
    "href": "reference/everything.html#examples",
    "title": "everything",
    "section": "Examples",
    "text": "Examples\nSuppose we have a table with several numeric columns and we’d like to validate that all these columns have less than 1000. We can use the everything() column selector function to select all columns for validation.\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"2023_hours\": [182, 168, 175],\n        \"2024_hours\": [200, 165, 190],\n        \"2023_pay_total\": [19.29, 17.75, 18.35],\n        \"2024_pay_total\": [20.73, 18.35, 20.10],\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_lt(columns=pb.everything(), value=1000)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    2023_hours\n    1000\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    2024_hours\n    1000\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    2023_pay_total\n    1000\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    2024_pay_total\n    1000\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nFrom the results of the validation table we get four validation steps, one each column in the table. The values in every column were all lower than 1000.\nWe can also use the everything() function in combination with other column selectors (within col()) to create more complex column selection criteria (i.e., to select columns that satisfy multiple conditions). For example, to select every column except those that begin with \"2023\" we can use the - operator to combine column selectors.\n\ntbl = pl.DataFrame(\n    {\n        \"2023_hours\": [182, 168, 175],\n        \"2024_hours\": [200, 165, 190],\n        \"2023_pay_total\": [19.29, 17.75, 18.35],\n        \"2024_pay_total\": [20.73, 18.35, 20.10],\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_lt(columns=pb.col(pb.everything() - pb.starts_with(\"2023\")), value=1000)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    2024_hours\n    1000\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    2024_pay_total\n    1000\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nFrom the results of the validation table we get two validation steps, one for 2024_hours and one for 2024_pay_total."
  },
  {
    "objectID": "reference/validate_yaml.html",
    "href": "reference/validate_yaml.html",
    "title": "validate_yaml",
    "section": "",
    "text": "validate_yaml(yaml)\nValidate YAML configuration against the expected structure.\nThis function validates that a YAML configuration conforms to the expected structure for validation workflows. It checks for required fields, proper data types, and valid validation method names. This is useful for validating configurations before execution or for building configuration editors and validators.\nThe function performs comprehensive validation including:"
  },
  {
    "objectID": "reference/validate_yaml.html#parameters",
    "href": "reference/validate_yaml.html#parameters",
    "title": "validate_yaml",
    "section": "Parameters",
    "text": "Parameters\n\nyaml : Union[str, Path]\n\nYAML configuration as string or file path. Can be: (1) a YAML string containing the validation configuration, or (2) a Path object or string path to a YAML file."
  },
  {
    "objectID": "reference/validate_yaml.html#raises",
    "href": "reference/validate_yaml.html#raises",
    "title": "validate_yaml",
    "section": "Raises",
    "text": "Raises\n\n: YAMLValidationError\n\nIf the YAML is invalid, malformed, or execution fails. This includes syntax errors, missing required fields, unknown validation methods, or data loading failures."
  },
  {
    "objectID": "reference/validate_yaml.html#examples",
    "href": "reference/validate_yaml.html#examples",
    "title": "validate_yaml",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll demonstrate how to validate YAML configurations before using them with validation workflows. This is particularly useful for building robust data validation systems where you want to catch configuration errors early.\nLet’s start with validating a basic configuration:\n\nimport pointblank as pb\n\n# Define a basic YAML validation configuration\nyaml_config = '''\ntbl: small_table\nsteps:\n- rows_distinct\n- col_exists:\n    columns: [a, b]\n'''\n\n# Validate the configuration: no exception means it's valid\npb.validate_yaml(yaml_config)\nprint(\"Basic YAML configuration is valid\")\n\nBasic YAML configuration is valid\n\n\nThe function completed without raising an exception, which means our configuration is valid and follows the expected structure.\nNow let’s validate a more complex configuration with thresholds and metadata:\n\n# Complex YAML configuration with all optional fields\nyaml_config = '''\ntbl: small_table\ntbl_name: My Dataset\nlabel: Quality check\nlang: en\nlocale: en\nthresholds:\n  warning: 0.1\n  error: 0.25\n  critical: 0.35\nsteps:\n- rows_distinct\n- col_vals_gt:\n    columns: [d]\n    value: 100\n- col_vals_regex:\n    columns: [b]\n    pattern: '[0-9]-[a-z]{3}-[0-9]{3}'\n'''\n\n# Validate the configuration\npb.validate_yaml(yaml_config)\nprint(\"Complex YAML configuration is valid\")\n\n# Count the validation steps\nimport pointblank.yaml as pby\nconfig = pby.load_yaml_config(yaml_config)\nprint(f\"Configuration has {len(config['steps'])} validation steps\")\n\nComplex YAML configuration is valid\nConfiguration has 3 validation steps\n\n\nThis configuration includes all the optional metadata fields and complex validation steps, demonstrating that the validation handles the full range of supported options.\nLet’s see what happens when we try to validate an invalid configuration:\n\n# Invalid YAML configuration: missing required 'tbl' field\ninvalid_yaml = '''\nsteps:\n- rows_distinct\n'''\n\ntry:\n    pb.validate_yaml(invalid_yaml)\nexcept pb.yaml.YAMLValidationError as e:\n    print(f\"Validation failed: {e}\")\n\nValidation failed: Error loading YAML configuration: YAML must contain 'tbl' field\n\n\nThe validation correctly identifies that our configuration is missing the required 'tbl' field.\nHere’s a practical example of using validation in a workflow builder:\n\ndef safe_yaml_interrogate(yaml_config):\n    \"\"\"Safely execute a YAML configuration after validation.\"\"\"\n    try:\n        # Validate the YAML configuration first\n        pb.validate_yaml(yaml_config)\n        print(\"✓ YAML configuration is valid\")\n\n        # Then execute the workflow\n        result = pb.yaml_interrogate(yaml_config)\n        print(f\"Validation completed with {len(result.validation_info)} steps\")\n        return result\n\n    except pb.yaml.YAMLValidationError as e:\n        print(f\"Configuration error: {e}\")\n        return None\n\n# Test with a valid YAML configuration\ntest_yaml = '''\ntbl: small_table\nsteps:\n- col_vals_between:\n    columns: [c]\n    left: 1\n    right: 10\n'''\n\nresult = safe_yaml_interrogate(test_yaml)\n\n✓ YAML configuration is valid\nValidation completed with 1 steps\n\n\nThis pattern of validating before executing helps build more reliable data validation pipelines by catching configuration errors early in the process.\nNote that this function only validates the structure and does not check if the specified data source (‘tbl’) exists or is accessible. Data source validation occurs during execution with yaml_interrogate()."
  },
  {
    "objectID": "reference/validate_yaml.html#see-also",
    "href": "reference/validate_yaml.html#see-also",
    "title": "validate_yaml",
    "section": "See Also",
    "text": "See Also\nyaml_interrogate : execute YAML-based validation workflows"
  },
  {
    "objectID": "reference/Validate.warning.html",
    "href": "reference/Validate.warning.html",
    "title": "Validate.warning",
    "section": "",
    "text": "Validate.warning(i=None, scalar=False)\nGet the ‘warning’ level status for each validation step.\nThe ‘warning’ status for a validation step is True if the fraction of failing test units meets or exceeds the threshold for the ‘warning’ level. Otherwise, the status is False.\nThe ascribed name of ‘warning’ is semantic and does not imply that a warning message is generated, it is simply a status indicator that could be used to trigger some action to be taken. Here’s how it fits in with other status indicators:\nThis method provides a dictionary of the ‘warning’ status for each validation step. If the scalar=True argument is provided and i= is a scalar, the value is returned as a scalar instead of a dictionary."
  },
  {
    "objectID": "reference/Validate.warning.html#parameters",
    "href": "reference/Validate.warning.html#parameters",
    "title": "Validate.warning",
    "section": "Parameters",
    "text": "Parameters\n\ni : int | list[int] | None = None\n\nThe validation step number(s) from which the ‘warning’ status is obtained. Can be provided as a list of integers or a single integer. If None, all steps are included.\n\nscalar : bool = False\n\nIf True and i= is a scalar, return the value as a scalar instead of a dictionary."
  },
  {
    "objectID": "reference/Validate.warning.html#returns",
    "href": "reference/Validate.warning.html#returns",
    "title": "Validate.warning",
    "section": "Returns",
    "text": "Returns\n\n : dict[int, bool] | bool\n\nA dictionary of the ‘warning’ status for each validation step or a scalar value."
  },
  {
    "objectID": "reference/Validate.warning.html#examples",
    "href": "reference/Validate.warning.html#examples",
    "title": "Validate.warning",
    "section": "Examples",
    "text": "Examples\nIn the example below, we’ll use a simple Polars DataFrame with three columns (a, b, and c). There will be three validation steps, and the first step will have some failing test units, the rest will be completely passing. We’ve set thresholds here for each of the steps by using thresholds=(2, 4, 5), which means:\n\nthe ‘warning’ threshold is 2 failing test units\nthe ‘error’ threshold is 4 failing test units\nthe ‘critical’ threshold is 5 failing test units\n\nAfter interrogation, the warning() method is used to determine the ‘warning’ status for each validation step.\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [7, 4, 9, 7, 12, 3, 10],\n        \"b\": [9, 8, 10, 5, 10, 6, 2],\n        \"c\": [\"a\", \"b\", \"a\", \"a\", \"b\", \"b\", \"a\"]\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl, thresholds=(2, 4, 5))\n    .col_vals_gt(columns=\"a\", value=5)\n    .col_vals_lt(columns=\"b\", value=15)\n    .col_vals_in_set(columns=\"c\", set=[\"a\", \"b\"])\n    .interrogate()\n)\n\nvalidation.warning()\n\n{1: True, 2: False, 3: False}\n\n\nThe returned dictionary provides the ‘warning’ status for each validation step. The first step has a True value since the number of failing test units meets the threshold for the ‘warning’ level. The second and third steps have False values since the number of failing test units was 0, which is below the threshold for the ‘warning’ level.\nWe can also visually inspect the ‘warning’ status across all steps by viewing the validation table:\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:13:36PolarsWARNING2ERROR4CRITICAL5\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #AAAAAA\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    a\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    7\n    50.71\n    20.29\n    ●\n    ○\n    ○\n    CSV\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    b\n    15\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    7\n    71.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        \n        \n    c\n    a, b\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    7\n    71.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:13:36 UTC&lt; 1 s2025-11-23 00:13:36 UTC\n  \n\n\n\n\n\n\n        \n\n\nWe can see that there’s a filled gray circle in the first step (look to the far right side, in the W column) indicating that the ‘warning’ threshold was met. The other steps have empty gray circles. This means that thresholds were ‘set but not met’ in those steps.\nIf we wanted to check the ‘warning’ status for a single validation step, we can provide the step number. Also, we could have the value returned as a scalar by setting scalar=True (ensuring that i= is a scalar).\n\nvalidation.warning(i=1)\n\n{1: True}\n\n\nThe returned value is True, indicating that the first validation step had met the ‘warning’ threshold."
  },
  {
    "objectID": "reference/config.html",
    "href": "reference/config.html",
    "title": "config",
    "section": "",
    "text": "config(\n    report_incl_header=True,\n    report_incl_footer=True,\n    preview_incl_header=True,\n)\nConfiguration settings for the Pointblank library.\n\n\n\nreport_incl_header : bool = True\n\nThis controls whether the header should be present in the validation table report. The header contains the table name, label information, and might contain global failure threshold levels (if set).\n\nreport_incl_footer : bool = True\n\nShould the footer of the validation table report be displayed? The footer contains the starting and ending times of the interrogation.\n\npreview_incl_header : bool = True\n\nWhether the header should be present in any preview table (generated via the preview() function).\n\n\n\n\n\n\n : PointblankConfig\n\nA PointblankConfig object with the specified configuration settings."
  },
  {
    "objectID": "reference/config.html#parameters",
    "href": "reference/config.html#parameters",
    "title": "config",
    "section": "",
    "text": "report_incl_header : bool = True\n\nThis controls whether the header should be present in the validation table report. The header contains the table name, label information, and might contain global failure threshold levels (if set).\n\nreport_incl_footer : bool = True\n\nShould the footer of the validation table report be displayed? The footer contains the starting and ending times of the interrogation.\n\npreview_incl_header : bool = True\n\nWhether the header should be present in any preview table (generated via the preview() function)."
  },
  {
    "objectID": "reference/config.html#returns",
    "href": "reference/config.html#returns",
    "title": "config",
    "section": "",
    "text": ": PointblankConfig\n\nA PointblankConfig object with the specified configuration settings."
  },
  {
    "objectID": "reference/Validate.col_vals_gt.html",
    "href": "reference/Validate.col_vals_gt.html",
    "title": "Validate.col_vals_gt",
    "section": "",
    "text": "Validate.col_vals_gt(\n    columns,\n    value,\n    na_pass=False,\n    pre=None,\n    segments=None,\n    thresholds=None,\n    actions=None,\n    brief=None,\n    active=True,\n)\nAre column data greater than a fixed value or data in another column?\nThe col_vals_gt() validation method checks whether column values in a table are greater than a specified value= (the exact comparison used in this function is col_val &gt; value). The value= can be specified as a single, literal value or as a column name given in col(). This validation will operate over the number of test units that is equal to the number of rows in the table (determined after any pre= mutation has been applied)."
  },
  {
    "objectID": "reference/Validate.col_vals_gt.html#parameters",
    "href": "reference/Validate.col_vals_gt.html#parameters",
    "title": "Validate.col_vals_gt",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns : str | list[str] | Column | ColumnSelector | ColumnSelectorNarwhals\n\nA single column or a list of columns to validate. Can also use col() with column selectors to specify one or more columns. If multiple columns are supplied or resolved, there will be a separate validation step generated for each column.\n\nvalue : float | int | Column\n\nThe value to compare against. This can be a single value or a single column name given in col(). The latter option allows for a column-to-column comparison. For more information on which types of values are allowed, see the What Can Be Used in value=? section.\n\nna_pass : bool = False\n\nShould any encountered None, NA, or Null values be considered as passing test units? By default, this is False. Set to True to pass test units with missing values.\n\npre : Callable | None = None\n\nAn optional preprocessing function or lambda to apply to the data table during interrogation. This function should take a table as input and return a modified table. Have a look at the Preprocessing section for more information on how to use this argument.\n\nsegments : SegmentSpec | None = None\n\nAn optional directive on segmentation, which serves to split a validation step into multiple (one step per segment). Can be a single column name, a tuple that specifies a column name and its corresponding values to segment on, or a combination of both (provided as a list). Read the Segmentation section for usage information.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nSet threshold failure levels for reporting and reacting to exceedences of the levels. The thresholds are set at the step level and will override any global thresholds set in Validate(thresholds=...). The default is None, which means that no thresholds will be set locally and global thresholds (if any) will take effect. Look at the Thresholds section for information on how to set threshold levels.\n\nactions : Actions | None = None\n\nOptional actions to take when the validation step(s) meets or exceeds any set threshold levels. If provided, the Actions class should be used to define the actions.\n\nbrief : str | bool | None = None\n\nAn optional brief description of the validation step that will be displayed in the reporting table. You can use the templating elements like \"{step}\" to insert the step number, or \"{auto}\" to include an automatically generated brief. If True the entire brief will be automatically generated. If None (the default) then there won’t be a brief.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.col_vals_gt.html#returns",
    "href": "reference/Validate.col_vals_gt.html#returns",
    "title": "Validate.col_vals_gt",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.col_vals_gt.html#what-can-be-used-in-value",
    "href": "reference/Validate.col_vals_gt.html#what-can-be-used-in-value",
    "title": "Validate.col_vals_gt",
    "section": "What Can Be Used in value=?",
    "text": "What Can Be Used in value=?\nThe value= argument allows for a variety of input types. The most common are:\n\na single numeric value\na single date or datetime value\nA col() object that represents a column name\n\nWhen supplying a number as the basis of comparison, keep in mind that all resolved columns must also be numeric. Should you have columns that are of the date or datetime types, you can supply a date or datetime value as the value= argument. There is flexibility in how you provide the date or datetime value, as it can be:\n\na string-based date or datetime (e.g., \"2023-10-01\", \"2023-10-01 13:45:30\", etc.)\na date or datetime object using the datetime module (e.g., datetime.date(2023, 10, 1), datetime.datetime(2023, 10, 1, 13, 45, 30), etc.)\n\nFinally, when supplying a column name in the value= argument, it must be specified within col(). This is a column-to-column comparison and, crucially, the columns being compared must be of the same type (e.g., both numeric, both date, etc.)."
  },
  {
    "objectID": "reference/Validate.col_vals_gt.html#preprocessing",
    "href": "reference/Validate.col_vals_gt.html#preprocessing",
    "title": "Validate.col_vals_gt",
    "section": "Preprocessing",
    "text": "Preprocessing\nThe pre= argument allows for a preprocessing function or lambda to be applied to the data table during interrogation. This function should take a table as input and return a modified table. This is useful for performing any necessary transformations or filtering on the data before the validation step is applied.\nThe preprocessing function can be any callable that takes a table as input and returns a modified table. For example, you could use a lambda function to filter the table based on certain criteria or to apply a transformation to the data. Note that you can refer to columns via columns= and value=col(...) that are expected to be present in the transformed table, but may not exist in the table before preprocessing. Regarding the lifetime of the transformed table, it only exists during the validation step and is not stored in the Validate object or used in subsequent validation steps."
  },
  {
    "objectID": "reference/Validate.col_vals_gt.html#segmentation",
    "href": "reference/Validate.col_vals_gt.html#segmentation",
    "title": "Validate.col_vals_gt",
    "section": "Segmentation",
    "text": "Segmentation\nThe segments= argument allows for the segmentation of a validation step into multiple segments. This is useful for applying the same validation step to different subsets of the data. The segmentation can be done based on a single column or specific fields within a column.\nProviding a single column name will result in a separate validation step for each unique value in that column. For example, if you have a column called \"region\" with values \"North\", \"South\", and \"East\", the validation step will be applied separately to each region.\nAlternatively, you can provide a tuple that specifies a column name and its corresponding values to segment on. For example, if you have a column called \"date\" and you want to segment on only specific dates, you can provide a tuple like (\"date\", [\"2023-01-01\", \"2023-01-02\"]). Any other values in the column will be disregarded (i.e., no validation steps will be created for them).\nA list with a combination of column names and tuples can be provided as well. This allows for more complex segmentation scenarios. The following inputs are both valid:\n# Segments from all unique values in the `region` column\n# and specific dates in the `date` column\nsegments=[\"region\", (\"date\", [\"2023-01-01\", \"2023-01-02\"])]\n\n# Segments from all unique values in the `region` and `date` columns\nsegments=[\"region\", \"date\"]\nThe segmentation is performed during interrogation, and the resulting validation steps will be numbered sequentially. Each segment will have its own validation step, and the results will be reported separately. This allows for a more granular analysis of the data and helps identify issues within specific segments.\nImportantly, the segmentation process will be performed after any preprocessing of the data table. Because of this, one can conceivably use the pre= argument to generate a column that can be used for segmentation. For example, you could create a new column called \"segment\" through use of pre= and then use that column for segmentation."
  },
  {
    "objectID": "reference/Validate.col_vals_gt.html#thresholds",
    "href": "reference/Validate.col_vals_gt.html#thresholds",
    "title": "Validate.col_vals_gt",
    "section": "Thresholds",
    "text": "Thresholds\nThe thresholds= parameter is used to set the failure-condition levels for the validation step. If they are set here at the step level, these thresholds will override any thresholds set at the global level in Validate(thresholds=...).\nThere are three threshold levels: ‘warning’, ‘error’, and ‘critical’. The threshold values can either be set as a proportion failing of all test units (a value between 0 to 1), or, the absolute number of failing test units (as integer that’s 1 or greater).\nThresholds can be defined using one of these input schemes:\n\nuse the Thresholds class (the most direct way to create thresholds)\nprovide a tuple of 1-3 values, where position 0 is the ‘warning’ level, position 1 is the ‘error’ level, and position 2 is the ‘critical’ level\ncreate a dictionary of 1-3 value entries; the valid keys: are ‘warning’, ‘error’, and ‘critical’\na single integer/float value denoting absolute number or fraction of failing test units for the ‘warning’ level only\n\nIf the number of failing test units exceeds set thresholds, the validation step will be marked as ‘warning’, ‘error’, or ‘critical’. All of the threshold levels don’t need to be set, you’re free to set any combination of them.\nAside from reporting failure conditions, thresholds can be used to determine the actions to take for each level of failure (using the actions= parameter)."
  },
  {
    "objectID": "reference/Validate.col_vals_gt.html#examples",
    "href": "reference/Validate.col_vals_gt.html#examples",
    "title": "Validate.col_vals_gt",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with three numeric columns (a, b, and c). The table is shown below:\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [5, 6, 5, 7, 6, 5],\n        \"b\": [1, 2, 1, 2, 2, 2],\n        \"c\": [2, 1, 2, 2, 3, 4],\n    }\n)\n\npb.preview(tbl)\n\n\n\n\n\n  \n  \n  \n  \n\n\n\n\n\n  \n  aInt64\n  bInt64\n  cInt64\n\n\n\n  \n    1\n    5\n    1\n    2\n  \n  \n    2\n    6\n    2\n    1\n  \n  \n    3\n    5\n    1\n    2\n  \n  \n    4\n    7\n    2\n    2\n  \n  \n    5\n    6\n    2\n    3\n  \n  \n    6\n    5\n    2\n    4\n  \n\n\n\n\n\n\n        \n\n\nLet’s validate that values in column a are all greater than the value of 4. We’ll determine if this validation had any failing test units (there are six test units, one for each row).\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(columns=\"a\", value=4)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    a\n    4\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    61.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nPrinting the validation object shows the validation table in an HTML viewing environment. The validation table shows the single entry that corresponds to the validation step created by using col_vals_gt(). All test units passed, and there are no failing test units.\nAside from checking a column against a literal value, we can also use a column name in the value= argument (with the helper function col() to perform a column-to-column comparison. For the next example, we’ll use col_vals_gt() to check whether the values in column c are greater than values in column b.\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(columns=\"c\", value=pb.col(\"b\"))\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    c\n    b\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    40.67\n    20.33\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe validation table reports two failing test units. The specific failing cases are:\n\nRow 1: c is 1 and b is 2.\nRow 3: c is 2 and b is 2."
  },
  {
    "objectID": "reference/Validate.prompt.html",
    "href": "reference/Validate.prompt.html",
    "title": "Validate.prompt",
    "section": "",
    "text": "Validate.prompt(\n    prompt,\n    model,\n    columns_subset=None,\n    batch_size=1000,\n    max_concurrent=3,\n    pre=None,\n    segments=None,\n    thresholds=None,\n    actions=None,\n    brief=None,\n    active=True,\n)\nValidate rows using AI/LLM-powered analysis.\nThe prompt() validation method uses Large Language Models (LLMs) to validate rows of data based on natural language criteria. Similar to other Pointblank validation methods, this generates binary test results (pass/fail) that integrate seamlessly with the standard reporting framework.\nLike col_vals_*() methods, prompt() evaluates data against specific criteria, but instead of using programmatic rules, it uses natural language prompts interpreted by an LLM. Like rows_distinct() and rows_complete(), it operates at the row level and allows you to specify a subset of columns for evaluation using columns_subset=.\nThe system automatically combines your validation criteria from the prompt= parameter with the necessary technical context, data formatting instructions, and response structure requirements. This is all so you only need to focus on describing your validation logic in plain language.\nEach row becomes a test unit that either passes or fails the validation criteria, producing the familiar True/False results that appear in Pointblank validation reports. This method is particularly useful for complex validation rules that are difficult to express with traditional validation methods, such as semantic checks, context-dependent validation, or subjective quality assessments."
  },
  {
    "objectID": "reference/Validate.prompt.html#parameters",
    "href": "reference/Validate.prompt.html#parameters",
    "title": "Validate.prompt",
    "section": "Parameters",
    "text": "Parameters\n\nprompt : str\n\nA natural language description of the validation criteria. This prompt should clearly describe what constitutes valid vs invalid rows. Some examples: \"Each row should contain a valid email address and a realistic person name\", \"Values should indicate positive sentiment\", \"The description should mention a country name\".\n\ncolumns_subset : str | list[str] | None = None\n\nA single column or list of columns to include in the validation. If None, all columns will be included. Specifying fewer columns can improve performance and reduce API costs so try to include only the columns necessary for the validation.\n\nmodel : str\n\nThe model to be used. This should be in the form of provider:model (e.g., \"anthropic:claude-sonnet-4-5\"). Supported providers are \"anthropic\", \"openai\", \"ollama\", and \"bedrock\". The model name should be the specific model to be used from the provider. Model names are subject to change so consult the provider’s documentation for the most up-to-date model names.\n\nbatch_size : int = 1000\n\nNumber of rows to process in each batch. Larger batches are more efficient but may hit API limits. Default is 1000.\n\nmax_concurrent : int = 3\n\nMaximum number of concurrent API requests. Higher values speed up processing but may hit rate limits. Default is 3.\n\npre : Callable | None = None\n\nAn optional preprocessing function or lambda to apply to the data table during interrogation. This function should take a table as input and return a modified table.\n\nsegments : SegmentSpec | None = None\n\nAn optional directive on segmentation, which serves to split a validation step into multiple (one step per segment). Can be a single column name, a tuple that specifies a column name and its corresponding values to segment on, or a combination of both (provided as a list).\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nSet threshold failure levels for reporting and reacting to exceedences of the levels. The thresholds are set at the step level and will override any global thresholds set in Validate(thresholds=...). The default is None, which means that no thresholds will be set locally and global thresholds (if any) will take effect.\n\nactions : Actions | None = None\n\nOptional actions to take when the validation step meets or exceeds any set threshold levels. If provided, the Actions class should be used to define the actions.\n\nbrief : str | bool | None = None\n\nAn optional brief description of the validation step that will be displayed in the reporting table. You can use the templating elements like \"{step}\" to insert the step number, or \"{auto}\" to include an automatically generated brief. If True the entire brief will be automatically generated. If None (the default) then there won’t be a brief.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.prompt.html#returns",
    "href": "reference/Validate.prompt.html#returns",
    "title": "Validate.prompt",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.prompt.html#constructing-the-model-argument",
    "href": "reference/Validate.prompt.html#constructing-the-model-argument",
    "title": "Validate.prompt",
    "section": "Constructing the model Argument",
    "text": "Constructing the model Argument\nThe model= argument should be constructed using the provider and model name separated by a colon (provider:model). The provider text can any of:\n\n\"anthropic\" (Anthropic)\n\"openai\" (OpenAI)\n\"ollama\" (Ollama)\n\"bedrock\" (Amazon Bedrock)\n\nThe model name should be the specific model to be used from the provider. Model names are subject to change so consult the provider’s documentation for the most up-to-date model names."
  },
  {
    "objectID": "reference/Validate.prompt.html#notes-on-authentication",
    "href": "reference/Validate.prompt.html#notes-on-authentication",
    "title": "Validate.prompt",
    "section": "Notes on Authentication",
    "text": "Notes on Authentication\nAPI keys are automatically loaded from environment variables or .env files and are not stored in the validation object for security reasons. You should consider using a secure method for handling API keys.\nOne way to do this is to load the API key from an environment variable and retrieve it using the os module (specifically the os.getenv() function). Places to store the API key might include .bashrc, .bash_profile, .zshrc, or .zsh_profile.\nAnother solution is to store one or more model provider API keys in an .env file (in the root of your project). If the API keys have correct names (e.g., ANTHROPIC_API_KEY or OPENAI_API_KEY) then the AI validation will automatically load the API key from the .env file. An .env file might look like this:\nANTHROPIC_API_KEY=\"your_anthropic_api_key_here\"\nOPENAI_API_KEY=\"your_openai_api_key_here\"\nThere’s no need to have the python-dotenv package installed when using .env files in this way.\nProvider-specific setup:\n\nOpenAI: set OPENAI_API_KEY environment variable or create .env file\nAnthropic: set ANTHROPIC_API_KEY environment variable or create .env file\nOllama: no API key required, just ensure Ollama is running locally\nBedrock: configure AWS credentials through standard AWS methods"
  },
  {
    "objectID": "reference/Validate.prompt.html#ai-validation-process",
    "href": "reference/Validate.prompt.html#ai-validation-process",
    "title": "Validate.prompt",
    "section": "AI Validation Process",
    "text": "AI Validation Process\nThe AI validation process works as follows:\n\ndata batching: the data is split into batches of the specified size\nrow deduplication: duplicate rows (based on selected columns) are identified and only unique combinations are sent to the LLM for analysis\njson conversion: each batch of unique rows is converted to JSON format for the LLM\nprompt construction: the user prompt is embedded in a structured system prompt\nllm processing: each batch is sent to the LLM for analysis\nresponse parsing: LLM responses are parsed to extract validation results\nresult projection: results are mapped back to all original rows using row signatures\nresult aggregation: results from all batches are combined\n\nPerformance Optimization: the process uses row signature memoization to avoid redundant LLM calls. When multiple rows have identical values in the selected columns, only one representative row is validated, and the result is applied to all matching rows. This can dramatically reduce API costs and processing time for datasets with repetitive patterns.\nThe LLM receives data in this JSON format:\n{\n  \"columns\": [\"col1\", \"col2\", \"col3\"],\n  \"rows\": [\n    {\"col1\": \"value1\", \"col2\": \"value2\", \"col3\": \"value3\", \"_pb_row_index\": 0},\n    {\"col1\": \"value4\", \"col2\": \"value5\", \"col3\": \"value6\", \"_pb_row_index\": 1}\n  ]\n}\nThe LLM returns validation results in this format:\n[\n  {\"index\": 0, \"result\": true},\n  {\"index\": 1, \"result\": false}\n]"
  },
  {
    "objectID": "reference/Validate.prompt.html#prompt-design-tips",
    "href": "reference/Validate.prompt.html#prompt-design-tips",
    "title": "Validate.prompt",
    "section": "Prompt Design Tips",
    "text": "Prompt Design Tips\nFor best results, design prompts that are:\n\nboolean-oriented: frame validation criteria to elicit clear valid/invalid responses\nspecific: clearly define what makes a row valid/invalid\nunambiguous: avoid subjective language that could be interpreted differently\ncontext-aware: include relevant business rules or domain knowledge\nexample-driven: consider providing examples in the prompt when helpful\n\nCritical: Prompts must be designed so the LLM can determine whether each row passes or fails the validation criteria. The system expects binary validation responses, so avoid open-ended questions or prompts that might generate explanatory text instead of clear pass/fail judgments.\nGood prompt examples:\n\n“Each row should contain a valid email address in the ‘email’ column and a non-empty name in the ‘name’ column”\n“The ‘sentiment’ column should contain positive sentiment words (happy, good, excellent, etc.)”\n“Product descriptions should mention at least one technical specification”\n\nPoor prompt examples (avoid these):\n\n“What do you think about this data?” (too open-ended)\n“Describe the quality of each row” (asks for description, not validation)\n“How would you improve this data?” (asks for suggestions, not pass/fail)"
  },
  {
    "objectID": "reference/Validate.prompt.html#performance-considerations",
    "href": "reference/Validate.prompt.html#performance-considerations",
    "title": "Validate.prompt",
    "section": "Performance Considerations",
    "text": "Performance Considerations\nAI validation is significantly slower than traditional validation methods due to API calls to LLM providers. However, performance varies dramatically based on data characteristics:\nHigh Memoization Scenarios (seconds to minutes):\n\ndata with many duplicate rows in the selected columns\nlow cardinality data (repeated patterns)\nsmall number of unique row combinations\n\nLow Memoization Scenarios (minutes to hours):\n\nhigh cardinality data with mostly unique rows\nlarge datasets with few repeated patterns\nall or most rows requiring individual LLM evaluation\n\nThe row signature memoization optimization can reduce processing time significantly when data has repetitive patterns. For datasets where every row is unique, expect longer processing times similar to validating each row individually.\nStrategies to Reduce Processing Time:\n\ntest on data slices: define a sampling function like def sample_1000(df): return df.head(1000) and use pre=sample_1000 to validate on smaller samples\nfilter relevant data: define filter functions like def active_only(df): return df.filter(df[\"status\"] == \"active\") and use pre=active_only to focus on a specific subset\noptimize column selection: use columns_subset= to include only the columns necessary for validation\nstart with smaller batches: begin with batch_size=100 for testing, then increase gradually\nreduce concurrency: lower max_concurrent=1 if hitting rate limits\nuse faster/cheaper models: consider using smaller or more efficient models for initial testing before switching to more capable models"
  },
  {
    "objectID": "reference/Validate.prompt.html#examples",
    "href": "reference/Validate.prompt.html#examples",
    "title": "Validate.prompt",
    "section": "Examples",
    "text": "Examples\nThe following examples demonstrate how to use AI validation for different types of data quality checks. These examples show both basic usage and more advanced configurations with custom thresholds and actions.\nBasic AI validation example:\nThis first example shows a simple validation scenario where we want to check that customer records have both valid email addresses and non-empty names. Notice how we use columns_subset= to focus only on the relevant columns, which improves both performance and cost-effectiveness.\nimport pointblank as pb\nimport polars as pl\n\n# Sample data with email and name columns\ntbl = pl.DataFrame({\n    \"email\": [\"john@example.com\", \"invalid-email\", \"jane@test.org\"],\n    \"name\": [\"John Doe\", \"\", \"Jane Smith\"],\n    \"age\": [25, 30, 35]\n})\n\n# Validate using AI\nvalidation = (\n    pb.Validate(data=tbl)\n    .prompt(\n        prompt=\"Each row should have a valid email address and a non-empty name\",\n        columns_subset=[\"email\", \"name\"],  # Only check these columns\n        model=\"openai:gpt-4o-mini\",\n    )\n    .interrogate()\n)\n\nvalidation\nIn this example, the AI will identify that the second row fails validation because it has an invalid email format (\"invalid-email\") and the third row also fails because it has an empty name field. The validation results will show 2 out of 3 rows failing the criteria.\nAdvanced example with custom thresholds:\nThis more sophisticated example demonstrates how to use AI validation with custom thresholds and actions. Here we’re validating phone number formats to ensure they include area codes, which is a common data quality requirement for customer contact information.\ncustomer_data = pl.DataFrame({\n    \"customer_id\": [1, 2, 3, 4, 5],\n    \"name\": [\"John Doe\", \"Jane Smith\", \"Bob Johnson\", \"Alice Brown\", \"Charlie Davis\"],\n    \"phone_number\": [\n        \"(555) 123-4567\",  # Valid with area code\n        \"555-987-6543\",    # Valid with area code\n        \"123-4567\",        # Missing area code\n        \"(800) 555-1234\",  # Valid with area code\n        \"987-6543\"         # Missing area code\n    ]\n})\n\nvalidation = (\n    pb.Validate(data=customer_data)\n    .prompt(\n        prompt=\"Do all the phone numbers include an area code?\",\n        columns_subset=\"phone_number\",  # Only check the `phone_number` column\n        model=\"openai:gpt-4o\",\n        batch_size=500,\n        max_concurrent=5,\n        thresholds=pb.Thresholds(warning=0.1, error=0.2, critical=0.3),\n        actions=pb.Actions(error=\"Too many phone numbers missing area codes.\")\n    )\n    .interrogate()\n)\nThis validation will identify that 2 out of 5 phone numbers (40%) are missing area codes, which exceeds all threshold levels. The validation will trigger the specified error action since the failure rate (40%) is above the error threshold (20%). The AI can recognize various phone number formats and determine whether they include area codes."
  },
  {
    "objectID": "reference/starts_with.html",
    "href": "reference/starts_with.html",
    "title": "starts_with",
    "section": "",
    "text": "starts_with(text, case_sensitive=False)\nSelect columns that start with specified text.\nMany validation methods have a columns= argument that can be used to specify the columns for validation (e.g., col_vals_gt(), col_vals_regex(), etc.). The starts_with() selector function can be used to select one or more columns that start with some specified text. So if the set of table columns consists of\n[name_first, name_last, age, address]\nand you want to validate columns that start with \"name\", you can use columns=starts_with(\"name\"). This will select the name_first and name_last columns.\nThere will be a validation step created for every resolved column. Note that if there aren’t any columns resolved from using starts_with() (or any other expression using selector functions), the validation step will fail to be evaluated during the interrogation process. Such a failure to evaluate will be reported in the validation results but it won’t affect the interrogation process overall (i.e., the process won’t be halted)."
  },
  {
    "objectID": "reference/starts_with.html#parameters",
    "href": "reference/starts_with.html#parameters",
    "title": "starts_with",
    "section": "Parameters",
    "text": "Parameters\n\ntext : str\n\nThe text that the column name should start with.\n\ncase_sensitive : bool = False\n\nWhether column names should be treated as case-sensitive. The default is False."
  },
  {
    "objectID": "reference/starts_with.html#returns",
    "href": "reference/starts_with.html#returns",
    "title": "starts_with",
    "section": "Returns",
    "text": "Returns\n\n : StartsWith\n\nA StartsWith object, which can be used to select columns that start with the specified text."
  },
  {
    "objectID": "reference/starts_with.html#relevant-validation-methods-where-starts_with-can-be-used",
    "href": "reference/starts_with.html#relevant-validation-methods-where-starts_with-can-be-used",
    "title": "starts_with",
    "section": "Relevant Validation Methods where starts_with() can be Used",
    "text": "Relevant Validation Methods where starts_with() can be Used\nThis selector function can be used in the columns= argument of the following validation methods:\n\ncol_vals_gt()\ncol_vals_lt()\ncol_vals_ge()\ncol_vals_le()\ncol_vals_eq()\ncol_vals_ne()\ncol_vals_between()\ncol_vals_outside()\ncol_vals_in_set()\ncol_vals_not_in_set()\ncol_vals_increasing()\ncol_vals_decreasing()\ncol_vals_null()\ncol_vals_not_null()\ncol_vals_regex()\ncol_vals_within_spec()\ncol_exists()\n\nThe starts_with() selector function doesn’t need to be used in isolation. Read the next section for information on how to compose it with other column selectors for more refined ways to select columns."
  },
  {
    "objectID": "reference/starts_with.html#additional-flexibilty-through-composition-with-other-column-selectors",
    "href": "reference/starts_with.html#additional-flexibilty-through-composition-with-other-column-selectors",
    "title": "starts_with",
    "section": "Additional Flexibilty through Composition with Other Column Selectors",
    "text": "Additional Flexibilty through Composition with Other Column Selectors\nThe starts_with() function can be composed with other column selectors to create fine-grained column selections. For example, to select columns that start with \"a\" and end with \"e\", you can use the starts_with() and ends_with() functions together. The only condition is that the expressions are wrapped in the col() function, like this:\ncol(starts_with(\"a\") & ends_with(\"e\"))\nThere are four operators that can be used to compose column selectors:\n\n& (and)\n| (or)\n- (difference)\n~ (not)\n\nThe & operator is used to select columns that satisfy both conditions. The | operator is used to select columns that satisfy either condition. The - operator is used to select columns that satisfy the first condition but not the second. The ~ operator is used to select columns that don’t satisfy the condition. As many selector functions can be used as needed and the operators can be combined to create complex column selection criteria (parentheses can be used to group conditions and control the order of evaluation)."
  },
  {
    "objectID": "reference/starts_with.html#examples",
    "href": "reference/starts_with.html#examples",
    "title": "starts_with",
    "section": "Examples",
    "text": "Examples\nSuppose we have a table with columns name, paid_2021, paid_2022, and person_id and we’d like to validate that the values in columns that start with \"paid\" are greater than 10. We can use the starts_with() column selector function to specify the columns that start with \"paid\" as the columns to validate.\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n        \"paid_2021\": [16.32, 16.25, 15.75],\n        \"paid_2022\": [18.62, 16.95, 18.25],\n        \"person_id\": [\"A123\", \"B456\", \"C789\"],\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(columns=pb.starts_with(\"paid\"), value=10)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    paid_2021\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    paid_2022\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nFrom the results of the validation table we get two validation steps, one for paid_2021 and one for paid_2022. The values in both columns were all greater than 10.\nWe can also use the starts_with() function in combination with other column selectors (within col()) to create more complex column selection criteria (i.e., to select columns that satisfy multiple conditions). For example, to select columns that start with \"paid\" and match the text \"2023\" or \"2024\", we can use the & operator to combine column selectors.\n\ntbl = pl.DataFrame(\n    {\n        \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n        \"hours_2022\": [160, 180, 160],\n        \"hours_2023\": [182, 168, 175],\n        \"hours_2024\": [200, 165, 190],\n        \"paid_2022\": [18.62, 16.95, 18.25],\n        \"paid_2023\": [19.29, 17.75, 18.35],\n        \"paid_2024\": [20.73, 18.35, 20.10],\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(\n        columns=pb.col(pb.starts_with(\"paid\") & pb.matches(\"23|24\")),\n        value=10\n    )\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    paid_2023\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    paid_2024\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nFrom the results of the validation table we get two validation steps, one for paid_2023 and one for paid_2024."
  },
  {
    "objectID": "reference/get_column_count.html",
    "href": "reference/get_column_count.html",
    "title": "get_column_count",
    "section": "",
    "text": "get_column_count(data)\nGet the number of columns in a table.\nThe get_column_count() function returns the number of columns in a table. The function works with any table that is supported by the pointblank library, including Pandas, Polars, and Ibis backend tables (e.g., DuckDB, MySQL, PostgreSQL, SQLite, Parquet, etc.). It also supports direct input of CSV files, Parquet files, and database connection strings."
  },
  {
    "objectID": "reference/get_column_count.html#parameters",
    "href": "reference/get_column_count.html#parameters",
    "title": "get_column_count",
    "section": "Parameters",
    "text": "Parameters\n\ndata : FrameT | Any\n\nThe table for which to get the column count, which could be a DataFrame object, an Ibis table object, a CSV file path, a Parquet file path, or a database connection string. Read the Supported Input Table Types section for details on the supported table types."
  },
  {
    "objectID": "reference/get_column_count.html#returns",
    "href": "reference/get_column_count.html#returns",
    "title": "get_column_count",
    "section": "Returns",
    "text": "Returns\n\n : int\n\nThe number of columns in the table."
  },
  {
    "objectID": "reference/get_column_count.html#supported-input-table-types",
    "href": "reference/get_column_count.html#supported-input-table-types",
    "title": "get_column_count",
    "section": "Supported Input Table Types",
    "text": "Supported Input Table Types\nThe data= parameter can be given any of the following table types:\n\nPolars DataFrame (\"polars\")\nPandas DataFrame (\"pandas\")\nPySpark table (\"pyspark\")\nDuckDB table (\"duckdb\")*\nMySQL table (\"mysql\")*\nPostgreSQL table (\"postgresql\")*\nSQLite table (\"sqlite\")*\nMicrosoft SQL Server table (\"mssql\")*\nSnowflake table (\"snowflake\")*\nDatabricks table (\"databricks\")*\nBigQuery table (\"bigquery\")*\nParquet table (\"parquet\")*\nCSV files (string path or pathlib.Path object with .csv extension)\nParquet files (string path, pathlib.Path object, glob pattern, directory with .parquet extension, or partitioned dataset)\nDatabase connection strings (URI format with optional table specification)\n\nThe table types marked with an asterisk need to be prepared as Ibis tables (with type of ibis.expr.types.relations.Table). Furthermore, using get_column_count() with these types of tables requires the Ibis library (v9.5.0 or above) to be installed. If the input table is a Polars or Pandas DataFrame, the availability of Ibis is not needed.\nTo use a CSV file, ensure that a string or pathlib.Path object with a .csv extension is provided. The file will be automatically detected and loaded using the best available DataFrame library. The loading preference is Polars first, then Pandas as a fallback.\nGitHub URLs pointing to CSV or Parquet files are automatically detected and converted to raw content URLs for downloading. The URL format should be: https://github.com/user/repo/blob/branch/path/file.csv or https://github.com/user/repo/blob/branch/path/file.parquet\nConnection strings follow database URL formats and must also specify a table using the ::table_name suffix. Examples include:\n\"duckdb:///path/to/database.ddb::table_name\"\n\"sqlite:///path/to/database.db::table_name\"\n\"postgresql://user:password@localhost:5432/database::table_name\"\n\"mysql://user:password@localhost:3306/database::table_name\"\n\"bigquery://project/dataset::table_name\"\n\"snowflake://user:password@account/database/schema::table_name\"\nWhen using connection strings, the Ibis library with the appropriate backend driver is required."
  },
  {
    "objectID": "reference/get_column_count.html#examples",
    "href": "reference/get_column_count.html#examples",
    "title": "get_column_count",
    "section": "Examples",
    "text": "Examples\nTo get the number of columns in a table, we can use the get_column_count() function. Here’s an example using the small_table dataset (itself loaded using the load_dataset() function):\n\nimport pointblank as pb\n\nsmall_table_polars = pb.load_dataset(\"small_table\")\n\npb.get_column_count(small_table_polars)\n\n8\n\n\nThis table is a Polars DataFrame, but the get_column_count() function works with any table supported by pointblank, including Pandas DataFrames and Ibis backend tables. Here’s an example using a DuckDB table handled by Ibis:\n\nsmall_table_duckdb = pb.load_dataset(\"small_table\", tbl_type=\"duckdb\")\n\npb.get_column_count(small_table_duckdb)\n\n8\n\n\n\nWorking with CSV Files\nThe get_column_count() function can directly accept CSV file paths:\n\n# Get a path to a CSV file from the package data\ncsv_path = pb.get_data_path(\"global_sales\", \"csv\")\n\npb.get_column_count(csv_path)\n\n20\n\n\n\n\nWorking with Parquet Files\nThe function supports various Parquet input formats:\n\n# Single Parquet file from package data\nparquet_path = pb.get_data_path(\"nycflights\", \"parquet\")\n\npb.get_column_count(parquet_path)\n\n18\n\n\nYou can also use glob patterns and directories:\n# Multiple Parquet files with glob patterns\npb.get_column_count(\"data/sales_*.parquet\")\n\n# Directory containing Parquet files\npb.get_column_count(\"parquet_data/\")\n\n# Partitioned Parquet dataset\npb.get_column_count(\"sales_data/\")  # Auto-discovers partition columns\n\n\nWorking with Database Connection Strings\nThe function supports database connection strings for direct access to database tables:\n\n# Get path to a DuckDB database file from package data\nduckdb_path = pb.get_data_path(\"game_revenue\", \"duckdb\")\n\npb.get_column_count(f\"duckdb:///{duckdb_path}::game_revenue\")\n\n11\n\n\nThe function always returns the number of columns in the table as an integer value, which is 8 for the small_table dataset."
  },
  {
    "objectID": "reference/Validate.col_vals_lt.html",
    "href": "reference/Validate.col_vals_lt.html",
    "title": "Validate.col_vals_lt",
    "section": "",
    "text": "Validate.col_vals_lt(\n    columns,\n    value,\n    na_pass=False,\n    pre=None,\n    segments=None,\n    thresholds=None,\n    actions=None,\n    brief=None,\n    active=True,\n)\nAre column data less than a fixed value or data in another column?\nThe col_vals_lt() validation method checks whether column values in a table are less than a specified value= (the exact comparison used in this function is col_val &lt; value). The value= can be specified as a single, literal value or as a column name given in col(). This validation will operate over the number of test units that is equal to the number of rows in the table (determined after any pre= mutation has been applied)."
  },
  {
    "objectID": "reference/Validate.col_vals_lt.html#parameters",
    "href": "reference/Validate.col_vals_lt.html#parameters",
    "title": "Validate.col_vals_lt",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns : str | list[str] | Column | ColumnSelector | ColumnSelectorNarwhals\n\nA single column or a list of columns to validate. Can also use col() with column selectors to specify one or more columns. If multiple columns are supplied or resolved, there will be a separate validation step generated for each column.\n\nvalue : float | int | Column\n\nThe value to compare against. This can be a single value or a single column name given in col(). The latter option allows for a column-to-column comparison. For more information on which types of values are allowed, see the What Can Be Used in value=? section.\n\nna_pass : bool = False\n\nShould any encountered None, NA, or Null values be considered as passing test units? By default, this is False. Set to True to pass test units with missing values.\n\npre : Callable | None = None\n\nAn optional preprocessing function or lambda to apply to the data table during interrogation. This function should take a table as input and return a modified table. Have a look at the Preprocessing section for more information on how to use this argument.\n\nsegments : SegmentSpec | None = None\n\nAn optional directive on segmentation, which serves to split a validation step into multiple (one step per segment). Can be a single column name, a tuple that specifies a column name and its corresponding values to segment on, or a combination of both (provided as a list). Read the Segmentation section for usage information.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nSet threshold failure levels for reporting and reacting to exceedences of the levels. The thresholds are set at the step level and will override any global thresholds set in Validate(thresholds=...). The default is None, which means that no thresholds will be set locally and global thresholds (if any) will take effect. Look at the Thresholds section for information on how to set threshold levels.\n\nactions : Actions | None = None\n\nOptional actions to take when the validation step(s) meets or exceeds any set threshold levels. If provided, the Actions class should be used to define the actions.\n\nbrief : str | bool | None = None\n\nAn optional brief description of the validation step that will be displayed in the reporting table. You can use the templating elements like \"{step}\" to insert the step number, or \"{auto}\" to include an automatically generated brief. If True the entire brief will be automatically generated. If None (the default) then there won’t be a brief.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.col_vals_lt.html#returns",
    "href": "reference/Validate.col_vals_lt.html#returns",
    "title": "Validate.col_vals_lt",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.col_vals_lt.html#what-can-be-used-in-value",
    "href": "reference/Validate.col_vals_lt.html#what-can-be-used-in-value",
    "title": "Validate.col_vals_lt",
    "section": "What Can Be Used in value=?",
    "text": "What Can Be Used in value=?\nThe value= argument allows for a variety of input types. The most common are:\n\na single numeric value\na single date or datetime value\nA col() object that represents a column name\n\nWhen supplying a number as the basis of comparison, keep in mind that all resolved columns must also be numeric. Should you have columns that are of the date or datetime types, you can supply a date or datetime value as the value= argument. There is flexibility in how you provide the date or datetime value, as it can be:\n\na string-based date or datetime (e.g., \"2023-10-01\", \"2023-10-01 13:45:30\", etc.)\na date or datetime object using the datetime module (e.g., datetime.date(2023, 10, 1), datetime.datetime(2023, 10, 1, 13, 45, 30), etc.)\n\nFinally, when supplying a column name in the value= argument, it must be specified within col(). This is a column-to-column comparison and, crucially, the columns being compared must be of the same type (e.g., both numeric, both date, etc.)."
  },
  {
    "objectID": "reference/Validate.col_vals_lt.html#preprocessing",
    "href": "reference/Validate.col_vals_lt.html#preprocessing",
    "title": "Validate.col_vals_lt",
    "section": "Preprocessing",
    "text": "Preprocessing\nThe pre= argument allows for a preprocessing function or lambda to be applied to the data table during interrogation. This function should take a table as input and return a modified table. This is useful for performing any necessary transformations or filtering on the data before the validation step is applied.\nThe preprocessing function can be any callable that takes a table as input and returns a modified table. For example, you could use a lambda function to filter the table based on certain criteria or to apply a transformation to the data. Note that you can refer to columns via columns= and value=col(...) that are expected to be present in the transformed table, but may not exist in the table before preprocessing. Regarding the lifetime of the transformed table, it only exists during the validation step and is not stored in the Validate object or used in subsequent validation steps."
  },
  {
    "objectID": "reference/Validate.col_vals_lt.html#segmentation",
    "href": "reference/Validate.col_vals_lt.html#segmentation",
    "title": "Validate.col_vals_lt",
    "section": "Segmentation",
    "text": "Segmentation\nThe segments= argument allows for the segmentation of a validation step into multiple segments. This is useful for applying the same validation step to different subsets of the data. The segmentation can be done based on a single column or specific fields within a column.\nProviding a single column name will result in a separate validation step for each unique value in that column. For example, if you have a column called \"region\" with values \"North\", \"South\", and \"East\", the validation step will be applied separately to each region.\nAlternatively, you can provide a tuple that specifies a column name and its corresponding values to segment on. For example, if you have a column called \"date\" and you want to segment on only specific dates, you can provide a tuple like (\"date\", [\"2023-01-01\", \"2023-01-02\"]). Any other values in the column will be disregarded (i.e., no validation steps will be created for them).\nA list with a combination of column names and tuples can be provided as well. This allows for more complex segmentation scenarios. The following inputs are both valid:\n# Segments from all unique values in the `region` column\n# and specific dates in the `date` column\nsegments=[\"region\", (\"date\", [\"2023-01-01\", \"2023-01-02\"])]\n\n# Segments from all unique values in the `region` and `date` columns\nsegments=[\"region\", \"date\"]\nThe segmentation is performed during interrogation, and the resulting validation steps will be numbered sequentially. Each segment will have its own validation step, and the results will be reported separately. This allows for a more granular analysis of the data and helps identify issues within specific segments.\nImportantly, the segmentation process will be performed after any preprocessing of the data table. Because of this, one can conceivably use the pre= argument to generate a column that can be used for segmentation. For example, you could create a new column called \"segment\" through use of pre= and then use that column for segmentation."
  },
  {
    "objectID": "reference/Validate.col_vals_lt.html#thresholds",
    "href": "reference/Validate.col_vals_lt.html#thresholds",
    "title": "Validate.col_vals_lt",
    "section": "Thresholds",
    "text": "Thresholds\nThe thresholds= parameter is used to set the failure-condition levels for the validation step. If they are set here at the step level, these thresholds will override any thresholds set at the global level in Validate(thresholds=...).\nThere are three threshold levels: ‘warning’, ‘error’, and ‘critical’. The threshold values can either be set as a proportion failing of all test units (a value between 0 to 1), or, the absolute number of failing test units (as integer that’s 1 or greater).\nThresholds can be defined using one of these input schemes:\n\nuse the Thresholds class (the most direct way to create thresholds)\nprovide a tuple of 1-3 values, where position 0 is the ‘warning’ level, position 1 is the ‘error’ level, and position 2 is the ‘critical’ level\ncreate a dictionary of 1-3 value entries; the valid keys: are ‘warning’, ‘error’, and ‘critical’\na single integer/float value denoting absolute number or fraction of failing test units for the ‘warning’ level only\n\nIf the number of failing test units exceeds set thresholds, the validation step will be marked as ‘warning’, ‘error’, or ‘critical’. All of the threshold levels don’t need to be set, you’re free to set any combination of them.\nAside from reporting failure conditions, thresholds can be used to determine the actions to take for each level of failure (using the actions= parameter)."
  },
  {
    "objectID": "reference/Validate.col_vals_lt.html#examples",
    "href": "reference/Validate.col_vals_lt.html#examples",
    "title": "Validate.col_vals_lt",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with three numeric columns (a, b, and c). The table is shown below:\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [5, 6, 5, 9, 7, 5],\n        \"b\": [1, 2, 1, 2, 2, 2],\n        \"c\": [2, 1, 1, 4, 3, 4],\n    }\n)\n\npb.preview(tbl)\n\n\n\n\n\n  \n  \n  \n  \n\n\n\n\n\n  \n  aInt64\n  bInt64\n  cInt64\n\n\n\n  \n    1\n    5\n    1\n    2\n  \n  \n    2\n    6\n    2\n    1\n  \n  \n    3\n    5\n    1\n    1\n  \n  \n    4\n    9\n    2\n    4\n  \n  \n    5\n    7\n    2\n    3\n  \n  \n    6\n    5\n    2\n    4\n  \n\n\n\n\n\n\n        \n\n\nLet’s validate that values in column a are all less than the value of 10. We’ll determine if this validation had any failing test units (there are six test units, one for each row).\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_lt(columns=\"a\", value=10)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    a\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    61.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nPrinting the validation object shows the validation table in an HTML viewing environment. The validation table shows the single entry that corresponds to the validation step created by using col_vals_lt(). All test units passed, and there are no failing test units.\nAside from checking a column against a literal value, we can also use a column name in the value= argument (with the helper function col() to perform a column-to-column comparison. For the next example, we’ll use col_vals_lt() to check whether the values in column b are less than values in column c.\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_lt(columns=\"b\", value=pb.col(\"c\"))\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    b\n    c\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    40.67\n    20.33\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe validation table reports two failing test units. The specific failing cases are:\n\nRow 1: b is 2 and c is 1.\nRow 2: b is 1 and c is 1."
  },
  {
    "objectID": "reference/Schema.html",
    "href": "reference/Schema.html",
    "title": "Schema",
    "section": "",
    "text": "Schema(columns=None, tbl=None, **kwargs)\nDefinition of a schema object.\nThe schema object defines the structure of a table. Once it is defined, the object can be used in a validation workflow, using Validate and its methods, to ensure that the structure of a table matches the expected schema. The validation method that works with the schema object is called col_schema_match().\nA schema for a table can be constructed with the Schema class in a number of ways:\nThe schema object can also be constructed by providing a DataFrame or Ibis table object (using the tbl= parameter) and the schema will be collected from either type of object. The schema object can be printed to display the column names and dtypes. Note that if tbl= is provided then there shouldn’t be any other inputs provided through either columns= or **kwargs."
  },
  {
    "objectID": "reference/Schema.html#parameters",
    "href": "reference/Schema.html#parameters",
    "title": "Schema",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns : str | list[str] | list[tuple[str, str]] | list[tuple[str]] | dict[str, str] | None = None\n\nA list of strings (representing column names), a list of tuples (for column names and column dtypes), or a dictionary containing column and dtype information. If any of these inputs are provided here, it will take precedence over any column arguments provided via **kwargs.\n\ntbl : any | None = None\n\nA DataFrame (Polars or Pandas) or an Ibis table object from which the schema will be collected. Read the Supported Input Table Types section for details on the supported table types.\n\n****kwargs** :  = {}\n\nIndividual column arguments that are in the form of column=dtype or column=[dtype1, dtype2, ...]. These will be ignored if the columns= parameter is not None."
  },
  {
    "objectID": "reference/Schema.html#returns",
    "href": "reference/Schema.html#returns",
    "title": "Schema",
    "section": "Returns",
    "text": "Returns\n\n : Schema\n\nA schema object."
  },
  {
    "objectID": "reference/Schema.html#supported-input-table-types",
    "href": "reference/Schema.html#supported-input-table-types",
    "title": "Schema",
    "section": "Supported Input Table Types",
    "text": "Supported Input Table Types\nThe tbl= parameter, if used, can be given any of the following table types:\n\nPolars DataFrame (\"polars\")\nPandas DataFrame (\"pandas\")\nPySpark table (\"pyspark\")\nDuckDB table (\"duckdb\")*\nMySQL table (\"mysql\")*\nPostgreSQL table (\"postgresql\")*\nSQLite table (\"sqlite\")*\nMicrosoft SQL Server table (\"mssql\")*\nSnowflake table (\"snowflake\")*\nDatabricks table (\"databricks\")*\nBigQuery table (\"bigquery\")*\nParquet table (\"parquet\")*\n\nThe table types marked with an asterisk need to be prepared as Ibis tables (with type of ibis.expr.types.relations.Table). Furthermore, using Schema(tbl=) with these types of tables requires the Ibis library (v9.5.0 or above) to be installed. If the input table is a Polars or Pandas DataFrame, the availability of Ibis is not needed."
  },
  {
    "objectID": "reference/Schema.html#additional-notes-on-schema-construction",
    "href": "reference/Schema.html#additional-notes-on-schema-construction",
    "title": "Schema",
    "section": "Additional Notes on Schema Construction",
    "text": "Additional Notes on Schema Construction\nWhile there is flexibility in how a schema can be constructed, there is the potential for some confusion. So let’s go through each of the methods of constructing a schema in more detail and single out some important points.\nWhen providing a list of column names to columns=, a col_schema_match() validation step will only check the column names. Any arguments pertaining to dtypes will be ignored.\nWhen using a list of tuples in columns=, the tuples could contain the column name and dtype or just the column name. This construction allows for more flexibility in constructing the schema as some columns will be checked for dtypes and others will not. This method is the only way to have mixed checks of column names and dtypes in col_schema_match().\nWhen providing a dictionary to columns=, the keys are the column names and the values are the dtypes. This method of input is useful in those cases where you might already have a dictionary of column names and dtypes that you want to use as the schema.\nIf using individual column arguments in the form of keyword arguments, the column names are the keyword arguments and the dtypes are the values. This method emphasizes readability and is perhaps more convenient when manually constructing a schema with a small number of columns.\nFinally, multiple dtypes can be provided for a single column by providing a list or tuple of dtypes in place of a scalar string value. Having multiple dtypes for a column allows for the dtype check via col_schema_match() to make multiple attempts at matching the column dtype. Should any of the dtypes match the column dtype, that part of the schema check will pass. Here are some examples of how you could provide single and multiple dtypes for a column:\n# list of tuples\nschema_1 = pb.Schema(columns=[(\"name\", \"String\"), (\"age\", [\"Float64\", \"Int64\"])])\n\n# dictionary\nschema_2 = pb.Schema(columns={\"name\": \"String\", \"age\": [\"Float64\", \"Int64\"]})\n\n# keyword arguments\nschema_3 = pb.Schema(name=\"String\", age=[\"Float64\", \"Int64\"])\nAll of the above examples will construct the same schema object."
  },
  {
    "objectID": "reference/Schema.html#examples",
    "href": "reference/Schema.html#examples",
    "title": "Schema",
    "section": "Examples",
    "text": "Examples\nA schema can be constructed via the Schema class in multiple ways. Let’s use the following Polars DataFrame as a basis for constructing a schema:\n\nimport pointblank as pb\nimport polars as pl\n\ndf = pl.DataFrame({\n    \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n    \"age\": [25, 30, 35],\n    \"height\": [5.6, 6.0, 5.8]\n})\n\nYou could provide Schema(columns=) a list of tuples containing column names and data types:\n\nschema = pb.Schema(columns=[(\"name\", \"String\"), (\"age\", \"Int64\"), (\"height\", \"Float64\")])\n\nAlternatively, a dictionary containing column names and dtypes also works:\n\nschema = pb.Schema(columns={\"name\": \"String\", \"age\": \"Int64\", \"height\": \"Float64\"})\n\nAnother input method involves using individual column arguments in the form of keyword arguments:\n\nschema = pb.Schema(name=\"String\", age=\"Int64\", height=\"Float64\")\n\nFinally, could also provide a DataFrame (Polars and Pandas) or an Ibis table object to tbl= and the schema will be collected:\nschema = pb.Schema(tbl=df)\nWhichever method you choose, you can verify the schema inputs by printing the schema object:\n\nprint(schema)\n\nPointblank Schema\n  name: String\n  age: Int64\n  height: Float64\n\n\nThe Schema object can be used to validate the structure of a table against the schema. The relevant Validate method for this is col_schema_match(). In a validation workflow, you’ll have a target table (defined at the beginning of the workflow) and you might want to ensure that your expectations of the table structure are met. The col_schema_match() method works with a Schema object to validate the structure of the table. Here’s an example of how you could use col_schema_match() in a validation workflow:\n\n# Define the schema\nschema = pb.Schema(name=\"String\", age=\"Int64\", height=\"Float64\")\n\n# Define a validation that checks the schema against the table (`df`)\nvalidation = (\n    pb.Validate(data=df)\n    .col_schema_match(schema=schema)\n    .interrogate()\n)\n\n# Display the validation results\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_schema_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            col_schema_match()\n        \n        \n        \n    —\n    SCHEMA\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe col_schema_match() validation method will validate the structure of the table against the schema during interrogation. If the structure of the table does not match the schema, the single test unit will fail. In this case, the defined schema matched the structure of the table, so the validation passed.\nWe can also choose to check only the column names of the target table. This can be done by providing a simplified Schema object, which is given a list of column names:\n\nschema = pb.Schema(columns=[\"name\", \"age\", \"height\"])\n\nvalidation = (\n    pb.Validate(data=df)\n    .col_schema_match(schema=schema)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_schema_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            col_schema_match()\n        \n        \n        \n    —\n    SCHEMA\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nIn this case, the schema only checks the column names of the table against the schema during interrogation. If the column names of the table do not match the schema, the single test unit will fail. In this case, the defined schema matched the column names of the table, so the validation passed.\nIf you wanted to check column names and dtypes only for a subset of columns (and just the column names for the rest), you could use a list of mixed one- or two-item tuples in columns=:\n\nschema = pb.Schema(columns=[(\"name\", \"String\"), (\"age\", ), (\"height\", )])\n\nvalidation = (\n    pb.Validate(data=df)\n    .col_schema_match(schema=schema)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_schema_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            col_schema_match()\n        \n        \n        \n    —\n    SCHEMA\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nNot specifying a dtype for a column (as is the case for the age and height columns in the above example) will only check the column name.\nThere may also be the case where you want to check the column names and specify multiple dtypes for a column to have several attempts at matching the dtype. This can be done by providing a list of dtypes where there would normally be a single dtype:\n\nschema = pb.Schema(\n  columns=[(\"name\", \"String\"), (\"age\", [\"Float64\", \"Int64\"]), (\"height\", \"Float64\")]\n)\n\nvalidation = (\n    pb.Validate(data=df)\n    .col_schema_match(schema=schema)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_schema_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            col_schema_match()\n        \n        \n        \n    —\n    SCHEMA\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nFor the age column, the schema will check for both Float64 and Int64 dtypes. If either of these dtypes is found in the column, the portion of the schema check will succeed."
  },
  {
    "objectID": "reference/Schema.html#see-also",
    "href": "reference/Schema.html#see-also",
    "title": "Schema",
    "section": "See Also",
    "text": "See Also\nThe col_schema_match() validation method, where a Schema object is used in a validation workflow."
  },
  {
    "objectID": "reference/matches.html",
    "href": "reference/matches.html",
    "title": "matches",
    "section": "",
    "text": "matches(pattern, case_sensitive=False)\nSelect columns that match a specified regular expression pattern.\nMany validation methods have a columns= argument that can be used to specify the columns for validation (e.g., col_vals_gt(), col_vals_regex(), etc.). The matches() selector function can be used to select one or more columns matching a provided regular expression pattern. So if the set of table columns consists of\n[rev_01, rev_02, profit_01, profit_02, age]\nand you want to validate columns that have two digits at the end of the name, you can use columns=matches(r\"[0-9]{2}$\"). This will select the rev_01, rev_02, profit_01, and profit_02 columns.\nThere will be a validation step created for every resolved column. Note that if there aren’t any columns resolved from using matches() (or any other expression using selector functions), the validation step will fail to be evaluated during the interrogation process. Such a failure to evaluate will be reported in the validation results but it won’t affect the interrogation process overall (i.e., the process won’t be halted)."
  },
  {
    "objectID": "reference/matches.html#parameters",
    "href": "reference/matches.html#parameters",
    "title": "matches",
    "section": "Parameters",
    "text": "Parameters\n\npattern : str\n\nThe regular expression pattern that the column name should match.\n\ncase_sensitive : bool = False\n\nWhether column names should be treated as case-sensitive. The default is False."
  },
  {
    "objectID": "reference/matches.html#returns",
    "href": "reference/matches.html#returns",
    "title": "matches",
    "section": "Returns",
    "text": "Returns\n\n : Matches\n\nA Matches object, which can be used to select columns that match the specified pattern."
  },
  {
    "objectID": "reference/matches.html#relevant-validation-methods-where-matches-can-be-used",
    "href": "reference/matches.html#relevant-validation-methods-where-matches-can-be-used",
    "title": "matches",
    "section": "Relevant Validation Methods where matches() can be Used",
    "text": "Relevant Validation Methods where matches() can be Used\nThis selector function can be used in the columns= argument of the following validation methods:\n\ncol_vals_gt()\ncol_vals_lt()\ncol_vals_ge()\ncol_vals_le()\ncol_vals_eq()\ncol_vals_ne()\ncol_vals_between()\ncol_vals_outside()\ncol_vals_in_set()\ncol_vals_not_in_set()\ncol_vals_increasing()\ncol_vals_decreasing()\ncol_vals_null()\ncol_vals_not_null()\ncol_vals_regex()\ncol_vals_within_spec()\ncol_exists()\n\nThe matches() selector function doesn’t need to be used in isolation. Read the next section for information on how to compose it with other column selectors for more refined ways to select columns."
  },
  {
    "objectID": "reference/matches.html#additional-flexibilty-through-composition-with-other-column-selectors",
    "href": "reference/matches.html#additional-flexibilty-through-composition-with-other-column-selectors",
    "title": "matches",
    "section": "Additional Flexibilty through Composition with Other Column Selectors",
    "text": "Additional Flexibilty through Composition with Other Column Selectors\nThe matches() function can be composed with other column selectors to create fine-grained column selections. For example, to select columns that have the text starting with five digits and end with \"_id\", you can use the matches() and ends_with() functions together. The only condition is that the expressions are wrapped in the col() function, like this:\ncol(matches(r\"^[0-9]{5}\") & ends_with(\"_id\"))\nThere are four operators that can be used to compose column selectors:\n\n& (and)\n| (or)\n- (difference)\n~ (not)\n\nThe & operator is used to select columns that satisfy both conditions. The | operator is used to select columns that satisfy either condition. The - operator is used to select columns that satisfy the first condition but not the second. The ~ operator is used to select columns that don’t satisfy the condition. As many selector functions can be used as needed and the operators can be combined to create complex column selection criteria (parentheses can be used to group conditions and control the order of evaluation)."
  },
  {
    "objectID": "reference/matches.html#examples",
    "href": "reference/matches.html#examples",
    "title": "matches",
    "section": "Examples",
    "text": "Examples\nSuppose we have a table with columns name, id_old, new_identifier, and pay_2021 and we’d like to validate that text values in columns having \"id\" or \"identifier\" in the name have a specific syntax. We can use the matches() column selector function to specify the columns that match the pattern.\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n        \"id_old\": [\"ID0021\", \"ID0032\", \"ID0043\"],\n        \"new_identifier\": [\"ID9054\", \"ID9065\", \"ID9076\"],\n        \"pay_2021\": [16.32, 16.25, 15.75],\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_regex(columns=pb.matches(\"id|identifier\"), pattern=r\"ID[0-9]{4}\")\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    id_old\n    ID[0-9]{4}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    new_identifier\n    ID[0-9]{4}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nFrom the results of the validation table we get two validation steps, one for id_old and one for new_identifier. The values in both columns all match the pattern \"ID[0-9]{4}\".\nWe can also use the matches() function in combination with other column selectors (within col()) to create more complex column selection criteria (i.e., to select columns that satisfy multiple conditions). For example, to select columns that contain \"pay\" and match the text \"2023\" or \"2024\", we can use the & operator to combine column selectors.\n\ntbl = pl.DataFrame(\n    {\n        \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n        \"2022_hours\": [160, 180, 160],\n        \"2023_hours\": [182, 168, 175],\n        \"2024_hours\": [200, 165, 190],\n        \"2022_pay_total\": [18.62, 16.95, 18.25],\n        \"2023_pay_total\": [19.29, 17.75, 18.35],\n        \"2024_pay_total\": [20.73, 18.35, 20.10],\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(\n        columns=pb.col(pb.contains(\"pay\") & pb.matches(\"2023|2024\")),\n        value=10\n    )\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    2023_pay_total\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    2024_pay_total\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nFrom the results of the validation table we get two validation steps, one for 2023_pay_total and one for 2024_pay_total."
  },
  {
    "objectID": "reference/Validate.conjointly.html",
    "href": "reference/Validate.conjointly.html",
    "title": "Validate.conjointly",
    "section": "",
    "text": "Validate.conjointly(\n    *exprs,\n    pre=None,\n    thresholds=None,\n    actions=None,\n    brief=None,\n    active=True,\n)\nPerform multiple row-wise validations for joint validity.\nThe conjointly() validation method checks whether each row in the table passes multiple validation conditions simultaneously. This enables compound validation logic where a test unit (typically a row) must satisfy all specified conditions to pass the validation.\nThis method accepts multiple validation expressions as callables, which should return boolean expressions when applied to the data. You can use lambdas that incorporate Polars/Pandas/Ibis expressions (based on the target table type) or create more complex validation functions. The validation will operate over the number of test units that is equal to the number of rows in the table (determined after any pre= mutation has been applied)."
  },
  {
    "objectID": "reference/Validate.conjointly.html#parameters",
    "href": "reference/Validate.conjointly.html#parameters",
    "title": "Validate.conjointly",
    "section": "Parameters",
    "text": "Parameters\n\n*exprs : Callable = ()\n\nMultiple validation expressions provided as callable functions. Each callable should accept a table as its single argument and return a boolean expression or Series/Column that evaluates to boolean values for each row.\n\npre : Callable | None = None\n\nAn optional preprocessing function or lambda to apply to the data table during interrogation. This function should take a table as input and return a modified table. Have a look at the Preprocessing section for more information on how to use this argument.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nSet threshold failure levels for reporting and reacting to exceedences of the levels. The thresholds are set at the step level and will override any global thresholds set in Validate(thresholds=...). The default is None, which means that no thresholds will be set locally and global thresholds (if any) will take effect. Look at the Thresholds section for information on how to set threshold levels.\n\nactions : Actions | None = None\n\nOptional actions to take when the validation step meets or exceeds any set threshold levels. If provided, the Actions class should be used to define the actions.\n\nbrief : str | bool | None = None\n\nAn optional brief description of the validation step that will be displayed in the reporting table. You can use the templating elements like \"{step}\" to insert the step number, or \"{auto}\" to include an automatically generated brief. If True the entire brief will be automatically generated. If None (the default) then there won’t be a brief.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.conjointly.html#returns",
    "href": "reference/Validate.conjointly.html#returns",
    "title": "Validate.conjointly",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.conjointly.html#preprocessing",
    "href": "reference/Validate.conjointly.html#preprocessing",
    "title": "Validate.conjointly",
    "section": "Preprocessing",
    "text": "Preprocessing\nThe pre= argument allows for a preprocessing function or lambda to be applied to the data table during interrogation. This function should take a table as input and return a modified table. This is useful for performing any necessary transformations or filtering on the data before the validation step is applied.\nThe preprocessing function can be any callable that takes a table as input and returns a modified table. For example, you could use a lambda function to filter the table based on certain criteria or to apply a transformation to the data. Regarding the lifetime of the transformed table, it only exists during the validation step and is not stored in the Validate object or used in subsequent validation steps."
  },
  {
    "objectID": "reference/Validate.conjointly.html#thresholds",
    "href": "reference/Validate.conjointly.html#thresholds",
    "title": "Validate.conjointly",
    "section": "Thresholds",
    "text": "Thresholds\nThe thresholds= parameter is used to set the failure-condition levels for the validation step. If they are set here at the step level, these thresholds will override any thresholds set at the global level in Validate(thresholds=...).\nThere are three threshold levels: ‘warning’, ‘error’, and ‘critical’. The threshold values can either be set as a proportion failing of all test units (a value between 0 to 1), or, the absolute number of failing test units (as integer that’s 1 or greater).\nThresholds can be defined using one of these input schemes:\n\nuse the Thresholds class (the most direct way to create thresholds)\nprovide a tuple of 1-3 values, where position 0 is the ‘warning’ level, position 1 is the ‘error’ level, and position 2 is the ‘critical’ level\ncreate a dictionary of 1-3 value entries; the valid keys: are ‘warning’, ‘error’, and ‘critical’\na single integer/float value denoting absolute number or fraction of failing test units for the ‘warning’ level only\n\nIf the number of failing test units exceeds set thresholds, the validation step will be marked as ‘warning’, ‘error’, or ‘critical’. All of the threshold levels don’t need to be set, you’re free to set any combination of them.\nAside from reporting failure conditions, thresholds can be used to determine the actions to take for each level of failure (using the actions= parameter)."
  },
  {
    "objectID": "reference/Validate.conjointly.html#examples",
    "href": "reference/Validate.conjointly.html#examples",
    "title": "Validate.conjointly",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with three numeric columns (a, b, and c). The table is shown below:\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [5, 7, 1, 3, 9, 4],\n        \"b\": [6, 3, 0, 5, 8, 2],\n        \"c\": [10, 4, 8, 9, 10, 5],\n    }\n)\n\npb.preview(tbl)\n\n\n\n\n\n  \n  \n  \n  \n\n\n\n\n\n  \n  aInt64\n  bInt64\n  cInt64\n\n\n\n  \n    1\n    5\n    6\n    10\n  \n  \n    2\n    7\n    3\n    4\n  \n  \n    3\n    1\n    0\n    8\n  \n  \n    4\n    3\n    5\n    9\n  \n  \n    5\n    9\n    8\n    10\n  \n  \n    6\n    4\n    2\n    5\n  \n\n\n\n\n\n\n        \n\n\nLet’s validate that the values in each row satisfy multiple conditions simultaneously:\n\nColumn a should be greater than 2\nColumn b should be less than 7\nThe sum of a and b should be less than the value in column c\n\nWe’ll use conjointly() to check all these conditions together:\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .conjointly(\n        lambda df: pl.col(\"a\") &gt; 2,\n        lambda df: pl.col(\"b\") &lt; 7,\n        lambda df: pl.col(\"a\") + pl.col(\"b\") &lt; pl.col(\"c\")\n    )\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    conjointly\n    \n        \n            \n            \n        \n    \n\n        \n        \n            conjointly()\n        \n        \n        \n    \n    COLUMN EXPR\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    10.17\n    50.83\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe validation table shows that not all rows satisfy all three conditions together. For a row to pass the conjoint validation, all three conditions must be true for that row.\nWe can also use preprocessing to filter the data before applying the conjoint validation:\n\n# Define preprocessing function for serialization compatibility\ndef filter_by_c_gt_5(df):\n    return df.filter(pl.col(\"c\") &gt; 5)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .conjointly(\n        lambda df: pl.col(\"a\") &gt; 2,\n        lambda df: pl.col(\"b\") &lt; 7,\n        lambda df: pl.col(\"a\") + pl.col(\"b\") &lt; pl.col(\"c\"),\n        pre=filter_by_c_gt_5\n    )\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    conjointly\n    \n        \n            \n            \n        \n    \n\n        \n        \n            conjointly()\n        \n        \n        \n    \n    COLUMN EXPR\n    \n    \n        \n            \n            \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    10.25\n    30.75\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThis allows for more complex validation scenarios where the data is first prepared and then validated against multiple conditions simultaneously.\nOr, you can use the backend-agnostic column expression helper expr_col() to write expressions that work across different table backends:\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [5, 7, 1, 3, 9, 4],\n        \"b\": [6, 3, 0, 5, 8, 2],\n        \"c\": [10, 4, 8, 9, 10, 5],\n    }\n)\n\n# Using backend-agnostic syntax with expr_col()\nvalidation = (\n    pb.Validate(data=tbl)\n    .conjointly(\n        lambda df: pb.expr_col(\"a\") &gt; 2,\n        lambda df: pb.expr_col(\"b\") &lt; 7,\n        lambda df: pb.expr_col(\"a\") + pb.expr_col(\"b\") &lt; pb.expr_col(\"c\")\n    )\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    conjointly\n    \n        \n            \n            \n        \n    \n\n        \n        \n            conjointly()\n        \n        \n        \n    \n    COLUMN EXPR\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    10.17\n    50.83\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nUsing expr_col() allows your validation code to work consistently across Pandas, Polars, and Ibis table backends without changes, making your validation pipelines more portable."
  },
  {
    "objectID": "reference/Validate.conjointly.html#see-also",
    "href": "reference/Validate.conjointly.html#see-also",
    "title": "Validate.conjointly",
    "section": "See Also",
    "text": "See Also\nLook at the documentation of the expr_col() function for more information on how to use it with different table backends."
  },
  {
    "objectID": "reference/Validate.col_vals_within_spec.html",
    "href": "reference/Validate.col_vals_within_spec.html",
    "title": "Validate.col_vals_within_spec",
    "section": "",
    "text": "Validate.col_vals_within_spec(\n    columns,\n    spec,\n    na_pass=False,\n    pre=None,\n    segments=None,\n    thresholds=None,\n    actions=None,\n    brief=None,\n    active=True,\n)\nValidate whether column values fit within a specification.\nThe col_vals_within_spec() validation method checks whether column values in a table correspond to a specification (spec=) type (details of which are available in the Specifications section). Specifications include common data types like email addresses, URLs, postal codes, vehicle identification numbers (VINs), International Bank Account Numbers (IBANs), and more. This validation will operate over the number of test units that is equal to the number of rows in the table."
  },
  {
    "objectID": "reference/Validate.col_vals_within_spec.html#parameters",
    "href": "reference/Validate.col_vals_within_spec.html#parameters",
    "title": "Validate.col_vals_within_spec",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns : str | list[str] | Column | ColumnSelector | ColumnSelectorNarwhals\n\nA single column or a list of columns to validate. Can also use col() with column selectors to specify one or more columns. If multiple columns are supplied or resolved, there will be a separate validation step generated for each column.\n\nspec : str\n\nA specification string for defining the specification type. Examples are \"email\", \"url\", and \"postal_code[USA]\". See the Specifications section for all available options.\n\nna_pass : bool = False\n\nShould any encountered None, NA, or Null values be considered as passing test units? By default, this is False. Set to True to pass test units with missing values.\n\npre : Callable | None = None\n\nAn optional preprocessing function or lambda to apply to the data table during interrogation. This function should take a table as input and return a modified table. Have a look at the Preprocessing section for more information on how to use this argument.\n\nsegments : SegmentSpec | None = None\n\nAn optional directive on segmentation, which serves to split a validation step into multiple (one step per segment). Can be a single column name, a tuple that specifies a column name and its corresponding values to segment on, or a combination of both (provided as a list). Read the Segmentation section for usage information.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nSet threshold failure levels for reporting and reacting to exceedences of the levels. The thresholds are set at the step level and will override any global thresholds set in Validate(thresholds=...). The default is None, which means that no thresholds will be set locally and global thresholds (if any) will take effect. Look at the Thresholds section for information on how to set threshold levels.\n\nactions : Actions | None = None\n\nOptional actions to take when the validation step(s) meets or exceeds any set threshold levels. If provided, the Actions class should be used to define the actions.\n\nbrief : str | bool | None = None\n\nAn optional brief description of the validation step that will be displayed in the reporting table. You can use the templating elements like \"{step}\" to insert the step number, or \"{auto}\" to include an automatically generated brief. If True the entire brief will be automatically generated. If None (the default) then there won’t be a brief.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.col_vals_within_spec.html#returns",
    "href": "reference/Validate.col_vals_within_spec.html#returns",
    "title": "Validate.col_vals_within_spec",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.col_vals_within_spec.html#specifications",
    "href": "reference/Validate.col_vals_within_spec.html#specifications",
    "title": "Validate.col_vals_within_spec",
    "section": "Specifications",
    "text": "Specifications\nA specification type must be used with the spec= argument. This is a string-based keyword that corresponds to the type of data in the specified columns. The following keywords can be used:\n\n\"isbn\": The International Standard Book Number (ISBN) is a unique numerical identifier for books. This keyword validates both 10-digit and 13-digit ISBNs.\n\"vin\": A vehicle identification number (VIN) is a unique code used by the automotive industry to identify individual motor vehicles.\n\"postal_code[&lt;country_code&gt;]\": A postal code (also known as postcodes, PIN, or ZIP codes) is a series of letters, digits, or both included in a postal address. Because the coding varies by country, a country code in either the 2-letter (ISO 3166-1 alpha-2) or 3-letter (ISO 3166-1 alpha-3) format needs to be supplied (e.g., \"postal_code[US]\" or \"postal_code[USA]\"). The keyword alias \"zip\" can be used for US ZIP codes.\n\"credit_card\": A credit card number can be validated across a variety of issuers. The validation uses the Luhn algorithm.\n\"iban[&lt;country_code&gt;]\": The International Bank Account Number (IBAN) is a system of identifying bank accounts across countries. Because the length and coding varies by country, a country code needs to be supplied (e.g., \"iban[DE]\" or \"iban[DEU]\").\n\"swift\": Business Identifier Codes (also known as SWIFT-BIC, BIC, or SWIFT code) are unique identifiers for financial and non-financial institutions.\n\"phone\", \"email\", \"url\", \"ipv4\", \"ipv6\", \"mac\": Phone numbers, email addresses, Internet URLs, IPv4 or IPv6 addresses, and MAC addresses can be validated with their respective keywords.\n\nOnly a single spec= value should be provided per function call."
  },
  {
    "objectID": "reference/Validate.col_vals_within_spec.html#preprocessing",
    "href": "reference/Validate.col_vals_within_spec.html#preprocessing",
    "title": "Validate.col_vals_within_spec",
    "section": "Preprocessing",
    "text": "Preprocessing\nThe pre= argument allows for a preprocessing function or lambda to be applied to the data table during interrogation. This function should take a table as input and return a modified table. This is useful for performing any necessary transformations or filtering on the data before the validation step is applied.\nThe preprocessing function can be any callable that takes a table as input and returns a modified table. For example, you could use a lambda function to filter the table based on certain criteria or to apply a transformation to the data. Note that you can refer to a column via columns= that is expected to be present in the transformed table, but may not exist in the table before preprocessing. Regarding the lifetime of the transformed table, it only exists during the validation step and is not stored in the Validate object or used in subsequent validation steps."
  },
  {
    "objectID": "reference/Validate.col_vals_within_spec.html#segmentation",
    "href": "reference/Validate.col_vals_within_spec.html#segmentation",
    "title": "Validate.col_vals_within_spec",
    "section": "Segmentation",
    "text": "Segmentation\nThe segments= argument allows for the segmentation of a validation step into multiple segments. This is useful for applying the same validation step to different subsets of the data. The segmentation can be done based on a single column or specific fields within a column.\nProviding a single column name will result in a separate validation step for each unique value in that column. For example, if you have a column called \"region\" with values \"North\", \"South\", and \"East\", the validation step will be applied separately to each region.\nAlternatively, you can provide a tuple that specifies a column name and its corresponding values to segment on. For example, if you have a column called \"date\" and you want to segment on only specific dates, you can provide a tuple like (\"date\", [\"2023-01-01\", \"2023-01-02\"]). Any other values in the column will be disregarded (i.e., no validation steps will be created for them).\nA list with a combination of column names and tuples can be provided as well. This allows for more complex segmentation scenarios. The following inputs are both valid:\n# Segments from all unique values in the `region` column\n# and specific dates in the `date` column\nsegments=[\"region\", (\"date\", [\"2023-01-01\", \"2023-01-02\"])]\n\n# Segments from all unique values in the `region` and `date` columns\nsegments=[\"region\", \"date\"]\nThe segmentation is performed during interrogation, and the resulting validation steps will be numbered sequentially. Each segment will have its own validation step, and the results will be reported separately. This allows for a more granular analysis of the data and helps identify issues within specific segments.\nImportantly, the segmentation process will be performed after any preprocessing of the data table. Because of this, one can conceivably use the pre= argument to generate a column that can be used for segmentation. For example, you could create a new column called \"segment\" through use of pre= and then use that column for segmentation."
  },
  {
    "objectID": "reference/Validate.col_vals_within_spec.html#thresholds",
    "href": "reference/Validate.col_vals_within_spec.html#thresholds",
    "title": "Validate.col_vals_within_spec",
    "section": "Thresholds",
    "text": "Thresholds\nThe thresholds= parameter is used to set the failure-condition levels for the validation step. If they are set here at the step level, these thresholds will override any thresholds set at the global level in Validate(thresholds=...).\nThere are three threshold levels: ‘warning’, ‘error’, and ‘critical’. The threshold values can either be set as a proportion failing of all test units (a value between 0 to 1), or, the absolute number of failing test units (as integer that’s 1 or greater).\nThresholds can be defined using one of these input schemes:\n\nuse the Thresholds class (the most direct way to create thresholds)\nprovide a tuple of 1-3 values, where position 0 is the ‘warning’ level, position 1 is the ‘error’ level, and position 2 is the ‘critical’ level\ncreate a dictionary of 1-3 value entries; the valid keys: are ‘warning’, ‘error’, and ‘critical’\na single integer/float value denoting absolute number or fraction of failing test units for the ‘warning’ level only\n\nIf the number of failing test units exceeds set thresholds, the validation step will be marked as ‘warning’, ‘error’, or ‘critical’. All of the threshold levels don’t need to be set, you’re free to set any combination of them.\nAside from reporting failure conditions, thresholds can be used to determine the actions to take for each level of failure (using the actions= parameter)."
  },
  {
    "objectID": "reference/Validate.col_vals_within_spec.html#examples",
    "href": "reference/Validate.col_vals_within_spec.html#examples",
    "title": "Validate.col_vals_within_spec",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with an email column. The table is shown below:\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"email\": [\n            \"user@example.com\",\n            \"admin@test.org\",\n            \"invalid-email\",\n            \"contact@company.co.uk\",\n        ],\n    }\n)\n\npb.preview(tbl)\n\n\n\n\n\n  \n  \n\n\n\n\n\n  \n  emailString\n\n\n\n  \n    1\n    user@example.com\n  \n  \n    2\n    admin@test.org\n  \n  \n    3\n    invalid-email\n  \n  \n    4\n    contact@company.co.uk\n  \n\n\n\n\n\n\n        \n\n\nLet’s validate that all of the values in the email column are valid email addresses. We’ll determine if this validation had any failing test units (there are four test units, one for each row).\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_within_spec(columns=\"email\", spec=\"email\")\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_within_spec\n    \n        \n            \n            \n                \n            \n        \n    \n\n        \n        \n            col_vals_within_spec()\n        \n        \n        \n    email\n    email\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    30.75\n    10.25\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe validation table shows that one test unit failed (the invalid email address in row 3)."
  },
  {
    "objectID": "reference/Validate.col_vals_ne.html",
    "href": "reference/Validate.col_vals_ne.html",
    "title": "Validate.col_vals_ne",
    "section": "",
    "text": "Validate.col_vals_ne(\n    columns,\n    value,\n    na_pass=False,\n    pre=None,\n    segments=None,\n    thresholds=None,\n    actions=None,\n    brief=None,\n    active=True,\n)\nAre column data not equal to a fixed value or data in another column?\nThe col_vals_ne() validation method checks whether column values in a table are not equal to a specified value= (the exact comparison used in this function is col_val != value). The value= can be specified as a single, literal value or as a column name given in col(). This validation will operate over the number of test units that is equal to the number of rows in the table (determined after any pre= mutation has been applied)."
  },
  {
    "objectID": "reference/Validate.col_vals_ne.html#parameters",
    "href": "reference/Validate.col_vals_ne.html#parameters",
    "title": "Validate.col_vals_ne",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns : str | list[str] | Column | ColumnSelector | ColumnSelectorNarwhals\n\nA single column or a list of columns to validate. Can also use col() with column selectors to specify one or more columns. If multiple columns are supplied or resolved, there will be a separate validation step generated for each column.\n\nvalue : float | int | Column\n\nThe value to compare against. This can be a single value or a single column name given in col(). The latter option allows for a column-to-column comparison. For more information on which types of values are allowed, see the What Can Be Used in value=? section.\n\nna_pass : bool = False\n\nShould any encountered None, NA, or Null values be considered as passing test units? By default, this is False. Set to True to pass test units with missing values.\n\npre : Callable | None = None\n\nAn optional preprocessing function or lambda to apply to the data table during interrogation. This function should take a table as input and return a modified table. Have a look at the Preprocessing section for more information on how to use this argument.\n\nsegments : SegmentSpec | None = None\n\nAn optional directive on segmentation, which serves to split a validation step into multiple (one step per segment). Can be a single column name, a tuple that specifies a column name and its corresponding values to segment on, or a combination of both (provided as a list). Read the Segmentation section for usage information.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nSet threshold failure levels for reporting and reacting to exceedences of the levels. The thresholds are set at the step level and will override any global thresholds set in Validate(thresholds=...). The default is None, which means that no thresholds will be set locally and global thresholds (if any) will take effect. Look at the Thresholds section for information on how to set threshold levels.\n\nactions : Actions | None = None\n\nOptional actions to take when the validation step(s) meets or exceeds any set threshold levels. If provided, the Actions class should be used to define the actions.\n\nbrief : str | bool | None = None\n\nAn optional brief description of the validation step that will be displayed in the reporting table. You can use the templating elements like \"{step}\" to insert the step number, or \"{auto}\" to include an automatically generated brief. If True the entire brief will be automatically generated. If None (the default) then there won’t be a brief.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.col_vals_ne.html#returns",
    "href": "reference/Validate.col_vals_ne.html#returns",
    "title": "Validate.col_vals_ne",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.col_vals_ne.html#what-can-be-used-in-value",
    "href": "reference/Validate.col_vals_ne.html#what-can-be-used-in-value",
    "title": "Validate.col_vals_ne",
    "section": "What Can Be Used in value=?",
    "text": "What Can Be Used in value=?\nThe value= argument allows for a variety of input types. The most common are:\n\na single numeric value\na single date or datetime value\nA col() object that represents a column name\n\nWhen supplying a number as the basis of comparison, keep in mind that all resolved columns must also be numeric. Should you have columns that are of the date or datetime types, you can supply a date or datetime value as the value= argument. There is flexibility in how you provide the date or datetime value, as it can be:\n\na string-based date or datetime (e.g., \"2023-10-01\", \"2023-10-01 13:45:30\", etc.)\na date or datetime object using the datetime module (e.g., datetime.date(2023, 10, 1), datetime.datetime(2023, 10, 1, 13, 45, 30), etc.)\n\nFinally, when supplying a column name in the value= argument, it must be specified within col(). This is a column-to-column comparison and, crucially, the columns being compared must be of the same type (e.g., both numeric, both date, etc.)."
  },
  {
    "objectID": "reference/Validate.col_vals_ne.html#preprocessing",
    "href": "reference/Validate.col_vals_ne.html#preprocessing",
    "title": "Validate.col_vals_ne",
    "section": "Preprocessing",
    "text": "Preprocessing\nThe pre= argument allows for a preprocessing function or lambda to be applied to the data table during interrogation. This function should take a table as input and return a modified table. This is useful for performing any necessary transformations or filtering on the data before the validation step is applied.\nThe preprocessing function can be any callable that takes a table as input and returns a modified table. For example, you could use a lambda function to filter the table based on certain criteria or to apply a transformation to the data. Note that you can refer to columns via columns= and value=col(...) that are expected to be present in the transformed table, but may not exist in the table before preprocessing. Regarding the lifetime of the transformed table, it only exists during the validation step and is not stored in the Validate object or used in subsequent validation steps."
  },
  {
    "objectID": "reference/Validate.col_vals_ne.html#segmentation",
    "href": "reference/Validate.col_vals_ne.html#segmentation",
    "title": "Validate.col_vals_ne",
    "section": "Segmentation",
    "text": "Segmentation\nThe segments= argument allows for the segmentation of a validation step into multiple segments. This is useful for applying the same validation step to different subsets of the data. The segmentation can be done based on a single column or specific fields within a column.\nProviding a single column name will result in a separate validation step for each unique value in that column. For example, if you have a column called \"region\" with values \"North\", \"South\", and \"East\", the validation step will be applied separately to each region.\nAlternatively, you can provide a tuple that specifies a column name and its corresponding values to segment on. For example, if you have a column called \"date\" and you want to segment on only specific dates, you can provide a tuple like (\"date\", [\"2023-01-01\", \"2023-01-02\"]). Any other values in the column will be disregarded (i.e., no validation steps will be created for them).\nA list with a combination of column names and tuples can be provided as well. This allows for more complex segmentation scenarios. The following inputs are both valid:\n# Segments from all unique values in the `region` column\n# and specific dates in the `date` column\nsegments=[\"region\", (\"date\", [\"2023-01-01\", \"2023-01-02\"])]\n\n# Segments from all unique values in the `region` and `date` columns\nsegments=[\"region\", \"date\"]\nThe segmentation is performed during interrogation, and the resulting validation steps will be numbered sequentially. Each segment will have its own validation step, and the results will be reported separately. This allows for a more granular analysis of the data and helps identify issues within specific segments.\nImportantly, the segmentation process will be performed after any preprocessing of the data table. Because of this, one can conceivably use the pre= argument to generate a column that can be used for segmentation. For example, you could create a new column called \"segment\" through use of pre= and then use that column for segmentation."
  },
  {
    "objectID": "reference/Validate.col_vals_ne.html#thresholds",
    "href": "reference/Validate.col_vals_ne.html#thresholds",
    "title": "Validate.col_vals_ne",
    "section": "Thresholds",
    "text": "Thresholds\nThe thresholds= parameter is used to set the failure-condition levels for the validation step. If they are set here at the step level, these thresholds will override any thresholds set at the global level in Validate(thresholds=...).\nThere are three threshold levels: ‘warning’, ‘error’, and ‘critical’. The threshold values can either be set as a proportion failing of all test units (a value between 0 to 1), or, the absolute number of failing test units (as integer that’s 1 or greater).\nThresholds can be defined using one of these input schemes:\n\nuse the Thresholds class (the most direct way to create thresholds)\nprovide a tuple of 1-3 values, where position 0 is the ‘warning’ level, position 1 is the ‘error’ level, and position 2 is the ‘critical’ level\ncreate a dictionary of 1-3 value entries; the valid keys: are ‘warning’, ‘error’, and ‘critical’\na single integer/float value denoting absolute number or fraction of failing test units for the ‘warning’ level only\n\nIf the number of failing test units exceeds set thresholds, the validation step will be marked as ‘warning’, ‘error’, or ‘critical’. All of the threshold levels don’t need to be set, you’re free to set any combination of them.\nAside from reporting failure conditions, thresholds can be used to determine the actions to take for each level of failure (using the actions= parameter)."
  },
  {
    "objectID": "reference/Validate.col_vals_ne.html#examples",
    "href": "reference/Validate.col_vals_ne.html#examples",
    "title": "Validate.col_vals_ne",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with two numeric columns (a and b). The table is shown below:\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [5, 5, 5, 5, 5, 5],\n        \"b\": [5, 6, 3, 6, 5, 8],\n    }\n)\n\npb.preview(tbl)\n\n\n\n\n\n  \n  \n  \n\n\n\n\n\n  \n  aInt64\n  bInt64\n\n\n\n  \n    1\n    5\n    5\n  \n  \n    2\n    5\n    6\n  \n  \n    3\n    5\n    3\n  \n  \n    4\n    5\n    6\n  \n  \n    5\n    5\n    5\n  \n  \n    6\n    5\n    8\n  \n\n\n\n\n\n\n        \n\n\nLet’s validate that values in column a are not equal to the value of 3. We’ll determine if this validation had any failing test units (there are six test units, one for each row).\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_ne(columns=\"a\", value=3)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_ne\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_ne()\n        \n        \n        \n    a\n    3\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    61.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nPrinting the validation object shows the validation table in an HTML viewing environment. The validation table shows the single entry that corresponds to the validation step created by using col_vals_ne(). All test units passed, and there are no failing test units.\nAside from checking a column against a literal value, we can also use a column name in the value= argument (with the helper function col() to perform a column-to-column comparison. For the next example, we’ll use col_vals_ne() to check whether the values in column a aren’t equal to the values in column b.\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_ne(columns=\"a\", value=pb.col(\"b\"))\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_ne\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_ne()\n        \n        \n        \n    a\n    b\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    40.67\n    20.33\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe validation table reports two failing test units. The specific failing cases are in rows 0 and 4, where a is 5 and b is 5 in both cases (i.e., they are equal to each other)."
  },
  {
    "objectID": "reference/ends_with.html",
    "href": "reference/ends_with.html",
    "title": "ends_with",
    "section": "",
    "text": "ends_with(text, case_sensitive=False)\nSelect columns that end with specified text.\nMany validation methods have a columns= argument that can be used to specify the columns for validation (e.g., col_vals_gt(), col_vals_regex(), etc.). The ends_with() selector function can be used to select one or more columns that end with some specified text. So if the set of table columns consists of\n[first_name, last_name, age, address]\nand you want to validate columns that end with \"name\", you can use columns=ends_with(\"name\"). This will select the first_name and last_name columns.\nThere will be a validation step created for every resolved column. Note that if there aren’t any columns resolved from using ends_with() (or any other expression using selector functions), the validation step will fail to be evaluated during the interrogation process. Such a failure to evaluate will be reported in the validation results but it won’t affect the interrogation process overall (i.e., the process won’t be halted)."
  },
  {
    "objectID": "reference/ends_with.html#parameters",
    "href": "reference/ends_with.html#parameters",
    "title": "ends_with",
    "section": "Parameters",
    "text": "Parameters\n\ntext : str\n\nThe text that the column name should end with.\n\ncase_sensitive : bool = False\n\nWhether column names should be treated as case-sensitive. The default is False."
  },
  {
    "objectID": "reference/ends_with.html#returns",
    "href": "reference/ends_with.html#returns",
    "title": "ends_with",
    "section": "Returns",
    "text": "Returns\n\n : EndsWith\n\nAn EndsWith object, which can be used to select columns that end with the specified text."
  },
  {
    "objectID": "reference/ends_with.html#relevant-validation-methods-where-ends_with-can-be-used",
    "href": "reference/ends_with.html#relevant-validation-methods-where-ends_with-can-be-used",
    "title": "ends_with",
    "section": "Relevant Validation Methods where ends_with() can be Used",
    "text": "Relevant Validation Methods where ends_with() can be Used\nThis selector function can be used in the columns= argument of the following validation methods:\n\ncol_vals_gt()\ncol_vals_lt()\ncol_vals_ge()\ncol_vals_le()\ncol_vals_eq()\ncol_vals_ne()\ncol_vals_between()\ncol_vals_outside()\ncol_vals_in_set()\ncol_vals_not_in_set()\ncol_vals_increasing()\ncol_vals_decreasing()\ncol_vals_null()\ncol_vals_not_null()\ncol_vals_regex()\ncol_vals_within_spec()\ncol_exists()\n\nThe ends_with() selector function doesn’t need to be used in isolation. Read the next section for information on how to compose it with other column selectors for more refined ways to select columns."
  },
  {
    "objectID": "reference/ends_with.html#additional-flexibilty-through-composition-with-other-column-selectors",
    "href": "reference/ends_with.html#additional-flexibilty-through-composition-with-other-column-selectors",
    "title": "ends_with",
    "section": "Additional Flexibilty through Composition with Other Column Selectors",
    "text": "Additional Flexibilty through Composition with Other Column Selectors\nThe ends_with() function can be composed with other column selectors to create fine-grained column selections. For example, to select columns that end with \"e\" and start with \"a\", you can use the ends_with() and starts_with() functions together. The only condition is that the expressions are wrapped in the col() function, like this:\ncol(ends_with(\"e\") & starts_with(\"a\"))\nThere are four operators that can be used to compose column selectors:\n\n& (and)\n| (or)\n- (difference)\n~ (not)\n\nThe & operator is used to select columns that satisfy both conditions. The | operator is used to select columns that satisfy either condition. The - operator is used to select columns that satisfy the first condition but not the second. The ~ operator is used to select columns that don’t satisfy the condition. As many selector functions can be used as needed and the operators can be combined to create complex column selection criteria (parentheses can be used to group conditions and control the order of evaluation)."
  },
  {
    "objectID": "reference/ends_with.html#examples",
    "href": "reference/ends_with.html#examples",
    "title": "ends_with",
    "section": "Examples",
    "text": "Examples\nSuppose we have a table with columns name, 2021_pay, 2022_pay, and person_id and we’d like to validate that the values in columns that end with \"pay\" are greater than 10. We can use the ends_with() column selector function to specify the columns that end with \"pay\" as the columns to validate.\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n        \"2021_pay\": [16.32, 16.25, 15.75],\n        \"2022_pay\": [18.62, 16.95, 18.25],\n        \"person_id\": [\"A123\", \"B456\", \"C789\"],\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(columns=pb.ends_with(\"pay\"), value=10)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    2021_pay\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    2022_pay\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nFrom the results of the validation table we get two validation steps, one for 2021_pay and one for 2022_pay. The values in both columns were all greater than 10.\nWe can also use the ends_with() function in combination with other column selectors (within col()) to create more complex column selection criteria (i.e., to select columns that satisfy multiple conditions). For example, to select columns that end with \"pay\" and match the text \"2023\" or \"2024\", we can use the & operator to combine column selectors.\n\ntbl = pl.DataFrame(\n    {\n        \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n        \"2022_hours\": [160, 180, 160],\n        \"2023_hours\": [182, 168, 175],\n        \"2024_hours\": [200, 165, 190],\n        \"2022_pay\": [18.62, 16.95, 18.25],\n        \"2023_pay\": [19.29, 17.75, 18.35],\n        \"2024_pay\": [20.73, 18.35, 20.10],\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(\n        columns=pb.col(pb.ends_with(\"pay\") & pb.matches(\"2023|2024\")),\n        value=10\n    )\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    2023_pay\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    2024_pay\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nFrom the results of the validation table we get two validation steps, one for 2023_pay and one for 2024_pay."
  },
  {
    "objectID": "reference/Validate.critical.html",
    "href": "reference/Validate.critical.html",
    "title": "Validate.critical",
    "section": "",
    "text": "Validate.critical(i=None, scalar=False)\nGet the ‘critical’ level status for each validation step.\nThe ‘critical’ status for a validation step is True if the fraction of failing test units meets or exceeds the threshold for the ‘critical’ level. Otherwise, the status is False.\nThe ascribed name of ‘critical’ is semantic and is thus simply a status indicator that could be used to trigger some action to be take. Here’s how it fits in with other status indicators:\nThis method provides a dictionary of the ‘critical’ status for each validation step. If the scalar=True argument is provided and i= is a scalar, the value is returned as a scalar instead of a dictionary."
  },
  {
    "objectID": "reference/Validate.critical.html#parameters",
    "href": "reference/Validate.critical.html#parameters",
    "title": "Validate.critical",
    "section": "Parameters",
    "text": "Parameters\n\ni : int | list[int] | None = None\n\nThe validation step number(s) from which the ‘critical’ status is obtained. Can be provided as a list of integers or a single integer. If None, all steps are included.\n\nscalar : bool = False\n\nIf True and i= is a scalar, return the value as a scalar instead of a dictionary."
  },
  {
    "objectID": "reference/Validate.critical.html#returns",
    "href": "reference/Validate.critical.html#returns",
    "title": "Validate.critical",
    "section": "Returns",
    "text": "Returns\n\n : dict[int, bool] | bool\n\nA dictionary of the ‘critical’ status for each validation step or a scalar value."
  },
  {
    "objectID": "reference/Validate.critical.html#examples",
    "href": "reference/Validate.critical.html#examples",
    "title": "Validate.critical",
    "section": "Examples",
    "text": "Examples\nIn the example below, we’ll use a simple Polars DataFrame with three columns (a, b, and c). There will be three validation steps, and the first step will have many failing test units, the rest will be completely passing. We’ve set thresholds here for each of the steps by using thresholds=(2, 4, 5), which means:\n\nthe ‘warning’ threshold is 2 failing test units\nthe ‘error’ threshold is 4 failing test units\nthe ‘critical’ threshold is 5 failing test units\n\nAfter interrogation, the critical() method is used to determine the ‘critical’ status for each validation step.\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [2, 4, 4, 7, 2, 3, 8],\n        \"b\": [9, 8, 10, 5, 10, 6, 2],\n        \"c\": [\"a\", \"b\", \"a\", \"a\", \"b\", \"b\", \"a\"]\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl, thresholds=(2, 4, 5))\n    .col_vals_gt(columns=\"a\", value=5)\n    .col_vals_lt(columns=\"b\", value=15)\n    .col_vals_in_set(columns=\"c\", set=[\"a\", \"b\"])\n    .interrogate()\n)\n\nvalidation.critical()\n\n{1: True, 2: False, 3: False}\n\n\nThe returned dictionary provides the ‘critical’ status for each validation step. The first step has a True value since the number of failing test units meets the threshold for the ‘critical’ level. The second and third steps have False values since the number of failing test units was 0, which is below the threshold for the ‘critical’ level.\nWe can also visually inspect the ‘critical’ status across all steps by viewing the validation table:\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:11:57PolarsWARNING2ERROR4CRITICAL5\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #FF3300\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    a\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    7\n    20.29\n    50.71\n    ●\n    ●\n    ●\n    CSV\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    b\n    15\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    7\n    71.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        \n        \n    c\n    a, b\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    7\n    71.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:11:57 UTC&lt; 1 s2025-11-23 00:11:57 UTC\n  \n\n\n\n\n\n\n        \n\n\nWe can see that there are filled gray, yellow, and red circles in the first step (far right side, in the W, E, and C columns) indicating that the ‘warning’, ‘error’, and ‘critical’ thresholds were met. The other steps have empty gray, yellow, and red circles. This means that thresholds were ‘set but not met’ in those steps.\nIf we wanted to check the ‘critical’ status for a single validation step, we can provide the step number. Also, we could have the value returned as a scalar by setting scalar=True (ensuring that i= is a scalar).\n\nvalidation.critical(i=1)\n\n{1: True}\n\n\nThe returned value is True, indicating that the first validation step had the ‘critical’ threshold met."
  },
  {
    "objectID": "reference/Validate.rows_distinct.html",
    "href": "reference/Validate.rows_distinct.html",
    "title": "Validate.rows_distinct",
    "section": "",
    "text": "Validate.rows_distinct(\n    columns_subset=None,\n    pre=None,\n    segments=None,\n    thresholds=None,\n    actions=None,\n    brief=None,\n    active=True,\n)\nValidate whether rows in the table are distinct.\nThe rows_distinct() method checks whether rows in the table are distinct. This validation will operate over the number of test units that is equal to the number of rows in the table (determined after any pre= mutation has been applied)."
  },
  {
    "objectID": "reference/Validate.rows_distinct.html#parameters",
    "href": "reference/Validate.rows_distinct.html#parameters",
    "title": "Validate.rows_distinct",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns_subset : str | list[str] | None = None\n\nA single column or a list of columns to use as a subset for the distinct comparison. If None, then all columns in the table will be used for the comparison. If multiple columns are supplied, the distinct comparison will be made over the combination of values in those columns.\n\npre : Callable | None = None\n\nAn optional preprocessing function or lambda to apply to the data table during interrogation. This function should take a table as input and return a modified table. Have a look at the Preprocessing section for more information on how to use this argument.\n\nsegments : SegmentSpec | None = None\n\nAn optional directive on segmentation, which serves to split a validation step into multiple (one step per segment). Can be a single column name, a tuple that specifies a column name and its corresponding values to segment on, or a combination of both (provided as a list). Read the Segmentation section for usage information.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nSet threshold failure levels for reporting and reacting to exceedences of the levels. The thresholds are set at the step level and will override any global thresholds set in Validate(thresholds=...). The default is None, which means that no thresholds will be set locally and global thresholds (if any) will take effect. Look at the Thresholds section for information on how to set threshold levels.\n\nactions : Actions | None = None\n\nOptional actions to take when the validation step meets or exceeds any set threshold levels. If provided, the Actions class should be used to define the actions.\n\nbrief : str | bool | None = None\n\nAn optional brief description of the validation step that will be displayed in the reporting table. You can use the templating elements like \"{step}\" to insert the step number, or \"{auto}\" to include an automatically generated brief. If True the entire brief will be automatically generated. If None (the default) then there won’t be a brief.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.rows_distinct.html#returns",
    "href": "reference/Validate.rows_distinct.html#returns",
    "title": "Validate.rows_distinct",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.rows_distinct.html#preprocessing",
    "href": "reference/Validate.rows_distinct.html#preprocessing",
    "title": "Validate.rows_distinct",
    "section": "Preprocessing",
    "text": "Preprocessing\nThe pre= argument allows for a preprocessing function or lambda to be applied to the data table during interrogation. This function should take a table as input and return a modified table. This is useful for performing any necessary transformations or filtering on the data before the validation step is applied.\nThe preprocessing function can be any callable that takes a table as input and returns a modified table. For example, you could use a lambda function to filter the table based on certain criteria or to apply a transformation to the data. Note that you can refer to columns via columns_subset= that are expected to be present in the transformed table, but may not exist in the table before preprocessing. Regarding the lifetime of the transformed table, it only exists during the validation step and is not stored in the Validate object or used in subsequent validation steps."
  },
  {
    "objectID": "reference/Validate.rows_distinct.html#segmentation",
    "href": "reference/Validate.rows_distinct.html#segmentation",
    "title": "Validate.rows_distinct",
    "section": "Segmentation",
    "text": "Segmentation\nThe segments= argument allows for the segmentation of a validation step into multiple segments. This is useful for applying the same validation step to different subsets of the data. The segmentation can be done based on a single column or specific fields within a column.\nProviding a single column name will result in a separate validation step for each unique value in that column. For example, if you have a column called \"region\" with values \"North\", \"South\", and \"East\", the validation step will be applied separately to each region.\nAlternatively, you can provide a tuple that specifies a column name and its corresponding values to segment on. For example, if you have a column called \"date\" and you want to segment on only specific dates, you can provide a tuple like (\"date\", [\"2023-01-01\", \"2023-01-02\"]). Any other values in the column will be disregarded (i.e., no validation steps will be created for them).\nA list with a combination of column names and tuples can be provided as well. This allows for more complex segmentation scenarios. The following inputs are both valid:\n# Segments from all unique values in the `region` column\n# and specific dates in the `date` column\nsegments=[\"region\", (\"date\", [\"2023-01-01\", \"2023-01-02\"])]\n\n# Segments from all unique values in the `region` and `date` columns\nsegments=[\"region\", \"date\"]\nThe segmentation is performed during interrogation, and the resulting validation steps will be numbered sequentially. Each segment will have its own validation step, and the results will be reported separately. This allows for a more granular analysis of the data and helps identify issues within specific segments.\nImportantly, the segmentation process will be performed after any preprocessing of the data table. Because of this, one can conceivably use the pre= argument to generate a column that can be used for segmentation. For example, you could create a new column called \"segment\" through use of pre= and then use that column for segmentation."
  },
  {
    "objectID": "reference/Validate.rows_distinct.html#thresholds",
    "href": "reference/Validate.rows_distinct.html#thresholds",
    "title": "Validate.rows_distinct",
    "section": "Thresholds",
    "text": "Thresholds\nThe thresholds= parameter is used to set the failure-condition levels for the validation step. If they are set here at the step level, these thresholds will override any thresholds set at the global level in Validate(thresholds=...).\nThere are three threshold levels: ‘warning’, ‘error’, and ‘critical’. The threshold values can either be set as a proportion failing of all test units (a value between 0 to 1), or, the absolute number of failing test units (as integer that’s 1 or greater).\nThresholds can be defined using one of these input schemes:\n\nuse the Thresholds class (the most direct way to create thresholds)\nprovide a tuple of 1-3 values, where position 0 is the ‘warning’ level, position 1 is the ‘error’ level, and position 2 is the ‘critical’ level\ncreate a dictionary of 1-3 value entries; the valid keys: are ‘warning’, ‘error’, and ‘critical’\na single integer/float value denoting absolute number or fraction of failing test units for the ‘warning’ level only\n\nIf the number of failing test units exceeds set thresholds, the validation step will be marked as ‘warning’, ‘error’, or ‘critical’. All of the threshold levels don’t need to be set, you’re free to set any combination of them.\nAside from reporting failure conditions, thresholds can be used to determine the actions to take for each level of failure (using the actions= parameter)."
  },
  {
    "objectID": "reference/Validate.rows_distinct.html#examples",
    "href": "reference/Validate.rows_distinct.html#examples",
    "title": "Validate.rows_distinct",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with three string columns (col_1, col_2, and col_3). The table is shown below:\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"col_1\": [\"a\", \"b\", \"c\", \"d\"],\n        \"col_2\": [\"a\", \"a\", \"c\", \"d\"],\n        \"col_3\": [\"a\", \"a\", \"d\", \"e\"],\n    }\n)\n\npb.preview(tbl)\n\n\n\n\n\n  \n  \n  \n  \n\n\n\n\n\n  \n  col_1String\n  col_2String\n  col_3String\n\n\n\n  \n    1\n    a\n    a\n    a\n  \n  \n    2\n    b\n    a\n    a\n  \n  \n    3\n    c\n    c\n    d\n  \n  \n    4\n    d\n    d\n    e\n  \n\n\n\n\n\n\n        \n\n\nLet’s validate that the rows in the table are distinct with rows_distinct(). We’ll determine if this validation had any failing test units (there are four test units, one for each row). A failing test units means that a given row is not distinct from every other row.\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .rows_distinct()\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    rows_distinct\n    \n        \n            \n            \n                \n                \n                \n            \n        \n    \n\n        \n        \n            rows_distinct()\n        \n        \n        \n    ALL COLUMNS\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    41.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nFrom this validation table we see that there are no failing test units. All rows in the table are distinct from one another.\nWe can also use a subset of columns to determine distinctness. Let’s specify the subset using columns col_2 and col_3 for the next validation.\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .rows_distinct(columns_subset=[\"col_2\", \"col_3\"])\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    rows_distinct\n    \n        \n            \n            \n                \n                \n                \n            \n        \n    \n\n        \n        \n            rows_distinct()\n        \n        \n        \n    col_2, col_3\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    20.50\n    20.50\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe validation table reports two failing test units. The first and second rows are duplicated when considering only the values in columns col_2 and col_3. There’s only one set of duplicates but there are two failing test units since each row is compared to all others."
  },
  {
    "objectID": "reference/Validate.col_vals_expr.html",
    "href": "reference/Validate.col_vals_expr.html",
    "title": "Validate.col_vals_expr",
    "section": "",
    "text": "Validate.col_vals_expr(\n    expr,\n    pre=None,\n    segments=None,\n    thresholds=None,\n    actions=None,\n    brief=None,\n    active=True,\n)\nValidate column values using a custom expression.\nThe col_vals_expr() validation method checks whether column values in a table satisfy a custom expr= expression. This validation will operate over the number of test units that is equal to the number of rows in the table (determined after any pre= mutation has been applied)."
  },
  {
    "objectID": "reference/Validate.col_vals_expr.html#parameters",
    "href": "reference/Validate.col_vals_expr.html#parameters",
    "title": "Validate.col_vals_expr",
    "section": "Parameters",
    "text": "Parameters\n\nexpr : any\n\nA column expression that will evaluate each row in the table, returning a boolean value per table row. If the target table is a Polars DataFrame, the expression should either be a Polars column expression or a Narwhals one. For a Pandas DataFrame, the expression should either be a lambda expression or a Narwhals column expression.\n\npre : Callable | None = None\n\nAn optional preprocessing function or lambda to apply to the data table during interrogation. This function should take a table as input and return a modified table. Have a look at the Preprocessing section for more information on how to use this argument.\n\nsegments : SegmentSpec | None = None\n\nAn optional directive on segmentation, which serves to split a validation step into multiple (one step per segment). Can be a single column name, a tuple that specifies a column name and its corresponding values to segment on, or a combination of both (provided as a list). Read the Segmentation section for usage information.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nSet threshold failure levels for reporting and reacting to exceedences of the levels. The thresholds are set at the step level and will override any global thresholds set in Validate(thresholds=...). The default is None, which means that no thresholds will be set locally and global thresholds (if any) will take effect. Look at the Thresholds section for information on how to set threshold levels.\n\nactions : Actions | None = None\n\nOptional actions to take when the validation step meets or exceeds any set threshold levels. If provided, the Actions class should be used to define the actions.\n\nbrief : str | bool | None = None\n\nAn optional brief description of the validation step that will be displayed in the reporting table. You can use the templating elements like \"{step}\" to insert the step number, or \"{auto}\" to include an automatically generated brief. If True the entire brief will be automatically generated. If None (the default) then there won’t be a brief.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.col_vals_expr.html#returns",
    "href": "reference/Validate.col_vals_expr.html#returns",
    "title": "Validate.col_vals_expr",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.col_vals_expr.html#preprocessing",
    "href": "reference/Validate.col_vals_expr.html#preprocessing",
    "title": "Validate.col_vals_expr",
    "section": "Preprocessing",
    "text": "Preprocessing\nThe pre= argument allows for a preprocessing function or lambda to be applied to the data table during interrogation. This function should take a table as input and return a modified table. This is useful for performing any necessary transformations or filtering on the data before the validation step is applied.\nThe preprocessing function can be any callable that takes a table as input and returns a modified table. For example, you could use a lambda function to filter the table based on certain criteria or to apply a transformation to the data. Regarding the lifetime of the transformed table, it only exists during the validation step and is not stored in the Validate object or used in subsequent validation steps."
  },
  {
    "objectID": "reference/Validate.col_vals_expr.html#segmentation",
    "href": "reference/Validate.col_vals_expr.html#segmentation",
    "title": "Validate.col_vals_expr",
    "section": "Segmentation",
    "text": "Segmentation\nThe segments= argument allows for the segmentation of a validation step into multiple segments. This is useful for applying the same validation step to different subsets of the data. The segmentation can be done based on a single column or specific fields within a column.\nProviding a single column name will result in a separate validation step for each unique value in that column. For example, if you have a column called \"region\" with values \"North\", \"South\", and \"East\", the validation step will be applied separately to each region.\nAlternatively, you can provide a tuple that specifies a column name and its corresponding values to segment on. For example, if you have a column called \"date\" and you want to segment on only specific dates, you can provide a tuple like (\"date\", [\"2023-01-01\", \"2023-01-02\"]). Any other values in the column will be disregarded (i.e., no validation steps will be created for them).\nA list with a combination of column names and tuples can be provided as well. This allows for more complex segmentation scenarios. The following inputs are both valid:\n# Segments from all unique values in the `region` column\n# and specific dates in the `date` column\nsegments=[\"region\", (\"date\", [\"2023-01-01\", \"2023-01-02\"])]\n\n# Segments from all unique values in the `region` and `date` columns\nsegments=[\"region\", \"date\"]\nThe segmentation is performed during interrogation, and the resulting validation steps will be numbered sequentially. Each segment will have its own validation step, and the results will be reported separately. This allows for a more granular analysis of the data and helps identify issues within specific segments.\nImportantly, the segmentation process will be performed after any preprocessing of the data table. Because of this, one can conceivably use the pre= argument to generate a column that can be used for segmentation. For example, you could create a new column called \"segment\" through use of pre= and then use that column for segmentation."
  },
  {
    "objectID": "reference/Validate.col_vals_expr.html#thresholds",
    "href": "reference/Validate.col_vals_expr.html#thresholds",
    "title": "Validate.col_vals_expr",
    "section": "Thresholds",
    "text": "Thresholds\nThe thresholds= parameter is used to set the failure-condition levels for the validation step. If they are set here at the step level, these thresholds will override any thresholds set at the global level in Validate(thresholds=...).\nThere are three threshold levels: ‘warning’, ‘error’, and ‘critical’. The threshold values can either be set as a proportion failing of all test units (a value between 0 to 1), or, the absolute number of failing test units (as integer that’s 1 or greater).\nThresholds can be defined using one of these input schemes:\n\nuse the Thresholds class (the most direct way to create thresholds)\nprovide a tuple of 1-3 values, where position 0 is the ‘warning’ level, position 1 is the ‘error’ level, and position 2 is the ‘critical’ level\ncreate a dictionary of 1-3 value entries; the valid keys: are ‘warning’, ‘error’, and ‘critical’\na single integer/float value denoting absolute number or fraction of failing test units for the ‘warning’ level only\n\nIf the number of failing test units exceeds set thresholds, the validation step will be marked as ‘warning’, ‘error’, or ‘critical’. All of the threshold levels don’t need to be set, you’re free to set any combination of them.\nAside from reporting failure conditions, thresholds can be used to determine the actions to take for each level of failure (using the actions= parameter)."
  },
  {
    "objectID": "reference/Validate.col_vals_expr.html#examples",
    "href": "reference/Validate.col_vals_expr.html#examples",
    "title": "Validate.col_vals_expr",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with three columns (a, b, and c). The table is shown below:\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [1, 2, 1, 7, 8, 6],\n        \"b\": [0, 0, 0, 1, 1, 1],\n        \"c\": [0.5, 0.3, 0.8, 1.4, 1.9, 1.2],\n    }\n)\n\npb.preview(tbl)\n\n\n\n\n\n  \n  \n  \n  \n\n\n\n\n\n  \n  aInt64\n  bInt64\n  cFloat64\n\n\n\n  \n    1\n    1\n    0\n    0.5\n  \n  \n    2\n    2\n    0\n    0.3\n  \n  \n    3\n    1\n    0\n    0.8\n  \n  \n    4\n    7\n    1\n    1.4\n  \n  \n    5\n    8\n    1\n    1.9\n  \n  \n    6\n    6\n    1\n    1.2\n  \n\n\n\n\n\n\n        \n\n\nLet’s validate that the values in column a are all integers. We’ll determine if this validation had any failing test units (there are six test units, one for each row).\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_expr(expr=pl.col(\"a\") % 1 == 0)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_expr\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_expr()\n        \n        \n        \n    —\n    COLUMN EXPR\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    61.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nPrinting the validation object shows the validation table in an HTML viewing environment. The validation table shows the single entry that corresponds to the validation step created by using col_vals_expr(). All test units passed, with no failing test units."
  },
  {
    "objectID": "reference/Validate.f_failed.html",
    "href": "reference/Validate.f_failed.html",
    "title": "Validate.f_failed",
    "section": "",
    "text": "Validate.f_failed(i=None, scalar=False)\nProvides a dictionary of the fraction of test units that failed for each validation step.\nA measure of the fraction of test units that failed is provided by the f_failed attribute. This is the fraction of test units that failed the validation step over the total number of test units. Given this is a fractional value, it will always be in the range of 0 to 1.\nTest units are the atomic units of the validation process. Different validations can have different numbers of test units. For example, a validation that checks for the presence of a column in a table will have a single test unit. A validation that checks for the presence of a value in a column will have as many test units as there are rows in the table.\nThis method provides a dictionary of the fraction of failing test units for each validation step. If the scalar=True argument is provided and i= is a scalar, the value is returned as a scalar instead of a dictionary. Furthermore, a value obtained here will be the complement to the analogous value returned by the f_passed() method (i.e., 1 - f_passed())."
  },
  {
    "objectID": "reference/Validate.f_failed.html#parameters",
    "href": "reference/Validate.f_failed.html#parameters",
    "title": "Validate.f_failed",
    "section": "Parameters",
    "text": "Parameters\n\ni : int | list[int] | None = None\n\nThe validation step number(s) from which the fraction of failing test units is obtained. Can be provided as a list of integers or a single integer. If None, all steps are included.\n\nscalar : bool = False\n\nIf True and i= is a scalar, return the value as a scalar instead of a dictionary."
  },
  {
    "objectID": "reference/Validate.f_failed.html#returns",
    "href": "reference/Validate.f_failed.html#returns",
    "title": "Validate.f_failed",
    "section": "Returns",
    "text": "Returns\n\n : dict[int, float] | float\n\nA dictionary of the fraction of failing test units for each validation step or a scalar value."
  },
  {
    "objectID": "reference/Validate.f_failed.html#examples",
    "href": "reference/Validate.f_failed.html#examples",
    "title": "Validate.f_failed",
    "section": "Examples",
    "text": "Examples\nIn the example below, we’ll use a simple Polars DataFrame with three columns (a, b, and c). There will be three validation steps, all having some failing test units. After interrogation, the f_failed() method is used to determine the fraction of failing test units for each validation step.\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [7, 4, 9, 7, 12, 3, 10],\n        \"b\": [9, 8, 10, 5, 10, 6, 2],\n        \"c\": [\"a\", \"b\", \"c\", \"a\", \"b\", \"d\", \"c\"]\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(columns=\"a\", value=5)\n    .col_vals_gt(columns=\"b\", value=pb.col(\"a\"))\n    .col_vals_in_set(columns=\"c\", set=[\"a\", \"b\"])\n    .interrogate()\n)\n\nvalidation.f_failed()\n\n{1: 0.2857142857142857, 2: 0.42857142857142855, 3: 0.42857142857142855}\n\n\nThe returned dictionary shows the fraction of failing test units for each validation step. The values are all greater than 0 since there were failing test units in each step.\nIf we wanted to check the fraction of failing test units for a single validation step, we can provide the step number. Also, we could have the value returned as a scalar by setting scalar=True (ensuring that i= is a scalar).\n\nvalidation.f_failed(i=1)\n\n{1: 0.2857142857142857}\n\n\nThe returned value is the proportion of failing test units for the first validation step (2 failing test units out of 7 total test units)."
  },
  {
    "objectID": "reference/DraftValidation.html",
    "href": "reference/DraftValidation.html",
    "title": "DraftValidation",
    "section": "",
    "text": "DraftValidation(data, model, api_key=None, verify_ssl=True)\nDraft a validation plan for a given table using an LLM.\nBy using a large language model (LLM) to draft a validation plan, you can quickly generate a starting point for validating a table. This can be useful when you have a new table and you want to get a sense of how to validate it (and adjustments could always be made later). The DraftValidation class uses the chatlas package to draft a validation plan for a given table using an LLM from either the \"anthropic\", \"openai\", \"ollama\" or \"bedrock\" provider. You can install all requirements for the class through an optional ‘generate’ install of Pointblank via pip install pointblank[generate].\n\n\n\n\n\n\nWarning\n\n\n\nThe DraftValidation class is still experimental. Please report any issues you encounter in the Pointblank issue tracker.\n\n\n\n\n\ndata : FrameT | Any\n\nThe data to be used for drafting a validation plan.\n\nmodel : str\n\nThe model to be used. This should be in the form of provider:model (e.g., \"anthropic:claude-sonnet-4-5\"). Supported providers are \"anthropic\", \"openai\", \"ollama\", and \"bedrock\".\n\napi_key : str | None = None\n\nThe API key to be used for the model.\n\nverify_ssl : bool = True\n\nWhether to verify SSL certificates when making requests to the LLM provider. Set to False to disable SSL verification (e.g., when behind a corporate firewall with self-signed certificates). Defaults to True. Use with caution as disabling SSL verification can pose security risks.\n\n\n\n\n\n\n : str\n\nThe drafted validation plan.\n\n\n\n\n\nThe model= argument should be constructed using the provider and model name separated by a colon (provider:model). The provider text can any of:\n\n\"anthropic\" (Anthropic)\n\"openai\" (OpenAI)\n\"ollama\" (Ollama)\n\"bedrock\" (Amazon Bedrock)\n\nThe model name should be the specific model to be used from the provider. Model names are subject to change so consult the provider’s documentation for the most up-to-date model names.\n\n\n\nProviding a valid API key as a string in the api_key argument is adequate for getting started but you should consider using a more secure method for handling API keys.\nOne way to do this is to load the API key from an environent variable and retrieve it using the os module (specifically the os.getenv() function). Places to store the API key might include .bashrc, .bash_profile, .zshrc, or .zsh_profile.\nAnother solution is to store one or more model provider API keys in an .env file (in the root of your project). If the API keys have correct names (e.g., ANTHROPIC_API_KEY or OPENAI_API_KEY) then DraftValidation will automatically load the API key from the .env file and there’s no need to provide the api_key argument. An .env file might look like this:\nANTHROPIC_API_KEY=\"your_anthropic_api_key_here\"\nOPENAI_API_KEY=\"your_openai_api_key_here\"\nThere’s no need to have the python-dotenv package installed when using .env files in this way.\n\n\n\nBy default, SSL certificate verification is enabled for all requests to LLM providers. However, in certain network environments (such as corporate networks with self-signed certificates or firewall proxies), you may encounter SSL certificate verification errors.\nTo disable SSL verification, set the verify_ssl parameter to False:\nimport pointblank as pb\n\ndata = pb.load_dataset(dataset=\"nycflights\", tbl_type=\"duckdb\")\n\n# Disable SSL verification for networks with self-signed certificates\npb.DraftValidation(\n    data=data,\n    model=\"anthropic:claude-sonnet-4-5\",\n    verify_ssl=False\n)\n\n\n\n\n\n\nWarning\n\n\n\nDisabling SSL verification (through verify_ssl=False) can expose your API keys and data to man-in-the-middle attacks. Only use this option in trusted network environments and when absolutely necessary.\n\n\n\n\n\nThe data sent to the model provider is a JSON summary of the table. This data summary is generated internally by DraftValidation using the DataScan class. The summary includes the following information:\n\nthe number of rows and columns in the table\nthe type of dataset (e.g., Polars, DuckDB, Pandas, etc.)\nthe column names and their types\ncolumn level statistics such as the number of missing values, min, max, mean, and median, etc.\na short list of data values in each column\n\nThe JSON summary is used to provide the model with the necessary information to draft a validation plan. As such, even very large tables can be used with the DraftValidation class since the contents of the table are not sent to the model provider.\nThe Amazon Bedrock is a special case since it is a self-hosted model and security controls are in place to ensure that data is kept within the user’s AWS environment. If using an Ollama model all data is handled locally, though only a few models are capable enough to perform the task of drafting a validation plan.\n\n\n\nLet’s look at how the DraftValidation class can be used to draft a validation plan for a table. The table to be used is \"nycflights\", which is available here via the load_dataset() function. The model to be used is \"anthropic:claude-sonnet-4-5\" (which performs very well compared to other LLMs). The example assumes that the API key is stored in an .env file as ANTHROPIC_API_KEY.\nimport pointblank as pb\n\n# Load the \"nycflights\" dataset as a DuckDB table\ndata = pb.load_dataset(dataset=\"nycflights\", tbl_type=\"duckdb\")\n\n# Draft a validation plan for the \"nycflights\" table\npb.DraftValidation(data=data, model=\"anthropic:claude-sonnet-4-5\")\nThe output will be a drafted validation plan for the \"nycflights\" table and this will appear in the console.\n```python\nimport pointblank as pb\n\n# Define schema based on column names and dtypes\nschema = pb.Schema(columns=[\n    (\"year\", \"int64\"),\n    (\"month\", \"int64\"),\n    (\"day\", \"int64\"),\n    (\"dep_time\", \"int64\"),\n    (\"sched_dep_time\", \"int64\"),\n    (\"dep_delay\", \"int64\"),\n    (\"arr_time\", \"int64\"),\n    (\"sched_arr_time\", \"int64\"),\n    (\"arr_delay\", \"int64\"),\n    (\"carrier\", \"string\"),\n    (\"flight\", \"int64\"),\n    (\"tailnum\", \"string\"),\n    (\"origin\", \"string\"),\n    (\"dest\", \"string\"),\n    (\"air_time\", \"int64\"),\n    (\"distance\", \"int64\"),\n    (\"hour\", \"int64\"),\n    (\"minute\", \"int64\")\n])\n\n# The validation plan\nvalidation = (\n    pb.Validate(\n        data=your_data,  # Replace your_data with the actual data variable\n        label=\"Draft Validation\",\n        thresholds=pb.Thresholds(warning=0.10, error=0.25, critical=0.35)\n    )\n    .col_schema_match(schema=schema)\n    .col_vals_not_null(columns=[\n        \"year\", \"month\", \"day\", \"sched_dep_time\", \"carrier\", \"flight\",\n        \"origin\", \"dest\", \"distance\", \"hour\", \"minute\"\n    ])\n    .col_vals_between(columns=\"month\", left=1, right=12)\n    .col_vals_between(columns=\"day\", left=1, right=31)\n    .col_vals_between(columns=\"sched_dep_time\", left=106, right=2359)\n    .col_vals_between(columns=\"dep_delay\", left=-43, right=1301, na_pass=True)\n    .col_vals_between(columns=\"air_time\", left=20, right=695, na_pass=True)\n    .col_vals_between(columns=\"distance\", left=17, right=4983)\n    .col_vals_between(columns=\"hour\", left=1, right=23)\n    .col_vals_between(columns=\"minute\", left=0, right=59)\n    .col_vals_in_set(columns=\"origin\", set=[\"EWR\", \"LGA\", \"JFK\"])\n    .col_count_match(count=18)\n    .row_count_match(count=336776)\n    .rows_distinct()\n    .interrogate()\n)\n\nvalidation\n```\nThe drafted validation plan can be copied and pasted into a Python script or notebook for further use. In other words, the generated plan can be adjusted as needed to suit the specific requirements of the table being validated.\nNote that the output does not know how the data was obtained, so it uses the placeholder your_data in the data= argument of the Validate class. When adapted for use, this should be replaced with the actual data variable."
  },
  {
    "objectID": "reference/DraftValidation.html#parameters",
    "href": "reference/DraftValidation.html#parameters",
    "title": "DraftValidation",
    "section": "",
    "text": "data : FrameT | Any\n\nThe data to be used for drafting a validation plan.\n\nmodel : str\n\nThe model to be used. This should be in the form of provider:model (e.g., \"anthropic:claude-sonnet-4-5\"). Supported providers are \"anthropic\", \"openai\", \"ollama\", and \"bedrock\".\n\napi_key : str | None = None\n\nThe API key to be used for the model.\n\nverify_ssl : bool = True\n\nWhether to verify SSL certificates when making requests to the LLM provider. Set to False to disable SSL verification (e.g., when behind a corporate firewall with self-signed certificates). Defaults to True. Use with caution as disabling SSL verification can pose security risks."
  },
  {
    "objectID": "reference/DraftValidation.html#returns",
    "href": "reference/DraftValidation.html#returns",
    "title": "DraftValidation",
    "section": "",
    "text": ": str\n\nThe drafted validation plan."
  },
  {
    "objectID": "reference/DraftValidation.html#constructing-the-model-argument",
    "href": "reference/DraftValidation.html#constructing-the-model-argument",
    "title": "DraftValidation",
    "section": "",
    "text": "The model= argument should be constructed using the provider and model name separated by a colon (provider:model). The provider text can any of:\n\n\"anthropic\" (Anthropic)\n\"openai\" (OpenAI)\n\"ollama\" (Ollama)\n\"bedrock\" (Amazon Bedrock)\n\nThe model name should be the specific model to be used from the provider. Model names are subject to change so consult the provider’s documentation for the most up-to-date model names."
  },
  {
    "objectID": "reference/DraftValidation.html#notes-on-authentication",
    "href": "reference/DraftValidation.html#notes-on-authentication",
    "title": "DraftValidation",
    "section": "",
    "text": "Providing a valid API key as a string in the api_key argument is adequate for getting started but you should consider using a more secure method for handling API keys.\nOne way to do this is to load the API key from an environent variable and retrieve it using the os module (specifically the os.getenv() function). Places to store the API key might include .bashrc, .bash_profile, .zshrc, or .zsh_profile.\nAnother solution is to store one or more model provider API keys in an .env file (in the root of your project). If the API keys have correct names (e.g., ANTHROPIC_API_KEY or OPENAI_API_KEY) then DraftValidation will automatically load the API key from the .env file and there’s no need to provide the api_key argument. An .env file might look like this:\nANTHROPIC_API_KEY=\"your_anthropic_api_key_here\"\nOPENAI_API_KEY=\"your_openai_api_key_here\"\nThere’s no need to have the python-dotenv package installed when using .env files in this way."
  },
  {
    "objectID": "reference/DraftValidation.html#notes-on-ssl-certificate-verification",
    "href": "reference/DraftValidation.html#notes-on-ssl-certificate-verification",
    "title": "DraftValidation",
    "section": "",
    "text": "By default, SSL certificate verification is enabled for all requests to LLM providers. However, in certain network environments (such as corporate networks with self-signed certificates or firewall proxies), you may encounter SSL certificate verification errors.\nTo disable SSL verification, set the verify_ssl parameter to False:\nimport pointblank as pb\n\ndata = pb.load_dataset(dataset=\"nycflights\", tbl_type=\"duckdb\")\n\n# Disable SSL verification for networks with self-signed certificates\npb.DraftValidation(\n    data=data,\n    model=\"anthropic:claude-sonnet-4-5\",\n    verify_ssl=False\n)\n\n\n\n\n\n\nWarning\n\n\n\nDisabling SSL verification (through verify_ssl=False) can expose your API keys and data to man-in-the-middle attacks. Only use this option in trusted network environments and when absolutely necessary."
  },
  {
    "objectID": "reference/DraftValidation.html#notes-on-data-sent-to-the-model-provider",
    "href": "reference/DraftValidation.html#notes-on-data-sent-to-the-model-provider",
    "title": "DraftValidation",
    "section": "",
    "text": "The data sent to the model provider is a JSON summary of the table. This data summary is generated internally by DraftValidation using the DataScan class. The summary includes the following information:\n\nthe number of rows and columns in the table\nthe type of dataset (e.g., Polars, DuckDB, Pandas, etc.)\nthe column names and their types\ncolumn level statistics such as the number of missing values, min, max, mean, and median, etc.\na short list of data values in each column\n\nThe JSON summary is used to provide the model with the necessary information to draft a validation plan. As such, even very large tables can be used with the DraftValidation class since the contents of the table are not sent to the model provider.\nThe Amazon Bedrock is a special case since it is a self-hosted model and security controls are in place to ensure that data is kept within the user’s AWS environment. If using an Ollama model all data is handled locally, though only a few models are capable enough to perform the task of drafting a validation plan."
  },
  {
    "objectID": "reference/DraftValidation.html#examples",
    "href": "reference/DraftValidation.html#examples",
    "title": "DraftValidation",
    "section": "",
    "text": "Let’s look at how the DraftValidation class can be used to draft a validation plan for a table. The table to be used is \"nycflights\", which is available here via the load_dataset() function. The model to be used is \"anthropic:claude-sonnet-4-5\" (which performs very well compared to other LLMs). The example assumes that the API key is stored in an .env file as ANTHROPIC_API_KEY.\nimport pointblank as pb\n\n# Load the \"nycflights\" dataset as a DuckDB table\ndata = pb.load_dataset(dataset=\"nycflights\", tbl_type=\"duckdb\")\n\n# Draft a validation plan for the \"nycflights\" table\npb.DraftValidation(data=data, model=\"anthropic:claude-sonnet-4-5\")\nThe output will be a drafted validation plan for the \"nycflights\" table and this will appear in the console.\n```python\nimport pointblank as pb\n\n# Define schema based on column names and dtypes\nschema = pb.Schema(columns=[\n    (\"year\", \"int64\"),\n    (\"month\", \"int64\"),\n    (\"day\", \"int64\"),\n    (\"dep_time\", \"int64\"),\n    (\"sched_dep_time\", \"int64\"),\n    (\"dep_delay\", \"int64\"),\n    (\"arr_time\", \"int64\"),\n    (\"sched_arr_time\", \"int64\"),\n    (\"arr_delay\", \"int64\"),\n    (\"carrier\", \"string\"),\n    (\"flight\", \"int64\"),\n    (\"tailnum\", \"string\"),\n    (\"origin\", \"string\"),\n    (\"dest\", \"string\"),\n    (\"air_time\", \"int64\"),\n    (\"distance\", \"int64\"),\n    (\"hour\", \"int64\"),\n    (\"minute\", \"int64\")\n])\n\n# The validation plan\nvalidation = (\n    pb.Validate(\n        data=your_data,  # Replace your_data with the actual data variable\n        label=\"Draft Validation\",\n        thresholds=pb.Thresholds(warning=0.10, error=0.25, critical=0.35)\n    )\n    .col_schema_match(schema=schema)\n    .col_vals_not_null(columns=[\n        \"year\", \"month\", \"day\", \"sched_dep_time\", \"carrier\", \"flight\",\n        \"origin\", \"dest\", \"distance\", \"hour\", \"minute\"\n    ])\n    .col_vals_between(columns=\"month\", left=1, right=12)\n    .col_vals_between(columns=\"day\", left=1, right=31)\n    .col_vals_between(columns=\"sched_dep_time\", left=106, right=2359)\n    .col_vals_between(columns=\"dep_delay\", left=-43, right=1301, na_pass=True)\n    .col_vals_between(columns=\"air_time\", left=20, right=695, na_pass=True)\n    .col_vals_between(columns=\"distance\", left=17, right=4983)\n    .col_vals_between(columns=\"hour\", left=1, right=23)\n    .col_vals_between(columns=\"minute\", left=0, right=59)\n    .col_vals_in_set(columns=\"origin\", set=[\"EWR\", \"LGA\", \"JFK\"])\n    .col_count_match(count=18)\n    .row_count_match(count=336776)\n    .rows_distinct()\n    .interrogate()\n)\n\nvalidation\n```\nThe drafted validation plan can be copied and pasted into a Python script or notebook for further use. In other words, the generated plan can be adjusted as needed to suit the specific requirements of the table being validated.\nNote that the output does not know how the data was obtained, so it uses the placeholder your_data in the data= argument of the Validate class. When adapted for use, this should be replaced with the actual data variable."
  },
  {
    "objectID": "reference/Validate.col_exists.html",
    "href": "reference/Validate.col_exists.html",
    "title": "Validate.col_exists",
    "section": "",
    "text": "Validate.col_exists(\n    columns,\n    thresholds=None,\n    actions=None,\n    brief=None,\n    active=True,\n)\nValidate whether one or more columns exist in the table.\nThe col_exists() method checks whether one or more columns exist in the target table. The only requirement is specification of the column names. Each validation step or expectation will operate over a single test unit, which is whether the column exists or not."
  },
  {
    "objectID": "reference/Validate.col_exists.html#parameters",
    "href": "reference/Validate.col_exists.html#parameters",
    "title": "Validate.col_exists",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns : str | list[str] | Column | ColumnSelector | ColumnSelectorNarwhals\n\nA single column or a list of columns to validate. Can also use col() with column selectors to specify one or more columns. If multiple columns are supplied or resolved, there will be a separate validation step generated for each column.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nSet threshold failure levels for reporting and reacting to exceedences of the levels. The thresholds are set at the step level and will override any global thresholds set in Validate(thresholds=...). The default is None, which means that no thresholds will be set locally and global thresholds (if any) will take effect. Look at the Thresholds section for information on how to set threshold levels.\n\nactions : Actions | None = None\n\nOptional actions to take when the validation step(s) meets or exceeds any set threshold levels. If provided, the Actions class should be used to define the actions.\n\nbrief : str | bool | None = None\n\nAn optional brief description of the validation step that will be displayed in the reporting table. You can use the templating elements like \"{step}\" to insert the step number, or \"{auto}\" to include an automatically generated brief. If True the entire brief will be automatically generated. If None (the default) then there won’t be a brief.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.col_exists.html#returns",
    "href": "reference/Validate.col_exists.html#returns",
    "title": "Validate.col_exists",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.col_exists.html#thresholds",
    "href": "reference/Validate.col_exists.html#thresholds",
    "title": "Validate.col_exists",
    "section": "Thresholds",
    "text": "Thresholds\nThe thresholds= parameter is used to set the failure-condition levels for the validation step. If they are set here at the step level, these thresholds will override any thresholds set at the global level in Validate(thresholds=...).\nThere are three threshold levels: ‘warning’, ‘error’, and ‘critical’. The threshold values can either be set as a proportion failing of all test units (a value between 0 to 1), or, the absolute number of failing test units (as integer that’s 1 or greater).\nThresholds can be defined using one of these input schemes:\n\nuse the Thresholds class (the most direct way to create thresholds)\nprovide a tuple of 1-3 values, where position 0 is the ‘warning’ level, position 1 is the ‘error’ level, and position 2 is the ‘critical’ level\ncreate a dictionary of 1-3 value entries; the valid keys: are ‘warning’, ‘error’, and ‘critical’\na single integer/float value denoting absolute number or fraction of failing test units for the ‘warning’ level only\n\nIf the number of failing test units exceeds set thresholds, the validation step will be marked as ‘warning’, ‘error’, or ‘critical’. All of the threshold levels don’t need to be set, you’re free to set any combination of them.\nAside from reporting failure conditions, thresholds can be used to determine the actions to take for each level of failure (using the actions= parameter)."
  },
  {
    "objectID": "reference/Validate.col_exists.html#examples",
    "href": "reference/Validate.col_exists.html#examples",
    "title": "Validate.col_exists",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with a string columns (a) and a numeric column (b). The table is shown below:\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [\"apple\", \"banana\", \"cherry\", \"date\"],\n        \"b\": [1, 6, 3, 5],\n    }\n)\n\npb.preview(tbl)\n\n\n\n\n\n  \n  \n  \n\n\n\n\n\n  \n  aString\n  bInt64\n\n\n\n  \n    1\n    apple\n    1\n  \n  \n    2\n    banana\n    6\n  \n  \n    3\n    cherry\n    3\n  \n  \n    4\n    date\n    5\n  \n\n\n\n\n\n\n        \n\n\nLet’s validate that the columns a and b actually exist in the table. We’ll determine if this validation had any failing test units (each validation will have a single test unit).\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_exists(columns=[\"a\", \"b\"])\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    a\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    b\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nPrinting the validation object shows the validation table in an HTML viewing environment. The validation table shows two entries (one check per column) generated by the col_exists() validation step. Both steps passed since both columns provided in columns= are present in the table.\nNow, let’s check for the existence of a different set of columns.\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_exists(columns=[\"b\", \"c\"])\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    b\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    c\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    00.00\n    11.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe validation table reports one passing validation step (the check for column b) and one failing validation step (the check for column c, which doesn’t exist)."
  },
  {
    "objectID": "reference/first_n.html",
    "href": "reference/first_n.html",
    "title": "first_n",
    "section": "",
    "text": "first_n(n, offset=0)\nSelect the first n columns in the column list.\nMany validation methods have a columns= argument that can be used to specify the columns for validation (e.g., col_vals_gt(), col_vals_regex(), etc.). The first_n() selector function can be used to select n columns positioned at the start of the column list. So if the set of table columns consists of\n[rev_01, rev_02, profit_01, profit_02, age]\nand you want to validate the first two columns, you can use columns=first_n(2). This will select the rev_01 and rev_02 columns and a validation step will be created for each.\nThe offset= parameter can be used to skip a certain number of columns from the start of the column list. So if you want to select the third and fourth columns, you can use columns=first_n(2, offset=2)."
  },
  {
    "objectID": "reference/first_n.html#parameters",
    "href": "reference/first_n.html#parameters",
    "title": "first_n",
    "section": "Parameters",
    "text": "Parameters\n\nn : int\n\nThe number of columns to select from the start of the column list. Should be a positive integer value. If n is greater than the number of columns in the table, all columns will be selected.\n\noffset : int = 0\n\nThe offset from the start of the column list. The default is 0. If offset is greater than the number of columns in the table, no columns will be selected."
  },
  {
    "objectID": "reference/first_n.html#returns",
    "href": "reference/first_n.html#returns",
    "title": "first_n",
    "section": "Returns",
    "text": "Returns\n\n : FirstN\n\nA FirstN object, which can be used to select the first n columns."
  },
  {
    "objectID": "reference/first_n.html#relevant-validation-methods-where-first_n-can-be-used",
    "href": "reference/first_n.html#relevant-validation-methods-where-first_n-can-be-used",
    "title": "first_n",
    "section": "Relevant Validation Methods where first_n() can be Used",
    "text": "Relevant Validation Methods where first_n() can be Used\nThis selector function can be used in the columns= argument of the following validation methods:\n\ncol_vals_gt()\ncol_vals_lt()\ncol_vals_ge()\ncol_vals_le()\ncol_vals_eq()\ncol_vals_ne()\ncol_vals_between()\ncol_vals_outside()\ncol_vals_in_set()\ncol_vals_not_in_set()\ncol_vals_increasing()\ncol_vals_decreasing()\ncol_vals_null()\ncol_vals_not_null()\ncol_vals_regex()\ncol_vals_within_spec()\ncol_exists()\n\nThe first_n() selector function doesn’t need to be used in isolation. Read the next section for information on how to compose it with other column selectors for more refined ways to select columns."
  },
  {
    "objectID": "reference/first_n.html#additional-flexibilty-through-composition-with-other-column-selectors",
    "href": "reference/first_n.html#additional-flexibilty-through-composition-with-other-column-selectors",
    "title": "first_n",
    "section": "Additional Flexibilty through Composition with Other Column Selectors",
    "text": "Additional Flexibilty through Composition with Other Column Selectors\nThe first_n() function can be composed with other column selectors to create fine-grained column selections. For example, to select all column names starting with “rev” along with the first two columns, you can use the first_n() and starts_with() functions together. The only condition is that the expressions are wrapped in the col() function, like this:\ncol(first_n(2) | starts_with(\"rev\"))\nThere are four operators that can be used to compose column selectors:\n\n& (and)\n| (or)\n- (difference)\n~ (not)\n\nThe & operator is used to select columns that satisfy both conditions. The | operator is used to select columns that satisfy either condition. The - operator is used to select columns that satisfy the first condition but not the second. The ~ operator is used to select columns that don’t satisfy the condition. As many selector functions can be used as needed and the operators can be combined to create complex column selection criteria (parentheses can be used to group conditions and control the order of evaluation)."
  },
  {
    "objectID": "reference/first_n.html#examples",
    "href": "reference/first_n.html#examples",
    "title": "first_n",
    "section": "Examples",
    "text": "Examples\nSuppose we have a table with columns paid_2021, paid_2022, paid_2023, paid_2024, and name and we’d like to validate that the values in the first four columns are greater than 10. We can use the first_n() column selector function to specify that the first four columns in the table are the columns to validate.\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"paid_2021\": [17.94, 16.55, 17.85],\n        \"paid_2022\": [18.62, 16.95, 18.25],\n        \"paid_2023\": [19.29, 17.75, 18.35],\n        \"paid_2024\": [20.73, 18.35, 20.10],\n        \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(columns=pb.first_n(4), value=10)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    paid_2021\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    paid_2022\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    paid_2023\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    paid_2024\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nFrom the results of the validation table we get four validation steps. The values in all those columns were all greater than 10.\nWe can also use the first_n() function in combination with other column selectors (within col()) to create more complex column selection criteria (i.e., to select columns that satisfy multiple conditions). For example, to select the first four columns but also omit those columns that end with \"2023\", we can use the - operator to combine column selectors.\n\ntbl = pl.DataFrame(\n    {\n        \"paid_2021\": [17.94, 16.55, 17.85],\n        \"paid_2022\": [18.62, 16.95, 18.25],\n        \"paid_2023\": [19.29, 17.75, 18.35],\n        \"paid_2024\": [20.73, 18.35, 20.10],\n        \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(columns=pb.col(pb.first_n(4) - pb.ends_with(\"2023\")), value=10)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    paid_2021\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    paid_2022\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    paid_2024\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nFrom the results of the validation table we get three validation steps, one for paid_2021, paid_2022, and paid_2024."
  },
  {
    "objectID": "reference/Validate.get_step_report.html",
    "href": "reference/Validate.get_step_report.html",
    "title": "Validate.get_step_report",
    "section": "",
    "text": "Validate.get_step_report(i, columns_subset=None, header=':default:', limit=10)\nGet a detailed report for a single validation step.\nThe get_step_report() method returns a report of what went well—or what failed spectacularly—for a given validation step. The report includes a summary of the validation step and a detailed breakdown of the interrogation results. The report is presented as a GT table object, which can be displayed in a notebook or exported to an HTML file."
  },
  {
    "objectID": "reference/Validate.get_step_report.html#parameters",
    "href": "reference/Validate.get_step_report.html#parameters",
    "title": "Validate.get_step_report",
    "section": "Parameters",
    "text": "Parameters\n\ni : int\n\nThe step number for which to get the report.\n\ncolumns_subset : str | list[str] | Column | None = None\n\nThe columns to display in a step report that shows errors in the input table. By default all columns are shown (None). If a subset of columns is desired, we can provide a list of column names, a string with a single column name, a Column object, or a ColumnSelector object. The last two options allow for more flexible column selection using column selector functions. Errors are raised if the column names provided don’t match any columns in the table (when provided as a string or list of strings) or if column selector expressions don’t resolve to any columns.\n\nheader : str = ':default:'\n\nOptions for customizing the header of the step report. The default is the \":default:\" value which produces a header with a standard title and set of details underneath. Aside from this default, free text can be provided for the header. This will be interpreted as Markdown text and transformed internally to HTML. You can provide one of two templating elements: {title} and {details}. The default header has the template \"{title}{details}\" so you can easily start from that and modify as you see fit. If you don’t want a header at all, you can set header=None to remove it entirely.\n\nlimit : int | None = 10\n\nThe number of rows to display for those validation steps that check values in rows (the col_vals_*() validation steps). The default is 10 rows and the limit can be removed entirely by setting limit=None."
  },
  {
    "objectID": "reference/Validate.get_step_report.html#returns",
    "href": "reference/Validate.get_step_report.html#returns",
    "title": "Validate.get_step_report",
    "section": "Returns",
    "text": "Returns\n\n : GT\n\nA GT table object that represents the detailed report for the validation step."
  },
  {
    "objectID": "reference/Validate.get_step_report.html#types-of-step-reports",
    "href": "reference/Validate.get_step_report.html#types-of-step-reports",
    "title": "Validate.get_step_report",
    "section": "Types of Step Reports",
    "text": "Types of Step Reports\nThe get_step_report() method produces a report based on the type of validation step. The following column-value or row-based validation step validation methods will produce a report that shows the rows of the data that failed:\n\ncol_vals_gt()\ncol_vals_ge()\ncol_vals_lt()\ncol_vals_le()\ncol_vals_eq()\ncol_vals_ne()\ncol_vals_between()\ncol_vals_outside()\ncol_vals_in_set()\ncol_vals_not_in_set()\ncol_vals_increasing()\ncol_vals_decreasing()\ncol_vals_null()\ncol_vals_not_null()\ncol_vals_regex()\ncol_vals_within_spec()\ncol_vals_expr()\nconjointly()\nprompt()\nrows_complete()\n\nThe rows_distinct() validation step will produce a report that shows duplicate rows (or duplicate values in one or a set of columns as defined in that method’s columns_subset= parameter.\nThe col_schema_match() validation step will produce a report that shows the schema of the data table and the schema of the validation step. The report will indicate whether the schemas match or not."
  },
  {
    "objectID": "reference/Validate.get_step_report.html#examples",
    "href": "reference/Validate.get_step_report.html#examples",
    "title": "Validate.get_step_report",
    "section": "Examples",
    "text": "Examples\nLet’s create a validation plan with a few validation steps and interrogate the data. With that, we’ll have a look at the validation reporting table for the entire collection of steps and what went well or what failed.\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"pandas\"),\n        tbl_name=\"small_table\",\n        label=\"Example for the get_step_report() method\",\n        thresholds=(1, 0.20, 0.40)\n    )\n    .col_vals_lt(columns=\"d\", value=3500)\n    .col_vals_between(columns=\"c\", left=1, right=8)\n    .col_vals_gt(columns=\"a\", value=3)\n    .col_vals_regex(columns=\"b\", pattern=r\"[0-9]-[a-z]{3}-[0-9]{3}\")\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #AAAAAA\n    1\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    d\n    3500\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    ●\n    ○\n    ○\n    CSV\n  \n  \n    #EBBC14\n    2\n    \n        \n            \n\n    col_vals_between\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_between()\n        \n        \n        \n    c\n    [1, 8]\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    90.69\n    40.31\n    ●\n    ●\n    ○\n    CSV\n  \n  \n    #FF3300\n    3\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    a\n    3\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    60.46\n    70.54\n    ●\n    ●\n    ●\n    CSV\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    b\n    [0-9]-[a-z]{3}-[0-9]{3}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n\n\n\n\n\n\n        \n\n\nThere were four validation steps performed, where the first three steps had failing test units and the last step had no failures. Let’s get a detailed report for the first step by using the get_step_report() method.\n\nvalidation.get_step_report(i=1)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 1ASSERTION d &lt; 35002 / 13 TEST UNIT FAILURES IN COLUMN 6 EXTRACT OF ALL 2 ROWS (WITH TEST UNIT FAILURES IN RED):\n  \n\n  \n  date_timedatetime64[ns]\n  datedatetime64[ns]\n  aint64\n  bobject\n  cfloat64\n  dfloat64\n  ebool\n  fobject\n\n\n\n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04 00:00:00\n    3\n    5-egh-163\n    8.0\n    9999.99\n    True\n    low\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06 00:00:00\n    2\n    5-jdo-903\n    \n    3892.4\n    False\n    mid\n  \n\n\n\n\n\n\n        \n\n\nThe report for the first step is displayed. The report includes a summary of the validation step and a detailed breakdown of the interrogation results. The report provides details on what the validation step was checking, the extent to which the test units failed, and a table that shows the failing rows of the data with the column of interest highlighted.\nThe second and third steps also had failing test units. Reports for those steps can be viewed by using get_step_report(i=2) and get_step_report(i=3) respectively.\nThe final step did not have any failing test units. A report for the final step can still be viewed by using get_step_report(i=4). The report will indicate that every test unit passed and a prview of the target table will be provided.\n\nvalidation.get_step_report(i=4)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 4 ✓ASSERTION b matches regex [0-9]-[a-z]{3}-[0-9]{3}13 TEST UNITS ALL PASSED IN COLUMN 4PREVIEW OF TARGET TABLE:\n  \n\n  \n  date_timedatetime64[ns]\n  datedatetime64[ns]\n  aint64\n  bobject\n  cfloat64\n  dfloat64\n  ebool\n  fobject\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04 00:00:00\n    2\n    1-bcd-345\n    3.0\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04 00:00:00\n    3\n    5-egh-163\n    8.0\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05 00:00:00\n    6\n    8-kdg-938\n    3.0\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06 00:00:00\n    2\n    5-jdo-903\n    NA\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09 00:00:00\n    8\n    3-ldm-038\n    7.0\n    283.94\n    True\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20 00:00:00\n    3\n    5-bce-642\n    9.0\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20 00:00:00\n    3\n    5-bce-642\n    9.0\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26 00:00:00\n    4\n    2-dmx-010\n    7.0\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28 00:00:00\n    2\n    7-dmx-010\n    8.0\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30 00:00:00\n    1\n    3-dka-303\n    NA\n    2230.09\n    True\n    high\n  \n\n\n\n\n\n\n        \n\n\nIf you’d like to trim down the number of columns shown in the report, you can provide a subset of columns to display. For example, if you only want to see the columns a, b, and c, you can provide those column names as a list.\n\nvalidation.get_step_report(i=1, columns_subset=[\"a\", \"b\", \"c\"])\n\n\n\n\n\n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 1ASSERTION d &lt; 35002 / 13 TEST UNIT FAILURES IN COLUMN 6 (NOT SHOWN)EXTRACT OF ALL 2 ROWS :\n  \n\n  \n  aint64\n  bobject\n  cfloat64\n\n\n\n  \n    2\n    3\n    5-egh-163\n    8.0\n  \n  \n    4\n    2\n    5-jdo-903\n    \n  \n\n\n\n\n\n\n        \n\n\nIf you’d like to increase or reduce the maximum number of rows shown in the report, you can provide a different value for the limit parameter. For example, if you’d like to see only up to 5 rows, you can set limit=5.\n\nvalidation.get_step_report(i=3, limit=5)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 3ASSERTION a &gt; 37 / 13 TEST UNIT FAILURES IN COLUMN 3 EXTRACT OF FIRST 5 ROWS (WITH TEST UNIT FAILURES IN RED):\n  \n\n  \n  date_timedatetime64[ns]\n  datedatetime64[ns]\n  aint64\n  bobject\n  cfloat64\n  dfloat64\n  ebool\n  fobject\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04 00:00:00\n    2\n    1-bcd-345\n    3.0\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04 00:00:00\n    3\n    5-egh-163\n    8.0\n    9999.99\n    True\n    low\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06 00:00:00\n    2\n    5-jdo-903\n    \n    3892.4\n    False\n    mid\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20 00:00:00\n    3\n    5-bce-642\n    9.0\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20 00:00:00\n    3\n    5-bce-642\n    9.0\n    837.93\n    False\n    high\n  \n\n\n\n\n\n\n        \n\n\nStep 3 actually had 7 failing test units, but only the first 5 rows are shown in the step report because of the limit=5 parameter."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Pointblank",
    "section": "",
    "text": "Data validation toolkit for assessing and monitoring data quality.\nPointblank is a data validation framework for Python that makes data quality checks beautiful, powerful, and stakeholder-friendly. Instead of cryptic error messages, get stunning interactive reports that turn data issues into conversations.\nHere’s what a validation looks like (click “Show the code” to see how it’s done):\nShow the code\nimport pointblank as pb\nimport polars as pl\n\nvalidation = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"polars\"),\n        tbl_name=\"game_revenue\",\n        label=\"Comprehensive validation of game revenue data\",\n        thresholds=pb.Thresholds(warning=0.10, error=0.25, critical=0.35),\n        brief=True\n    )\n    .col_vals_regex(columns=\"player_id\", pattern=r\"^[A-Z]{12}[0-9]{3}$\")        # STEP 1\n    .col_vals_gt(columns=\"session_duration\", value=20)                          # STEP 2\n    .col_vals_ge(columns=\"item_revenue\", value=0.20)                            # STEP 3\n    .col_vals_in_set(columns=\"item_type\", set=[\"iap\", \"ad\"])                    # STEP 4\n    .col_vals_in_set(                                                           # STEP 5\n        columns=\"acquisition\",\n        set=[\"google\", \"facebook\", \"organic\", \"crosspromo\", \"other_campaign\"]\n    )\n    .col_vals_not_in_set(columns=\"country\", set=[\"Mongolia\", \"Germany\"])        # STEP 6\n    .col_vals_between(                                                          # STEP 7\n        columns=\"session_duration\",\n        left=10, right=50,\n        pre = lambda df: df.select(pl.median(\"session_duration\")),\n        brief=\"Expect that the median of `session_duration` should be between `10` and `50`.\"\n    )\n    .rows_distinct(columns_subset=[\"player_id\", \"session_id\", \"time\"])          # STEP 8\n    .row_count_match(count=2000)                                                # STEP 9\n    .col_count_match(count=11)                                                  # STEP 10\n    .col_vals_not_null(columns=\"item_type\")                                     # STEP 11\n    .col_exists(columns=\"start_day\")                                            # STEP 12\n    .interrogate()\n)\n\nvalidation.get_tabular_report(title=\"Game Revenue Validation Report\")\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Game Revenue Validation Report\n\n  \n  \n    Comprehensive validation of game revenue dataPolarsgame_revenueWARNING0.1ERROR0.25CRITICAL0.35\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        Expect that values in player_id should match the regular expression: ^[A-Z]{12}[0-9]{3}$.\n\n        \n    player_id\n    ^[A-Z]{12}[0-9]{3}$\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #EBBC14\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Expect that values in session_duration should be &gt; 20.\n\n        \n    session_duration\n    20\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    14180.71\n    5820.29\n    ●\n    ●\n    ○\n    CSV\n  \n  \n    #FF3300\n    3\n    \n        \n            \n\n    col_vals_ge\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_ge()\n        \n        Expect that values in item_revenue should be &gt;= 0.2.\n\n        \n    item_revenue\n    0.2\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    11920.60\n    8080.40\n    ●\n    ●\n    ●\n    CSV\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Expect that values in item_type should be in the set of iap, ad.\n\n        \n    item_type\n    iap, ad\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C66\n    5\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Expect that values in acquisition should be in the set of google, facebook, organic, and 2 more.\n\n        \n    acquisition\n    google, facebook, organic, crosspromo, other_campaign\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    19750.99\n    250.01\n    ○\n    ○\n    ○\n    CSV\n  \n  \n    #AAAAAA\n    6\n    \n        \n            \n\n    col_vals_not_in_set\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_in_set()\n        \n        Expect that values in country should not be in the set of Mongolia, Germany.\n\n        \n    country\n    Mongolia, Germany\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    17750.89\n    2250.11\n    ●\n    ○\n    ○\n    CSV\n  \n  \n    #4CA64C\n    7\n    \n        \n            \n\n    col_vals_between\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_between()\n        \n        Expect that the median of session_duration should be between 10 and 50.\n\n        \n    session_duration\n    [10, 50]\n    \n    \n        \n            \n            \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C66\n    8\n    \n        \n            \n\n    rows_distinct\n    \n        \n            \n            \n                \n                \n                \n            \n        \n    \n\n        \n        \n            rows_distinct()\n        \n        Expect entirely distinct rows across player_id, session_id, time.\n\n        \n    player_id, session_id, time\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    19780.99\n    220.01\n    ○\n    ○\n    ○\n    CSV\n  \n  \n    #4CA64C\n    9\n    \n        \n            \n\n    row_count_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            row_count_match()\n        \n        Expect that the row count is exactly 2000.\n\n        \n    —\n    2000\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C\n    10\n    \n        \n            \n\n    col_count_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            col_count_match()\n        \n        Expect that the column count is exactly 11.\n\n        \n    —\n    11\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C\n    11\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        Expect that all values in item_type should not be Null.\n\n        \n    item_type\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C\n    12\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column start_day exists.\n\n        \n    start_day\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:10:50 UTC&lt; 1 s2025-11-23 00:10:50 UTC\nThat’s the kind of report you get from Pointblank: clear, interactive, and designed for everyone on your team. And if you need help getting started or want to work faster, Pointblank has built-in AI support through the assistant() function to guide you along the way. You can also use DraftValidation to quickly generate a validation plan from your existing data (great for getting started fast).\nReady to validate? Start with our Installation guide or jump straight to the User Guide.\nBy the way, Pointblank is made with 💙 by Posit.",
    "crumbs": [
      "Get Started",
      "Welcome to Pointblank"
    ]
  },
  {
    "objectID": "index.html#what-is-data-validation",
    "href": "index.html#what-is-data-validation",
    "title": "Pointblank",
    "section": "What is Data Validation?",
    "text": "What is Data Validation?\nData validation ensures your data meets quality standards before it’s used in analysis, reports, or downstream systems. Pointblank provides a structured way to define validation rules, execute them, and communicate results to both technical and non-technical stakeholders.\nWith Pointblank you can:\n\nValidate data through a fluent, chainable API with 25+ validation methods\nSet thresholds to define acceptable levels of data quality (warning, error, critical)\nTake actions when thresholds are exceeded (notifications, logging, custom functions)\nGenerate reports that make data quality issues immediately understandable\nInspect data with built-in tools for previewing, summarizing, and finding missing values",
    "crumbs": [
      "Get Started",
      "Welcome to Pointblank"
    ]
  },
  {
    "objectID": "index.html#why-pointblank",
    "href": "index.html#why-pointblank",
    "title": "Pointblank",
    "section": "Why Pointblank?",
    "text": "Why Pointblank?\nPointblank is designed for the entire data team, not just engineers:\n\n🎨 Beautiful Reports: Interactive validation reports that stakeholders actually want to read\n📊 Threshold Management: Define quality standards with warning, error, and critical levels\n🔍 Error Drill-Down: Inspect failing data to get to root causes quickly\n🔗 Universal Compatibility: Works with Polars, Pandas, DuckDB, MySQL, PostgreSQL, SQLite, and more\n🌍 Multilingual Support: Reports available in 40 languages for global teams\n📝 YAML Support: Write validations in YAML for version control and team collaboration\n⚡ CLI Tools: Run validations from the command line for CI/CD pipelines or as quick checks\n📋 Rich Inspection: Preview data, analyze columns, and visualize missing values",
    "crumbs": [
      "Get Started",
      "Welcome to Pointblank"
    ]
  },
  {
    "objectID": "index.html#quick-examples",
    "href": "index.html#quick-examples",
    "title": "Pointblank",
    "section": "Quick Examples",
    "text": "Quick Examples\n\nThreshold-Based Quality\nSet expectations and react when data quality degrades (with alerts, logging, or custom functions):\nvalidation = (\n    pb.Validate(data=sales_data, thresholds=(0.01, 0.02, 0.05)) # Three threhold levels set\n    .col_vals_not_null(columns=\"customer_id\")\n    .col_vals_in_set(columns=\"status\", set=[\"pending\", \"shipped\", \"delivered\"])\n    .interrogate()\n)\n\n\nYAML Workflows\nWorks wonderfully for CI/CD pipelines and team collaboration:\nvalidate:\n  data: sales_data\n  tbl_name: \"sales_data\"\n  thresholds: [0.01, 0.02, 0.05]\n\nsteps:\n  - col_vals_not_null:\n      columns: \"customer_id\"\n  - col_vals_in_set:\n      columns: \"status\"\n      set: [\"pending\", \"shipped\", \"delivered\"]\nvalidation = pb.yaml_interrogate(\"validation.yaml\")\n\n\nCommand Line Power\nRun validations without writing code:\n# Quick validation\npb validate sales_data.csv --check col-vals-not-null --column customer_id\n\n# Run YAML workflows\npb run validation.yaml --exit-code  # &lt;- Great for CI/CD!\n\n# Explore your data\npb scan sales_data.csv\npb missing sales_data.csv",
    "crumbs": [
      "Get Started",
      "Welcome to Pointblank"
    ]
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "Pointblank",
    "section": "Installation",
    "text": "Installation\nInstall Pointblank using pip or conda:\npip install pointblank\n# or\nconda install conda-forge::pointblank\nFor specific backends:\npip install \"pointblank[pl]\"       # Polars support\npip install \"pointblank[pd]\"       # Pandas support\npip install \"pointblank[duckdb]\"   # DuckDB support\npip install \"pointblank[postgres]\" # PostgreSQL support\nSee the Installation guide for more details.",
    "crumbs": [
      "Get Started",
      "Welcome to Pointblank"
    ]
  },
  {
    "objectID": "index.html#text-formats",
    "href": "index.html#text-formats",
    "title": "Pointblank",
    "section": "Text Formats",
    "text": "Text Formats\nThe docs are also available in llms.txt format:\n\nllms.txt: a sitemap listing all documentation pages\nllms-full.txt: all the documentation in one file",
    "crumbs": [
      "Get Started",
      "Welcome to Pointblank"
    ]
  },
  {
    "objectID": "index.html#join-the-community",
    "href": "index.html#join-the-community",
    "title": "Pointblank",
    "section": "Join the Community",
    "text": "Join the Community\nWe’d love to hear from you! Connect with us:\n\nGitHub Issues for bug reports and feature requests\nDiscord server for discussions and help\nContributing guidelines if you’d like to contribute\n\n\nLicense: MIT | © 2024-2025 Posit Software, PBC",
    "crumbs": [
      "Get Started",
      "Welcome to Pointblank"
    ]
  },
  {
    "objectID": "user-guide-pdf.html",
    "href": "user-guide-pdf.html",
    "title": "CLI Reference",
    "section": "",
    "text": "Data validation toolkit for assessing and monitoring data quality.\n\n\n© 2024–2025 Posit Software, PBC"
  },
  {
    "objectID": "user-guide-pdf.html#validation-methods",
    "href": "user-guide-pdf.html#validation-methods",
    "title": "CLI Reference",
    "section": "1.1 Validation Methods",
    "text": "1.1 Validation Methods\nPointblank’s core functionality revolves around validation steps, which are individual checks that verify different aspects of your data. These steps are created by calling validation methods from the Validate class. When combined they create a comprehensive validation plan for your data.\nHere’s an example of a validation that incorporates three different validation methods:\n\nimport pointblank as pb\nimport polars as pl\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"),\n        label=\"Three different validation methods.\"\n    )\n    .col_vals_gt(columns=\"a\", value=0)\n    .rows_distinct()\n    .col_exists(columns=\"date\")\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Three different validation methods.Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    a\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    rows_distinct\n    \n        \n            \n            \n                \n                \n                \n            \n        \n    \n\n        \n        \n            rows_distinct()\n        \n        \n        \n    ALL COLUMNS\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    90.69\n    20.15\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    date\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThis example showcases how you can combine different types of validations in a single validation plan:\n\na column value validation with Validate.col_vals_gt()\na row-based validation with Validate.rows_distinct()\na table structure validation with Validate.col_exists()\n\nMost validation methods share common parameters that enhance their flexibility and power. These shared parameters (overviewed in the next few sections) create a consistent interface across all validation steps while allowing you to customize validation behavior for specific needs."
  },
  {
    "objectID": "user-guide-pdf.html#column-selection-patterns",
    "href": "user-guide-pdf.html#column-selection-patterns",
    "title": "CLI Reference",
    "section": "1.2 Column Selection Patterns",
    "text": "1.2 Column Selection Patterns\nYou can apply the same validation logic to multiple columns at once through use of column selection patterns (used in the columns= parameter). This reduces repetitive code and makes your validation plans more maintainable:\n\nimport narwhals.selectors as nws\n\n# Map validations across multiple columns\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"),\n        label=\"Applying column mapping in `columns`.\"\n    )\n\n    # Apply validation rules to multiple columns ---\n    .col_vals_not_null(\n        columns=[\"a\", \"b\", \"c\"]\n    )\n\n    # Apply to numeric columns only with a Narwhals selector ---\n    .col_vals_gt(\n        columns=nws.numeric(),\n        value=0\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Applying column mapping in `columns`.Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    a\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    b\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C66\n    3\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    c\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    a\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C66\n    5\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    c\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    6\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThis technique is particularly valuable when working with wide datasets containing many similarly-structured columns or when applying standard quality checks across an entire table. It also ensures consistency in how validation rules are applied across related data columns."
  },
  {
    "objectID": "user-guide-pdf.html#preprocessing",
    "href": "user-guide-pdf.html#preprocessing",
    "title": "CLI Reference",
    "section": "1.3 Preprocessing",
    "text": "1.3 Preprocessing\nPreprocessing (with the pre= parameter) allows you to transform or modify your data before applying validation checks, enabling you to validate derived or modified data without altering the original dataset:\n\nimport polars as pl\n\n# Define preprocessing functions for `pre=` parameters\ndef double_column_a(df):\n    return df.with_columns(pl.col(\"a\") * 2)\n\ndef square_column_c(df):\n    return df.with_columns(pl.col(\"c\").pow(2))\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"),\n        label=\"Preprocessing validation steps via `pre=`.\"\n    )\n    .col_vals_gt(\n        columns=\"a\", value=5,\n\n        # Apply transformation before validation ---\n        pre=double_column_a  # Double values before checking\n    )\n    .col_vals_lt(\n        columns=\"c\", value=100,\n\n        # Apply more complex transformation ---\n        pre=square_column_c  # Square values before checking\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Preprocessing validation steps via `pre=`.Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    a\n    5\n    \n    \n        \n            \n            \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    90.69\n    40.31\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    c\n    100\n    \n    \n        \n            \n            \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nPreprocessing enables validation of transformed data without modifying your original dataset, making it ideal for checking derived metrics, or validating normalized values. This approach keeps your validation code clean while allowing for sophisticated data quality checks on calculated results."
  },
  {
    "objectID": "user-guide-pdf.html#segmentation",
    "href": "user-guide-pdf.html#segmentation",
    "title": "CLI Reference",
    "section": "1.4 Segmentation",
    "text": "1.4 Segmentation\nSegmentation (through the segments= parameter) allows you to validate data across different groups, enabling you to identify segment-specific quality issues that might be hidden in aggregate analyses:\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"),\n        label=\"Segmenting validation steps via `segments=`.\"\n    )\n    .col_vals_gt(\n        columns=\"c\", value=3,\n\n        # Split into steps by categorical values in column 'f' ---\n        segments=\"f\"\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Segmenting validation steps via `segments=`.Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    SEGMENT  f / high \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    c\n    3\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    20.33\n    40.67\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    SEGMENT  f / low \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    c\n    3\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    40.80\n    10.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    3\n    SEGMENT  f / mid \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    c\n    3\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    2\n    10.50\n    10.50\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nSegmentation is powerful for detecting patterns of quality issues that may exist only in specific data subsets, such as certain time periods, categories, or geographical regions. It helps ensure that all significant segments of your data meet quality standards, not just the data as a whole."
  },
  {
    "objectID": "user-guide-pdf.html#thresholds",
    "href": "user-guide-pdf.html#thresholds",
    "title": "CLI Reference",
    "section": "1.5 Thresholds",
    "text": "1.5 Thresholds\nThresholds (set through the thresholds= parameter) let you set acceptable levels of failure before triggering warnings, errors, or critical notifications for individual validation steps:\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"),\n        label=\"Using thresholds.\"\n    )\n\n    # Add validation steps with different thresholds ---\n    .col_vals_gt(\n        columns=\"a\", value=1,\n        thresholds=pb.Thresholds(warning=0.1, error=0.2, critical=0.3)\n    )\n\n    # Add another step with stricter thresholds ---\n    .col_vals_lt(\n        columns=\"c\", value=10,\n        thresholds=pb.Thresholds(warning=0.05, error=0.1)\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Using thresholds.Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    a\n    1\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    120.92\n    10.08\n    ○\n    ○\n    ○\n    CSV\n  \n  \n    #EBBC14\n    2\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    c\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    ●\n    ●\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThresholds provide a nuanced way to monitor data quality, allowing you to set different severity levels based on the importance of each validation and your organization’s tolerance for specific types of data issues."
  },
  {
    "objectID": "user-guide-pdf.html#actions",
    "href": "user-guide-pdf.html#actions",
    "title": "CLI Reference",
    "section": "1.6 Actions",
    "text": "1.6 Actions\nActions (which can be configured in the actions= parameter) allow you to define specific responses when validation thresholds are crossed. You can use simple string messages or custom functions for more complex behavior:\n\n# Example 1: Action with a string message ---\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"),\n        label=\"Using actions with a string message.\"\n    )\n    .col_vals_gt(\n        columns=\"c\", value=2,\n        thresholds=pb.Thresholds(warning=0.1, error=0.2),\n\n        # Add a print-to-console action for the 'warning' threshold ---\n        actions=pb.Actions(\n            warning=\"WARNING: Values below `{value}` detected in column 'c'.\"\n        )\n    )\n    .interrogate()\n)\n\nWARNING: Values below `2` detected in column 'c'.\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Using actions with a string message.Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #EBBC14\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    c\n    2\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    100.77\n    30.23\n    ●\n    ●\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\n\n# Example 2: Action with a callable function ---\n\ndef custom_action():\n    from datetime import datetime\n    print(f\"Data quality issue found ({datetime.now()}).\")\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"),\n        label=\"Using actions with a callable function.\"\n    )\n    .col_vals_gt(\n        columns=\"a\", value=5,\n        thresholds=pb.Thresholds(warning=0.1, error=0.2),\n\n        # Apply the function to the 'error' threshold ---\n        actions=pb.Actions(error=custom_action)\n    )\n    .interrogate()\n)\n\nData quality issue found (2025-11-23 00:08:34.135669).\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Using actions with a callable function.Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #EBBC14\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    a\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    30.23\n    100.77\n    ●\n    ●\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nWith custom action functions, you can implement sophisticated responses like sending notifications or logging to external systems."
  },
  {
    "objectID": "user-guide-pdf.html#briefs",
    "href": "user-guide-pdf.html#briefs",
    "title": "CLI Reference",
    "section": "1.7 Briefs",
    "text": "1.7 Briefs\nBriefs (which can be set through the brief= parameter) allow you to customize descriptions associated with validation steps, making validation results more understandable to stakeholders. Briefs can be either automatically generated by setting brief=True or defined as custom messages for more specific explanations:\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"),\n        label=\"Using `brief=` for displaying brief messages.\"\n    )\n    .col_vals_gt(\n        columns=\"a\", value=0,\n\n        # Use `True` for automatic generation of briefs ---\n        brief=True\n    )\n    .col_exists(\n        columns=[\"date\", \"date_time\"],\n\n        # Add a custom brief for this validation step ---\n        brief=\"Verify required date columns exist for time-series analysis\"\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Using `brief=` for displaying brief messages.Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Expect that values in a should be &gt; 0.\n\n        \n    a\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Verify required date columns exist for time-series analysis\n\n        \n    date\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Verify required date columns exist for time-series analysis\n\n        \n    date_time\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nBriefs make validation results more meaningful by providing context about why each check matters. They’re particularly valuable in shared reports where stakeholders from various disciplines need to understand validation results in domain-specific terms."
  },
  {
    "objectID": "user-guide-pdf.html#getting-more-information",
    "href": "user-guide-pdf.html#getting-more-information",
    "title": "CLI Reference",
    "section": "1.8 Getting More Information",
    "text": "1.8 Getting More Information\nEach validation step can be further customized and has additional options. See these pages for more information:\n\nValidation Methods: A closer look at the more common validation methods\nColumn Selection Patterns: Techniques for targeting specific columns\nPreprocessing: Transform data before validation\nSegmentation: Apply validations to specific segments of your data\nThresholds: Set quality standards and trigger severity levels\nActions: Respond to threshold exceedances with notifications or custom functions\nBriefs: Add context to validation steps"
  },
  {
    "objectID": "user-guide-pdf.html#conclusion",
    "href": "user-guide-pdf.html#conclusion",
    "title": "CLI Reference",
    "section": "1.9 Conclusion",
    "text": "1.9 Conclusion\nValidation steps are the building blocks of data validation in Pointblank. By combining steps from different categories and leveraging common features like thresholds, actions, and preprocessing, you can create comprehensive data quality checks tailored to your specific needs.\nThe next sections of this guide will dive deeper into each of these topics, providing detailed explanations and examples.\nPointblank provides a comprehensive suite of validation methods to verify different aspects of your data. Each method creates a validation step that becomes part of your validation plan.\nThese validation methods cover everything from checking column values against thresholds to validating the table structure and detecting duplicates. Combined into validation steps, they form the foundation of your data quality workflow.\nPointblank provides over 25 validation methods to handle diverse data quality requirements. These are grouped into three main categories:\n\nColumn Value Validations\nRow-based Validations\nTable Structure Validations\nAI-Powered Validations\n\nWithin each of these categories, we’ll walk through several examples showing how each validation method creates steps in your validation plan.\nAnd we’ll use the small_table dataset for all of our examples. Here’s a preview of it:\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows13Columns8\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05\n    6\n    8-kdg-938\n    3\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    None\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09\n    8\n    3-ldm-038\n    7\n    283.94\n    True\n    low\n  \n  \n    6\n    2016-01-11 06:15:00\n    2016-01-11\n    4\n    2-dhe-923\n    4\n    3291.03\n    True\n    mid\n  \n  \n    7\n    2016-01-15 18:46:00\n    2016-01-15\n    7\n    1-knw-093\n    3\n    843.34\n    True\n    high\n  \n  \n    8\n    2016-01-17 11:27:00\n    2016-01-17\n    4\n    5-boe-639\n    2\n    1035.64\n    False\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26\n    4\n    2-dmx-010\n    7\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28\n    2\n    7-dmx-010\n    8\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30\n    1\n    3-dka-303\n    None\n    2230.09\n    True\n    high"
  },
  {
    "objectID": "user-guide-pdf.html#validation-methods-to-validation-steps",
    "href": "user-guide-pdf.html#validation-methods-to-validation-steps",
    "title": "CLI Reference",
    "section": "1.10 Validation Methods to Validation Steps",
    "text": "1.10 Validation Methods to Validation Steps\nIn Pointblank, validation methods become validation steps when you add them to a validation plan. Each method creates a distinct step that performs a specific check on your data.\nHere’s a simple example showing how three validation methods create three validation steps:\n\nimport pointblank as pb\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n\n    # Step 1: Check that values in column `a` are greater than 2 ---\n    .col_vals_gt(columns=\"a\", value=2, brief=\"Values in 'a' must exceed 2.\")\n\n    # Step 2: Check that column 'date' exists in the table ---\n    .col_exists(columns=\"date\", brief=\"Column 'date' must exist.\")\n\n    # Step 3: Check that the table has exactly 13 rows ---\n    .row_count_match(count=13, brief=\"Table should have exactly 13 rows.\")\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Values in 'a' must exceed 2.\n\n        \n    a\n    2\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    90.69\n    40.31\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Column 'date' must exist.\n\n        \n    date\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    row_count_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            row_count_match()\n        \n        Table should have exactly 13 rows.\n\n        \n    —\n    13\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nEach validation method produces one step in the validation report above. When combined, these steps form a complete validation plan that systematically checks different aspects of your data quality."
  },
  {
    "objectID": "user-guide-pdf.html#common-arguments",
    "href": "user-guide-pdf.html#common-arguments",
    "title": "CLI Reference",
    "section": "1.11 Common Arguments",
    "text": "1.11 Common Arguments\nMost validation methods in Pointblank share a set of common arguments that provide consistency and flexibility across different validation types:\n\ncolumns=: specifies which column(s) to validate (used in column-based validations)\npre=: allows data transformation before validation\nsegments=: enables validation across different data subsets\nthresholds=: sets acceptable failure thresholds\nactions=: defines actions to take when validations fail\nbrief=: provides a description of what the validation is checking\nactive=: determines if the validation step should be executed (default is True)\nna_pass=: controls how missing values are handled (only for column value validation methods)\n\nFor column validation methods, the na_pass= parameter determines whether missing values (Null/None/NA) should pass validation (this parameter is covered in a later section).\nThese arguments follow a consistent pattern across validation methods, so you don’t need to memorize different parameter sets for each function. This systematic approach makes Pointblank more intuitive to work with as you build increasingly complex validation plans.\nWe’ll cover most of these common arguments in their own dedicated sections later in the User Guide, as some of them represent a deeper topic worthy of focused attention."
  },
  {
    "objectID": "user-guide-pdf.html#column-value-validations",
    "href": "user-guide-pdf.html#column-value-validations",
    "title": "CLI Reference",
    "section": "1.12 1. Column Value Validations",
    "text": "1.12 1. Column Value Validations\nThese methods check individual values within columns against specific criteria:\n\nComparison checks (col_vals_gt(), col_vals_lt(), etc.) for comparing values to thresholds or other columns\nRange checks (col_vals_between(), col_vals_outside()) for verifying that values fall within or outside specific ranges\nSet membership checks (col_vals_in_set(), col_vals_not_in_set()) for validating values against predefined sets\nNull value checks (col_vals_null(), col_vals_not_null()) for testing presence or absence of null values\nPattern matching checks (col_vals_regex(), col_vals_within_spec()) for validating text patterns with regular expressions or against standard specifications\nTrending value checks (col_vals_increasing(), col_vals_decreasing()) for verifying that values increase or decrease as you move down the rows\nCustom expression checks (col_vals_expr()) for complex validations using custom expressions\n\nNow let’s look at some key examples from select categories of column value validations.\n\n1.12.1 Comparison Checks\nLet’s start with a simple example of how col_vals_gt() might be used to check if the values in a column are greater than a specified value.\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .col_vals_gt(columns=\"a\", value=5)\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    a\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    30.23\n    100.77\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nIf you’re checking data in a column that contains Null/None/NA values and you’d like to disregard those values (i.e., let them pass validation), you can use na_pass=True. The following example checks values in column c of small_table, which contains two None values:\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .col_vals_le(columns=\"c\", value=10, na_pass=True)\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_le\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_le()\n        \n        \n        \n    c\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nIn the above validation table, we see that all test units passed. If we didn’t use na_pass=True there would be 2 failing test units, one for each None value in the c column.\nIt’s possible to check against column values against values in an adjacent column. To do this, supply the value= argument with the column name within the col() helper function. Here’s an example of that:\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .col_vals_lt(columns=\"a\", value=pb.col(\"c\"))\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    a\n    c\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    60.46\n    70.54\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThis validation checks that values in column a are less than values in column c.\n\n\n1.12.2 Checking of Missing Values\nA very common thing to validate is that there are no Null/NA/missing values in a column. The col_vals_not_null() method checks for the presence of missing values:\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .col_vals_not_null(columns=\"a\")\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    a\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nColumn a has no missing values and the above validation proves this.\n\n\n1.12.3 Checking Strings with Regexes\nA regular expression (regex) validation via the col_vals_regex() validation method checks if values in a column match a specified pattern. Here’s an example with two validation steps, each checking text values in a column:\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .col_vals_regex(columns=\"b\", pattern=r\"^\\d-[a-z]{3}-\\d{3}$\")\n    .col_vals_regex(columns=\"f\", pattern=r\"high|low|mid\")\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    b\n    ^\\d-[a-z]{3}-\\d{3}$\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    f\n    high|low|mid\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\n\n\n1.12.4 Checking Strings Against Specifications\nThe col_vals_within_spec() method validates column values against common data specifications like email addresses, URLs, postal codes, credit card numbers, ISBNs, VINs, and IBANs. This is particularly useful when you need to validate that text data conforms to standard formats:\n\nimport polars as pl\n\n# Create a sample table with various data types\nsample_data = pl.DataFrame({\n    \"isbn\": [\"978-0-306-40615-7\", \"0-306-40615-2\", \"invalid\"],\n    \"email\": [\"test@example.com\", \"user@domain.co.uk\", \"not-an-email\"],\n    \"zip\": [\"12345\", \"90210\", \"invalid\"]\n})\n\n(\n    pb.Validate(data=sample_data)\n    .col_vals_within_spec(columns=\"isbn\", spec=\"isbn\")\n    .col_vals_within_spec(columns=\"email\", spec=\"email\")\n    .col_vals_within_spec(columns=\"zip\", spec=\"postal_code[US]\")\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_within_spec\n    \n        \n            \n            \n                \n            \n        \n    \n\n        \n        \n            col_vals_within_spec()\n        \n        \n        \n    isbn\n    isbn\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    20.67\n    10.33\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_within_spec\n    \n        \n            \n            \n                \n            \n        \n    \n\n        \n        \n            col_vals_within_spec()\n        \n        \n        \n    email\n    email\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    20.67\n    10.33\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    3\n    \n        \n            \n\n    col_vals_within_spec\n    \n        \n            \n            \n                \n            \n        \n    \n\n        \n        \n            col_vals_within_spec()\n        \n        \n        \n    zip\n    postal_code[US]\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    20.67\n    10.33\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\n\n\n1.12.5 Checking for Trending Values\nThe col_vals_increasing() and col_vals_decreasing() validation methods check whether column values are increasing or decreasing as you move down the rows. These are useful for validating time series data, sequential identifiers, or any data where you expect monotonic trends:\n\nimport polars as pl\n\n# Create a sample table with increasing and decreasing values\ntrend_data = pl.DataFrame({\n    \"id\": [1, 2, 3, 4, 5],\n    \"temperature\": [20, 22, 25, 28, 30],\n    \"countdown\": [100, 80, 60, 40, 20]\n})\n\n(\n    pb.Validate(data=trend_data)\n    .col_vals_increasing(columns=\"id\")\n    .col_vals_increasing(columns=\"temperature\")\n    .col_vals_decreasing(columns=\"countdown\")\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_increasing\n    \n        \n            \n            \n                \n            \n        \n    \n\n        \n        \n            col_vals_increasing()\n        \n        \n        \n    id\n    \n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_increasing\n    \n        \n            \n            \n                \n            \n        \n    \n\n        \n        \n            col_vals_increasing()\n        \n        \n        \n    temperature\n    \n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_vals_decreasing\n    \n        \n            \n            \n                \n            \n        \n    \n\n        \n        \n            col_vals_decreasing()\n        \n        \n        \n    countdown\n    \n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe allow_stationary= parameter lets you control whether consecutive identical values should pass validation. By default, stationary values (e.g., [1, 2, 2, 3]) will fail the increasing check, but setting allow_stationary=True will allow them to pass.\n\n\n1.12.6 Handling Missing Values with na_pass=\nWhen validating columns containing Null/None/NA values, you can control how these missing values are treated with the na_pass= parameter:\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .col_vals_le(columns=\"c\", value=10, na_pass=True)\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_le\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_le()\n        \n        \n        \n    c\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nIn the above example, column c contains two None values, but all test units pass because we set na_pass=True. Without this setting, those two values would fail the validation.\nIn summary, na_pass= works like this:\n\nna_pass=True: missing values pass validation regardless of the condition being tested\nna_pass=False (the default): missing values fail validation"
  },
  {
    "objectID": "user-guide-pdf.html#row-based-validations",
    "href": "user-guide-pdf.html#row-based-validations",
    "title": "CLI Reference",
    "section": "1.13 2. Row-based Validations",
    "text": "1.13 2. Row-based Validations\nRow-based validations focus on examining properties that span across entire rows rather than individual columns. These are essential for detecting issues that can’t be found by looking at columns in isolation:\n\nrows_distinct(): ensures no duplicate rows exist in the table\nrows_complete(): verifies that no rows contain any missing values\n\nThese row-level validations are particularly valuable for ensuring data integrity and completeness at the record level, which is crucial for many analytical and operational data applications.\n\n1.13.1 Checking Row Distinctness\nHere’s an example where we check for duplicate rows with rows_distinct():\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .rows_distinct()\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    rows_distinct\n    \n        \n            \n            \n                \n                \n                \n            \n        \n    \n\n        \n        \n            rows_distinct()\n        \n        \n        \n    ALL COLUMNS\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    90.69\n    20.15\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nWe can also adapt the rows_distinct() check to use a single column or a subset of columns. To do that, we need to use the columns_subset= parameter. Here’s an example of that:\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .rows_distinct(columns_subset=\"b\")\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    rows_distinct\n    \n        \n            \n            \n                \n                \n                \n            \n        \n    \n\n        \n        \n            rows_distinct()\n        \n        \n        \n    b\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\n\n\n1.13.2 Checking Row Completeness\nAnother important validation is checking for complete rows: rows that have no missing values across all columns or a specified subset of columns. The rows_complete() validation method performs this check.\nHere’s an example checking if all rows in the table are complete (have no missing values in any column):\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .rows_complete()\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    rows_complete\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            rows_complete()\n        \n        \n        \n    ALL COLUMNS\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nAs the report indicates, there are some incomplete rows in the table."
  },
  {
    "objectID": "user-guide-pdf.html#table-structure-validations",
    "href": "user-guide-pdf.html#table-structure-validations",
    "title": "CLI Reference",
    "section": "1.14 3. Table Structure Validations",
    "text": "1.14 3. Table Structure Validations\nTable structure validations ensure that the overall architecture of your data meets expectations. These structural checks form a foundation for more detailed data quality assessments:\n\ncol_exists(): verifies a column exists in the table\ncol_schema_match(): ensures table matches a defined schema\ncol_count_match(): confirms the table has the expected number of columns\nrow_count_match(): verifies the table has the expected number of rows\ntbl_match(): validates that the target table matches a comparison table\n\nThese structural validations provide essential checks on the fundamental organization of your data tables, ensuring they have the expected dimensions and components needed for reliable data analysis.\n\n1.14.1 Checking Column Presence\nIf you need to check for the presence of individual columns, the Validate.col_exists() validation method is useful. In this example, we check whether the date column is present in the table:\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .col_exists(columns=\"date\")\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    date\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThat column is present, so the single test unit of this validation step is a passing one.\n\n\n1.14.2 Checking the Table Schema\nFor deeper checks of table structure, a schema validation can be performed with the col_schema_match() validation method, where the goal is to check whether the structure of a table matches an expected schema. To define an expected table schema, we need to use the Schema class. Here is a simple example that (1) prepares a schema consisting of column names, (2) uses that schema object in a col_schema_match() validation step:\n\nschema = pb.Schema(columns=[\"date_time\", \"date\", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\"])\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .col_schema_match(schema=schema)\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_schema_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            col_schema_match()\n        \n        \n        \n    —\n    SCHEMA\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe col_schema_match() validation step will only have a single test unit (signifying pass or fail). We can see in the above validation report that the column schema validation passed.\nMore often, a schema will be defined using column names and column types. We can do that by using a list of tuples in the columns= parameter of Schema. Here’s an example of that approach in action:\n\nschema = pb.Schema(\n    columns=[\n        (\"date_time\", \"Datetime(time_unit='us', time_zone=None)\"),\n        (\"date\", \"Date\"),\n        (\"a\", \"Int64\"),\n        (\"b\", \"String\"),\n        (\"c\", \"Int64\"),\n        (\"d\", \"Float64\"),\n        (\"e\", \"Boolean\"),\n        (\"f\", \"String\"),\n    ]\n)\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .col_schema_match(schema=schema)\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_schema_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            col_schema_match()\n        \n        \n        \n    —\n    SCHEMA\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe col_schema_match() validation method has several boolean parameters for making the checks less stringent:\n\ncomplete=: requires exact column matching (all expected columns must exist, no extra columns allowed)\nin_order=: enforces that columns appear in the same order as defined in the schema\ncase_sensitive_colnames=: column names must match with exact letter case\ncase_sensitive_dtypes=: data type strings must match with exact letter case\n\nThese parameters all default to True, providing strict schema validation. Setting any to False relaxes the validation requirements, making the checks more flexible when exact matching isn’t necessary or practical for your use case.\n\n\n1.14.3 Comparing Tables with tbl_match()\nThe tbl_match() validation method provides a comprehensive way to verify that two tables are identical. It performs a progressive series of checks, from least to most stringent:\n\nColumn count match\nRow count match\nSchema match (loose - case-insensitive, any order)\nSchema match (order - columns in correct order)\nSchema match (exact - case-sensitive, correct order)\nData match (cell-by-cell comparison)\n\nThis progressive approach helps identify exactly where tables differ. Here’s an example comparing the small_table dataset with itself:\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .tbl_match(tbl_compare=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    tbl_match\n    \n        \n            \n            \n                \n                \n            \n            \n                \n                \n            \n            \n            \n        \n    \n\n        \n        \n            tbl_match()\n        \n        \n        \n    None\n    EXTERNAL TABLE\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThis validation method is especially useful for:\n\nVerifying that data transformations preserve expected properties\nComparing production data against a golden dataset\nEnsuring data consistency across different environments\nValidating that imported data matches source data\n\n\n\n1.14.4 Checking Counts of Row and Columns\nRow and column count validations check the number of rows and columns in a table.\nUsing row_count_match() checks whether the number of rows in a table matches a specified count.\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .row_count_match(count=13)\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    row_count_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            row_count_match()\n        \n        \n        \n    —\n    13\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe col_count_match() validation method checks if the number of columns in a table matches a specified count.\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .col_count_match(count=8)\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_count_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            col_count_match()\n        \n        \n        \n    —\n    8\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nExpectations on column and row counts can be useful in certain situations and they align nicely with schema checks."
  },
  {
    "objectID": "user-guide-pdf.html#ai-powered-validations",
    "href": "user-guide-pdf.html#ai-powered-validations",
    "title": "CLI Reference",
    "section": "1.15 4. AI-Powered Validations",
    "text": "1.15 4. AI-Powered Validations\nAI-powered validations use Large Language Models (LLMs) to validate data based on natural language criteria. This opens up new possibilities for complex validation rules that are difficult to express with traditional programmatic methods.\n\n1.15.1 Validating with Natural Language Prompts\nThe prompt() validation method allows you to describe validation criteria in plain language. The LLM interprets your prompt and evaluates each row, producing pass/fail results just like other Pointblank validation methods.\nThis is particularly useful for:\n\nSemantic checks (e.g., “descriptions should mention a product name”)\nContext-dependent validation (e.g., “prices should be reasonable for the product category”)\nSubjective quality assessments (e.g., “comments should be professional and constructive”)\nComplex rules that would require extensive regex patterns or custom functions\n\nHere’s a simple example that validates whether text descriptions contain specific information:\n\nimport polars as pl\n\n# Create sample data with product descriptions\nproducts = pl.DataFrame({\n    \"product\": [\"Widget A\", \"Gadget B\", \"Tool C\"],\n    \"description\": [\n        \"High-quality widget made in USA\",\n        \"Innovative gadget with warranty\",\n        \"Professional tool\"\n    ],\n    \"price\": [29.99, 49.99, 19.99]\n})\n\n# Validate that descriptions mention quality or features\n(\n    pb.Validate(data=products)\n    .prompt(\n        prompt=\"Each description should mention either quality, features, or warranty\",\n        columns_subset=[\"description\"],\n        model=\"anthropic:claude-sonnet-4-5\"\n    )\n    .interrogate()\n)\n\nThe columns_subset= parameter lets you specify which columns to include in the validation, improving performance and reducing API costs by only sending relevant data to the LLM.\nNote: To use prompt(), you need to have the appropriate API credentials configured for your chosen LLM provider (Anthropic, OpenAI, Ollama, or AWS Bedrock)."
  },
  {
    "objectID": "user-guide-pdf.html#conclusion-1",
    "href": "user-guide-pdf.html#conclusion-1",
    "title": "CLI Reference",
    "section": "1.16 Conclusion",
    "text": "1.16 Conclusion\nIn this article, we’ve explored the various types of validation methods that Pointblank offers for ensuring data quality. These methods provide a framework for validating column values, checking row properties, verifying table structures, and even using AI for complex semantic validations. By combining these validation methods into comprehensive plans, you can systematically test your data against business rules and quality expectations. And this all helps to ensure your data remains reliable and trustworthy.\n\ntitle: Column Selection Patterns jupyter: python3 toc-expand: 2 html-table-processing: none bread-crumbs: true —\nData validation often requires working with columns in flexible ways. Pointblank offers two powerful approaches:\n\nApplying validation rules across multiple columns: validate many columns with a single rule\nComparing values between columns: create validations that compare values across different columns\n\nThis guide covers both approaches in detail with practical examples."
  },
  {
    "objectID": "user-guide-pdf.html#part-1-applying-rules-across-multiple-columns",
    "href": "user-guide-pdf.html#part-1-applying-rules-across-multiple-columns",
    "title": "CLI Reference",
    "section": "1.17 Part 1: Applying Rules Across Multiple Columns",
    "text": "1.17 Part 1: Applying Rules Across Multiple Columns\nMany of Pointblank’s validation methods perform column-level checks. These methods provide the columns= parameter, which accepts not just a single column name but multiple columns through various selection methods.\nWhy is this useful? Often you’ll want to perform the same validation check (e.g., checking that numerical values are all positive) across multiple columns. Rather than defining the same rules multiple times, you can map the validation across those columns in a single step.\nLet’s explore this using the game_revenue dataset:\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows2,000Columns11\n  \n\n  \n  player_idString\n  session_idString\n  session_startDatetime\n  timeDatetime\n  item_typeString\n  item_nameString\n  item_revenueFloat64\n  session_durationFloat64\n  start_dayDate\n  acquisitionString\n  countryString\n\n\n\n  \n    1\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:31:27+00:00\n    iap\n    offer2\n    8.99\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    2\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:36:57+00:00\n    iap\n    gems3\n    22.49\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    3\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:37:45+00:00\n    iap\n    gold7\n    107.99\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    4\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:42:33+00:00\n    ad\n    ad_20sec\n    0.76\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    5\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-hdu9jkls\n    2015-01-01 11:50:02+00:00\n    2015-01-01 11:55:20+00:00\n    ad\n    ad_5sec\n    0.03\n    35.2\n    2015-01-01\n    google\n    Germany\n  \n  \n    1996\n    NAOJRDMCSEBI281\n    NAOJRDMCSEBI281-j2vs9ilp\n    2015-01-21 01:57:50+00:00\n    2015-01-21 02:02:50+00:00\n    ad\n    ad_survey\n    1.332\n    25.8\n    2015-01-11\n    organic\n    Norway\n  \n  \n    1997\n    NAOJRDMCSEBI281\n    NAOJRDMCSEBI281-j2vs9ilp\n    2015-01-21 01:57:50+00:00\n    2015-01-21 02:22:14+00:00\n    ad\n    ad_survey\n    1.35\n    25.8\n    2015-01-11\n    organic\n    Norway\n  \n  \n    1998\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-vbhcsmtr\n    2015-01-21 02:39:48+00:00\n    2015-01-21 02:40:00+00:00\n    ad\n    ad_5sec\n    0.03\n    8.4\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    1999\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-vbhcsmtr\n    2015-01-21 02:39:48+00:00\n    2015-01-21 02:47:12+00:00\n    iap\n    offer5\n    26.09\n    8.4\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    2000\n    GJCXNTWEBIPQ369\n    GJCXNTWEBIPQ369-9elq67md\n    2015-01-21 03:59:23+00:00\n    2015-01-21 04:06:29+00:00\n    ad\n    ad_5sec\n    0.12\n    18.5\n    2015-01-14\n    organic\n    United States\n  \n\n\n\n\n\n\n        \n\n\n\n1.17.1 Using a List of Column Names\nThe simplest way to validate multiple columns is to provide a list to the columns= parameter. In the game_revenue dataset, we have two columns with numerical data: item_revenue and session_duration. If we expect all values in both columns to be greater than 0, we can write:\n\nimport pointblank as pb\n\n(\n    pb.Validate(data=pb.load_dataset(\"game_revenue\"))\n    .col_vals_gt(\n        columns=[\"item_revenue\", \"session_duration\"],\n        value=0\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    item_revenue\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    session_duration\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe validation report shows two validation steps were created from a single method call! All validation parameters are shared across all generated steps, including thresholds and briefs:\n\n(\n    pb.Validate(data=pb.load_dataset(\"game_revenue\"))\n    .col_vals_gt(\n        columns=[\"item_revenue\", \"session_duration\"],\n        value=0,\n        thresholds=(0.1, 0.2, 0.3),\n        brief=\"`{col}` must be greater than zero.\"\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        item_revenue must be greater than zero.\n\n        \n    item_revenue\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        session_duration must be greater than zero.\n\n        \n    session_duration\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n\n\n\n\n\n\n        \n\n\nIn this example, you can see that the validation report displays customized briefs for each column (“item_revenue must be greater than zero.” and “session_duration must be greater than zero.”), automatically substituting the column name using the {col} placeholder in the brief template. This feature is particularly helpful when reviewing reports, as it provides clear, human-readable descriptions of what each validation step is checking. When working with multiple columns through a single validation call, these dynamically generated briefs make your validation reports more understandable for both technical and non-technical stakeholders.\n\n\n1.17.2 Using Pointblank’s Column Selectors\nFor more advanced column selection, Pointblank provides selector functions that resolve columns based on:\n\ntext patterns in column names\ncolumn position\ncolumn data type\n\nTwo common selectors, starts_with() and ends_with(), resolve columns based on text patterns in column names.\nThe game_revenue dataset has three columns starting with “item”: item_type, item_name, and item_revenue. Let’s check that these columns contain no missing values:\n\n(\n    pb.Validate(data=pb.load_dataset(\"game_revenue\"))\n    .col_vals_not_null(columns=pb.starts_with(\"item\"))\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    item_type\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    item_name\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    item_revenue\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThree validation steps were automatically created because three columns matched the pattern.\nThe complete list of column selectors includes:\n\nstarts_with()\nends_with()\ncontains()\nmatches()\neverything()\nfirst_n()\nlast_n()\n\n\n\n1.17.3 Combining Column Selectors\nColumn selectors can be combined for more powerful selection. To do this, use the col() helper function with logical operators:\n\n& (and)\n| (or)\n- (difference)\n~ (not)\n\nFor example, to select all columns except the first four:\n\ncol_selection = pb.col(pb.everything() - pb.first_n(4))\n\n(\n    pb.Validate(data=pb.load_dataset(\"game_revenue\"))\n    .col_vals_not_null(\n        columns=col_selection,\n        thresholds=(1, 0.05, 0.1)\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    item_type\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    item_name\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    item_revenue\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    session_duration\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C\n    5\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    start_day\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C\n    6\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    acquisition\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C\n    7\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    country\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n\n\n\n\n\n\n        \n\n\nThis selects every column except the first four, resulting in seven validation steps.\n\n\n1.17.4 Narwhals Selectors\nPointblank also supports column selectors from the Narwhals library, which include:\n\nmatches()\nby_dtype()\nboolean()\ncategorical()\ndatetime()\nnumeric()\nstring()\n\nHere’s an example selecting all numeric columns:\n\nimport narwhals.selectors as ncs\n\n(\n    pb.Validate(data=pb.load_dataset(\"game_revenue\"))\n    .col_vals_gt(\n        columns=ncs.numeric(),\n        value=0\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    item_revenue\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    session_duration\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nAnd selecting all string columns matching “item_”:\n\n(\n    pb.Validate(data=pb.load_dataset(\"game_revenue\"))\n    .col_vals_not_null(columns=pb.col(ncs.string() & ncs.matches(\"item_\")))\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    item_type\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    item_name\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThis example demonstrates the power of combining Narwhals selectors with logical operators. By using ncs.string() to select string columns and then filtering with ncs.matches(\"item_\"), we can precisely target text columns with specific naming patterns. This type of targeted selection is particularly valuable when working with wide datasets that have consistent column naming conventions, allowing you to apply appropriate validation rules to logically grouped columns without explicitly listing each one.\n\n\n1.17.5 Caveats for Using Column Selectors\nWhile column selectors are powerful, there are some caveats. If a selector doesn’t match any columns, the validation won’t fail but will show an ‘explosion’ in the report:\n\n(\n    pb.Validate(data=pb.load_dataset(\"game_revenue\"))\n    .col_vals_not_null(columns=pb.starts_with(\"items\"))\n    .col_vals_gt(columns=\"item_revenue\", value=0)\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    StartsWith(text='items', case_sensitive=False)\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    💥\n    —\n    —\n    —\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    item_revenue\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nNotice that although there was a problem with Step 1 (that should be addressed), the interrogation did move on to Step 2 without complication.\nTo mitigate uncertainty, include validation steps that check for the existence of key columns with col_exists() or verify the schema with col_schema_match()."
  },
  {
    "objectID": "user-guide-pdf.html#part-2-comparing-values-between-columns",
    "href": "user-guide-pdf.html#part-2-comparing-values-between-columns",
    "title": "CLI Reference",
    "section": "1.18 Part 2: Comparing Values Between Columns",
    "text": "1.18 Part 2: Comparing Values Between Columns\nSometimes you need to compare values across different columns rather than against fixed values. Pointblank enables this through the col() helper function.\nLet’s look at examples using the small_table dataset:\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows13Columns8\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05\n    6\n    8-kdg-938\n    3\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    None\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09\n    8\n    3-ldm-038\n    7\n    283.94\n    True\n    low\n  \n  \n    6\n    2016-01-11 06:15:00\n    2016-01-11\n    4\n    2-dhe-923\n    4\n    3291.03\n    True\n    mid\n  \n  \n    7\n    2016-01-15 18:46:00\n    2016-01-15\n    7\n    1-knw-093\n    3\n    843.34\n    True\n    high\n  \n  \n    8\n    2016-01-17 11:27:00\n    2016-01-17\n    4\n    5-boe-639\n    2\n    1035.64\n    False\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26\n    4\n    2-dmx-010\n    7\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28\n    2\n    7-dmx-010\n    8\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30\n    1\n    3-dka-303\n    None\n    2230.09\n    True\n    high\n  \n\n\n\n\n\n\n        \n\n\n\n1.18.1 Using col() to Specify a Comparison Column\nWhile we typically use validation methods to compare column values against fixed values:\n...\n.col_vals_gt(columns=\"a\", value=2, ...)\n...\nWe can also compare values between columns by using col() in the value= parameter:\n...\n.col_vals_gt(columns=\"a\", value=pb.col(\"x\"), ...)\n...\nThis checks that each value in column a is greater than the corresponding value in column x. Here’s a concrete example:\n\n(\n    pb.Validate(data=pb.load_dataset(\"small_table\"))\n    .col_vals_gt(\n        columns=\"d\",\n        value=pb.col(\"c\")\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    c\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nNotice that the validation report shows both column names (d and c). There are two failing test units because of missing values in column c. When comparing across columns, missing values in either column can cause failures.\nTo handle missing values, use na_pass=True:\n\n(\n    pb.Validate(data=pb.load_dataset(\"small_table\"))\n    .col_vals_gt(\n        columns=\"d\",\n        value=pb.col(\"c\"),\n        na_pass=True\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    c\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nNow all tests pass.\nThe following validation methods accept a col() expression in their value= parameter:\n\ncol_vals_gt()\ncol_vals_lt()\ncol_vals_ge()\ncol_vals_le()\ncol_vals_eq()\ncol_vals_ne()\n\n\n\n1.18.2 Using col() in Range Checks\nFor range validations via col_vals_between() and col_vals_outside() you can use a mix of column references and fixed values:\n\n(\n    pb.Validate(data=pb.load_dataset(\"small_table\"))\n    .col_vals_between(\n        columns=\"d\",\n        left=pb.col(\"c\"),\n        right=10_000,\n        na_pass=True\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_between\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_between()\n        \n        \n        \n    d\n    [c, 10000]\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe validation report shows the range as [c, 10000], indicating that the lower bound comes from column c while the upper bound is fixed at 10000."
  },
  {
    "objectID": "user-guide-pdf.html#advanced-examples-combining-both-approaches",
    "href": "user-guide-pdf.html#advanced-examples-combining-both-approaches",
    "title": "CLI Reference",
    "section": "1.19 Advanced Examples: Combining Both Approaches",
    "text": "1.19 Advanced Examples: Combining Both Approaches\nThe true power comes from combining both approaches: validating multiple columns and using cross-column comparisons:\n\nvalidation = (\n    pb.Validate(data=pb.load_dataset(\"small_table\"))\n    .col_vals_gt(\n        columns=[\"c\", \"d\"],\n        value=pb.col(\"a\"),\n        na_pass=True\n    )\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    c\n    a\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    80.62\n    50.38\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    a\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThis creates validation steps checking that values in both columns d and e are greater than their corresponding values in column a."
  },
  {
    "objectID": "user-guide-pdf.html#conclusion-2",
    "href": "user-guide-pdf.html#conclusion-2",
    "title": "CLI Reference",
    "section": "1.20 Conclusion",
    "text": "1.20 Conclusion\nPointblank provides flexible approaches to working with columns:\n\nColumn selection: validate multiple columns with a single validation rule\nCross-column comparison: compare values between columns\n\nThese capabilities allow you to:\n\nwrite more concise validation code\napply consistent validation rules across similar columns\ncreate dynamic validations that check relationships between columns\nbuild comprehensive data quality checks with minimal code\n\nBy getting familiar with these techniques, you can create more elegant and powerful validation plans while also reducing repetition in your code.\nWhile the available validation methods can do a lot for you, there’s likewise a lot of things you can’t easily do with them. What if you wanted to validate that\n\nstring lengths in a column are less than 10 characters?\nthe median of values in a column is less than the median of values in another column?\nthere are at least three instances of every categorical value in a column?\n\nThese constitute more sophisticated validation requirements, yet such examinations are quite prevalent in practice. Rather than expanding our library to encompass every conceivable validation scenario (a pursuit that would yield an unwieldy and potentially infinite collection) we instead employ a more elegant approach. By transforming the table under examination through judicious preprocessing and exposing key metrics, we may subsequently employ the existing collection of validation methods. This compositional strategy affords us considerable analytical power while maintaining conceptual clarity and implementation parsimony.\nCentral to this approach is the idea of composability. Pointblank makes it easy to safely transform the target table for a given validation via the pre= argument. Any computed columns are available for the (short) lifetime of the validation step during interrogation. This composability means:\n\nwe can validate on different forms of the initial dataset (e.g., validating on aggregate forms, validating on calculated columns, etc.)\nthere’s no need to start an entirely new validation process for each transformed version of the data (i.e., one tabular report could be produced instead of several)\n\nThis compositional paradigm allows us to use data transformation effectively within our validation workflows, maintaining both flexibility and clarity in our data quality assessments."
  },
  {
    "objectID": "user-guide-pdf.html#transforming-data-with-lambda-functions",
    "href": "user-guide-pdf.html#transforming-data-with-lambda-functions",
    "title": "CLI Reference",
    "section": "1.21 Transforming Data with Lambda Functions",
    "text": "1.21 Transforming Data with Lambda Functions\nNow, through examples, let’s look at the process of performing the validations mentioned above. We’ll use the small_table dataset for all of the examples. Here it is in its entirety:\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows13Columns8\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05\n    6\n    8-kdg-938\n    3\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    None\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09\n    8\n    3-ldm-038\n    7\n    283.94\n    True\n    low\n  \n  \n    6\n    2016-01-11 06:15:00\n    2016-01-11\n    4\n    2-dhe-923\n    4\n    3291.03\n    True\n    mid\n  \n  \n    7\n    2016-01-15 18:46:00\n    2016-01-15\n    7\n    1-knw-093\n    3\n    843.34\n    True\n    high\n  \n  \n    8\n    2016-01-17 11:27:00\n    2016-01-17\n    4\n    5-boe-639\n    2\n    1035.64\n    False\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26\n    4\n    2-dmx-010\n    7\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28\n    2\n    7-dmx-010\n    8\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30\n    1\n    3-dka-303\n    None\n    2230.09\n    True\n    high\n  \n\n\n\n\n\n\n        \n\n\nIn getting to grips with the basics, we’ll try to validate that string lengths in the b column are less than 10 characters. We can’t directly use the col_vals_lt() validation method with that column because it is meant to be used with a column of numeric values. Let’s just give that method what it needs and create a column with string lengths!\nThe target table is a Polars DataFrame so we’ll provide a function that uses the Polars API to add in that numeric column:\n\nimport polars as pl\n\n# Define a preprocessing function that gets string lengths from column `b`\ndef add_string_length_column(df):\n    return df.with_columns(string_lengths=pl.col(\"b\").str.len_chars())\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"),\n        tbl_name=\"small_table\",\n        label=\"String lengths\"\n    )\n    .col_vals_lt(\n\n        # The generated column, via `pre=` (see below) ---\n        columns=\"string_lengths\",\n\n        # The string length value to be less than ---\n        value=10,\n\n        # The preprocessing function that modifies the table ---\n        pre=add_string_length_column\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    String lengthsPolarssmall_table\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    string_lengths\n    10\n    \n    \n        \n            \n            \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe validation was successfully constructed and we can see from the validation report table that all strings in b had lengths less than 10 characters. Also note that the icon under the TBL column is no longer a rightward-facing arrow, but one that is indicative of a transformation taking place.\nLet’s examine the transformation approach more closely. In the previous example, we’re not directly testing the b column itself. Instead, we’re validating the string_lengths column that was generated by the lambda function provided to pre=. The Polars API’s with_columns() method does the heavy lifting, creating numerical values that represent each string’s length in the original column.\nThat transformation occurs only during interrogation and only for that validation step. Any prior or subsequent steps would normally use the as-provided small_table. Having the possibility for data transformation being isolated at the step level means that you don’t have to generate separate validation plans for each form of the data, you’re free to fluidly transform the target table as necessary for perform validations on different representations of the data."
  },
  {
    "objectID": "user-guide-pdf.html#using-custom-functions-for-preprocessing",
    "href": "user-guide-pdf.html#using-custom-functions-for-preprocessing",
    "title": "CLI Reference",
    "section": "1.22 Using Custom Functions for Preprocessing",
    "text": "1.22 Using Custom Functions for Preprocessing\nWhile lambda functions work well for simple transformations, custom named functions can make your validation code more organized and reusable, especially for complex preprocessing logic. Let’s implement the same string length validation using a dedicated function:\n\ndef add_string_lengths(df):\n    # This generates string length from a column `b`; the new column with\n    # the values is called `string_lengths` (will be placed as the last column)\n    return df.with_columns(string_lengths=pl.col(\"b\").str.len_chars())\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"),\n        tbl_name=\"small_table\",\n        label=\"String lengths for column `b`.\"\n    )\n    .col_vals_lt(\n\n        # Use of a column selector function to select the last column ---\n        columns=pb.last_n(1),\n\n        # The string length to be less than ---\n        value=10,\n\n        # Custom function for generating string lengths in a new column ---\n        pre=add_string_lengths\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    String lengths for column `b`.Polarssmall_table\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    string_lengths\n    10\n    \n    \n        \n            \n            \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe column-generating logic was placed in the add_string_lengths() function, which is then passed to pre=. Notice we’re using pb.last_n(1) in the columns parameter. This is a convenient column selector that targets the last column in the DataFrame, which in our case is the newly created string_lengths column. This saves us from having to explicitly write out the column name, making our code more adaptable if column names change. Despite not specifying the name directly, you’ll still see the actual column name (string_lengths) displayed in the validation report."
  },
  {
    "objectID": "user-guide-pdf.html#creating-parameterized-preprocessing-functions",
    "href": "user-guide-pdf.html#creating-parameterized-preprocessing-functions",
    "title": "CLI Reference",
    "section": "1.23 Creating Parameterized Preprocessing Functions",
    "text": "1.23 Creating Parameterized Preprocessing Functions\nSo far we’ve used simple functions and lambdas, but sometimes you may want to create more flexible preprocessing functions that can be configured with parameters. Let’s create a reusable function that can calculate string lengths for any column:\n\ndef string_length_calculator(column_name):\n    \"\"\"Returns a preprocessing function that calculates string lengths for the specified column.\"\"\"\n    def preprocessor(df):\n        return df.with_columns(string_lengths=pl.col(column_name).str.len_chars())\n    return preprocessor\n\n# Validate string lengths in column b\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"),\n        tbl_name=\"small_table\",\n        label=\"String lengths for column `b`.\"\n    )\n    .col_vals_lt(\n        columns=pb.last_n(1),\n        value=10,\n        pre=string_length_calculator(column_name=\"b\")\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    String lengths for column `b`.Polarssmall_table\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    string_lengths\n    10\n    \n    \n        \n            \n            \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThis pattern is called a function factory, which is a function that creates and returns another function. The outer function (string_length_calculator()) accepts parameters that customize the behavior of the returned preprocessing function. The inner function (preprocessor()) is what actually gets called during validation.\nThis approach offers several benefits as it:\n\ncreates reusable, configurable preprocessing functions\nkeeps your validation code DRY\nallows you to separate configuration from implementation\nenables easy application of the same transformation to different columns\n\nYou could extend this pattern to create even more sophisticated preprocessing functions with multiple parameters, default values, and complex logic."
  },
  {
    "objectID": "user-guide-pdf.html#using-narwhals-to-preprocess-many-types-of-dataframes",
    "href": "user-guide-pdf.html#using-narwhals-to-preprocess-many-types-of-dataframes",
    "title": "CLI Reference",
    "section": "1.24 Using Narwhals to Preprocess Many Types of DataFrames",
    "text": "1.24 Using Narwhals to Preprocess Many Types of DataFrames\nIn this previous example we used a Polars table. You might have a situation where you perform data validation variously on Pandas and Polars DataFrames. This is where Narwhals becomes handy: it provides a single, consistent API that works across multiple DataFrame types, eliminating the need to learn and switch between different APIs depending on your data source.\nLet’s obtain small_table as a Pandas DataFrame. We’ll construct a validation step to verify that the median of column c is greater than the median in column a.\n\nimport narwhals as nw\n\n# Define preprocessing function using Narwhals for cross-backend compatibility\ndef get_median_columns_c_and_a(df):\n    return nw.from_native(df).select(nw.median(\"c\"), nw.median(\"a\"))\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"pandas\"),\n        tbl_name=\"small_table\",\n        label=\"Median comparison.\",\n    )\n    .col_vals_gt(\n        columns=\"c\",\n        value=pb.col(\"a\"),\n\n        # Using Narwhals to modify the table; generates table with columns `c` and `a` ---\n        pre=get_median_columns_c_and_a\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Median comparison.Pandassmall_table\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    c\n    a\n    \n    \n        \n            \n            \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe goal is to check that the median value of c is greater than the corresponding median of column a, which we set up through the columns= and value= parameters in the col_vals_gt() method.\nThere’s a bit to unpack here so let’s look at at the lambda function first. Narwhals can translate a Pandas DataFrame to a Narwhals DataFrame with its from_native() function. After that initiating step, you’re free to use the Narwhals API (which is modeled on a subset of the Polars API) to do the necessary data transformation. In this case, we are getting the medians of the c and a columns and ending up with a one-row, two-column table.\nWe should note that the transformed table is, perhaps surprisingly, a Narwhals DataFrame (we didn’t have to go back to a Pandas DataFrame by using .to_native()). Pointblank is able to work directly with the Narwhals DataFrame for validation purposes, which makes the workflow more concise.\nOne more thing to note: Pointblank provides a convenient syntactic sugar for working with Narwhals. If you name the lambda parameter dfn instead of df, the system automatically applies nw.from_native() to the input DataFrame first. This lets you write more concise code without having to explicitly convert the DataFrame to a Narwhals format."
  },
  {
    "objectID": "user-guide-pdf.html#swapping-in-a-totally-different-dataframe",
    "href": "user-guide-pdf.html#swapping-in-a-totally-different-dataframe",
    "title": "CLI Reference",
    "section": "1.25 Swapping in a Totally Different DataFrame",
    "text": "1.25 Swapping in a Totally Different DataFrame\nSometimes data validation requires looking at completely transformed versions of your data (such as aggregated summaries, pivoted views, or even reference tables). While this approach goes against the typical paradigm of validating a single target table, there are legitimate use cases where you might need to validate properties that only emerge after significant transformations.\nLet’s now try to prepare the final validation scenario, checking that there are at least three instances of every categorical value in column f (which contains string values in the set of \"low\", \"mid\", and \"high\"). This time, we’ll prepare the transformed table (transformed by Polars expressions) outside of the Pointblank code.\n\ndata_original = pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\")\ndata_transformed = data_original.group_by(\"f\").len(name=\"n\")\n\ndata_transformed\n\n\nshape: (3, 2)fnstru32\"mid\"2\"high\"6\"low\"5\n\n\nThen, we’ll plug in the data_transformed DataFrame with a preprocessing function:\n\n# Define preprocessing function to use the transformed data\ndef use_transformed_data(df):\n    return data_transformed\n\n(\n    pb.Validate(\n        data=data_original,\n        tbl_name=\"small_table\",\n        label=\"Category counts.\",\n    )\n    .col_vals_ge(\n        columns=\"n\",\n        value=3,\n        pre=use_transformed_data\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Category counts.Polarssmall_table\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_ge\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_ge()\n        \n        \n        \n    n\n    3\n    \n    \n        \n            \n            \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    20.67\n    10.33\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nWe can see from the validation report table that there are three test units. This corresponds to a row for each of the categorical value counts. From the report, we find that two of the three test units are passing test units (turns out there are only two instances of \"mid\" in column f).\nNote that the swapped-in table can be any table type that Pointblank supports, like a Polars DataFrame (as shown here), a Pandas DataFrame, a Narwhals DataFrame, or any other compatible format. This flexibility allows you to validate properties of your data that might only be apparent after significant reshaping or aggregation."
  },
  {
    "objectID": "user-guide-pdf.html#conclusion-3",
    "href": "user-guide-pdf.html#conclusion-3",
    "title": "CLI Reference",
    "section": "1.26 Conclusion",
    "text": "1.26 Conclusion\nThe preprocessing capabilities in Pointblank provide the power and flexibility for validating complex data properties beyond what’s directly possible with the standard validation methods. Through the pre= parameter, you can:\n\ntransform your data on-the-fly with computed columns\ngenerate aggregated metrics to validate statistical properties\nwork seamlessly across different DataFrame types using Narwhals\nswap in completely different tables when validating properties that emerge only after transformation\n\nBy combining these preprocessing techniques with Pointblank’s validation methods, you can create comprehensive data quality checks that address virtually any validation scenario without needing an endless library of specialized validation functions. This composable approach keeps your validation code concise while allowing you to verify even the most complex data quality requirements.\nRemember that preprocessing happens just for the specific validation step, keeping your validation plan organized and maintaining the integrity of your original data throughout the rest of the validation process.\nWhen validating data, you often need to analyze specific subsets or segments of your data separately. Maybe you want to ensure that data quality meets standards in each geographic region, for each product category, or across different time periods. This is where the segments= argument can be useful.\nData segmentation lets you split a validation step into multiple segments, with each segment receiving its own validation step. Rather than validating an entire table at once, you could instead validate different partitions separately and get separate results for each.\nThe segments= argument is available in many validation methods; typically it’s in those methods that check values within rows, and those methods that examine entire rows (rows_distinct(), rows_complete()). When you use it, Pointblank will:\n\nsplit your data according to your segmentation criteria\nrun the validation separately on each segment\nreport results individually for each segment\n\nLet’s explore how to use the segments= argument through a few practical examples."
  },
  {
    "objectID": "user-guide-pdf.html#basic-segmentation-by-column-values",
    "href": "user-guide-pdf.html#basic-segmentation-by-column-values",
    "title": "CLI Reference",
    "section": "1.27 Basic Segmentation by Column Values",
    "text": "1.27 Basic Segmentation by Column Values\nThe simplest way to segment data is by the unique values in a column. For the upcoming example, we’ll use the small_table dataset, which contains a categorical-value column called f.\nFirst, let’s preview the dataset:\n\ntable = pb.load_dataset()\n\npb.preview(table)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows13Columns8\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05\n    6\n    8-kdg-938\n    3\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    None\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09\n    8\n    3-ldm-038\n    7\n    283.94\n    True\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26\n    4\n    2-dmx-010\n    7\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28\n    2\n    7-dmx-010\n    8\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30\n    1\n    3-dka-303\n    None\n    2230.09\n    True\n    high\n  \n\n\n\n\n\n\n        \n\n\nNow, let’s validate that values in column d are greater than 100, but we’ll also segment the validation by the categorical values in column f:\n\nvalidation_1 = (\n    pb.Validate(\n        data=pb.load_dataset(),\n        tbl_name=\"small_table\",\n        label=\"Segmented validation by category\"\n    )\n    .col_vals_gt(\n        columns=\"d\", value=100,\n\n        # Segment by unique values in column `f` ---\n        segments=\"f\"\n    )\n    .interrogate()\n)\n\nvalidation_1\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Segmented validation by categoryPolarssmall_table\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    SEGMENT  f / high \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    100\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    61.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    SEGMENT  f / low \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    100\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    3\n    SEGMENT  f / mid \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    100\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    2\n    21.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nIn the validation report, notice that instead of a single validation step, we have multiple steps: one for each unique value in the f column. The segmentation is clearly indicated in the STEP column with labels like SEGMENT  f / high, making it easy to identify which segment each validation result belongs to. This clear labeling helps when reviewing reports, especially with complex validations that use multiple segmentation criteria."
  },
  {
    "objectID": "user-guide-pdf.html#segmenting-on-specific-values",
    "href": "user-guide-pdf.html#segmenting-on-specific-values",
    "title": "CLI Reference",
    "section": "1.28 Segmenting on Specific Values",
    "text": "1.28 Segmenting on Specific Values\nSometimes you don’t want to segment on all unique values in a column, but only on specific ones of interest. You can do this by providing a tuple with the column name and a list of values:\n\nvalidation_2 = (\n    pb.Validate(\n        data=pb.load_dataset(),\n        tbl_name=\"small_table\",\n        label=\"Segmented validation on specific categories\"\n    )\n    .col_vals_gt(\n        columns=\"d\",\n        value=100,\n        segments=(\"f\", [\"low\", \"high\"])  # Only segment on \"low\" and \"high\" values in column `f`\n    )\n    .interrogate()\n)\n\nvalidation_2\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Segmented validation on specific categoriesPolarssmall_table\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    SEGMENT  f / low \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    100\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    SEGMENT  f / high \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    100\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    61.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nIn this example, we only create validation steps for the \"low\" and \"high\" segments, ignoring any rows with f equal to \"mid\"."
  },
  {
    "objectID": "user-guide-pdf.html#multiple-segmentation-criteria",
    "href": "user-guide-pdf.html#multiple-segmentation-criteria",
    "title": "CLI Reference",
    "section": "1.29 Multiple Segmentation Criteria",
    "text": "1.29 Multiple Segmentation Criteria\nFor more complex segmentation, you can provide a list of columns or column-value tuples. This creates segments based on combinations of criteria:\n\nvalidation_3 = (\n    pb.Validate(\n        data=pb.load_dataset(),\n        tbl_name=\"small_table\",\n        label=\"Multiple segmentation criteria\"\n    )\n    .col_vals_gt(\n        columns=\"d\",\n        value=100,\n\n        # Segment by values in `f` AND specific values in `a` ---\n        segments=[\"f\", (\"a\", [1, 2])]\n    )\n    .interrogate()\n)\n\nvalidation_3\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Multiple segmentation criteriaPolarssmall_table\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    SEGMENT  f / high \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    100\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    61.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    SEGMENT  f / low \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    100\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    3\n    SEGMENT  f / mid \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    100\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    2\n    21.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    SEGMENT  a / 1 \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    100\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    5\n    SEGMENT  a / 2 \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    100\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThis creates validation steps for each combination of values in column f and the specified values in column a."
  },
  {
    "objectID": "user-guide-pdf.html#segmentation-with-preprocessing",
    "href": "user-guide-pdf.html#segmentation-with-preprocessing",
    "title": "CLI Reference",
    "section": "1.30 Segmentation with Preprocessing",
    "text": "1.30 Segmentation with Preprocessing\nYou can combine segmentation with preprocessing for powerful and flexible validations. All preprocessing is applied before segmentation occurs, which means you can create derived columns to segment on:\n\nimport polars as pl\n\n# Define preprocessing function for creating a categorical column\ndef add_d_category_column(df):\n    return df.with_columns(\n        d_category=pl.when(pl.col(\"d\") &gt; 150).then(pl.lit(\"high\")).otherwise(pl.lit(\"low\"))\n    )\n\nvalidation_4 = (\n    pb.Validate(\n        data=pb.load_dataset(tbl_type=\"polars\"),\n        tbl_name=\"small_table\",\n        label=\"Segmentation with preprocessing\",\n    )\n    .col_vals_gt(\n        columns=\"d\", value=100,\n\n        # Create a column containing categorical values ---\n        pre=add_d_category_column,\n\n        # Segment by the computed column `d_category` generated via `pre=` ---\n        segments=\"d_category\",\n    )\n    .interrogate()\n)\n\nvalidation_4\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Segmentation with preprocessingPolarssmall_table\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    SEGMENT  d_category / high \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    100\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    12\n    121.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    SEGMENT  d_category / low \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    100\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nIn this example, we first create a derived column d_category based on whether d is greater than 150. Then, we segment our validation based on this derived column by using segments=\"d_category\"."
  },
  {
    "objectID": "user-guide-pdf.html#when-to-use-segmentation",
    "href": "user-guide-pdf.html#when-to-use-segmentation",
    "title": "CLI Reference",
    "section": "1.31 When to Use Segmentation",
    "text": "1.31 When to Use Segmentation\nSegmentation is particularly useful when:\n\nData quality standards vary by group: different regions, product lines, or customer segments might have different acceptable thresholds\nIdentifying problem areas: segmentation helps pinpoint exactly where data quality issues exist, rather than just knowing that some issue exists somewhere in the data\nGenerating detailed reports: by segmenting, you get more granular reporting that can be shared with different stakeholders responsible for different parts of the data\nTracking improvements over time: segmented validations make it easier to see if data quality is improving in specific areas that were previously problematic\n\nBy using segmentation strategically in these scenarios, you can transform your data validation from a simple pass/fail system into a much more nuanced diagnostic tool that provides actionable insights about data quality across different dimensions. This targeted approach not only helps identify issues more precisely but also enables more effective communication of data quality metrics to relevant stakeholders."
  },
  {
    "objectID": "user-guide-pdf.html#segmentation-vs.-multiple-validation-steps",
    "href": "user-guide-pdf.html#segmentation-vs.-multiple-validation-steps",
    "title": "CLI Reference",
    "section": "1.32 Segmentation vs. Multiple Validation Steps",
    "text": "1.32 Segmentation vs. Multiple Validation Steps\nSo why use segmentation instead of just creating separate validation steps for each segment using filtering in the pre= argument? Well, segmentation offers several nice advantages:\n\nConciseness: you define your validation logic once, not repeatedly for each segment\nConsistency: we can be certain that the same validation is applied uniformly across segments\nClarity: the validation report will clearly organize results by segment (with extra labeling)\nConvenience: there’s no need to manually extract and filter subsets of your data\n\nSegmentation can end of simplifying your validation code while also providing more structured and informative reporting about different portions of your data."
  },
  {
    "objectID": "user-guide-pdf.html#practical-example-validating-sales-data-by-region-and-product-type",
    "href": "user-guide-pdf.html#practical-example-validating-sales-data-by-region-and-product-type",
    "title": "CLI Reference",
    "section": "1.33 Practical Example: Validating Sales Data by Region and Product Type",
    "text": "1.33 Practical Example: Validating Sales Data by Region and Product Type\nLet’s see a more realistic example where we validate sales data segmented by both region and product type:\n\nimport pandas as pd\nimport numpy as np\n\n# Create a sample sales dataset\nnp.random.seed(123)\n\n# Create a simple sales dataset\nsales_data = pd.DataFrame({\n    \"region\": np.random.choice([\"North\", \"South\", \"East\", \"West\"], 100),\n    \"product_type\": np.random.choice([\"Electronics\", \"Clothing\", \"Food\"], 100),\n    \"units_sold\": np.random.randint(5, 100, 100),\n    \"revenue\": np.random.uniform(100, 10000, 100),\n    \"cost\": np.random.uniform(50, 5000, 100)\n})\n\n# Calculate profit\nsales_data[\"profit\"] = sales_data[\"revenue\"] - sales_data[\"cost\"]\nsales_data[\"profit_margin\"] = sales_data[\"profit\"] / sales_data[\"revenue\"]\n\n# Preview the dataset\npb.preview(sales_data)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PandasRows100Columns7\n  \n\n  \n  regionobject\n  product_typeobject\n  units_soldint64\n  revenuefloat64\n  costfloat64\n  profitfloat64\n  profit_marginfloat64\n\n\n\n  \n    1\n    East\n    Clothing\n    55\n    8428.654356103547\n    1363.5197435071943\n    7065.134612596353\n    0.8382280627607168\n  \n  \n    2\n    South\n    Electronics\n    7\n    6589.7066024003025\n    3824.069456121553\n    2765.6371462787497\n    0.41969048292246663\n  \n  \n    3\n    East\n    Food\n    23\n    4680.5819759229435\n    4122.545156369359\n    558.0368195535848\n    0.11922381071929586\n  \n  \n    4\n    East\n    Clothing\n    51\n    5693.611988153584\n    1797.3122335569797\n    3896.2997545966045\n    0.6843282897927435\n  \n  \n    5\n    North\n    Clothing\n    50\n    4296.763518753258\n    4872.448283639371\n    -575.684764886113\n    -0.13398102138354426\n  \n  \n    96\n    West\n    Clothing\n    85\n    6551.261354681658\n    936.7119894981438\n    5614.549365183515\n    0.8570180704470368\n  \n  \n    97\n    South\n    Electronics\n    29\n    9543.579639173184\n    2779.779531480257\n    6763.800107692927\n    0.7087277901396456\n  \n  \n    98\n    East\n    Food\n    20\n    4822.302251263769\n    2833.48720726181\n    1988.815044001959\n    0.41242023837903463\n  \n  \n    99\n    North\n    Clothing\n    54\n    8801.046116310079\n    2185.8559620190636\n    6615.1901542910155\n    0.7516368016788095\n  \n  \n    100\n    North\n    Clothing\n    85\n    7942.857049695305\n    1834.7969383843642\n    6108.060111310941\n    0.7690003827458094\n  \n\n\n\n\n\n\n        \n\n\nNow, let’s validate that profit margins are above 20% across different regions and product types:\n\nvalidation_5 = (\n    pb.Validate(\n        data=sales_data,\n        tbl_name=\"sales_data\",\n        label=\"Sales data validation by region and product\"\n    )\n    .col_vals_gt(\n        columns=\"profit_margin\",\n        value=0.2,\n        segments=[\"region\", \"product_type\"],\n        brief=\"Profit margin &gt; 20% check\"\n    )\n    .interrogate()\n)\n\nvalidation_5\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Sales data validation by region and productPandassales_data\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    SEGMENT  region / East \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Profit margin &gt; 20% check\n\n        \n    profit_margin\n    0.2\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    30\n    200.67\n    100.33\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    SEGMENT  region / North \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Profit margin &gt; 20% check\n\n        \n    profit_margin\n    0.2\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    25\n    170.68\n    80.32\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    3\n    SEGMENT  region / South \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Profit margin &gt; 20% check\n\n        \n    profit_margin\n    0.2\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    21\n    180.86\n    30.14\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    4\n    SEGMENT  region / West \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Profit margin &gt; 20% check\n\n        \n    profit_margin\n    0.2\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    24\n    160.67\n    80.33\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    5\n    SEGMENT  product_type / Clothing \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Profit margin &gt; 20% check\n\n        \n    profit_margin\n    0.2\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    38\n    280.74\n    100.26\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    6\n    SEGMENT  product_type / Electronics \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Profit margin &gt; 20% check\n\n        \n    profit_margin\n    0.2\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    33\n    210.64\n    120.36\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    7\n    SEGMENT  product_type / Food \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Profit margin &gt; 20% check\n\n        \n    profit_margin\n    0.2\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    29\n    220.76\n    70.24\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThis validation gives us a detailed breakdown of profit margin performance across the different regions and product types, making it easy to identify areas that need attention."
  },
  {
    "objectID": "user-guide-pdf.html#best-practices-for-segmentation",
    "href": "user-guide-pdf.html#best-practices-for-segmentation",
    "title": "CLI Reference",
    "section": "1.34 Best Practices for Segmentation",
    "text": "1.34 Best Practices for Segmentation\nEffective data segmentation requires thoughtful planning about how to divide your data in ways that make sense for your validation needs. When implementing segmentation in your data validation workflow, consider these key principles:\n\nChoose meaningful segments: select segmentation columns that align with your business logic and organizational structure\nUse preprocessing when needed: if your raw data doesn’t have good segmentation columns, create them through preprocessing (with the pre= argument)\nCombine with actions: for critical segments, define segment-specific actions using the actions= parameter to respond to validation failures.\n\nBy implementing these best practices, you’ll create more targeted, maintainable, and actionable data validations. Segmentation becomes most powerful when it aligns with natural divisions in your data and analytical processes, allowing for more precise identification of quality issues while maintaining a unified validation framework."
  },
  {
    "objectID": "user-guide-pdf.html#conclusion-4",
    "href": "user-guide-pdf.html#conclusion-4",
    "title": "CLI Reference",
    "section": "1.35 Conclusion",
    "text": "1.35 Conclusion\nData segmentation can make your validations more targeted and informative. By dividing your data into meaningful segments, you can identify quality issues with greater precision, apply appropriate validation standards to different parts of your data, and generate more actionable reports.\nThe segments= parameter transforms validation from a monolithic process into a granular assessment of data quality across various dimensions of your dataset. Whether you’re dealing with regional differences, product categories, time periods, or any other meaningful divisions in your data, segmentation makes it possible to validate each portion according to its specific requirements while maintaining the simplicity of a unified validation framework.\nThresholds are a key concept in Pointblank that allow you to define acceptable limits for failing validation tests. Rather than a simple pass/fail model, thresholds enable you to signal failure at different severity levels (‘warning’, ‘error’, and ‘critical’), giving you fine-grained control over how data quality issues are reported and handled.\nWhen used with actions (covered in the next section), thresholds create a robust system for responding to data quality issues based on their severity. This approach allows you to:\n\nset different tolerance levels for different types of validation checks\nescalate responses based on the severity of data quality issues\nconfigure different notification strategies for different threshold levels\ncreate a more nuanced data validation workflow than simple pass/fail tests"
  },
  {
    "objectID": "user-guide-pdf.html#a-simple-example",
    "href": "user-guide-pdf.html#a-simple-example",
    "title": "CLI Reference",
    "section": "1.36 A Simple Example",
    "text": "1.36 A Simple Example\nLet’s start with a basic example that demonstrates how thresholds work in practice:\n\nimport pointblank as pb\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .col_vals_not_null(\n        columns=\"c\",\n\n        # Set thresholds for the validation step ---\n        thresholds=pb.Thresholds(warning=1, error=0.2)\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:38Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #AAAAAA\n    1\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    c\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    ●\n    ○\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nIn this example, we’re validating that column c contains no Null values. We’ve set:\n\nA ‘warning’ threshold of 1 (triggers when 1 or more values are Null)\nAn ‘error’ threshold of 0.2 (triggers when 20% or more values are Null)\n\nLooking at the results:\n\nthe FAIL column shows that 2 test units have failed\nthe W column (for ‘warning’) shows a filled gray circle, indicating the warning threshold has been exceeded\nthe E column (for ‘error’) shows an open yellow circle, indicating the error threshold has not been exceeded\nthe C column (for ‘critical’) shows a dash since we didn’t set a critical threshold"
  },
  {
    "objectID": "user-guide-pdf.html#types-of-threshold-values",
    "href": "user-guide-pdf.html#types-of-threshold-values",
    "title": "CLI Reference",
    "section": "1.37 Types of Threshold Values",
    "text": "1.37 Types of Threshold Values\nThresholds in Pointblank can be specified in two different ways:\n\n1.37.1 Absolute Thresholds\nAbsolute thresholds are specified as integers and represent a fixed number of failing test units:\n# Warning threshold of exactly 5 failing test units\nthresholds_absolute = pb.Thresholds(warning=5)\nWith this configuration, the ‘warning’ threshold would be triggered if 5 or more test units fail.\n\n\n1.37.2 Proportional Thresholds\nProportional thresholds are specified as decimals between 0 and 1, representing a percentage of the total test units:\n# Error threshold of 10% of test units failing\nthresholds_proportional = pb.Thresholds(error=0.1)\nWith this configuration, the ‘error’ threshold would be triggered if 10% or more of the test units fail.\n\n\n1.37.3 Boolean Shorthand\nFor cases where you want to allow exactly 1 failing test unit, you can use True as a convenient shorthand:\n# Critical threshold of exactly 1 failing test unit\nthresholds_boolean = pb.Thresholds(critical=True)\nThis is equivalent to setting critical=1 but provides a more intuitive way to express “allow at most one failure”. This shorthand is particularly useful for strict validations where any failure beyond a single edge case should trigger immediate attention."
  },
  {
    "objectID": "user-guide-pdf.html#understanding-severity-levels",
    "href": "user-guide-pdf.html#understanding-severity-levels",
    "title": "CLI Reference",
    "section": "1.38 Understanding Severity Levels",
    "text": "1.38 Understanding Severity Levels\nThe three threshold levels in Pointblank (‘warning’, ‘error’, and ‘critical’) are inspired by traditional logging levels used in software development. These names suggest a progression of severity:\n\n‘warning’ (level 30): indicates potential issues that don’t necessarily prevent normal operation\n‘error’ (level 40): suggests more serious problems that might impact data quality\n‘critical’ (level 50): represents the most severe issues that likely require immediate attention\n\nThese numerical values (30, 40, 50) are used internally by Pointblank when determining threshold hierarchy and can be accessed through the {level_num} field in action metadata (covered in the next User Guide article).\nWhile these names imply certain severity levels, they’re ultimately just convenient labels for different thresholds. You have complete flexibility in how you use them:\n\nyou could use ‘warning’ for issues that should block a pipeline\nyou might configure ‘critical’ for minor issues that just need documentation\nthe ‘error’ level could trigger informational emails rather than actual error handling\n\nThe naming is primarily a suggestion to help organize your validation strategy. What matters most is how you configure actions for each threshold level to suit your specific data quality requirements."
  },
  {
    "objectID": "user-guide-pdf.html#threshold-behavior",
    "href": "user-guide-pdf.html#threshold-behavior",
    "title": "CLI Reference",
    "section": "1.39 Threshold Behavior",
    "text": "1.39 Threshold Behavior\nIt’s important to understand a few key behaviors of thresholds:\n\nthresholds are inclusive: a value equal to or exceeding the threshold will trigger the associated level\nthresholds can be mixed: you can use absolute values for some levels and proportional for others\nthreshold levels are hierarchical: ‘critical’ is more severe than ‘error’, which is more severe than ‘warning’\nwhen a test fails, all applicable threshold levels are marked in the report (though actions may only execute for the highest level by default)"
  },
  {
    "objectID": "user-guide-pdf.html#setting-global-thresholds",
    "href": "user-guide-pdf.html#setting-global-thresholds",
    "title": "CLI Reference",
    "section": "1.40 Setting Global Thresholds",
    "text": "1.40 Setting Global Thresholds\nYou can set thresholds globally for all validation steps in a workflow using the thresholds= parameter in Validate:\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"),\n\n        # Setting thresholds for all validation steps ---\n        thresholds=pb.Thresholds(warning=1, error=0.1)\n    )\n    .col_vals_not_null(columns=\"a\")\n    .col_vals_gt(columns=\"a\", value=2)\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:38PolarsWARNING1ERROR0.1CRITICAL—\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    a\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    ○\n    ○\n    —\n    —\n  \n  \n    #EBBC14\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    a\n    2\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    90.69\n    40.31\n    ●\n    ●\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nWith this approach, the same thresholds are applied to every validation step in the workflow."
  },
  {
    "objectID": "user-guide-pdf.html#overriding-thresholds-for-specific-steps",
    "href": "user-guide-pdf.html#overriding-thresholds-for-specific-steps",
    "title": "CLI Reference",
    "section": "1.41 Overriding Thresholds for Specific Steps",
    "text": "1.41 Overriding Thresholds for Specific Steps\nYou can override global thresholds for specific validation steps by providing the thresholds= parameter in individual validation methods:\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"),\n\n        # Setting global thresholds ---\n        thresholds=pb.Thresholds(warning=1, error=0.1)\n    )\n    .col_vals_not_null(columns=\"a\")\n    .col_vals_gt(\n        columns=\"a\", value=2,\n\n        # Step-specific threshold that overrides global ---\n        thresholds=pb.Thresholds(warning=3)\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:39PolarsWARNING1ERROR0.1CRITICAL—\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    a\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    ○\n    ○\n    —\n    —\n  \n  \n    #AAAAAA\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    a\n    2\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    90.69\n    40.31\n    ●\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nIn this example, the second validation step uses its own ‘warning’ threshold of 3, overriding the global setting of 1."
  },
  {
    "objectID": "user-guide-pdf.html#ways-to-define-thresholds",
    "href": "user-guide-pdf.html#ways-to-define-thresholds",
    "title": "CLI Reference",
    "section": "1.42 Ways to Define Thresholds",
    "text": "1.42 Ways to Define Thresholds\nPointblank offers multiple ways to define thresholds to accommodate different coding styles and requirements.\n\n1.42.1 1. Using the Thresholds Class (Recommended)\nThe most explicit and flexible approach is using the Thresholds class:\n\n# Set individual thresholds for different levels\nthresholds_all_levels = pb.Thresholds(warning=0.05, error=0.1, critical=0.25)\n\n# Set only specific levels\nthresholds_error_only = pb.Thresholds(error=0.15)\n\nThis approach allows you to:\n\nset any combination of threshold levels\nuse descriptive parameter names for clarity\nskip levels you don’t need to set\n\n\n\n1.42.2 2. Using a Tuple\nFor concise code, you can use a tuple where positions represent ‘warning’, ‘error’, and ‘critical’ levels in that order:\n\n# (warning, error, critical)\nthresholds_tuple = (1, 0.1, 0.25)\n\n# Shorter tuples are also allowed\nthresholds_tuple_warning = (3,)            # Only the 'warning' threshold\nthresholds_tuple_warning_error = (3, 0.2)  # Both 'warning' and 'error' thresholds\n\nWhile concise, this approach requires you to start with the ‘warning’ level and add levels in order.\n\n\n1.42.3 3. Using a Dictionary\nYou can also use a dictionary with keys that match the threshold level names:\n\n# Can use any combination of threshold levels\nthresholds_dict = {\"warning\": 1, \"critical\": 0.15}\n\nThe dictionary must use the exact keys \"warning\", \"error\", and/or \"critical\".\n\n\n1.42.4 4. Using a Single Value\nThe simplest approach is using a single numeric value, which sets just the ‘warning’ threshold:\n\n# Sets 'warning' threshold to `5`\nthresholds_single = 5\n\nThis is equivalent to pb.Thresholds(warning=5)."
  },
  {
    "objectID": "user-guide-pdf.html#thresholds-and-validation-steps",
    "href": "user-guide-pdf.html#thresholds-and-validation-steps",
    "title": "CLI Reference",
    "section": "1.43 Thresholds and Validation Steps",
    "text": "1.43 Thresholds and Validation Steps\nLet’s look at a more complete validation workflow that demonstrates different threshold configurations:\n\n# Create a validation workflow with global and step-specific thresholds\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"),\n\n        # Global thresholds applied to all steps unless overridden ---\n        thresholds=pb.Thresholds(warning=0.05, error=0.1, critical=0.2)\n    )\n\n    # Step 1: Uses global thresholds ---\n    .col_vals_not_null(columns=\"b\")\n\n    # Step 2: Overrides with step-specific thresholds ---\n    .col_vals_gt(\n        columns=\"a\", value=2,\n        thresholds=pb.Thresholds(warning=1, critical=0.3) # No 'error' threshold\n    )\n\n    # Step 3: Uses a simplified tuple notation ---\n    .col_vals_not_null(columns=\"c\", thresholds=(2, 0.15))\n\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:39PolarsWARNING0.05ERROR0.1CRITICAL0.2\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    b\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #FF3300\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    a\n    2\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    90.69\n    40.31\n    ●\n    —\n    ●\n    CSV\n  \n  \n    #EBBC14\n    3\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    c\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    ●\n    ●\n    —\n    CSV"
  },
  {
    "objectID": "user-guide-pdf.html#thresholds-and-actions",
    "href": "user-guide-pdf.html#thresholds-and-actions",
    "title": "CLI Reference",
    "section": "1.44 Thresholds and Actions",
    "text": "1.44 Thresholds and Actions\nWhile thresholds by themselves provide visual indicators of validation severity in reports, their real power emerges when combined with Actions. The Actions system (covered in the next article) allows you to specify what happens when a threshold is exceeded.\nFor example, you might configure:\n\nA ‘warning’ threshold that logs a message\nAn ‘error’ threshold that sends an email notification\nA ‘critical’ threshold that blocks a data pipeline\n\nHere’s a simple preview of how thresholds and actions work together:\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"),\n\n        # Define thresholds for all three severity levels ---\n        thresholds=pb.Thresholds(warning=1, error=2, critical=3),\n\n        # Define actions for different threshold levels ---\n        actions=pb.Actions(\n            warning=\"Warning: {step} has {FAIL} failing values\",\n            error=\"ERROR: Step {step} exceeded the 'error' threshold\",\n            critical=\"CRITICAL: Data quality issue in column {col}\"\n        )\n    )\n    .col_vals_not_null(columns=\"c\")\n    .interrogate()\n)\n\nERROR: Step 1 exceeded the 'error' threshold\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:39PolarsWARNING1ERROR2CRITICAL3\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #EBBC14\n    1\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    c\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    ●\n    ●\n    ○\n    CSV"
  },
  {
    "objectID": "user-guide-pdf.html#conclusion-5",
    "href": "user-guide-pdf.html#conclusion-5",
    "title": "CLI Reference",
    "section": "1.45 Conclusion",
    "text": "1.45 Conclusion\nThresholds are a powerful feature that transform Pointblank from a simple validation tool into a sophisticated data quality monitoring system. By setting appropriate thresholds, you can:\n\nDefine different severity levels for data quality issues\nCustomize tolerance levels for different types of validation checks\nCreate a more nuanced approach to data validation than binary pass/fail\nEnable targeted actions based on the severity of issues detected\n\nIn the next article, we’ll explore the Actions system in depth, showing you how to define automatic responses when thresholds are exceeded.\nActions transform data validation from passive reporting to active response by automatically executing code when quality issues arise. They bridge the gap between detection and intervention, enabling immediate notifications and comprehensive logging when thresholds are exceeded.\nWhether you need simple console messages for interactive analysis or complex alerting for production pipelines, Actions provide the framework to make your validation workflows responsive. For example, when validating revenue values, you can configure immediate alerts if failures exceed acceptable thresholds, ensuring data issues are addressed promptly rather than discovered later.\nIn this article, we’ll explore how to use Actions to respond to threshold violations during data validation, and Final Actions to execute code after all validation steps are complete, giving you powerful tools to monitor, alert, and report on your data’s quality."
  },
  {
    "objectID": "user-guide-pdf.html#how-actions-work",
    "href": "user-guide-pdf.html#how-actions-work",
    "title": "CLI Reference",
    "section": "1.46 How Actions Work",
    "text": "1.46 How Actions Work\nLet’s look at an example on how this works in practice. The following validation plan contains a single step (using col_vals_gt()) where the thresholds= and actions= parameters are set using Thresholds and Actions calls:\n\nimport pointblank as pb\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\"))\n    .col_vals_gt(\n        columns=\"c\", value=2,\n        thresholds=pb.Thresholds(warning=1, error=5),\n\n        # Emit a console message when the warning threshold is exceeded ---\n        actions=pb.Actions(warning=\"WARNING: failing test found.\")\n    )\n    .interrogate()\n)\n\nWARNING: failing test found.\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:39Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #AAAAAA\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    c\n    2\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    100.77\n    30.23\n    ●\n    ○\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe code uses thresholds=pb.Thresholds(warning=1, error=5) to set a ‘warning’ threshold of 1 and an ‘error’ threshold of 5 failing test units. The results part of the validation table shows that:\n\nThe FAIL column shows that 3 tests units have failed\nThe W column (short for ‘warning’) shows a filled gray circle indicating it’s reached its threshold level\nThe E (‘error’) column shows an open yellow circle indicating it’s below the threshold level\n\nMore importantly, the text \"WARNING: failing test found.\" has been emitted. Here it appears above the validation table and that’s because the action is executed eagerly during interrogation (before the report has even been generated).\nSo, an action is executed for a particular condition (e.g., ‘warning’) within a validation step if these three things are true:\n\nthere is a threshold set for that condition (either globally, or as part of that step)\nthere is an associated action set for the condition (again, either set globally or within the step)\nduring interrogation, the threshold value for the condition was exceeded by the number or proportion of failing test units\n\nThere is a lot of flexibility for setting both thresholds and actions and everything here is considered optional. Put another way, you can set various thresholds and various actions as needed and the interrogation phase will determine whether all the requirements are met for executing an action."
  },
  {
    "objectID": "user-guide-pdf.html#defining-actions",
    "href": "user-guide-pdf.html#defining-actions",
    "title": "CLI Reference",
    "section": "1.47 Defining Actions",
    "text": "1.47 Defining Actions\nActions can be defined in several ways, providing flexibility for different notification needs.\n\n1.47.1 Using String Messages\nThere are a few options in how to define the actions:\n\nString: a message to be displayed in the console\nCallable: a function to be called\nList of Strings/Callables: for execution of multiple messages or functions\n\nThe actions are executed at interrogation time when the threshold level assigned to the action is exceeded by the number or proportion of failing test units. When providing a string, it will simply be printed to the console. A callable will also be executed at the time of interrogation. If providing a list of strings or callables, each item in the list will be executed in order. Such a list can contain a mix of strings and callables.\nDisplaying console messages may be a simple approach, but it is effective. And the strings don’t have to be static, there are templating features that can be useful for constructing strings for a variety of situations. The following placeholders are available for use:\n\n{type}: The validation step type where the action is executed (e.g., ‘col_vals_gt’, etc.)\n{level}: The threshold level where the action is executed (‘warning’, ‘error’, or ‘critical’)\n{step} or {i}: The step number in the validation workflow where the action is executed\n{col} or {column}: The column name where the action is executed\n{val} or {value}: An associated value for the validation method\n{time}: A datetime value for when the action was executed\n\nHere’s an example where we prepare a console message with a number of value placeholders (action_str) and use it globally at Actions(critical=):\n\naction_str = \"[{LEVEL}: {TYPE}]: Step {step} has failed validation. ({time})\"\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"duckdb\"),\n        thresholds=pb.Thresholds(warning=0.05, error=0.10, critical=0.15),\n\n        # Use `action_str` for any critical thresholds exceeded ---\n        actions=pb.Actions(critical=action_str),\n    )\n    .col_vals_regex(columns=\"player_id\", pattern=r\"[A-Z]{12}\\d{3}\")\n    .col_vals_gt(columns=\"item_revenue\", value=0.10)\n    .col_vals_ge(columns=\"session_duration\", value=15)\n    .interrogate()\n)\n\n[CRITICAL: COL_VALS_GT]: Step 2 has failed validation. (2025-11-23 00:08:40.046441+00:00)\n[CRITICAL: COL_VALS_GE]: Step 3 has failed validation. (2025-11-23 00:08:40.090474+00:00)\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:40DuckDBWARNING0.05ERROR0.1CRITICAL0.15\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    player_id\n    [A-Z]{12}\\d{3}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #FF3300\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    item_revenue\n    0.1\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    14400.72\n    5600.28\n    ●\n    ●\n    ●\n    —\n  \n  \n    #FF3300\n    3\n    \n        \n            \n\n    col_vals_ge\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_ge()\n        \n        \n        \n    session_duration\n    15\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    16860.84\n    3140.16\n    ●\n    ●\n    ●\n    —\n  \n\n\n\n\n\n\n        \n\n\nWhat we get here are two messages in the console, corresponding to critical failures in steps 2 and 3. The placeholders were replaced with the correct text for the context. Note that some of the resulting text is capitalized (e.g., \"CRITICAL\", \"COL_VALS_GT\", etc.) and this is because we capitalized the placeholder text itself. Have a look at the documentation article of Actions for more details on this.\n\n\n1.47.2 Using Callable Functions\nAside from strings, any callable can be used as an action value. Here’s an example where we use a custom function as part of an action:\n\ndef duration_issue():\n    from datetime import datetime\n    print(f\"Data quality issue found ({datetime.now()}).\")\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"duckdb\"),\n        thresholds=pb.Thresholds(warning=0.05, error=0.10, critical=0.15),\n    )\n    .col_vals_regex(columns=\"player_id\", pattern=r\"[A-Z]{12}\\d{3}\")\n    .col_vals_gt(columns=\"item_revenue\", value=0.05)\n    .col_vals_gt(\n        columns=\"session_duration\", value=15,\n\n        # Use the `duration_issue()` function as an action for this step ---\n        actions=pb.Actions(warning=duration_issue),\n    )\n    .interrogate()\n)\n\nData quality issue found (2025-11-23 00:08:40.438851).\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:40DuckDBWARNING0.05ERROR0.1CRITICAL0.15\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    player_id\n    [A-Z]{12}\\d{3}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #EBBC14\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    item_revenue\n    0.05\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    17010.85\n    2990.15\n    ●\n    ●\n    ○\n    —\n  \n  \n    #FF3300\n    3\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    session_duration\n    15\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    16750.84\n    3250.16\n    ●\n    ●\n    ●\n    —\n  \n\n\n\n\n\n\n        \n\n\nIn this case, the ‘warning’ action is set to call the user’s dq_issue() function. This action is only executed when the ‘warning’ threshold is exceeded in step 3. Because all three thresholds are exceeded in that step, the ‘warning’ action of executing the function occurs (resulting in a message being printed to the console).\nThis is an example where actions can be defined locally for an individual validation step. The global threshold setting applied to all three validation steps but the step-level action only applied to step 3. You are free to mix and match both threshold and action settings at the global level (i.e., set in the Validate call) or at the step level. The key thing to be aware of is that step-level settings of thresholds and actions take precedence."
  },
  {
    "objectID": "user-guide-pdf.html#accessing-context-in-actions",
    "href": "user-guide-pdf.html#accessing-context-in-actions",
    "title": "CLI Reference",
    "section": "1.48 Accessing Context in Actions",
    "text": "1.48 Accessing Context in Actions\nWhile string templates provide helpful placeholders to access information about validation steps, callable functions offer more flexibility through access to detailed metadata. When using functions as actions, you can retrieve comprehensive information about the validation context, allowing for complex logic and dynamic responses to validation issues.\n\n1.48.1 Using get_action_metadata() in Callables\nTo access information about the validation step where an action was triggered, we can call get_action_metadata() in the body of a function to be used within Actions. This provides useful context about the validation step that triggered the action.\n\ndef print_problem():\n    m = pb.get_action_metadata()\n    print(f\"{m['level']} ({m['level_num']}) for Step {m['step']}: {m['failure_text']}\")\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"duckdb\"),\n        thresholds=pb.Thresholds(warning=0.05, error=0.10, critical=0.15),\n\n        # Use the `print_problem()` function as the action ---\n        actions=pb.Actions(default=print_problem),\n        brief=True,\n    )\n    .col_vals_regex(columns=\"player_id\", pattern=r\"[A-Z]{12}\\d{3}\")\n    .col_vals_gt(columns=\"item_revenue\", value=0.05)\n    .col_vals_gt(columns=\"session_duration\", value=15)\n    .interrogate()\n)\n\nerror (40) for Step 2: Exceedance of failed test units where values in `item_revenue` should have been &gt; `0.05`.\ncritical (50) for Step 3: Exceedance of failed test units where values in `session_duration` should have been &gt; `15`.\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:40DuckDBWARNING0.05ERROR0.1CRITICAL0.15\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        Expect that values in player_id should match the regular expression: [A-Z]{12}\\d{3}.\n\n        \n    player_id\n    [A-Z]{12}\\d{3}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #EBBC14\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Expect that values in item_revenue should be &gt; 0.05.\n\n        \n    item_revenue\n    0.05\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    17010.85\n    2990.15\n    ●\n    ●\n    ○\n    —\n  \n  \n    #FF3300\n    3\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Expect that values in session_duration should be &gt; 15.\n\n        \n    session_duration\n    15\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    16750.84\n    3250.16\n    ●\n    ●\n    ●\n    —\n  \n\n\n\n\n\n\n        \n\n\nIn this example, we’re creating a function called print_problem() that prints information about each validation step that fails. We then apply this function as the default action for all threshold levels using actions=pb.Actions(default=print_problem). (Note that the default= and highest_only= parameters will be covered in more detail in following sections.)\nWe end up seeing two messages printed for failures in Steps 2 and 3. And though those steps had more than one threshold exceeded, only the most severe level in each yielded a console message (due to the default highest_only=True behavior).\nBy setting the action in Validate(actions=), we applied it to all validation steps where thresholds are exceeded. This eliminates the need to set actions= at every validation step (though you can do this as a local override, even setting actions=None to disable globally set actions).\n\n\n1.48.2 Available Metadata Fields\nThe dictionary returned by get_action_metadata() contains the following fields:\n\nstep: The step number.\ncolumn: The column name.\nvalue: The value being compared (only available in certain validation steps).\ntype: The assertion type (e.g., \"col_vals_gt\", etc.).\ntime: The time the validation step was executed (in ISO format).\nlevel: The severity level (\"warning\", \"error\", or \"critical\").\nlevel_num: The severity level as a numeric value (30, 40, or 50).\nautobrief: A localized and brief statement of the expectation for the step.\nfailure_text: Localized text that explains how the validation step failed."
  },
  {
    "objectID": "user-guide-pdf.html#customizing-action-behavior",
    "href": "user-guide-pdf.html#customizing-action-behavior",
    "title": "CLI Reference",
    "section": "1.49 Customizing Action Behavior",
    "text": "1.49 Customizing Action Behavior\nThe Actions class has two additional parameters that provide more control over how actions are executed:\n\n1.49.1 Setting Default Actions with default=\nInstead of specifying actions separately for each threshold level, you can use the default= parameter to set a common action for all levels:\n\ndef log_all_issues():\n    m = pb.get_action_metadata()\n    print(f\"[{m['level'].upper()}] Validation failed in step {m['step']} with level {m['level']}\")\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"duckdb\"),\n        thresholds=pb.Thresholds(warning=0.05, error=0.10, critical=0.15),\n\n        # The `log_all_issues()` callable is set to every threshold ---\n        actions=pb.Actions(default=log_all_issues),\n    )\n    .col_vals_regex(columns=\"player_id\", pattern=r\"[A-Z]{12}\\d{3}\")\n    .col_vals_gt(columns=\"item_revenue\", value=0.05)\n    .col_vals_gt(columns=\"session_duration\", value=15)\n    .interrogate()\n)\n\n[ERROR] Validation failed in step 2 with level error\n[CRITICAL] Validation failed in step 3 with level critical\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:40DuckDBWARNING0.05ERROR0.1CRITICAL0.15\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    player_id\n    [A-Z]{12}\\d{3}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #EBBC14\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    item_revenue\n    0.05\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    17010.85\n    2990.15\n    ●\n    ●\n    ○\n    —\n  \n  \n    #FF3300\n    3\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    session_duration\n    15\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    16750.84\n    3250.16\n    ●\n    ●\n    ●\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe default= parameter sets the same action for all threshold levels. If you later specify an action for a specific level, it will override this default for that level only.\nWhen using the default= parameter, be aware that your action (whether a string template or callable function) needs to work across all validation steps where thresholds might be exceeded. Not all validation methods provide the same context for string templates or in the metadata dictionary returned by get_action_metadata().\nFor example, some validation steps like col_vals_gt() provide a value field that can be accessed with {value} in string templates, while others like col_exists() don’t have this concept. When creating default actions, either use only the universally available placeholders ({step}, {level}, {type}, and {time}), or include conditional logic in your callable functions to handle different validation types appropriately.\n\n\n1.49.2 Controlling Action Execution with highest_only=\nBy default, Pointblank only executes the action for the most severe threshold level that’s been exceeded. If you want actions for all exceeded thresholds to be executed, you can set highest_only=False:\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"duckdb\"),\n        thresholds=pb.Thresholds(warning=0.05, error=0.10, critical=0.15),\n        actions=pb.Actions(\n            warning=\"Warning threshold exceeded in step {step}\",\n            error=\"Error threshold exceeded in step {step}\",\n            critical=\"Critical threshold exceeded in step {step}\",\n\n            # Execute all applicable actions ---\n            highest_only=False\n        ),\n    )\n    .col_vals_gt(columns=\"session_duration\", value=15)\n    .interrogate()\n)\n\nCritical threshold exceeded in step 1\nError threshold exceeded in step 1\nWarning threshold exceeded in step 1\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:41DuckDBWARNING0.05ERROR0.1CRITICAL0.15\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #FF3300\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    session_duration\n    15\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    16750.84\n    3250.16\n    ●\n    ●\n    ●\n    —\n  \n\n\n\n\n\n\n        \n\n\nIn this example, if all three thresholds are exceeded in a step, you’ll see all three messages printed, rather than just the critical one.\nThe default behavior (highest_only=True) helps prevent notification fatigue by limiting the number of actions executed when multiple thresholds are exceeded in the same validation step. For example, if a validation step fails with 60% of rows not passing, it would exceed ‘warning’, ‘error’, and ‘critical’ thresholds simultaneously. With highest_only=True, only the critical action would execute.\nYou might want to set highest_only=False when:\n\ndifferent threshold levels need to trigger different types of notifications (e.g., warnings to Slack, errors to email, critical to urgent notifications)\nyou need comprehensive logging of all severity levels for audit purposes\nyou’re building a dashboard that displays counts of issues at each severity level"
  },
  {
    "objectID": "user-guide-pdf.html#using-multiple-actions-for-a-threshold",
    "href": "user-guide-pdf.html#using-multiple-actions-for-a-threshold",
    "title": "CLI Reference",
    "section": "1.50 Using Multiple Actions for a Threshold",
    "text": "1.50 Using Multiple Actions for a Threshold\nYou can specify multiple actions to be executed for a single threshold level by providing a list:\n\ndef send_notification():\n    print(\"📧 Notification sent to data team\")\n\ndef log_to_system():\n    print(\"📝 Issue logged in system\")\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"duckdb\"),\n        thresholds=pb.Thresholds(critical=0.15),\n\n        # Set multiple actions for the critical threshold exceedance ---\n        actions=pb.Actions(\n            critical=[\n                \"CRITICAL: Data validation failed\",  # First action: display message\n                send_notification,                   # Second action: call function\n                log_to_system                        # Third action: call another function\n            ]\n        ),\n    )\n    .col_vals_gt(columns=\"session_duration\", value=15)\n    .interrogate()\n)\n\nCRITICAL: Data validation failed\n📧 Notification sent to data team\n📝 Issue logged in system\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:41DuckDBWARNING—ERROR—CRITICAL0.15\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #FF3300\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    session_duration\n    15\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    16750.84\n    3250.16\n    —\n    —\n    ●\n    —\n  \n\n\n\n\n\n\n        \n\n\nWhen providing a list of actions, they will be executed in sequence when the threshold is exceeded. This allows you to combine different types of actions such as displaying messages, sending notifications, and logging events."
  },
  {
    "objectID": "user-guide-pdf.html#final-actions",
    "href": "user-guide-pdf.html#final-actions",
    "title": "CLI Reference",
    "section": "1.51 Final Actions",
    "text": "1.51 Final Actions\n\n1.51.1 Creating Final Actions\nWhen you need to execute actions after all validation steps are complete, Pointblank provides the FinalActions class. Unlike Actions which triggers on a per-step basis during the validation process, FinalActions executes after the entire validation is complete, giving you a way to respond to the overall validation results.\nHere’s how to use FinalActions:\n\ndef send_alert():\n    summary = pb.get_validation_summary()\n    if summary[\"highest_severity\"] == \"critical\":\n        print(f\"ALERT: Critical validation failures found in `{summary['tbl_name']}`\")\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"duckdb\"),\n        tbl_name=\"game_revenue\",\n        thresholds=pb.Thresholds(warning=0.05, error=0.10, critical=0.15),\n\n        # Set final actions to be executed after all interrogations ---\n        final_actions=pb.FinalActions(\n            \"Validation complete.\",  # 1. a string message\n            send_alert               # 2. a callable function\n        )\n    )\n    .col_vals_regex(columns=\"player_id\", pattern=r\"[A-Z]{12}\\d{3}\")\n    .col_vals_gt(columns=\"item_revenue\", value=0.10)\n    .interrogate()\n)\n\nValidation complete.\nALERT: Critical validation failures found in `game_revenue`\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:41DuckDBgame_revenueWARNING0.05ERROR0.1CRITICAL0.15\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    player_id\n    [A-Z]{12}\\d{3}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #FF3300\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    item_revenue\n    0.1\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    14400.72\n    5600.28\n    ●\n    ●\n    ●\n    —\n  \n\n\n\n\n\n\n        \n\n\nIn this example:\n\nWe define the function send_alert() that checks the validation summary for critical failures\nWe provide a simple string message \"Validation complete.\" that will print to the console\nBoth actions will execute in order after all validation steps have completed\n\nBecause the ‘critical’ threshold was exceeded in Step 2, we see the printed alert of send_alert() after the simple string message.\nFinalActions accepts any number of actions as positional arguments. Each argument can be:\n\nString: A message to be displayed in the console\nCallable: A function to be called with no arguments\nList of Strings/Callables: Multiple actions to execute in sequence\n\nAll actions will be executed in the order they are provided after all validation steps have completed.\n\n\n1.51.2 Using get_validation_summary() in Final Actions\nWhen creating a callable function to use with FinalActions, you can access information about the overall validation results using the get_validation_summary() function. This gives you a dictionary with comprehensive information about the validation:\ndef comprehensive_report():\n    summary = pb.get_validation_summary()\n    print(f\"Validation Report for {summary['tbl_name']}:\")\n    print(f\"- Steps: {summary['n_steps']}\")\n    print(f\"- Passing steps: {summary['n_passing_steps']}\")\n    print(f\"- Failing steps: {summary['n_failing_steps']}\")\n\n    # Take additional actions based on results\n    if summary[\"n_failing_steps\"] &gt; 0:\n\n        # Create a Slack notification function ---\n        notify = pb.send_slack_notification(\n            webhook_url=\"https://hooks.slack.com/services/your/webhook/url\",\n            summary_msg=\"\"\"\n            🚨 *Validation Failure Alert*\n            • Table: {tbl_name}\n            • Failed Steps: {n_failing_steps} of {n_steps}\n            • Highest Severity: {highest_severity}\n            • Time: {time}\n            \"\"\",\n        )\n\n        # Execute the notification function\n        notify()\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"duckdb\"),\n        tbl_name=\"game_revenue\",\n        final_actions=pb.FinalActions(comprehensive_report),\n    )\n    .col_vals_regex(columns=\"player_id\", pattern=r\"[A-Z]{12}\\d{3}\")\n    .col_vals_gt(columns=\"item_revenue\", value=0.05)\n    .interrogate()\n)\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:41DuckDBgame_revenue\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    player_id\n    [A-Z]{12}\\d{3}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    item_revenue\n    0.05\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    17010.85\n    2990.15\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nHere we used the send_slack_notification() function, which is available in Pointblank as a pre-built action. It can be used by itself in final_actions= but here it’s integrated into the user’s comprehensive_report() function to provide finer control with conditional logic.\n\n\n1.51.3 Combining Step-level and Final Actions\nYou can use both Actions and FinalActions together for comprehensive validation control:\n\ndef log_step_failure():\n    m = pb.get_action_metadata()\n    print(f\"Step {m['step']} failed with {m['level']}\")\n\n\ndef generate_summary():\n    summary = pb.get_validation_summary()\n    # Sum up total failed test units across all steps\n    total_failed = sum(summary[\"dict_n_failed\"].values())\n    # Sum up total test units across all steps\n    total_units = sum(summary[\"dict_n\"].values())\n    print(f\"Validation complete: {total_failed} failures out of {total_units} tests\")\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"duckdb\"),\n        thresholds=pb.Thresholds(warning=0.05, error=0.10),\n\n        # Set an action for each step (highest threshold exceeded) ---\n        actions=pb.Actions(default=log_step_failure),\n\n        # Set a final action to get a summary of the validation process ---\n        final_actions=pb.FinalActions(generate_summary),\n    )\n    .col_vals_regex(columns=\"player_id\", pattern=r\"[A-Z]{12}\\d{3}\")\n    .col_vals_gt(columns=\"item_revenue\", value=0.05)\n    .interrogate()\n)\n\nStep 2 failed with error\nValidation complete: 299 failures out of 4000 tests\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:41DuckDBWARNING0.05ERROR0.1CRITICAL—\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    player_id\n    [A-Z]{12}\\d{3}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    —\n    —\n  \n  \n    #EBBC14\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    item_revenue\n    0.05\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    17010.85\n    2990.15\n    ●\n    ●\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThis approach allows you to:\n\nlog individual step failures during the validation process using Actions\ngenerate a comprehensive report after all validation steps are complete using FinalActions\n\nUsing both action types gives you fine-grained control over when and how notifications and other actions are triggered in your validation workflow."
  },
  {
    "objectID": "user-guide-pdf.html#conclusion-6",
    "href": "user-guide-pdf.html#conclusion-6",
    "title": "CLI Reference",
    "section": "1.52 Conclusion",
    "text": "1.52 Conclusion\nActions provide a powerful mechanism for responding to data validation results in Pointblank. By combining threshold settings with appropriate actions, you can create sophisticated data quality workflows that:\n\nprovide immediate feedback through console messages\nexecute custom functions when validation thresholds are exceeded\ncustomize notifications based on severity levels\ngenerate comprehensive reports after validation is complete\nautomate responses to data quality issues\n\nThe flexible design of Actions and FinalActions allows you to start simple with basic console messages and gradually build up to complex validation workflows with conditional logic, custom reporting, and integrations with other systems like Slack, email, or logging services.\nWhen designing your validation strategy, consider leveraging both step-level actions for immediate responses and final actions for holistic reporting. This combination provides comprehensive control over your data validation process and helps ensure that data quality issues are detected, reported, and addressed efficiently.\nWhen validating data with Pointblank, it’s often helpful to have descriptive labels for each validation step. This is where briefs come in. A brief is a short description of what a validation step is checking and it appears in the STEP column of the validation report table. Briefs make your validation reports more readable and they help others understand what each step is verifying without needing to look at the code.\nBriefs can be set in two ways:\n\nGlobally: applied to all validation steps via the brief= parameter in Validate\nLocally: set for individual validation steps via the brief= parameter in each validation method\n\nUnderstanding these two approaches to adding briefs gives you flexibility in how you document your validation process. Global briefs provide consistency across all steps and save time when you want similar descriptions throughout, while step-level briefs allow for precise customization when specific validations need more detailed or unique explanations. In practice, many validation workflows will combine both approaches (i.e., setting a useful global brief template while overriding it for steps that require special attention)."
  },
  {
    "objectID": "user-guide-pdf.html#global-briefs",
    "href": "user-guide-pdf.html#global-briefs",
    "title": "CLI Reference",
    "section": "1.53 Global Briefs",
    "text": "1.53 Global Briefs\nTo set a global brief that applies to all validation steps, use the Validate(brief=) parameter when creating a Validate object:\n\nimport pointblank as pb\nimport polars as pl\n\n# Sample data\ndata = pl.DataFrame({\n    \"id\": [1, 2, 3, 4, 5],\n    \"value\": [10, 20, 30, 40, 50],\n    \"category\": [\"A\", \"B\", \"C\", \"A\", \"B\"]\n})\n\n# Create a validation with a global brief\n(\n    pb.Validate(\n        data=data,\n\n        # Global brief template ---\n        brief=\"Step {step}: {auto}\"\n    )\n    .col_vals_gt(columns=\"value\", value=5)\n    .col_vals_in_set(columns=\"category\", set=[\"A\", \"B\", \"C\"])\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:42Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Step 1: Expect that values in value should be &gt; 5.\n\n        \n    value\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Step 2: Expect that values in category should be in the set of A, B, C.\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nIn this example, every validation step will have a brief description that follows the pattern \"Step X: [auto-generated description]\".\nThis is a simple example of template-based briefs. Later in this guide, we’ll explore the full range of templating elements available for creating custom brief descriptions that precisely communicate what each validation step is checking."
  },
  {
    "objectID": "user-guide-pdf.html#step-level-briefs",
    "href": "user-guide-pdf.html#step-level-briefs",
    "title": "CLI Reference",
    "section": "1.54 Step-level Briefs",
    "text": "1.54 Step-level Briefs\nYou can also set briefs for individual validation steps:\n\n(\n    pb.Validate(data=data)\n    .col_vals_gt(\n        columns=\"value\", value=5,\n        brief=\"Check if values exceed minimum threshold of 5\"\n    )\n    .col_vals_in_set(\n        columns=\"category\", set=[\"A\", \"B\", \"C\"],\n        brief=\"Verify categories are valid\"\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:42Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Check if values exceed minimum threshold of 5\n\n        \n    value\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Verify categories are valid\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nLocal briefs override any global briefs that might be set."
  },
  {
    "objectID": "user-guide-pdf.html#brief-templating",
    "href": "user-guide-pdf.html#brief-templating",
    "title": "CLI Reference",
    "section": "1.55 Brief Templating",
    "text": "1.55 Brief Templating\nBriefs support templating elements that get replaced with specific values:\n\n{auto}: an auto-generated description of the validation\n{step}: the step number in the validation plan\n{col}: the column name(s) being validated\n{value}: the comparison value used in the validation (when applicable)\n{thresholds}: a short summary of thresholds levels set (or unset) for the step\n{segment}, {segment_column}, {segment_value}: information on the step’s segment\n\nHere’s how to use these templates:\n\n(\n    pb.Validate(data=data)\n    .col_vals_gt(\n        columns=\"value\", value=5,\n        brief=\"Step {step}: Checking column '{col}' for values `&gt; 5`\"\n    )\n    .col_vals_in_set(\n        columns=\"category\", set=[\"A\", \"B\", \"C\"],\n        brief=\"{auto} **(Step {step})**\"\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:42Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Step 1: Checking column 'value' for values &gt; 5\n\n        \n    value\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Expect that values in category should be in the set of A, B, C. (Step 2)\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThese template elements make briefs highly flexible and customizable. You can combine multiple templating elements in a single brief to create descriptive yet concise validation step descriptions. The templates help maintain consistency across your validation reports while providing enough detail to understand what each step is checking.\nNote that not all templating elements will be relevant for every validation step. For instance, {value} is only applicable to validation functions that hold a comparison value like col_vals_gt(). If you include a templating element that isn’t relevant to a particular step, it will not be replaced with a corresponding value.\nBriefs support the use of Markdown formatting, allowing you to add emphasis with bold or italic text, include inline code formatting, or other Markdown elements to make your briefs more visually distinctive and informative. This can be especially helpful when you want certain parts of your briefs to stand out in the validation report."
  },
  {
    "objectID": "user-guide-pdf.html#automatic-briefs",
    "href": "user-guide-pdf.html#automatic-briefs",
    "title": "CLI Reference",
    "section": "1.56 Automatic Briefs",
    "text": "1.56 Automatic Briefs\nIf you want Pointblank to generate briefs for you automatically, you can set brief=True. Here, we’ll make that setting at the global level (by using Validate(brief=True)):\n\n(\n    pb.Validate(\n        data=data,\n\n        # Setting for automatically generated briefs ---\n        brief=True\n    )\n    .col_vals_gt(columns=\"value\", value=5)\n    .col_vals_in_set(columns=\"category\", set=[\"A\", \"B\", \"C\"])\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:42Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Expect that values in value should be &gt; 5.\n\n        \n    value\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Expect that values in category should be in the set of A, B, C.\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nAutomatic briefs are descriptive and include information about what’s being validated, including the column names and the validation conditions."
  },
  {
    "objectID": "user-guide-pdf.html#briefs-localized-to-a-specified-language",
    "href": "user-guide-pdf.html#briefs-localized-to-a-specified-language",
    "title": "CLI Reference",
    "section": "1.57 Briefs Localized to a Specified Language",
    "text": "1.57 Briefs Localized to a Specified Language\nWhen using the lang= parameter in Validate, automatically generated briefs will be created in the specified language (along with other elements of the validation report table):\n\n(\n    pb.Validate(\n        data=data,\n\n        # Setting the language as Spanish ---\n        lang=\"es\",\n\n        # Automatically generate all briefs in Spanish\n        brief=True\n    )\n    .col_vals_gt(columns=\"value\", value=5)\n    .col_vals_in_set(columns=\"category\", set=[\"A\", \"B\", \"C\"])\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Validación de Pointblank\n  \n  \n    2025-11-23|00:08:42Polars\n  \n\n  \n  \n  PASO\n  COLUMNAS\n  VALORES\n  TBL\n  EVAL\n  UNID.\n  PASA\n  FALLO\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Se espera que los valores en value sean &gt; 5.\n\n        \n    value\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51,00\n    00,00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Se espera que los valores en category estén en el conjunto de A, B, C.\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51,00\n    00,00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nWhen using the lang= parameter in combination with the {auto} templating element, the auto-generated portion of the brief will also be translated to the specified language. This makes it possible to create fully localized validation reports where both custom text and auto-generated descriptions appear in the same language.\nPointblank supports several languages for localized briefs, including French (\"fr\"), German (\"de\"), Spanish (\"es\"), Italian (\"it\"), and Portuguese (\"pt\"). For the complete list of supported languages, refer to the Validate documentation."
  },
  {
    "objectID": "user-guide-pdf.html#disabling-briefs",
    "href": "user-guide-pdf.html#disabling-briefs",
    "title": "CLI Reference",
    "section": "1.58 Disabling Briefs",
    "text": "1.58 Disabling Briefs\nIf you’ve set a global brief but want to disable it for specific validation steps, you can set brief=False:\n\n(\n    pb.Validate(\n        data=data,\n\n        # Global brief template ---\n        brief=\"Step {step}: {auto}\"\n    )\n    .col_vals_gt(columns=\"value\", value=5)  # This step uses the global brief setting\n    .col_vals_in_set(\n        columns=\"category\",\n        set=[\"A\", \"B\", \"C\"],\n\n        # No brief for this step ---\n        brief=False\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:42Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Step 1: Expect that values in value should be &gt; 5.\n\n        \n    value\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        \n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    51.00\n    00.00\n    —\n    —\n    —\n    —"
  },
  {
    "objectID": "user-guide-pdf.html#practical-example-comprehensive-validation-with-briefs",
    "href": "user-guide-pdf.html#practical-example-comprehensive-validation-with-briefs",
    "title": "CLI Reference",
    "section": "1.59 Practical Example: Comprehensive Validation with Briefs",
    "text": "1.59 Practical Example: Comprehensive Validation with Briefs\nIn real-world data validation scenarios, you’ll likely work with more complex datasets and apply various types of validation checks. This final example brings together many of the brief-generating techniques we’ve covered, showing how you can mix different approaches in a single validation workflow.\n\n# Create a slightly larger dataset\ndata_2 = pl.DataFrame({\n    \"id\": [1, 2, 3, 4, 5, 6, 7, 8],\n    \"value\": [10, 20, 30, 40, 50, 60, 70, 80],\n    \"ratio\": [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n    \"category\": [\"A\", \"B\", \"C\", \"A\", \"B\", \"C\", \"A\", \"B\"],\n    \"date\": [\"2023-01-01\", \"2023-01-02\", \"2023-01-03\", \"2023-01-04\",\n             \"2023-01-05\", \"2023-01-06\", \"2023-01-07\", \"2023-01-08\"]\n})\n\n(\n    pb.Validate(data=data_2)\n    .col_vals_gt(\n        columns=\"value\", value=0,\n\n        # Plaintext brief ---\n        brief=\"All values must be positive.\"\n    )\n    .col_vals_between(\n        columns=\"ratio\", left=0, right=1,\n\n        # Template-based brief ---\n        brief=\"**Step {step}**: Ratios should be between `0` and `1`.\"\n    )\n    .col_vals_in_set(\n        columns=\"category\", set=[\"A\", \"B\", \"C\"],\n\n        # Automatically generated brief ---\n        brief=True\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:42Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        All values must be positive.\n\n        \n    value\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    8\n    81.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_between\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_between()\n        \n        Step 2: Ratios should be between 0 and 1.\n\n        \n    ratio\n    [0, 1]\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    8\n    81.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Expect that values in category should be in the set of A, B, C.\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    8\n    81.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe example above demonstrates:\n\nplaintext briefs with direct messages\ntemplate-based briefs with Markdown formatting\nautomatically generated briefs (brief=True)\n\nBy combining these different brief styles, you can create validation reports that are informative, consistent, and tailored to your specific data quality requirements."
  },
  {
    "objectID": "user-guide-pdf.html#best-practices-for-using-briefs",
    "href": "user-guide-pdf.html#best-practices-for-using-briefs",
    "title": "CLI Reference",
    "section": "1.60 Best Practices for Using Briefs",
    "text": "1.60 Best Practices for Using Briefs\nWell-crafted briefs can significantly enhance the readability and usefulness of your validation reports. Here are some guidelines to follow:\n\nBe concise: briefs should be short and to the point; they’re meant to quickly communicate the purpose of a validation step\nBe specific: include relevant details or conditions that make the validation meaningful\nUse templates consistently: if you’re using template elements like \"{step}\" or \"{col}\", try to use them consistently across all briefs for a cleaner look\nUse auto-generated briefs as a starting point: you can start with Validate(brief=True) to see what Pointblank generates automatically, then customize as needed\nAdd custom briefs for complex validations: custom briefs are especially useful for complex validations where the purpose might not be immediately obvious from the code\n\nFollowing these best practices will help ensure your validation reports are easy to understand for everyone who needs to review them."
  },
  {
    "objectID": "user-guide-pdf.html#conclusion-7",
    "href": "user-guide-pdf.html#conclusion-7",
    "title": "CLI Reference",
    "section": "1.61 Conclusion",
    "text": "1.61 Conclusion\nBriefs help make validation reports more readable and understandable. By using global briefs, step-level briefs, or a combination of both, you can create validation reports that clearly communicate what each validation step is checking.\nWhether you want automatically generated descriptions or precisely tailored custom messages, the brief system provides the flexibility to make your data validation work more transparent and easier to interpret for all stakeholders."
  },
  {
    "objectID": "user-guide-pdf.html#basic-usage",
    "href": "user-guide-pdf.html#basic-usage",
    "title": "CLI Reference",
    "section": "2.1 Basic Usage",
    "text": "2.1 Basic Usage\nAt its core, col_vals_expr() validates whether an expression evaluates to True for each row in your data. Here’s a simple example:\n\nimport pointblank as pb\nimport polars as pl\n\n# Load small_table dataset as a Polars DataFrame\nsmall_table_pl = pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\")\n\n(\n    pb.Validate(data=small_table_pl)\n    .col_vals_expr(\n\n        # Use Polars expression syntax ---\n        expr=pl.col(\"d\") &gt; pl.col(\"a\") * 50,\n        brief=\"Column `d` should be at least 50 times larger than `a`.\"\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:42Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_expr\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_expr()\n        \n        Column d should be at least 50 times larger than a.\n\n        \n    —\n    COLUMN EXPR\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    120.92\n    10.08\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nIn this example, we’re validating that for each row, the value in column d is at least 50 times larger than the value in column a."
  },
  {
    "objectID": "user-guide-pdf.html#notes-on-expression-syntax",
    "href": "user-guide-pdf.html#notes-on-expression-syntax",
    "title": "CLI Reference",
    "section": "2.2 Notes on Expression Syntax",
    "text": "2.2 Notes on Expression Syntax\nThe expression syntax depends on your table type:\n\nPolars: uses Polars expression syntax with pl.col(\"column_name\")\nPandas: uses standard Python/NumPy syntax\n\nThe expression should:\n\nevaluate to a boolean result for each row\nreference columns using the appropriate syntax for your table type\nuse standard operators (+, -, *, /, &gt;, &lt;, ==, etc.)\nnot include assignments"
  },
  {
    "objectID": "user-guide-pdf.html#complex-expressions",
    "href": "user-guide-pdf.html#complex-expressions",
    "title": "CLI Reference",
    "section": "2.3 Complex Expressions",
    "text": "2.3 Complex Expressions\nThe real power of col_vals_expr() comes with complex expressions that would be difficult to represent using the standard validation functions:\n\n# Load game_revenue dataset as a Polars DataFrame\ngame_revenue_pl = pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"polars\")\n\n(\n    pb.Validate(data=game_revenue_pl)\n    .col_vals_expr(\n\n        # Use Polars expression syntax ---\n        expr=(pl.col(\"session_duration\") &gt; 20) | (pl.col(\"item_revenue\") &gt; 10),\n        brief=\"Sessions should be either long (&gt;20 min) or high-value (&gt;$10).\"\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:42Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_expr\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_expr()\n        \n        Sessions should be either long (&gt;20 min) or high-value (&gt;$10).\n\n        \n    —\n    COLUMN EXPR\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    15180.76\n    4820.24\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThis validates that either the session duration is longer than 20 minutes OR the item revenue is greater than $10."
  },
  {
    "objectID": "user-guide-pdf.html#example-multiple-conditions",
    "href": "user-guide-pdf.html#example-multiple-conditions",
    "title": "CLI Reference",
    "section": "2.4 Example: Multiple Conditions",
    "text": "2.4 Example: Multiple Conditions\nYou can create sophisticated validations with multiple conditions:\n\n# Create a simple Polars DataFrame\nemployee_df = pl.DataFrame({\n    \"age\": [25, 30, 15, 40, 35],\n    \"income\": [50000, 75000, 0, 100000, 60000],\n    \"years_experience\": [3, 8, 0, 15, 7]\n})\n\n(\n    pb.Validate(data=employee_df, tbl_name=\"employee_data\")\n    .col_vals_expr(\n\n        # Complex condition with multiple comparisons ---\n        expr=(\n            (pl.col(\"age\") &gt;= 18) &\n            (pl.col(\"income\") / (pl.col(\"years_experience\") + 1) &lt;= 25000)\n        ),\n        brief=\"Adults should have reasonable income-to-experience ratios.\"\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:42Polarsemployee_data\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_expr\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_expr()\n        \n        Adults should have reasonable income-to-experience ratios.\n\n        \n    —\n    COLUMN EXPR\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    40.80\n    10.20\n    —\n    —\n    —\n    CSV"
  },
  {
    "objectID": "user-guide-pdf.html#example-handling-null-values",
    "href": "user-guide-pdf.html#example-handling-null-values",
    "title": "CLI Reference",
    "section": "2.5 Example: Handling Null Values",
    "text": "2.5 Example: Handling Null Values\nWhen working with expressions, consider how to handle null/missing values:\n\n(\n    pb.Validate(data=small_table_pl)\n    .col_vals_expr(\n\n        # Check for nulls before division ---\n        expr=(pl.col(\"c\").is_not_null()) & ((pl.col(\"c\") / pl.col(\"a\")) &gt; 1.5),\n        brief=\"Ratio of `c`/`a` should exceed 1.5 (when `c` is not null).\"\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:42Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_expr\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_expr()\n        \n        Ratio of c/a should exceed 1.5 (when c is not null).\n\n        \n    —\n    COLUMN EXPR\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    50.38\n    80.62\n    —\n    —\n    —\n    CSV"
  },
  {
    "objectID": "user-guide-pdf.html#best-practices",
    "href": "user-guide-pdf.html#best-practices",
    "title": "CLI Reference",
    "section": "2.6 Best Practices",
    "text": "2.6 Best Practices\nHere are some tips and tricks for effectively using expression-based validation with col_vals_expr().\n\n2.6.1 Document Your Expressions\nAlways provide clear documentation in the brief= parameter:\n\n(\n    pb.Validate(data=small_table_pl)\n    .col_vals_expr(\n        expr=pl.col(\"d\") &gt; pl.col(\"a\") * 1.5,\n\n        # Document which columns are being compared ---\n        brief=\"Column `d` should be at least 1.5 times larger than column `a`.\"\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:43Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_expr\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_expr()\n        \n        Column d should be at least 1.5 times larger than column a.\n\n        \n    —\n    COLUMN EXPR\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\n\n\n2.6.2 Handle Edge Cases\nConsider potential edge cases like division by zero or nulls:\n\n(\n    pb.Validate(data=small_table_pl)\n    .col_vals_expr(\n\n        # Check denominator before division ---\n        expr=(pl.col(\"a\") != 0) & (pl.col(\"d\") / pl.col(\"a\") &gt; 1.5),\n        brief=\"Ratio of `d`/`a` should exceed 1.5 (avoiding division by zero).\"\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:43Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_expr\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_expr()\n        \n        Ratio of d/a should exceed 1.5 (avoiding division by zero).\n\n        \n    —\n    COLUMN EXPR\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\n\n\n2.6.3 Test on Small Datasets First\nWhen developing complex expressions, test on a small sample of your data first to ensure your logic is correct before applying it to large datasets."
  },
  {
    "objectID": "user-guide-pdf.html#conclusion-8",
    "href": "user-guide-pdf.html#conclusion-8",
    "title": "CLI Reference",
    "section": "2.7 Conclusion",
    "text": "2.7 Conclusion\nThe col_vals_expr() method provides a powerful way to implement complex validation logic in Pointblank when standard validation methods aren’t sufficient. By leveraging expressions, you can create sophisticated data quality checks tailored to your specific requirements, combining conditions across multiple columns and applying transformations as needed.\nThis flexibility makes expression-based validation an essential tool for addressing complex data quality scenarios in your validation workflows.\nSchema validation in Pointblank allows you to verify that your data conforms to an expected structure and type specification. This is particularly useful when ensuring data consistency across systems or validating incoming data against predefined requirements.\nLet’s first look at the dataset we’ll use for the first example:\n\nimport pointblank as pb\n\n# Preview the small_table dataset we'll use throughout this guide\npb.preview(pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows13Columns8\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05\n    6\n    8-kdg-938\n    3\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    None\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09\n    8\n    3-ldm-038\n    7\n    283.94\n    True\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26\n    4\n    2-dmx-010\n    7\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28\n    2\n    7-dmx-010\n    8\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30\n    1\n    3-dka-303\n    None\n    2230.09\n    True\n    high"
  },
  {
    "objectID": "user-guide-pdf.html#schema-definition-and-validation",
    "href": "user-guide-pdf.html#schema-definition-and-validation",
    "title": "CLI Reference",
    "section": "2.8 Schema Definition and Validation",
    "text": "2.8 Schema Definition and Validation\nA schema in Pointblank is created using the Schema class which defines the expected structure of a table. Once created, you apply schema validation through the col_schema_match() validation step.\n\n# Create a schema definition matching small_table structure\nschema = pb.Schema(\n    columns=[\n        (\"date_time\",),   # Only check column name\n        (\"date\",),        # Only check column name\n        (\"a\", \"Int64\"),   # Check name and type\n        (\"b\", \"String\"),  # Check name and type\n        (\"c\", \"Int64\"),   # Check name and type\n        (\"d\", \"Float64\"), # Check name and type\n        (\"e\", \"Boolean\"), # Check name and type\n        (\"f\",),           # Only check column name\n    ]\n)\n\n# Validate the small_table against the schema\nsmall_table_validation = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"),\n        label=\"Schema validation of `small_table`.\",\n    )\n    .col_schema_match(schema=schema)\n    .interrogate()\n)\n\nsmall_table_validation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Schema validation of `small_table`.Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_schema_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            col_schema_match()\n        \n        \n        \n    —\n    SCHEMA\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe output shows the validation passed successfully. When all columns have the correct names and types as specified in the schema, the validation passes with a single passing test unit. If there were discrepancies, this would fail, but the basic output wouldn’t show specific issues.\nFor detailed information about validation results, use get_step_report():\n\nsmall_table_validation.get_step_report(i=1)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 1 ✓COLUMN SCHEMA MATCHCOMPLETEIN ORDERCOLUMN ≠ columnDTYPE ≠ dtypefloat ≠ float64\n  \n\n  \n    TARGET\n  \n  \n    EXPECTED\n  \n\n\n  \n  COLUMN\n  DATA TYPE\n  \n  COLUMN\n  \n  DATA TYPE\n  \n\n\n\n  \n    1\n    date_time\n    Datetime(time_unit='us', time_zone=None)\n    1\n    date_time\n    ✓\n    —\n    \n  \n  \n    2\n    date\n    Date\n    2\n    date\n    ✓\n    —\n    \n  \n  \n    3\n    a\n    Int64\n    3\n    a\n    ✓\n    Int64\n    ✓\n  \n  \n    4\n    b\n    String\n    4\n    b\n    ✓\n    String\n    ✓\n  \n  \n    5\n    c\n    Int64\n    5\n    c\n    ✓\n    Int64\n    ✓\n  \n  \n    6\n    d\n    Float64\n    6\n    d\n    ✓\n    Float64\n    ✓\n  \n  \n    7\n    e\n    Boolean\n    7\n    e\n    ✓\n    Boolean\n    ✓\n  \n  \n    8\n    f\n    String\n    8\n    f\n    ✓\n    —\n    \n  \n\n  \n  \n  \n    Supplied Column Schema:[('date_time',), ('date',), ('a', 'Int64'), ('b', 'String'), ('c', 'Int64'), ('d', 'Float64'), ('e', 'Boolean'), ('f',)]\n  \n\n\n\n\n\n\n        \n\n\nThe step report provides specific details about which columns were checked and whether they matched the schema, helping diagnose issues when validation fails."
  },
  {
    "objectID": "user-guide-pdf.html#schema-components-and-column-types",
    "href": "user-guide-pdf.html#schema-components-and-column-types",
    "title": "CLI Reference",
    "section": "2.9 Schema Components and Column Types",
    "text": "2.9 Schema Components and Column Types\nWhen defining a schema, you need to specify column names and optionally their data types. By default, Pointblank enforces strict validation where:\n\nall columns in your table must match the specified schema\ncolumn order must match the schema\ncolumn types are case-sensitive\ntype names must match exactly\n\nThe schema definition accepts column types as string representations, which vary depending on your data source:\n\nstring: Character data (may also be \"String\", \"varchar\", \"character\", etc.)\ninteger: Integer values (may also be \"Int64\", \"int\", \"bigint\", etc.)\nnumeric: Numeric values including integers and floating-point numbers (may also be \"Float64\", \"double\", \"decimal\", etc.)\nboolean: Logical values (True/False) (may also be \"Boolean\", \"bool\", etc.)\ndatetime: Date and time values (may also be \"Datetime\", \"timestamp\", etc.)\ndate: Date values (may also be \"Date\", etc.)\ntime: Time values\n\nFor specific database engines or DataFrame libraries, you may need to use their exact type names (like \"VARCHAR(255)\" for SQL databases or \"Int64\" for Polars integers)."
  },
  {
    "objectID": "user-guide-pdf.html#discovering-column-types",
    "href": "user-guide-pdf.html#discovering-column-types",
    "title": "CLI Reference",
    "section": "2.10 Discovering Column Types",
    "text": "2.10 Discovering Column Types\nTo easily determine the correct type string for columns in your data, Pointblank provides two helpful functions:\n\nimport polars as pl\nfrom datetime import date\n\n# Define a sample dataframe\nsample_df = pl.DataFrame({\n    \"id\": [1, 2, 3],\n    \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n    \"join_date\": [date(2020, 1, 1), date(2021, 3, 15), date(2022, 7, 10)]\n})\n\n\n# Method 1: Using `preview()` with `show_types=True` to see column types\npb.preview(sample_df)\n\n\n\n\n\n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows3Columns3\n  \n\n  \n  idInt64\n  nameString\n  join_dateDate\n\n\n\n  \n    1\n    1\n    Alice\n    2020-01-01\n  \n  \n    2\n    2\n    Bob\n    2021-03-15\n  \n  \n    3\n    3\n    Charlie\n    2022-07-10\n  \n\n\n\n\n\n\n        \n\n\n\n# Method 2: Using `col_summary_tbl()` which shows column types and other details\npb.col_summary_tbl(sample_df)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows3Columns3\n  \n\n  \n  Column\n  NA\n  UQ\n  Mean\n  SD\n  Min\n  P5\n  Q1\n  Med\n  Q3\n  P95\n  Max\n  IQR\n\n\n\n  \n    \n    numeric\n    \n        \n            \n            \n                \n            \n        \n    \n\n    idInt64\n    00\n    31\n    2\n    1\n    1\n    1.01\n    1.5\n    2\n    2.5\n    2.9\n    3\n    1\n  \n  \n    \n    string\n    \n        \n            \n            \n                \n            \n        \n    \n\n    nameString\n    00\n    31\n    5\n    2\n    3\n    3.02\n    4\n    5\n    6\n    6.8\n    7\n    2\n  \n  \n    \n    date\n    \n        \n            \n            \n                \n            \n        \n    \n\n    join_dateDate\n    00\n    31\n    -\n    -\n    20200101\n    -\n    -\n    -\n    -\n    -\n    20220710\n    -\n  \n\n  \n  \n  \n    String columns statistics regard the string's length.\n  \n\n\n\n\n\n\n        \n\n\nThese functions help you identify the exact type strings to use in your schema definitions, eliminating guesswork and ensuring compatibility with your data source."
  },
  {
    "objectID": "user-guide-pdf.html#creating-a-schema",
    "href": "user-guide-pdf.html#creating-a-schema",
    "title": "CLI Reference",
    "section": "2.11 Creating a Schema",
    "text": "2.11 Creating a Schema\nYou can create a schema in four different ways, each with its own advantages. All schema objects can be printed to display their column names and data types.\n\n2.11.1 1. Using a List of Tuples with columns=\nThis approach allows for mixed validation: some columns checked for both name and type, others only for name:\n\nschema_tuples = pb.Schema(\n\n    # List of tuples approach: flexible for mixed type/name checking ---\n    columns=[\n        (\"name\", \"String\"), # Check name and type\n        (\"age\", \"Int64\"),   # Check name and type\n        (\"height\",)         # Check name only\n    ]\n)\n\nprint(schema_tuples)\n\nPointblank Schema\n  name: String\n  age: Int64\n  height: &lt;ANY&gt;\n\n\nThis is the only method that allows checking just column names for some columns while checking both names and types for others.\n\n\n2.11.2 2. Using a Dictionary with columns=\nThis approach is often the most readable when defining a schema manually, especially for larger schemas:\n\nschema_dict = pb.Schema(\n\n    # Dictionary approach (keys are column names, values are data types) ---\n    columns={\n        \"name\": \"String\",\n        \"age\": \"Int64\",\n        \"height\": \"Float64\",\n        \"created_at\": \"Datetime\"\n    }\n)\n\nprint(schema_dict)\n\nPointblank Schema\n  name: String\n  age: Int64\n  height: Float64\n  created_at: Datetime\n\n\nWith this method, you must always provide both column names (as keys) and their types (as values).\n\n\n2.11.3 3. Using Keyword Arguments\nFor more readable code with a small number of columns:\n\nschema_kwargs = pb.Schema(\n\n    # Keyword arguments approach (more readable for simple schemas) ---\n    name=\"String\",\n    age=\"Int64\",\n    height=\"Float64\"\n)\n\nprint(schema_kwargs)\n\nPointblank Schema\n  name: String\n  age: Int64\n  height: Float64\n\n\nLike the dictionary method, this approach requires both column names and types.\n\n\n2.11.4 4. Extracting from an Existing Table with tbl=\nYou can automatically extract a schema from an existing table:\n\nimport polars as pl\n\n# Create a sample dataframe\ndf = pl.DataFrame({\n    \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n    \"age\": [25, 30, 35],\n    \"height\": [5.6, 6.0, 5.8]\n})\n\n# Extract schema from table\nschema_from_table = pb.Schema(tbl=df)\n\nprint(schema_from_table)\n\nPointblank Schema\n  name: String\n  age: Int64\n  height: Float64\n\n\nThis is especially useful when you want to validate that future data matches the structure of a reference dataset."
  },
  {
    "objectID": "user-guide-pdf.html#multiple-data-types-for-a-column",
    "href": "user-guide-pdf.html#multiple-data-types-for-a-column",
    "title": "CLI Reference",
    "section": "2.12 Multiple Data Types for a Column",
    "text": "2.12 Multiple Data Types for a Column\nYou can specify multiple acceptable types for a column by providing a list of types:\n\n# Schema with multiple possible types for a column\nschema_multi_types = pb.Schema(\n    columns={\n        \"name\": \"String\",\n        \"age\": [\"Int64\", \"Float64\"],  # Accept either integer or float\n        \"active\": \"Boolean\"\n    }\n)\n\nprint(schema_multi_types)\n\nPointblank Schema\n  name: String\n  age: ['Int64', 'Float64']\n  active: Boolean\n\n\nThis is useful when working with data sources that might represent the same information in different ways (e.g., integers sometimes stored as floats)."
  },
  {
    "objectID": "user-guide-pdf.html#schema-validation-options",
    "href": "user-guide-pdf.html#schema-validation-options",
    "title": "CLI Reference",
    "section": "2.13 Schema Validation Options",
    "text": "2.13 Schema Validation Options\nWhen using col_schema_match(), you can customize validation behavior with several important options:\n\n\n\n\n\n\n\n\nOption\nDefault\nDescription\n\n\n\n\ncomplete\nTrue\nRequire exact column presence (no extra columns allowed)\n\n\nin_order\nTrue\nEnforce column order\n\n\ncase_sensitive_colnames\nTrue\nMake column name matching case-sensitive\n\n\ncase_sensitive_dtypes\nTrue\nMake data type matching case-sensitive\n\n\nfull_match_dtypes\nTrue\nRequire exact (not partial) type name matches\n\n\n\n\n2.13.1 Controlling Column Presence\nBy default, col_schema_match() requires a complete match between the schema’s columns and the table’s columns. You can make this more flexible:\n\n# Create a sample table\nusers_table_extra = pl.DataFrame({\n    \"id\": [1, 2, 3],\n    \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n    \"age\": [25, 30, 35],\n    \"extra_col\": [\"a\", \"b\", \"c\"]  # Extra column not in schema\n})\n\n# Create a schema\nschema = pb.Schema(\n    columns={\"id\": \"Int64\", \"name\": \"String\", \"age\": \"Int64\"}\n)\n\n# Validate without requiring all columns to be present\nvalidation = (\n    pb.Validate(data=users_table_extra)\n    .col_schema_match(\n        schema=schema,\n\n        # Allow schema columns to be a subset ---\n        complete=False\n    )\n    .interrogate()\n)\n\nvalidation.get_step_report(i=1)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 1 ✓COLUMN SCHEMA MATCHCOMPLETEIN ORDERCOLUMN ≠ columnDTYPE ≠ dtypefloat ≠ float64\n  \n\n  \n    TARGET\n  \n  \n    EXPECTED\n  \n\n\n  \n  COLUMN\n  DATA TYPE\n  \n  COLUMN\n  \n  DATA TYPE\n  \n\n\n\n  \n    1\n    id\n    Int64\n    1\n    id\n    ✓\n    Int64\n    ✓\n  \n  \n    2\n    name\n    String\n    2\n    name\n    ✓\n    String\n    ✓\n  \n  \n    3\n    age\n    Int64\n    3\n    age\n    ✓\n    Int64\n    ✓\n  \n  \n    4\n    extra_col\n    String\n    \n    \n    \n    \n    \n  \n\n  \n  \n  \n    Supplied Column Schema:[('id', 'Int64'), ('name', 'String'), ('age', 'Int64')]\n  \n\n\n\n\n\n\n        \n\n\n\n\n2.13.2 Column Order Enforcement\nYou can control whether column order matters in your validation:\n\n# Create a sample table\nusers_table = pl.DataFrame({\n    \"id\": [1, 2, 3],\n    \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n    \"age\": [25, 30, 35],\n})\n\n# Create a schema\nschema = pb.Schema(\n    columns={\"name\": \"String\", \"age\": \"Int64\", \"id\": \"Int64\"}\n)\n\n# Validate without enforcing column order\nvalidation = (\n    pb.Validate(data=users_table)\n    .col_schema_match(\n        schema=schema,\n\n        # Don't enforce column order ---\n        in_order=False\n    )\n    .interrogate()\n)\n\nvalidation.get_step_report(i=1)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 1 ✓COLUMN SCHEMA MATCHCOMPLETEIN ORDERCOLUMN ≠ columnDTYPE ≠ dtypefloat ≠ float64\n  \n\n  \n    TARGET\n  \n  \n    EXPECTED\n  \n\n\n  \n  COLUMN\n  DATA TYPE\n  \n  COLUMN\n  \n  DATA TYPE\n  \n\n\n\n  \n    1\n    id\n    Int64\n    3\n    id\n    ✓\n    Int64\n    ✓\n  \n  \n    2\n    name\n    String\n    1\n    name\n    ✓\n    String\n    ✓\n  \n  \n    3\n    age\n    Int64\n    2\n    age\n    ✓\n    Int64\n    ✓\n  \n\n  \n  \n  \n    Supplied Column Schema:[('name', 'String'), ('age', 'Int64'), ('id', 'Int64')]\n  \n\n\n\n\n\n\n        \n\n\n\n\n2.13.3 Case Sensitivity\nControl whether column names and data types are case-sensitive:\n\n# Create schema with different case charactistics\ncase_schema = pb.Schema(\n    columns={\"ID\": \"int64\", \"NAME\": \"string\", \"AGE\": \"int64\"}\n)\n\n# Create validation with case-insensitive column names and types\nvalidation = (\n    pb.Validate(data=users_table)\n    .col_schema_match(\n        schema=case_schema,\n\n        # Ignore case in column names ---\n        case_sensitive_colnames=False,\n\n        # Ignore case in data type names ---\n        case_sensitive_dtypes=False\n    )\n    .interrogate()\n)\n\nvalidation.get_step_report(i=1)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 1 ✓COLUMN SCHEMA MATCHCOMPLETEIN ORDERCOLUMN = columnDTYPE = dtypefloat ≠ float64\n  \n\n  \n    TARGET\n  \n  \n    EXPECTED\n  \n\n\n  \n  COLUMN\n  DATA TYPE\n  \n  COLUMN\n  \n  DATA TYPE\n  \n\n\n\n  \n    1\n    id\n    Int64\n    1\n    ID\n    ✓\n    int64\n    ✓\n  \n  \n    2\n    name\n    String\n    2\n    NAME\n    ✓\n    string\n    ✓\n  \n  \n    3\n    age\n    Int64\n    3\n    AGE\n    ✓\n    int64\n    ✓\n  \n\n  \n  \n  \n    Supplied Column Schema:[('ID', 'int64'), ('NAME', 'string'), ('AGE', 'int64')]\n  \n\n\n\n\n\n\n        \n\n\n\n\n2.13.4 Type Matching Precision\nControl how strictly data types must match:\n\n# Create schema with simplified type names\ntype_schema = pb.Schema(\n\n    # Using simplified type names ---\n    columns={\"id\": \"int\", \"name\": \"str\", \"age\": \"int\"}\n)\n\n# Allow partial type matches\nvalidation = (\n    pb.Validate(data=users_table)\n    .col_schema_match(\n        schema=type_schema,\n\n        # Ignore case in data type names ---\n        case_sensitive_dtypes=False,\n\n        # Allow partial type name matches ---\n        full_match_dtypes=False\n    )\n    .interrogate()\n)\n\nvalidation.get_step_report(i=1)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 1 ✓COLUMN SCHEMA MATCHCOMPLETEIN ORDERCOLUMN ≠ columnDTYPE = dtypefloat = float64\n  \n\n  \n    TARGET\n  \n  \n    EXPECTED\n  \n\n\n  \n  COLUMN\n  DATA TYPE\n  \n  COLUMN\n  \n  DATA TYPE\n  \n\n\n\n  \n    1\n    id\n    Int64\n    1\n    id\n    ✓\n    int\n    ✓\n  \n  \n    2\n    name\n    String\n    2\n    name\n    ✓\n    str\n    ✓\n  \n  \n    3\n    age\n    Int64\n    3\n    age\n    ✓\n    int\n    ✓\n  \n\n  \n  \n  \n    Supplied Column Schema:[('id', 'int'), ('name', 'str'), ('age', 'int')]"
  },
  {
    "objectID": "user-guide-pdf.html#common-schema-validation-patterns",
    "href": "user-guide-pdf.html#common-schema-validation-patterns",
    "title": "CLI Reference",
    "section": "2.14 Common Schema Validation Patterns",
    "text": "2.14 Common Schema Validation Patterns\nThis section explores common patterns for applying schema validation to different scenarios. Each pattern addresses specific validation needs you might encounter when working with real-world data. We’ll examine the step reports for these validations since they provide more detailed information about what was checked and how the validation performed, offering an intuitive way to understand the results beyond simple pass/fail indicators."
  },
  {
    "objectID": "user-guide-pdf.html#common-schema-validation-patterns-1",
    "href": "user-guide-pdf.html#common-schema-validation-patterns-1",
    "title": "CLI Reference",
    "section": "2.15 Common Schema Validation Patterns",
    "text": "2.15 Common Schema Validation Patterns\nThis section explores common patterns for applying schema validation to different scenarios. Each pattern addresses specific validation needs you might encounter when working with real-world data. We’ll examine the step reports (get_step_report()) for these validations since they provide more detailed information about what was checked and how the validation performed, offering an intuitive way to understand the results beyond simple pass/fail indicators.\n\n2.15.1 Structural Validation Only\nWhen you only care about column names but not their types:\n\n# Create a schema with only column names\nstructure_schema = pb.Schema(\n    columns=[\"id\", \"name\", \"age\", \"extra_col\"]\n)\n\n# Validate structure only\nvalidation = (\n    pb.Validate(data=users_table_extra)\n    .col_schema_match(schema=structure_schema)\n    .interrogate()\n)\n\nvalidation.get_step_report(i=1)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 1 ✓COLUMN SCHEMA MATCHCOMPLETEIN ORDERCOLUMN ≠ columnDTYPE ≠ dtypefloat ≠ float64\n  \n\n  \n    TARGET\n  \n  \n    EXPECTED\n  \n\n\n  \n  COLUMN\n  DATA TYPE\n  \n  COLUMN\n  \n  DATA TYPE\n  \n\n\n\n  \n    1\n    id\n    Int64\n    1\n    id\n    ✓\n    —\n    \n  \n  \n    2\n    name\n    String\n    2\n    name\n    ✓\n    —\n    \n  \n  \n    3\n    age\n    Int64\n    3\n    age\n    ✓\n    —\n    \n  \n  \n    4\n    extra_col\n    String\n    4\n    extra_col\n    ✓\n    —\n    \n  \n\n  \n  \n  \n    Supplied Column Schema:[('id',), ('name',), ('age',), ('extra_col',)]\n  \n\n\n\n\n\n\n        \n\n\n\n\n2.15.2 Mixed Validation\nValidate types for critical columns but just presence for others:\n\n# Mixed validation for different columns\nmixed_schema = pb.Schema(\n    columns=[\n        (\"id\", \"Int64\"),     # Check name and type\n        (\"name\", \"String\"),  # Check name and type\n        (\"age\",),            # Check name only\n        (\"extra_col\",)       # Check name only\n    ]\n)\n\n# Validate with mixed approach\nvalidation = (\n    pb.Validate(data=users_table_extra)\n    .col_schema_match(schema=mixed_schema)\n    .interrogate()\n)\n\nvalidation.get_step_report(i=1)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 1 ✓COLUMN SCHEMA MATCHCOMPLETEIN ORDERCOLUMN ≠ columnDTYPE ≠ dtypefloat ≠ float64\n  \n\n  \n    TARGET\n  \n  \n    EXPECTED\n  \n\n\n  \n  COLUMN\n  DATA TYPE\n  \n  COLUMN\n  \n  DATA TYPE\n  \n\n\n\n  \n    1\n    id\n    Int64\n    1\n    id\n    ✓\n    Int64\n    ✓\n  \n  \n    2\n    name\n    String\n    2\n    name\n    ✓\n    String\n    ✓\n  \n  \n    3\n    age\n    Int64\n    3\n    age\n    ✓\n    —\n    \n  \n  \n    4\n    extra_col\n    String\n    4\n    extra_col\n    ✓\n    —\n    \n  \n\n  \n  \n  \n    Supplied Column Schema:[('id', 'Int64'), ('name', 'String'), ('age',), ('extra_col',)]\n  \n\n\n\n\n\n\n        \n\n\n\n\n2.15.3 Progressive Schema Evolution\nAs your data evolves, you might need to adapt your validation approach:\n\n# Original schema\noriginal_schema = pb.Schema(\n    columns={\n        \"id\": \"Int64\",\n        \"name\": \"String\"\n    }\n)\n\n# New data with additional columns\nevolved_data = pl.DataFrame({\n    \"id\": [1, 2, 3],\n    \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n    \"age\": [25, 30, 35],           # New column\n    \"active\": [True, False, True]  # New column\n})\n\n# Validate with flexible parameters\nvalidation = (\n    pb.Validate(evolved_data)\n    .col_schema_match(\n        schema=original_schema,\n\n        # Allow extra columns ---\n        complete=False,\n\n        # Don't enforce order ---\n        in_order=False\n    )\n    .interrogate()\n)\n\nvalidation.get_step_report(i=1)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 1 ✓COLUMN SCHEMA MATCHCOMPLETEIN ORDERCOLUMN ≠ columnDTYPE ≠ dtypefloat ≠ float64\n  \n\n  \n    TARGET\n  \n  \n    EXPECTED\n  \n\n\n  \n  COLUMN\n  DATA TYPE\n  \n  COLUMN\n  \n  DATA TYPE\n  \n\n\n\n  \n    1\n    id\n    Int64\n    1\n    id\n    ✓\n    Int64\n    ✓\n  \n  \n    2\n    name\n    String\n    2\n    name\n    ✓\n    String\n    ✓\n  \n  \n    3\n    age\n    Int64\n    \n    \n    \n    \n    \n  \n  \n    4\n    active\n    Boolean\n    \n    \n    \n    \n    \n  \n\n  \n  \n  \n    Supplied Column Schema:[('id', 'Int64'), ('name', 'String')]"
  },
  {
    "objectID": "user-guide-pdf.html#integrating-with-larger-validation-workflows",
    "href": "user-guide-pdf.html#integrating-with-larger-validation-workflows",
    "title": "CLI Reference",
    "section": "2.16 Integrating with Larger Validation Workflows",
    "text": "2.16 Integrating with Larger Validation Workflows\nSchema validation is often just one part of a comprehensive data validation strategy. You can combine schema checks with other validation steps:\n\n# Define a schema\nschema = pb.Schema(\n    columns={\n        \"id\": \"Int64\",\n        \"name\": \"String\",\n        \"age\": \"Int64\"\n    }\n)\n\n# Create a validation plan\nvalidation = (\n    pb.Validate(\n        users_table,\n        label=\"User data validation\",\n        thresholds=pb.Thresholds(warning=0.05, error=0.1)\n    )\n\n    # Add schema validation ---\n    .col_schema_match(schema=schema)\n\n    # Add other validation steps ---\n    .col_vals_not_null(columns=\"id\")\n    .col_vals_gt(columns=\"age\", value=26)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    User data validationPolarsWARNING0.05ERROR0.1CRITICAL—\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_schema_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            col_schema_match()\n        \n        \n        \n    —\n    SCHEMA\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    ○\n    ○\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    id\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    ○\n    ○\n    —\n    —\n  \n  \n    #EBBC14\n    3\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    age\n    26\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    20.67\n    10.33\n    ●\n    ●\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThis approach allows you to first validate the structure of your data and then check specific business rules or constraints."
  },
  {
    "objectID": "user-guide-pdf.html#best-practices-1",
    "href": "user-guide-pdf.html#best-practices-1",
    "title": "CLI Reference",
    "section": "2.17 Best Practices",
    "text": "2.17 Best Practices\n\nDefine schemas early: document and define expected data structures early in your data workflow.\nChoose the right creation method:\n\nuse columns=&lt;dict&gt; for readability with many columns\nuse columns=&lt;list of tuples&gt; for mixed name/type validation\nuse kwargs for small schemas with simple column names\nuse tbl= to extract schemas from reference datasets\n\nBe deliberate about strictness: choose validation parameters based on your specific needs:\n\nstrict validation (complete=True) for critical data interfaces\nflexible validation (complete=False, in_order=False) for evolving datasets\n\nReuse schemas: create schema definitions that can be reused across multiple validation contexts.\nVersion control schemas: as your data evolves, maintain versions of your schemas to track changes.\nExtract schemas from reference data: when you have a ‘golden’ dataset that represents your ideal structure, use Schema(tbl=reference_data) to extract its schema.\nConsider type flexibility: use multiple types per column ([\"Int64\", \"Float64\"]) when working with data from diverse sources.\nCombine with targeted validation: use schema validation for structural checks and add specific validation steps for business rules."
  },
  {
    "objectID": "user-guide-pdf.html#conclusion-9",
    "href": "user-guide-pdf.html#conclusion-9",
    "title": "CLI Reference",
    "section": "2.18 Conclusion",
    "text": "2.18 Conclusion\nSchema validation provides a powerful mechanism for ensuring your data adheres to expected structural requirements. It serves as an excellent first line of defense in your data validation strategy, verifying that the data you’re working with has the expected shape before applying more detailed business rule validations.\nThe Schema class offers multiple ways to define schemas, from manual specification with dictionaries or keyword arguments to automatic extraction from reference tables. When combined with the flexible options of col_schema_match(), you can implement validation approaches ranging from strict structural enforcement to more flexible evolution-friendly checks.\nBy understanding the different schema creation methods and validation options, you can efficiently validate the structure of your data tables and ensure they meet your requirements before processing.\nIn addition to validation steps that create reports, Pointblank provides assertions. This is a lightweight way to confirm data quality by raising exceptions when validation conditions aren’t met. Assertions are particularly useful in:\n\ndata processing pipelines where you need to halt execution if data doesn’t meet expectations\ntesting environments where you want to verify data properties programmatically\nscripts and functions where you need immediate notification of data problems"
  },
  {
    "objectID": "user-guide-pdf.html#basic-assertion-workflow",
    "href": "user-guide-pdf.html#basic-assertion-workflow",
    "title": "CLI Reference",
    "section": "2.19 Basic Assertion Workflow",
    "text": "2.19 Basic Assertion Workflow\nThe assertion workflow uses your familiar validation steps with assertion methods to check that validations meet your requirements:\n\nimport pointblank as pb\nimport polars as pl\n\n# Create sample data\nsample_data = pl.DataFrame({\n    \"id\": [1, 2, 3, 4, 5],\n    \"value\": [10.5, 8.3, -2.1, 15.7, 7.2]\n})\n\n# Create a validation plan and assert that all steps pass\n(\n    pb.Validate(data=sample_data)\n    .col_vals_gt(columns=\"id\", value=0, brief=\"IDs must be positive\")\n    .col_vals_gt(columns=\"value\", value=-5, brief=\"Values should exceed -5\")\n\n    # Will automatically `interrogate()` and raise an AssertionError if any validation fails ---\n    .assert_passing()\n)\n\nThis simple pattern allows you to integrate data quality checks into your data pipelines. With it, you can create clear stopping points when data doesn’t meet specified criteria."
  },
  {
    "objectID": "user-guide-pdf.html#assertion-methods",
    "href": "user-guide-pdf.html#assertion-methods",
    "title": "CLI Reference",
    "section": "2.20 Assertion Methods",
    "text": "2.20 Assertion Methods\nPointblank offers two types of assertions:\n\nFull Passing Assertions: using assert_passing() to verify that every single test unit passes\nThreshold-Based Assertions: using assert_below_threshold() to verify that failure rates stay within acceptable thresholds\n\n\n2.20.1 assert_passing()\nThe assert_passing() method is the strictest form of assertion, requiring every single validation test unit to pass:\n\ntry:\n    (\n        pb.Validate(data=sample_data)\n        .col_vals_gt(columns=\"value\", value=0)\n\n        # Direct assertion: automatically interrogates ---\n        .assert_passing()\n    )\nexcept AssertionError as e:\n    print(\"AssertionError:\", str(e))\n\nAssertionError: The following assertions failed:\n- Step 1: Expect that values in `value` should be &gt; `0`.\n\n\n\n\n2.20.2 assert_below_threshold()\nThe assert_below_threshold() method is more flexible as it allows some failures as long as they stay below specified threshold levels. Pointblank uses three severity thresholds that increase in order of seriousness:\n\n‘warning’ (least severe): the first threshold that gets triggered when failures exceed this level\n‘error’ (more severe): the middle threshold indicating more serious data quality issues\n‘critical’ (most severe): the highest threshold indicating critical data quality problems\n\n\n# Create a two-column DataFrame for this example\ntbl_pl = pl.DataFrame({\n    \"a\": [4, 6, 9, 7, 12, 8, 7, 12, 10, 7],\n    \"b\": [9, 8, 10, 5, 10, 9, 14, 6, 6, 8],\n\n})\n\n# Set thresholds: warning=0.2 (20%), error=0.3 (30%), critical=0.4 (40%)\nvalidation = (\n    pb.Validate(data=tbl_pl, thresholds=(0.2, 0.3, 0.4))\n    .col_vals_gt(columns=\"b\", value=5)   # 1/10 failing (10% failure rate)\n    .col_vals_lt(columns=\"a\", value=11)  # 2/10 failing (20% failure rate)\n    .col_vals_ge(columns=\"b\", value=8)   # 3/10 failing (30% failure rate)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:44PolarsWARNING0.2ERROR0.3CRITICAL0.4\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    b\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    90.90\n    10.10\n    ○\n    ○\n    ○\n    CSV\n  \n  \n    #AAAAAA\n    2\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    a\n    11\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    ●\n    ○\n    ○\n    CSV\n  \n  \n    #EBBC14\n    3\n    \n        \n            \n\n    col_vals_ge\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_ge()\n        \n        \n        \n    b\n    8\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    70.70\n    30.30\n    ●\n    ●\n    ○\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe validation report above visually indicates threshold levels with colored circles:\n\ngray circles in the W column indicate the ‘warning’ threshold\nyellow circles in the E column indicate the ‘error’ threshold\nred circles in the C column indicate the ‘critical’ threshold\n\nThis won’t pass the assert_below_threshold() assertion for the ‘error’ level because step 3 exceeds this threshold (30% failure rate matches the error threshold):\n\ntry:\n    validation.assert_below_threshold(level=\"error\")\nexcept AssertionError as e:\n    print(\"AssertionError:\", str(e))\n\nAssertionError: The following steps exceeded the error threshold level:\nStep 3: Expect that values in `b` should be &gt;= `8`.\n\n\nWe can check against the ‘error’ threshold for specific steps with the i= parameter:\n\nvalidation.assert_below_threshold(level=\"error\", i=[1, 2])\n\nThis passes because the highest threshold exceeded in steps 1 and 2 is ‘warning’.\nThe assert_below_threshold() method takes these parameters:\n\nlevel=: threshold level to check against (\"warning\", \"error\", or \"critical\")\ni=: optional specific step number(s) to check\nmessage=: optional custom error message\n\nThis is particularly useful when:\n\nworking with real-world data where some percentage of failures is acceptable\nimplementing different severity levels for data quality rules\ngradually improving data quality with stepped thresholds\n\n\n\n\n\n\n\nNote\n\n\n\nAssertion methods like assert_passing() and assert_below_threshold() will automatically call interrogate() if needed, so you don’t have to explicitly include this step when using assertions directly."
  },
  {
    "objectID": "user-guide-pdf.html#using-status-check-methods",
    "href": "user-guide-pdf.html#using-status-check-methods",
    "title": "CLI Reference",
    "section": "2.21 Using Status Check Methods",
    "text": "2.21 Using Status Check Methods\nIn addition to assertion methods that raise exceptions, Pointblank provides status check methods that return boolean values:\n\n2.21.1 all_passed()\nThe all_passed() method will return True only if every single test unit in every validation step passed:\n\nvalidation = (\n    pb.Validate(data=sample_data)\n    .col_vals_gt(columns=\"value\", value=0)\n    .interrogate()\n)\n\nif not validation.all_passed():\n    print(\"Validation failed: some values are not positive\")\n\nValidation failed: some values are not positive\n\n\n\n\n2.21.2 warning(), error(), and critical()\nThe methods warning(), error(), and critical() all return information about whether validation steps exceeded that specific threshold level.\nWhile assertion methods raise exceptions to halt execution when thresholds are exceeded, these status methods give you fine-grained control to implement custom logic based on different validation quality levels.\n\nvalidation = (\n    pb.Validate(data=sample_data, thresholds=(0.05, 0.10, 0.20))\n    .col_vals_gt(columns=\"value\", value=0)  # Some values are negative\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:44PolarsWARNING0.05ERROR0.1CRITICAL0.2\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #FF3300\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    value\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    40.80\n    10.20\n    ●\n    ●\n    ●\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe warning() method returns a dictionary mapping step numbers to boolean values. A True value means that step exceeds the warning threshold:\n\n# Get dictionary of warning status for each step\nwarning_status = validation.warning()\nprint(f\"Warning status: {warning_status}\")  # {1: True} means step 1 exceeds warning threshold\n\nWarning status: {1: True}\n\n\nYou can check a specific step using the i= parameter, and get a single boolean with scalar=True:\n\n# Check error threshold for specific step\nhas_errors = validation.error(i=1, scalar=True)\n\nif has_errors:\n    print(\"Step 1 exceeded the error threshold.\")\n\nStep 1 exceeded the error threshold.\n\n\nSimilarly, we can check if any steps exceed the ‘critical’ threshold:\n\n# Check against critical threshold\ncritical_status = validation.critical()\nprint(f\"Critical status: {critical_status}\")\n\nCritical status: {1: True}\n\n\nThese methods are particularly useful for:\n\nConditional logic: taking different actions based on threshold severity\nReporting: generating summary reports about validation quality\nMonitoring: tracking data quality trends over time\nGraceful degradation: implementing fallback logic when quality decreases\n\nEach method has these options:\n\nwithout parameters: returns a dictionary mapping step numbers to boolean status values\nwith i=: check specific step(s)\nwith scalar=True: return a single boolean instead of a dictionary (when checking a specific step)\n\nWhile assertion methods raise exceptions to halt execution when thresholds are exceeded, these methods give you fine-grained control to implement custom logic based on different validation quality levels."
  },
  {
    "objectID": "user-guide-pdf.html#customizing-error-messages",
    "href": "user-guide-pdf.html#customizing-error-messages",
    "title": "CLI Reference",
    "section": "2.22 Customizing Error Messages",
    "text": "2.22 Customizing Error Messages\nYou can provide custom error messages when assertions fail to make them more meaningful in your specific workflow context:\n\n# Create a validation with potential failures\nvalidation = (\n    pb.Validate(data=sample_data, thresholds=(0.2, 0.3, 0.4))\n    .col_vals_gt(columns=\"value\", value=0)\n    .interrogate()\n)\n\n# Display the validation results\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:44PolarsWARNING0.2ERROR0.3CRITICAL0.4\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #AAAAAA\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    value\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    40.80\n    10.20\n    ●\n    ○\n    ○\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nWhen you need to customize the error message that appears when an assertion fails, use the message= parameter:\n\ntry:\n    # Custom message for threshold assertion\n    validation.assert_below_threshold(\n        level=\"warning\",\n        message=\"Data quality too low for processing!\"\n    )\nexcept AssertionError as e:\n    print(f\"Custom handling of failure: {e}\")\n\nCustom handling of failure: Data quality too low for processing!\n\n\nDescriptive error messages are essential in production systems where multiple team members might need to interpret validation failures. The custom message lets you provide context appropriate to your specific workflow or data pipeline stage."
  },
  {
    "objectID": "user-guide-pdf.html#combining-assertions-with-actions",
    "href": "user-guide-pdf.html#combining-assertions-with-actions",
    "title": "CLI Reference",
    "section": "2.23 Combining Assertions with Actions",
    "text": "2.23 Combining Assertions with Actions\nActions and assertions serve complementary but distinct purposes in data validation workflows:\n\nActions trigger during validation but shouldn’t raise errors (as this would halt report generation)\nAssertions are designed to raise errors based on specific conditions, making them ideal for flow control after validation completes\n\nHere’s a simplified example showing how to use them together. The print statements simulate logging or monitoring that would be valuable in production data pipelines:\n\n# Define a simple action function (won't raise errors)\ndef notify_quality_issue(message=\"Data quality issue detected\"):\n    print(f\"ACTION TRIGGERED: {message}\")\n\n# Create data with known failures\nproblem_data = pl.DataFrame({\n    \"id\": [1, 2, 3, -4, 5],  # One negative ID\n    \"value\": [10.5, 8.3, -2.1, 15.7, 7.2]  # One negative value\n})\n\n# First use actions for automated responses during validation\nprint(\"Running validation with actions...\")\nvalidation = (\n    pb.Validate(data=problem_data, thresholds=(0.1, 0.2, 0.3))\n    .col_vals_gt(\n        columns=\"id\", value=0,\n        brief=\"IDs must be positive\",\n        actions=pb.Actions(warning=notify_quality_issue)\n    )\n    .interrogate()  # Actions trigger here but won't stop report generation\n)\n\n# Then use assertions after validation for workflow control\nprint(\"\\nNow using assertion for flow control...\")\ntry:\n    validation.assert_below_threshold(level=\"warning\")\n    print(\"This line won't execute if the assertion fails\")\nexcept AssertionError as e:\n    print(f\"Validation failed threshold check: {e}\")\n    print(\"Implementing fallback process...\")\n\nRunning validation with actions...\nACTION TRIGGERED: Data quality issue detected\n\nNow using assertion for flow control...\nValidation failed threshold check: The following steps exceeded the warning threshold level:\nStep 1: Expect that values in `id` should be &gt; `0`.\nImplementing fallback process...\n\n\nThis approach gives you the best of both worlds:\n\nActions provide immediate notification during validation without interrupting the process\nAssertions control workflow execution after validation when important thresholds are exceeded\n\nThis pattern works well in data pipelines where you want both: (1) automated responses during validation and (2) clear decision points after validation is complete."
  },
  {
    "objectID": "user-guide-pdf.html#best-practices-for-assertions",
    "href": "user-guide-pdf.html#best-practices-for-assertions",
    "title": "CLI Reference",
    "section": "2.24 Best Practices for Assertions",
    "text": "2.24 Best Practices for Assertions\nWhen using assertions in your data workflows, consider these best practices:\n\nChoose the right assertion type:\n\nuse assert_passing() for critical validations where any failure is unacceptable\nuse assert_below_threshold() for validations where some failure rate is acceptable\n\nSet appropriate thresholds that match your data quality requirements:\n# Example threshold strategy\nvalidation = pb.Validate(\n    data=sample_data,\n    # warning at 1%, error at 5%, critical at 10%\n    thresholds=pb.Thresholds(warning=0.01, error=0.05, critical=0.10)\n)\nUse a graduated approach to validation severity:\n# Critical validations: must be perfect\nvalidation_1.assert_passing()\n\n# Important validations: must be below error threshold\nvalidation_2.assert_below_threshold(level=\"error\")\n\n# Monitor-only validations: check warning status\nwarning_status = validation_3.warning()\nPlacement in pipelines: place assertions at critical points where data quality is essential\nError handling: wrap assertions in try-except blocks for better error handling in production systems\nCombine with reporting: use both assertions and reporting approaches for comprehensive quality control"
  },
  {
    "objectID": "user-guide-pdf.html#conclusion-10",
    "href": "user-guide-pdf.html#conclusion-10",
    "title": "CLI Reference",
    "section": "2.25 Conclusion",
    "text": "2.25 Conclusion\nPointblank’s assertion methods give you flexible options for enforcing data quality requirements:\n\nassert_passing() for strict validation where every test unit must pass\nassert_below_threshold() for more flexible validation where some failures are tolerable\nStatus methods (warning(), error(), and critical()) for programmatic threshold checking\n\nBy using these assertion methods appropriately, you can build robust data pipelines with different levels of quality enforcement (from strict validation of critical data properties to more lenient checks for less critical aspects). This graduated approach to data quality helps create systems that are both reliable and practical in real-world data environments.\nDraft validation in Pointblank leverages large language models (LLMs) to automatically generate validation plans for your data. This feature is especially useful when starting validation on a new dataset or when you need to quickly establish baseline validation coverage.\nThe DraftValidation class connects to various LLM providers to analyze your data’s characteristics and generate a complete validation plan tailored to its structure and content."
  },
  {
    "objectID": "user-guide-pdf.html#how-draftvalidation-works",
    "href": "user-guide-pdf.html#how-draftvalidation-works",
    "title": "CLI Reference",
    "section": "2.26 How DraftValidation Works",
    "text": "2.26 How DraftValidation Works\nWhen you use DraftValidation, the process works through these steps:\n\na statistical summary of your data is generated using the DataScan class\nthis summary is converted to JSON format and sent to your selected LLM provider\nthe LLM uses the summary along with knowledge about Pointblank’s validation capabilities to generate a validation plan\nthe result is returned as executable Python code that you can use directly or modify as needed\n\nThe entire process happens without sending all of the data to the LLM provider, but only a summary that includes column names, data types, basic statistics, and a small sample of values."
  },
  {
    "objectID": "user-guide-pdf.html#requirements-and-setup",
    "href": "user-guide-pdf.html#requirements-and-setup",
    "title": "CLI Reference",
    "section": "2.27 Requirements and Setup",
    "text": "2.27 Requirements and Setup\nTo use the DraftValidation feature, you’ll need:\n\nan API key from a supported LLM provider\nthe required Python packages installed\n\nYou can install all necessary dependencies with:\npip install pointblank[generate]\nThis will install the chatlas package and other dependencies required for DraftValidation.\n\n2.27.1 Supported LLM Providers\nThe DraftValidation class supports multiple LLM providers:\n\nAnthropic (Claude models)\nOpenAI (GPT models)\nOllama (local LLMs)\nAmazon Bedrock (AWS-hosted models)\n\nEach provider has different capabilities and performance characteristics, but all can be used to generate validation plans through a consistent interface."
  },
  {
    "objectID": "user-guide-pdf.html#basic-usage-1",
    "href": "user-guide-pdf.html#basic-usage-1",
    "title": "CLI Reference",
    "section": "2.28 Basic Usage",
    "text": "2.28 Basic Usage\nThe simplest way to use DraftValidation is to provide your data and specify an LLM model. Let’s try it out with the global_sales dataset.\nimport pointblank as pb\n\n# Load a dataset\ndata = pb.load_dataset(dataset=\"global_sales\", tbl_type=\"polars\")\n\n# Generate a validation plan\npb.DraftValidation(\n    data=data,\n    model=\"anthropic:claude-sonnet-4-5\",\n    api_key=\"your_api_key_here\"  # Replace with your actual API key\n)\n```python\nimport pointblank as pb\n\n# Define schema based on column names and dtypes\nschema = pb.Schema(columns=[\n    (\"product_id\", \"String\"),\n    (\"product_category\", \"String\"),\n    (\"customer_id\", \"String\"),\n    (\"customer_segment\", \"String\"),\n    (\"region\", \"String\"),\n    (\"country\", \"String\"),\n    (\"city\", \"String\"),\n    (\"timestamp\", \"Datetime(time_unit='us', time_zone=None)\"),\n    (\"quarter\", \"String\"),\n    (\"month\", \"Int64\"),\n    (\"year\", \"Int64\"),\n    (\"price\", \"Float64\"),\n    (\"quantity\", \"Int64\"),\n    (\"status\", \"String\"),\n    (\"email\", \"String\"),\n    (\"revenue\", \"Float64\"),\n    (\"tax\", \"Float64\"),\n    (\"total\", \"Float64\"),\n    (\"payment_method\", \"String\"),\n    (\"sales_channel\", \"String\")\n])\n\n# The validation plan\nvalidation = (\n    pb.Validate(\n        data=your_data,  # Replace your_data with the actual data variable\n        label=\"Draft Validation\",\n        thresholds=pb.Thresholds(warning=0.10, error=0.25, critical=0.35)\n    )\n    .col_schema_match(schema=schema)\n    .col_vals_not_null(columns=[\n        \"product_category\", \"customer_segment\", \"region\", \"country\",\n        \"price\", \"quantity\", \"status\", \"email\", \"revenue\", \"tax\",\n        \"total\", \"payment_method\", \"sales_channel\"\n    ])\n    .col_vals_between(columns=\"month\", left=1, right=12, na_pass=True)\n    .col_vals_between(columns=\"year\", left=2021, right=2023, na_pass=True)\n    .col_vals_gt(columns=\"price\", value=0)\n    .col_vals_gt(columns=\"quantity\", value=0)\n    .col_vals_gt(columns=\"revenue\", value=0)\n    .col_vals_gt(columns=\"tax\", value=0)\n    .col_vals_gt(columns=\"total\", value=0)\n    .col_vals_in_set(columns=\"product_category\", set=[\n        \"Manufacturing\", \"Retail\", \"Healthcare\"\n    ])\n    .col_vals_in_set(columns=\"customer_segment\", set=[\n        \"Government\", \"Consumer\", \"SMB\"\n    ])\n    .col_vals_in_set(columns=\"region\", set=[\n        \"Asia Pacific\", \"Europe\", \"North America\"\n    ])\n    .col_vals_in_set(columns=\"status\", set=[\n        \"returned\", \"shipped\", \"delivered\"\n    ])\n    .col_vals_in_set(columns=\"payment_method\", set=[\n        \"Apple Pay\", \"PayPal\", \"Bank Transfer\", \"Credit Card\"\n    ])\n    .col_vals_in_set(columns=\"sales_channel\", set=[\n        \"Partner\", \"Distributor\", \"Phone\"\n    ])\n    .row_count_match(count=50000)\n    .col_count_match(count=20)\n    .rows_distinct()\n    .interrogate()\n)\n\nvalidation\n```\n\n2.28.1 Managing API Keys\nWhile you can directly provide API keys as shown above, there are more secure approaches:\nimport os\n\n# Get API key from environment variable\napi_key = os.getenv(\"ANTHROPIC_API_KEY\")\n\ndraft_validation = pb.DraftValidation(\n    data=data,\n    model=\"anthropic:claude-sonnet-4-5\",\n    api_key=api_key\n)\nYou can also store API keys in a .env file in your project’s root directory:\n# Contents of .env file\nANTHROPIC_API_KEY=your_anthropic_api_key_here\nOPENAI_API_KEY=your_openai_api_key_here\nIf your API keys have standard names (like ANTHROPIC_API_KEY or OPENAI_API_KEY), DraftValidation will automatically find and use them:\n# No API key needed if stored in .env with standard names\ndraft_validation = pb.DraftValidation(\n    data=data,\n    model=\"anthropic:claude-sonnet-4-5\"\n)"
  },
  {
    "objectID": "user-guide-pdf.html#example-output-for-nycflights",
    "href": "user-guide-pdf.html#example-output-for-nycflights",
    "title": "CLI Reference",
    "section": "2.29 Example Output for nycflights",
    "text": "2.29 Example Output for nycflights\nHere’s an example of a validation plan that might be generated by DraftValidation for the nycflights dataset:\npb.DraftValidation(\n    pb.load_dataset(dataset=\"nycflights\", tbl_type=\"duckdb\",\n    model=\"anthropic:claude-sonnet-4-5\"\n)\n```python\nimport pointblank as pb\n\n# Define schema based on column names and dtypes\nschema = pb.Schema(columns=[\n    (\"year\", \"int64\"),\n    (\"month\", \"int64\"),\n    (\"day\", \"int64\"),\n    (\"dep_time\", \"int64\"),\n    (\"sched_dep_time\", \"int64\"),\n    (\"dep_delay\", \"int64\"),\n    (\"arr_time\", \"int64\"),\n    (\"sched_arr_time\", \"int64\"),\n    (\"arr_delay\", \"int64\"),\n    (\"carrier\", \"string\"),\n    (\"flight\", \"int64\"),\n    (\"tailnum\", \"string\"),\n    (\"origin\", \"string\"),\n    (\"dest\", \"string\"),\n    (\"air_time\", \"int64\"),\n    (\"distance\", \"int64\"),\n    (\"hour\", \"int64\"),\n    (\"minute\", \"int64\")\n])\n\n# The validation plan\nvalidation = (\n    pb.Validate(\n        data=your_data,  # Replace your_data with the actual data variable\n        label=\"Draft Validation\",\n        thresholds=pb.Thresholds(warning=0.10, error=0.25, critical=0.35)\n    )\n    .col_schema_match(schema=schema)\n    .col_vals_not_null(columns=[\n        \"year\", \"month\", \"day\", \"sched_dep_time\", \"carrier\", \"flight\",\n        \"origin\", \"dest\", \"distance\", \"hour\", \"minute\"\n    ])\n    .col_vals_between(columns=\"month\", left=1, right=12)\n    .col_vals_between(columns=\"day\", left=1, right=31)\n    .col_vals_between(columns=\"sched_dep_time\", left=106, right=2359)\n    .col_vals_between(columns=\"dep_delay\", left=-43, right=1301, na_pass=True)\n    .col_vals_between(columns=\"air_time\", left=20, right=695, na_pass=True)\n    .col_vals_between(columns=\"distance\", left=17, right=4983)\n    .col_vals_between(columns=\"hour\", left=1, right=23)\n    .col_vals_between(columns=\"minute\", left=0, right=59)\n    .col_vals_in_set(columns=\"origin\", set=[\"EWR\", \"LGA\", \"JFK\"])\n    .col_count_match(count=18)\n    .row_count_match(count=336776)\n    .rows_distinct()\n    .interrogate()\n)\n\nvalidation\n```\nNotice how the generated plan includes:\n\nA schema validation with appropriate data types\nNot-null checks for required columns\nRange validations for numerical data\nSet membership checks for categorical data\nRow and column count validations\nAppropriate handling of missing values with na_pass=True"
  },
  {
    "objectID": "user-guide-pdf.html#working-with-model-providers",
    "href": "user-guide-pdf.html#working-with-model-providers",
    "title": "CLI Reference",
    "section": "2.30 Working with Model Providers",
    "text": "2.30 Working with Model Providers\n\n2.30.1 Specifying Models\nWhen using DraftValidation, you specify the model in the format \"provider:model_name\":\n# Using Anthropic's Claude model\npb.DraftValidation(data=data, model=\"anthropic:claude-sonnet-4-5\")\n\n# Using OpenAI's GPT model\npb.DraftValidation(data=data, model=\"openai:gpt-4-turbo\")\n\n# Using a local model with Ollama\npb.DraftValidation(data=data, model=\"ollama:llama3:latest\")\n\n# Using Amazon Bedrock\npb.DraftValidation(data=data, model=\"bedrock:anthropic.claude-3-sonnet-20240229-v1:0\")\n\n\n2.30.2 Model Performance and Privacy\nDifferent models have different capabilities when it comes to generating validation plans:\n\nAnthropic Claude Sonnet 4.5 generally provides the most comprehensive and accurate validation plans\nOpenAI GPT-4 models also perform well\nLocal models through Ollama can be useful for private data but they currently have reduced capabilities here\n\nA key advantage of DraftValidation is that your actual dataset is not sent to the LLM provider. Instead, only a summary is transmitted, which includes:\n\nthe number of rows and columns\ncolumn names and data types\nbasic statistics (min, max, mean, median, missing values count)\na small sample of values from each column (usually 5-10 values)\n\nThis approach protects your data while still providing enough context for the LLM to generate relevant validation rules."
  },
  {
    "objectID": "user-guide-pdf.html#customizing-generated-plans",
    "href": "user-guide-pdf.html#customizing-generated-plans",
    "title": "CLI Reference",
    "section": "2.31 Customizing Generated Plans",
    "text": "2.31 Customizing Generated Plans\nThe validation plan generated by DraftValidation is just a starting point. You’ll typically want to:\n\nreview the generated code for correctness\nreplace your_data with your actual data variable name that exists in your workspace\nensure the data object referenced is actually present in your workspace\nadjust thresholds and validation parameters\nadd domain-specific validation rules\nremove any unnecessary checks\n\nFor example, you might start by capturing the text representation of your draft validation. This will give you the raw Python code that you can copy into a new code cell in your notebook or script. From there, you can customize it by modifying thresholds to match your organization’s data quality standards, adding business-specific validation rules that require domain knowledge, or removing checks that aren’t relevant to your use case. Once you’ve made your modifications, you can execute the customized validation plan as you would any other Pointblank validation."
  },
  {
    "objectID": "user-guide-pdf.html#under-the-hood",
    "href": "user-guide-pdf.html#under-the-hood",
    "title": "CLI Reference",
    "section": "2.32 Under the Hood",
    "text": "2.32 Under the Hood\n\n2.32.1 The Generated Data Summary\nTo understand what the LLM works with, here’s an example of the data summary format that’s sent:\n{\n  \"table_info\": {\n    \"rows\": 336776,\n    \"columns\": 18,\n    \"table_type\": \"duckdb\"\n  },\n  \"column_info\": [\n    {\n      \"column_name\": \"year\",\n      \"column_type\": \"int64\",\n      \"missing_values\": 0,\n      \"min\": 2013,\n      \"max\": 2013,\n      \"mean\": 2013.0,\n      \"median\": 2013,\n      \"sample_values\": [2013, 2013, 2013, 2013, 2013]\n    },\n    {\n      \"column_name\": \"month\",\n      \"column_type\": \"int64\",\n      \"missing_values\": 0,\n      \"min\": 1,\n      \"max\": 12,\n      \"mean\": 6.548819,\n      \"median\": 7,\n      \"sample_values\": [1, 1, 1, 1, 1]\n    },\n    // Additional columns...\n  ]\n}\n\n\n2.32.2 The Prompt Strategy\nThe DraftValidation class uses a carefully crafted prompt that instructs the LLM to:\n\nuse the schema information to create a Schema object\ninclude col_vals_not_null() for columns with no missing values\nadd appropriate range validations based on min/max values\ninclude row and column count validations\nformat the output as clean, executable Python code\n\nThe prompt also contains constraints to ensure consistent, high-quality results, such as using line breaks in long lists for readability, applying na_pass=True for columns with missing values, and avoiding duplicate validations."
  },
  {
    "objectID": "user-guide-pdf.html#best-practices-and-troubleshooting",
    "href": "user-guide-pdf.html#best-practices-and-troubleshooting",
    "title": "CLI Reference",
    "section": "2.33 Best Practices and Troubleshooting",
    "text": "2.33 Best Practices and Troubleshooting\n\n2.33.1 When to Use DraftValidation\nDrafting a validation is most useful when:\n\nworking with a new dataset for the first time\nneeding to quickly establish baseline validation\nexploring potential validation rules before formalizing them\nvalidating columns with consistent patterns (numeric ranges, categories, etc.)\n\nConsider writing validation plans manually when you need very specific business rules, are working with sensitive data, need complex validation logic, or need to validate relationships between columns.\n\n\n2.33.2 Recommended Workflow and Common Issues\nHere’s a recommended workflow incorporating DraftValidation:\n\ngenerate an initial plan with DraftValidation\nreview the generated validations for relevance\nadjust thresholds and parameters as needed\nadd specific business logic and cross-column validations\nstore the final validation plan in version control\n\nIt’s possible that you might bump up against some issues. Here are some common ones and solutions you might try:\n\nAuthentication Errors: ensure your API key is valid and correctly passed to DraftValidation\nPackage Not Found: make sure you’ve installed the required packages with pip install pointblank[generate]\nUnsupported Model: verify you’re using the correct provider:model format\nPoor Quality Plans: try a more capable model"
  },
  {
    "objectID": "user-guide-pdf.html#conclusion-11",
    "href": "user-guide-pdf.html#conclusion-11",
    "title": "CLI Reference",
    "section": "2.34 Conclusion",
    "text": "2.34 Conclusion\nDraftValidation provides a powerful way to jumpstart your data validation process by leveraging LLMs to generate context-aware validation plans. By analyzing your data’s structure and content, DraftValidation can create comprehensive validation rules that would otherwise take significant time to develop manually.\nThe feature balances privacy (by sending only data summaries) with utility (by generating executable validation code). While the generated plans should always be reviewed and refined, they provide an excellent starting point for ensuring your data meets your quality requirements.\nBy understanding how DraftValidation works and how to customize its output, you can significantly accelerate your data validation workflows and improve the quality of your data throughout your projects."
  },
  {
    "objectID": "user-guide-pdf.html#basic-yaml-validation-structure",
    "href": "user-guide-pdf.html#basic-yaml-validation-structure",
    "title": "CLI Reference",
    "section": "3.1 Basic YAML Validation Structure",
    "text": "3.1 Basic YAML Validation Structure\nA YAML validation workflow consists of a few key components:\n\ntbl: specifies the data source (file path, dataset name, or Python expression)\nsteps: defines the validation checks to perform\nOptional metadata: table name, label, thresholds, actions, and other configuration\n\nHere’s a simple example validating the built-in small_table dataset:\ntbl: small_table\ndf_library: polars                     # Optional: specify DataFrame library\ntbl_name: \"Small Table Validation\"\nlabel: \"Basic data quality checks\"\nsteps:\n  - rows_distinct\n  - col_exists:\n      columns: [a, b, c, d]\n  - col_vals_not_null:\n      columns: [a, b]\nYou can save this configuration to a .yaml file and execute it using the yaml_interrogate() function:\n\nimport pointblank as pb\nfrom pathlib import Path\n\n# Save the YAML configuration to a file\nyaml_content = \"\"\"\ntbl: small_table\ndf_library: polars\ntbl_name: \"Small Table Validation\"\nlabel: \"Basic data quality checks\"\nsteps:\n  - rows_distinct\n  - col_exists:\n      columns: [a, b, c, d]\n  - col_vals_not_null:\n      columns: [a, b]\n\"\"\"\n\nyaml_file = Path(\"basic_validation.yaml\")\nyaml_file.write_text(yaml_content)\n\n# Execute the validation from the file\nresult = pb.yaml_interrogate(yaml_file)\nresult\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Basic data quality checksPolarsSmall Table Validation\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    rows_distinct\n    \n        \n            \n            \n                \n                \n                \n            \n        \n    \n\n        \n        \n            rows_distinct()\n        \n        \n        \n    ALL COLUMNS\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    90.69\n    20.15\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    a\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    b\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    c\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    5\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    d\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    6\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    a\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    7\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    b\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe validation table shows the results of each step, just as if you had written the equivalent Python code. You can also pass YAML content directly as a string for quick testing, but working with files is the recommended approach for production workflows."
  },
  {
    "objectID": "user-guide-pdf.html#data-sources-in-yaml",
    "href": "user-guide-pdf.html#data-sources-in-yaml",
    "title": "CLI Reference",
    "section": "3.2 Data Sources in YAML",
    "text": "3.2 Data Sources in YAML\nThe tbl field supports various data source types, making it easy to work with different kinds of data. You can also control the DataFrame library used for loading data with the df_library parameter.\n\n3.2.1 DataFrame Library Selection\nBy default, Pointblank loads data as Polars DataFrames, but you can specify alternative libraries:\n# Load as Polars DataFrame (default)\ntbl: small_table\ndf_library: polars\n\n# Load as Pandas DataFrame\ntbl: small_table\ndf_library: pandas\n\n# Load as DuckDB table (via Ibis)\ntbl: small_table\ndf_library: duckdb\nThis is particularly useful when using validation expressions that require specific DataFrame APIs:\n# Using Pandas-specific operations\ntbl: small_table\ndf_library: pandas\nsteps:\n  - specially:\n      expr: \"lambda df: df.assign(total=df['a'] + df['d'])\"\n\n# Using Polars-specific operations\ntbl: small_table\ndf_library: polars\nsteps:\n  - specially:\n      expr: \"lambda df: df.select(pl.col('a') + pl.col('d') &gt; 0)\"\n\n\n3.2.2 File-based Sources\n# CSV files (respects df_library setting)\ntbl: \"data/customers.csv\"\ndf_library: pandas\n\n# Parquet files\ntbl: \"warehouse/sales.parquet\"\ndf_library: polars\n\n# Multiple files with patterns\ntbl: \"logs/*.parquet\"\n\n\n3.2.3 Built-in Datasets\n# Use Pointblank's built-in datasets\ntbl: small_table\ntbl: game_revenue\ntbl: nycflights\n\n\n3.2.4 Python Expressions for Complex Sources\nFor more complex data loading, use the python: block syntax. This syntax can be used with several parameters throughout your YAML configuration:\n\ntbl: For complex data source loading (as shown below)\nexpr: For custom validation expressions in col_vals_expr\npre: For data preprocessing before validation steps\nactions: For callable action functions (warning, error, critical, and default)\n\n# Load data with custom Polars operations\ntbl:\n  python: |\n    pl.scan_csv(\"sales_data.csv\")\n    .filter(pl.col(\"date\") &gt;= \"2024-01-01\")\n    .head(1000)\n\n# Load from a database connection\ntbl:\n  python: |\n    pl.read_database(\n        query=\"SELECT * FROM customers WHERE active = true\",\n        connection=\"postgresql://user:pass@localhost/db\"\n    )"
  },
  {
    "objectID": "user-guide-pdf.html#reusable-templates-with-set_tbl",
    "href": "user-guide-pdf.html#reusable-templates-with-set_tbl",
    "title": "CLI Reference",
    "section": "3.3 Reusable Templates with set_tbl=",
    "text": "3.3 Reusable Templates with set_tbl=\nOne of the most powerful features of YAML validation workflows is the ability to create reusable templates that can be applied to different datasets. Using the set_tbl= parameter with yaml_interrogate(), you can define validation logic once and apply it to multiple data sources.\n\n3.3.1 Creating Validation Templates\nWhen creating templates for use with set_tbl=, the tbl field is still required but its value will be overridden. The recommended approach is to use tbl: null:\ntbl: null\ntbl_name: \"Sales Data Validation Template\"\nlabel: \"Standard validation checks for sales data\"\nsteps:\n  - col_exists:\n      columns: [customer_id, revenue, region, date]\n  - col_vals_not_null:\n      columns: [customer_id, revenue]\n  - col_vals_gt:\n      columns: [revenue]\n      value: 0\n  - col_vals_in_set:\n      columns: [region]\n      set: [North, South, East, West]\n\n\n3.3.2 Applying Templates to Multiple Datasets\nHere’s a practical example showing how to apply the same validation template to multiple quarterly datasets, demonstrating the power of reusable YAML configurations:\n\nimport pointblank as pb\nimport polars as pl\n\n# Define the template once\nsales_template = \"\"\"\ntbl: null  # Will be overridden\ntbl_name: \"Sales Data Validation\"\nlabel: \"Standard sales validation checks\"\nthresholds:\n  warning: 0.05\n  error: 0.1\nsteps:\n  - col_exists:\n      columns: [customer_id, revenue, region]\n  - col_vals_not_null:\n      columns: [customer_id, revenue]\n  - col_vals_gt:\n      columns: [revenue]\n      value: 0\n  - col_vals_in_set:\n      columns: [region]\n      set: [North, South, East, West]\n\"\"\"\n\n# Create different datasets\nq1_data = pl.DataFrame({\n    \"customer_id\": [1, 2, 3, 4],\n    \"revenue\": [100, 200, 150, 300],\n    \"region\": [\"North\", \"South\", \"East\", \"West\"]\n})\n\nq2_data = pl.DataFrame({\n    \"customer_id\": [5, 6, 7, 8],\n    \"revenue\": [250, 180, 220, 350],\n    \"region\": [\"South\", \"North\", \"West\", \"East\"]\n})\n\n# Apply the same template to both datasets\nq1_result = pb.yaml_interrogate(sales_template, set_tbl=q1_data)\nq2_result = pb.yaml_interrogate(sales_template, set_tbl=q2_data)\n\nprint(f\"Q1 validation: {all(v.all_passed for v in q1_result.validation_info)}\")\nprint(f\"Q2 validation: {all(v.all_passed for v in q2_result.validation_info)}\")\n\nQ1 validation: True\nQ2 validation: True\n\n\n\n\n3.3.3 Template Best Practices\n\nUse tbl: null: this clearly indicates the template expects a data source to be provided\nInclude comprehensive metadata: use tbl_name, label, and brief to make results self-documenting\nSet appropriate thresholds: define warning/error levels that make sense for your use case\nVersion control templates: store templates in your repository alongside your data processing code\nTest with sample data: validate your templates work with representative datasets\n\n\n\n3.3.4 Common Template Patterns\nFor API response validation, you can ensure that responses have the expected structure and valid status codes:\ntbl: null\ntbl_name: \"API Response Validation\"\nbrief: \"Standard checks for API response data\"\nsteps:\n  - col_exists:\n      columns: [user_id, status, timestamp]\n  - col_vals_in_set:\n      columns: [status]\n      set: [success, error, pending]\n  - col_vals_not_null:\n      columns: [user_id, timestamp]\nFor file upload validation, you can check file sizes and formats to ensure they meet your requirements:\ntbl: null\ntbl_name: \"File Upload Validation\"\nsteps:\n  - col_vals_gt:\n      columns: [file_size]\n      value: 0\n  - col_vals_lt:\n      columns: [file_size]\n      value: 10485760  # 10MB limit\n  - col_vals_in_set:\n      columns: [file_type]\n      set: [csv, json, xlsx, parquet]\nThis template approach is particularly valuable in data pipelines, ETL processes, and automated testing scenarios where you need to apply consistent validation logic across multiple similar datasets."
  },
  {
    "objectID": "user-guide-pdf.html#validation-steps",
    "href": "user-guide-pdf.html#validation-steps",
    "title": "CLI Reference",
    "section": "3.4 Validation Steps",
    "text": "3.4 Validation Steps\nYAML supports all of Pointblank’s validation methods. Here are some common patterns:\n\n3.4.1 Column-based Validations\ntbl: worldcities.csv\nsteps:\n  # Check for missing values\n  - col_vals_not_null:\n      columns: [city_name, country]\n\n  # Validate value ranges\n  - col_vals_between:\n      columns: latitude\n      left: -90\n      right: 90\n\n  # Check set membership\n  - col_vals_in_set:\n      columns: country_code\n      set: [US, CA, MX, UK, DE, FR]\n\n  # Regular expression validation\n  - col_vals_regex:\n      columns: postal_code\n      pattern: \"^[0-9]{5}(-[0-9]{4})?$\"\n\n\n3.4.2 Row-based Validations\ntbl: sales_data.csv\nsteps:\n  # Check for duplicate rows\n  - rows_distinct\n\n  # Ensure complete rows (no missing values)\n  - rows_complete\n\n  # Check row count\n  - row_count_match:\n      count: 1000\n\n\n3.4.3 Schema Validations\nSchema validation ensures your data has the expected structure and column types. The col_schema_match validation method uses a schema key that contains a columns list, where each item in the list can specify a column name alone or a column name with its expected data type.\nEach column entry can be specified as:\n\ncolumn_name: column name as a scalar string (structure validation, no type checking)\n[column_name, \"data_type\"]: column name with type validation (as a list with two elements)\n[column_name]: column name in a single-item list (equivalent to scalar, for consistency)\n\ntbl: customer_data.csv\nsteps:\n  # Complete schema validation (structure and types)\n  - col_schema_match:\n      schema:\n        columns:\n          - [customer_id, \"int64\"]\n          - [name, \"object\"]\n          - [email, \"object\"]\n          - [signup_date, \"datetime64[ns]\"]\n\n  # Structure-only validation (column names without types)\n  - col_schema_match:\n      schema:\n        columns:\n          - customer_id\n          - name\n          - email\n      complete: false\n      brief: \"Check that core columns exist\"\n\n3.4.3.1 Schema Validation Options\nSchema validations support the full range of validation options:\ntbl: data_file.csv\nsteps:\n  - col_schema_match:\n      schema:\n        columns:\n          - [id, \"int64\"]\n          - name\n      complete: false                  # Allow extra columns\n      in_order: false                  # Column order doesn't matter\n      case_sensitive_colnames: false   # Case-insensitive column names\n      case_sensitive_dtypes: false     # Case-insensitive type names\n      full_match_dtypes: false         # Allow partial type matching\n      brief: \"Flexible schema validation\"\n\n\n3.4.3.2 Other Structure Validations\ntbl: customer_data.csv\nsteps:\n  # Check column count\n  - col_count_match:\n      count: 4\n\n\n\n3.4.4 Trend Validations\nValidate that values follow increasing or decreasing patterns across rows:\ntbl: time_series_data.csv\nsteps:\n  # Ensure timestamp values increase\n  - col_vals_increasing:\n      columns: timestamp\n      brief: \"Timestamps must be in chronological order\"\n\n  # Validate countdown timer decreases\n  - col_vals_decreasing:\n      columns: countdown\n      allow_stationary: true\n      brief: \"Countdown values should decrease (ties allowed)\"\n\n  # Check trend with tolerance\n  - col_vals_increasing:\n      columns: temperature\n      decreasing_tol: 0.5\n      brief: \"Temperature trends upward (small drops &lt; 0.5°C allowed)\"\n\n\n3.4.5 Specification-based Validations\nValidate values against common data specifications like email addresses, URLs, postal codes, and more:\ntbl: user_contact_info.csv\nsteps:\n  # Validate email addresses\n  - col_vals_within_spec:\n      columns: email\n      spec: \"email\"\n\n  # Validate US ZIP codes\n  - col_vals_within_spec:\n      columns: zip_code\n      spec: \"postal_code[US]\"\n\n  # Validate URLs\n  - col_vals_within_spec:\n      columns: website\n      spec: \"url\"\n      na_pass: true\nAvailable specifications include: \"email\", \"url\", \"phone\", \"ipv4\", \"ipv6\", \"mac\", \"isbn\", \"vin\", \"credit_card\", \"swift\", \"postal_code[&lt;country&gt;]\", \"iban[&lt;country&gt;]\".\n\n\n3.4.6 Table Comparison\nValidate that an entire table matches a reference table:\ntbl: processed_output.csv\nsteps:\n  # Compare against expected output\n  - tbl_match:\n      tbl_compare:\n        python: |\n          pb.load_dataset(\"expected_output\", tbl_type=\"polars\")\n      brief: \"Output matches expected results\"\nThe tbl_match() validation performs comprehensive comparison including column count, row count, schema, and data values. It supports cross-backend validation (e.g., comparing Polars vs. Pandas DataFrames).\n\n\n3.4.7 AI-Powered Validation\nUse Large Language Models to validate data based on natural language criteria:\ntbl: customer_feedback.csv\nsteps:\n  # Validate sentiment\n  - prompt:\n      prompt: \"Customer feedback should express positive sentiment\"\n      model: \"anthropic:claude-sonnet-4\"\n      columns_subset: [feedback_text, rating]\n      batch_size: 500\n      thresholds:\n        warning: 0.1\n\n  # Validate semantic correctness\n  - prompt:\n      prompt: \"Product descriptions should mention the product category and at least one benefit\"\n      model: \"openai:gpt-4\"\n      columns_subset: [product_name, description, category]\nNote: AI validations require API keys to be set as environment variables (e.g., ANTHROPIC_API_KEY, OPENAI_API_KEY) or in a .env file. These validations are best suited for semantic, context-dependent, or subjective quality checks rather than simple numeric comparisons."
  },
  {
    "objectID": "user-guide-pdf.html#thresholds-and-severity-levels",
    "href": "user-guide-pdf.html#thresholds-and-severity-levels",
    "title": "CLI Reference",
    "section": "3.5 Thresholds and Severity Levels",
    "text": "3.5 Thresholds and Severity Levels\nThresholds determine when validation failures trigger different severity levels. You can set global thresholds for the entire workflow:\ntbl: sales_data.csv\ntbl_name: \"Sales Data Quality Check\"\nthresholds:\n  warning: 0.05    # 5% failure rate triggers warning\n  error: 0.10      # 10% failure rate triggers error\n  critical: 0.15   # 15% failure rate triggers critical\nsteps:\n  - col_vals_not_null:\n      columns: [customer_id, amount]\n  - col_vals_gt:\n      columns: amount\n      value: 0\nYou can also set thresholds for individual validation steps:\ntbl: user_data.csv\nsteps:\n  - col_vals_not_null:\n      columns: email\n      thresholds:\n        warning: 1      # Any missing email is a warning\n        error: 0.01     # 1% missing emails is an error\n\n  - col_vals_regex:\n      columns: email\n      pattern: \"^[\\\\w\\\\.-]+@[\\\\w\\\\.-]+\\\\.[a-zA-Z]{2,}$\"\n      thresholds:\n        error: 1        # Any invalid email format is an error"
  },
  {
    "objectID": "user-guide-pdf.html#actions-responding-to-validation-failures",
    "href": "user-guide-pdf.html#actions-responding-to-validation-failures",
    "title": "CLI Reference",
    "section": "3.6 Actions: Responding to Validation Failures",
    "text": "3.6 Actions: Responding to Validation Failures\nActions define what happens when validation thresholds are exceeded. You can use string templates with placeholder variables or callable functions.\n\n3.6.1 String Template Actions\ntbl: orders.csv\nthresholds:\n  warning: 0.02\n  error: 0.05\nactions:\n  warning: \"Warning: Step {step} found {n_failed} failures in {col} column\"\n  error: \"Error in {TYPE} validation: {n_failed}/{n} rows failed (Step {step})\"\n  critical: \"Critical failure detected at {time}\"\nsteps:\n  - col_vals_not_null:\n      columns: [order_id, customer_id]\nAvailable template variables include:\n\n{step}: validation step number\n{col}: column name being validated\n{val}: specific failing value (when applicable)\n{n_failed}: number of failing rows\n{n}: total number of rows checked\n{TYPE}: validation method name (e.g., “COL_VALS_NOT_NULL”)\n{LEVEL}: severity level (“WARNING”, “ERROR”, “CRITICAL”)\n{time}: timestamp of the validation\n\n\n\n3.6.2 Callable Actions\nFor more complex responses, use Python callable functions:\ntbl: critical_data.csv\nthresholds:\n  error: 1\nactions:\n  error:\n    python: |\n      lambda: print(\"ALERT: Critical data validation failed!\")\n  critical:\n    python: |\n      lambda: print(\"CRITICAL: Validation failure - manual intervention required!\")\nsteps:\n  - col_vals_not_null:\n      columns: [transaction_id, amount]\nNote: The Python environment in YAML actions is restricted for security. You can use built-in functions like print(), basic operations, and available DataFrame libraries, but cannot import external modules like requests or logging. For external notifications, consider using string template actions or handling alerts in your application code after the validation completes.\n\n\n3.6.3 Step-level Actions\nYou can also define actions for individual validation steps:\ntbl: financial_data.csv\nsteps:\n  - col_vals_not_null:\n      columns: account_balance\n      thresholds:\n        error: 1\n      actions:\n        error: \"Missing account balance detected in step {step}.\"\n\n  - col_vals_gt:\n      columns: account_balance\n      value: 0\n      actions:\n        warning:\n          python: |\n            lambda: print(\"Negative balance warning triggered.\")"
  },
  {
    "objectID": "user-guide-pdf.html#advanced-features",
    "href": "user-guide-pdf.html#advanced-features",
    "title": "CLI Reference",
    "section": "3.7 Advanced Features",
    "text": "3.7 Advanced Features\n\n3.7.1 Pre-processing with the pre Parameter\nYou can apply data transformations before validation using the pre parameter:\ntbl: transactions.csv\nsteps:\n  # Validate only recent transactions\n  - col_vals_gt:\n      columns: amount\n      value: 0\n      pre:\n        python: |\n          lambda df: df.filter(\n              pl.col(\"transaction_date\") &gt;= \"2024-01-01\"\n          )\n\n  # Check completeness for active customers only\n  - col_vals_not_null:\n      columns: [email, phone]\n      pre: |\n        lambda df: df.filter(pl.col(\"status\") == \"active\")\nNote that you can use either the explicit python: block syntax or the shortcut syntax (just pre: |) for the lambda expressions.\n\n\n3.7.2 Complex Expressions\nFor advanced validation logic, use a col_vals_expr step with custom expressions:\ntbl: sales_data.csv\nsteps:\n  # Custom business logic validation\n  - col_vals_expr:\n      expr:\n        python: |\n          (\n            pl.when(pl.col(\"product_type\") == \"premium\")\n            .then(pl.col(\"price\") &gt;= 100)\n            .when(pl.col(\"product_type\") == \"standard\")\n            .then(pl.col(\"price\").is_between(20, 99))\n            .otherwise(pl.col(\"price\") &lt;= 19)\n          )\n\n\n3.7.3 Brief Descriptions\nAdd human-readable descriptions to validation steps. The brief parameter supports string templating and automatic generation:\ntbl: customer_data.csv\nbrief: \"Customer data quality validation for {auto}\"\nsteps:\n  - col_vals_not_null:\n      columns: customer_id\n      brief: \"Ensure all customers have valid IDs\"\n\n  - col_vals_regex:\n      columns: email\n      pattern: \"^[\\\\w\\\\.-]+@[\\\\w\\\\.-]+\\\\.[a-zA-Z]{2,}$\"\n      brief: \"Validate email format compliance\"\n\n  - col_vals_between:\n      columns: age\n      left: 13\n      right: 120\n      brief: \"Check reasonable age ranges\"\n\n  # Use automatic brief generation\n  - col_vals_not_null:\n      columns: phone_number\n      brief: true\n\n  # Template variables in briefs\n  - col_vals_in_set:\n      columns: status\n      set: [active, inactive, pending]\n      brief: \"Column '{col}' must be one of: {set}\"\nBrief Templating Options:\n\ncustom strings: Write your own descriptive text\ntrue: Automatically generates a brief based on the validation method and parameters\n{auto}: Placeholder for auto-generated text within custom strings\ntemplate variables: Use the same variables available in actions:\n\n{col}: column name(s) being validated\n{step}: the step number in the validation plan\n{value}: the comparison value used in the validation (for single-value comparisons)\n{pattern}: for regex validations, the pattern being matched"
  },
  {
    "objectID": "user-guide-pdf.html#working-with-yaml-files",
    "href": "user-guide-pdf.html#working-with-yaml-files",
    "title": "CLI Reference",
    "section": "3.8 Working with YAML Files",
    "text": "3.8 Working with YAML Files\n\n3.8.1 Loading from Files\nYou can save your YAML configuration to files and load them:\n\n# Create a YAML file\nyaml_content = \"\"\"\ntbl: small_table\ntbl_name: \"File-based Validation\"\nsteps:\n  - col_vals_between:\n      columns: c\n      left: 1\n      right: 10\n  - col_vals_in_set:\n      columns: f\n      set: [low, mid, high]\n\"\"\"\n\n# Save to file\nfrom pathlib import Path\nyaml_file = Path(\"validation_config.yaml\")\nyaml_file.write_text(yaml_content)\n\n# Load and execute\nresult = pb.yaml_interrogate(yaml_file)\nresult\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:44PolarsFile-based Validation\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_between\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_between()\n        \n        \n        \n    c\n    [1, 10]\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        \n        \n    f\n    low, mid, high\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\n\n\n3.8.2 Converting YAML to Python\nUse yaml_to_python() to generate equivalent Python code from your YAML configuration:\n\nyaml_config = \"\"\"\ntbl: small_table\ntbl_name: \"Example Validation\"\nthresholds:\n  warning: 0.1\n  error: 0.2\nactions:\n  warning: \"Warning: {TYPE} validation failed\"\nsteps:\n  - col_vals_gt:\n      columns: a\n      value: 0\n  - col_vals_in_set:\n      columns: f\n      set: [low, mid, high]\n\"\"\"\n\n# Generate Python code\npython_code = pb.yaml_to_python(yaml_config)\nprint(python_code)\n\n```python\nimport pointblank as pb\n\n(\n    pb.Validate(\n        data=pb.load_dataset(\"small_table\", tbl_type=\"polars\"),\n        tbl_name=\"Example Validation\",\n        thresholds=pb.Thresholds(warning=0.1, error=0.2),\n        actions=pb.Actions(warning=\"Warning: {TYPE} validation failed\"),\n    )\n    .col_vals_gt(columns=\"a\", value=0)\n    .col_vals_in_set(columns=\"f\", set=[\"low\", \"mid\", \"high\"])\n    .interrogate()\n)\n```\n\n\nThis is useful for:\n\nlearning how YAML maps to Python API calls\ntransitioning from YAML to code-based workflows\ngenerating documentation that shows both approaches\ndebugging YAML configurations"
  },
  {
    "objectID": "user-guide-pdf.html#practical-examples",
    "href": "user-guide-pdf.html#practical-examples",
    "title": "CLI Reference",
    "section": "3.9 Practical Examples",
    "text": "3.9 Practical Examples\n\n3.9.1 Data Pipeline Validation\nHere’s a comprehensive example for validating data in a processing pipeline:\ntbl:\n  python: |\n    (\n      pl.scan_csv(\"raw_data/customer_events.csv\")\n      .filter(pl.col(\"event_date\") &gt;= \"2024-01-01\")\n    )\n\ntbl_name: \"Customer Events Pipeline Validation\"\nlabel: \"Daily data quality check for customer events\"\n\nthresholds:\n  warning: 0.01   # 1% failure rate\n  error: 0.05     # 5% failure rate\n\nactions:\n  warning: \"Pipeline warning: {TYPE} validation found {n_failed} issues\"\n  error:\n    python: |\n      lambda: print(\"ERROR: Pipeline validation failed - manual review required\")\n\nsteps:\n  # Schema validation\n  - col_schema_match:\n      schema:\n        columns:\n          - [customer_id, \"int64\"]\n          - [event_type, \"object\"]\n          - [event_date, \"object\"]\n          - [revenue, \"float64\"]\n      brief: \"Validate table structure matches expected schema\"\n\n  # Data completeness\n  - col_vals_not_null:\n      columns: [customer_id, event_type, event_date]\n      brief: \"Critical fields must be complete\"\n\n  # Business logic validation\n  - col_vals_in_set:\n      columns: event_type\n      set: [signup, purchase, cancellation, upgrade]\n      brief: \"Event types must be from approved list\"\n\n  # Data quality checks\n  - col_vals_gt:\n      columns: revenue\n      value: 0\n      na_pass: true\n      brief: \"Revenue values must be positive when present\"\n\n  # Temporal validation\n  - col_vals_expr:\n      expr:\n        python: |\n          pl.col(\"event_date\").str.strptime(pl.Date, \"%Y-%m-%d\").is_not_null()\n      brief: \"Event dates must be valid YYYY-MM-DD format\"\n\n\n3.9.2 Quality Monitoring Dashboard\nFor ongoing data quality monitoring:\ntbl: warehouse/daily_metrics.parquet\ntbl_name: \"Daily Metrics Quality Check\"\n\nthresholds:\n  warning: 5      # 5 failing rows\n  error: 50       # 50 failing rows\n  critical: 100   # 100 failing rows\n\nactions:\n  warning: \"Quality check warning: {n_failed} rows failed {TYPE} validation\"\n  error: \"Quality degradation detected: Step {step} failed for {n_failed}/{n} rows\"\n  critical:\n    python: |\n      lambda: print(\"CRITICAL: Data quality failure detected - immediate attention required\")\n  highest_only: false\n\nsteps:\n  - row_count_match:\n      count: 10000\n      brief: \"Verify expected daily record count\"\n\n  - col_vals_not_null:\n      columns: [date, metric_value, source_system]\n      brief: \"Core fields must be complete\"\n\n  - col_vals_between:\n      columns: metric_value\n      left: 0\n      right: 1000000\n      brief: \"Metric values within reasonable range\"\n\n  - rows_distinct:\n      columns_subset: [date, metric_name, source_system]\n      brief: \"No duplicate metric records per day\""
  },
  {
    "objectID": "user-guide-pdf.html#best-practices-2",
    "href": "user-guide-pdf.html#best-practices-2",
    "title": "CLI Reference",
    "section": "3.10 Best Practices",
    "text": "3.10 Best Practices\n\n3.10.1 Organization and Structure\n\nuse descriptive names: give your validations clear tbl_name and label values\nadd brief descriptions: document what each validation step checks\ngroup related validations: organize steps logically (schema, completeness, business rules)\nversion control: store YAML files in git alongside your data processing code\n\n\n\n3.10.2 Error Handling and Monitoring\n\nset appropriate thresholds: start conservative and adjust based on your data patterns\nuse actions for alerting: set up notifications for critical failures\ndocument expected failures: some data quality issues might be acceptable\nmonitor validation results: track validation performance over time\n\n\n\n3.10.3 Performance Considerations\n\nuse the pre parameter efficiently: apply filters early to reduce data volume\norder validations strategically: put fast, likely-to-fail checks first\nconsider data source location: local files are faster than remote sources\nuse appropriate column selections: only validate the columns you need"
  },
  {
    "objectID": "user-guide-pdf.html#wrapping-up",
    "href": "user-guide-pdf.html#wrapping-up",
    "title": "CLI Reference",
    "section": "3.11 Wrapping Up",
    "text": "3.11 Wrapping Up\nYAML validation workflows provide a powerful, declarative approach to data validation in Pointblank. Such workflows are great at expressing common validation patterns in a readable format that can be easily shared, version controlled, and maintained by teams.\nKey advantages of YAML workflows:\n\nreadable: non-programmers can understand and contribute to validation logic\nmaintainable: easy to modify validation rules without changing application code\nportable: YAML files can be shared between projects and teams\nversion controlled: track changes to validation logic over time\nflexible: support for simple checks and complex custom logic\n\nUse YAML workflows when you want declarative, maintainable validation definitions, and fall back to the Python API when you need complex programmatic logic or tight integration with application code. The two approaches complement each other well and can be used together as your validation needs evolve.\nThis reference provides a comprehensive guide to all YAML keys and parameters supported by Pointblank’s YAML validation workflows. Use this document as a quick lookup when building validation configurations."
  },
  {
    "objectID": "user-guide-pdf.html#global-configuration-keys",
    "href": "user-guide-pdf.html#global-configuration-keys",
    "title": "CLI Reference",
    "section": "3.12 Global Configuration Keys",
    "text": "3.12 Global Configuration Keys\n\n3.12.1 Top-level Structure\ntbl: data_source                       # REQUIRED: Data source specification\ndf_library: \"polars\"                   # OPTIONAL: DataFrame library (\"polars\", \"pandas\", \"duckdb\")\ntbl_name: \"Custom Table Name\"          # OPTIONAL: Human-readable table name\nlabel: \"Validation Description\"        # OPTIONAL: Description for the validation workflow\nlang: \"en\"                             # OPTIONAL: Language code (default: \"en\")\nlocale: \"en\"                           # OPTIONAL: Locale setting (default: \"en\")\nbrief: \"Global brief: {auto}\"          # OPTIONAL: Global brief template\nthresholds:                            # OPTIONAL: Global failure thresholds\n  warning: 0.1\n  error: 0.2\n  critical: 0.3\nactions:                               # OPTIONAL: Global failure actions\n  warning: \"Warning message template\"\n  error: \"Error message template\"\n  critical: \"Critical message template\"\n  highest_only: false\nsteps:                                 # REQUIRED: List of validation steps\n  - validation_method_name\n  - validation_method_name:\n      parameter: value\n\n\n3.12.2 Data Source (tbl)\nThe tbl key specifies the data source and supports multiple formats:\n# File paths\ntbl: \"data/file.csv\"\ntbl: \"data/file.parquet\"\n\n# Built-in datasets\ntbl: small_table\ntbl: game_revenue\ntbl: nycflights\n\n# Python expressions for complex data loading\ntbl:\n  python: |\n    pl.scan_csv(\"data.csv\").filter(pl.col(\"date\") &gt;= \"2024-01-01\")\n\n3.12.2.1 Using Templates with set_tbl=\nFor reusable validation templates that will always use a custom data source via the set_tbl= parameter in yaml_interrogate(), the tbl field is still required but its value doesn’t matter since it will be overridden. Recommended approaches:\n# Option 1: Use a valid dataset name (gets overridden anyway)\ntbl: small_table  # Will be ignored when `set_tbl=` is used\n\n# Option 2: Use YAML null (clearest semantic intent)\ntbl: null  # Indicates table will be provided via `set_tbl=`\nWhen using yaml_interrogate() with set_tbl=, the validation template becomes fully reusable:\n# Define reusable template\ntemplate = \"\"\"\ntbl: null  # Will be overridden\ntbl_name: \"Sales Validation\"\nsteps:\n  - col_exists:\n      columns: [customer_id, revenue, region]\n  - col_vals_gt:\n      columns: [revenue]\n      value: 0\n\"\"\"\n\n# Apply to different datasets\nq1_result = pb.yaml_interrogate(template, set_tbl=q1_data)\nq2_result = pb.yaml_interrogate(template, set_tbl=q2_data)\n\n\n\n3.12.3 DataFrame Library (df_library)\nThe df_library key controls which DataFrame library is used to load data sources. This parameter affects both built-in datasets and file loading:\n# Use Polars DataFrames (default)\ndf_library: polars\n\n# Use Pandas DataFrames\ndf_library: pandas\n\n# Use DuckDB tables (via Ibis)\ndf_library: duckdb\nExamples with different libraries:\n# Load built-in dataset as Pandas DataFrame\ntbl: small_table\ndf_library: pandas\nsteps:\n  - specially:\n      expr: \"lambda df: df.assign(validation_result=df['a'] &gt; 0)\"\n\n# Load CSV file as Polars DataFrame\ntbl: \"data/sales.csv\"\ndf_library: polars\nsteps:\n  - col_vals_gt:\n      columns: amount\n      value: 0\n\n# Load dataset as DuckDB table\ntbl: nycflights\ndf_library: duckdb\nsteps:\n  - row_count_match:\n      count: 336776\nThe df_library parameter is particularly useful when:\n\nusing validation expressions that require specific DataFrame APIs (e.g., Pandas .assign(), Polars .select())\nintegrating with existing pipelines that use a specific DataFrame library\noptimizing performance for different data sizes and operations\nensuring compatibility with downstream processing steps\n\n\n\n3.12.4 Global Thresholds\nThresholds define when validation failures trigger different severity levels:\nthresholds:\n  warning: 0.05    # 5% failure rate triggers warning\n  error: 0.10      # 10% failure rate triggers error\n  critical: 0.15   # 15% failure rate triggers critical\n\nvalues: numbers between 0 and 1 (percentages) or integers (row counts)\nlevels: warning, error, critical\n\n\n\n3.12.5 Global Actions\nActions define responses when thresholds are exceeded. When supplying a string to a severity level (‘warning’, ‘error’, ‘critical’), you can use template variables that will be automatically substituted with contextual information:\nactions:\n  warning: \"Warning: {n_failed} failures in step {step}\"\n  error:\n    python: |\n      lambda: print(\"Error detected!\")\n  critical: \"Critical failure at {time}\"\n  highest_only: false        # Execute all applicable actions vs. only highest severity\nTemplate variables available for action strings:\n\n{step}: current validation step number\n{col}: column name(s) being validated\n{val}: validation value or threshold\n{n_failed}: number of failing records\n{n}: total number of records\n{type}: validation method type\n{level}: severity level (‘warning’/‘error’/‘critical’)\n{time}: timestamp of validation"
  },
  {
    "objectID": "user-guide-pdf.html#validation-methods-reference",
    "href": "user-guide-pdf.html#validation-methods-reference",
    "title": "CLI Reference",
    "section": "3.13 Validation Methods Reference",
    "text": "3.13 Validation Methods Reference\n\n3.13.1 Column Value Validations\n\n3.13.1.1 Comparison Methods\ncol_vals_gt: are column data greater than a fixed value or data in another column?\n- col_vals_gt:\n    columns: [column_name]             # REQUIRED: Column(s) to validate\n    value: 100                         # REQUIRED: Comparison value\n    na_pass: true                      # OPTIONAL: Pass NULL values (default: false)\n    pre: |                             # OPTIONAL: Data preprocessing\n      lambda df: df.filter(condition)\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"Values must be &gt; 100\"      # OPTIONAL: Step description\ncol_vals_lt: are column data less than a fixed value or data in another column?\n- col_vals_lt:\n    columns: [column_name]\n    value: 100\n    na_pass: true\n    # ... (same parameters as col_vals_gt)\ncol_vals_ge: are column data greater than or equal to a fixed value or data in another column?\n- col_vals_ge:\n    columns: [column_name]\n    value: 100\n    na_pass: true\n    # ... (same parameters as col_vals_gt)\ncol_vals_le: are column data less than or equal to a fixed value or data in another column?\n- col_vals_le:\n    columns: [column_name]\n    value: 100\n    na_pass: true\n    # ... (same parameters as col_vals_gt)\ncol_vals_eq: are column data equal to a fixed value or data in another column?\n- col_vals_eq:\n    columns: [column_name]\n    value: \"expected_value\"\n    na_pass: true\n    # ... (same parameters as col_vals_gt)\ncol_vals_ne: are column data not equal to a fixed value or data in another column?\n- col_vals_ne:\n    columns: [column_name]\n    value: \"forbidden_value\"\n    na_pass: true\n    # ... (same parameters as col_vals_gt)\n\n\n3.13.1.2 Range Methods\ncol_vals_between: are column data between two specified values (inclusive)?\n- col_vals_between:\n    columns: [column_name]             # REQUIRED: Column(s) to validate\n    left: 0                            # REQUIRED: Lower bound\n    right: 100                         # REQUIRED: Upper bound\n    inclusive: [true, true]            # OPTIONAL: Include bounds [left, right]\n    na_pass: false                     # OPTIONAL: Pass NULL values\n    pre: |                             # OPTIONAL: Data preprocessing\n      lambda df: df.filter(condition)\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"Values between 0 and 100\"  # OPTIONAL: Step description\ncol_vals_outside: are column data outside of two specified values?\n- col_vals_outside:\n    columns: [column_name]\n    left: 0\n    right: 100\n    inclusive: [false, false]          # OPTIONAL: Exclude bounds [left, right]\n    na_pass: false\n    # ... (same parameters as col_vals_between)\n\n\n3.13.1.3 Set Membership Methods\ncol_vals_in_set: are column data part of a specified set of values?\n- col_vals_in_set:\n    columns: [column_name]             # REQUIRED: Column(s) to validate\n    set: [value1, value2, value3]      # REQUIRED: Allowed values\n    na_pass: false                     # OPTIONAL: Pass NULL values\n    pre: |                             # OPTIONAL: Data preprocessing\n      lambda df: df.filter(condition)\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"Values in allowed set\"     # OPTIONAL: Step description\ncol_vals_not_in_set: are column data not part of a specified set of values?\n- col_vals_not_in_set:\n    columns: [column_name]\n    set: [forbidden1, forbidden2]      # REQUIRED: Forbidden values\n    na_pass: false\n    # ... (same parameters as col_vals_in_set)\n\n\n3.13.1.4 NULL Value Methods\ncol_vals_null: are column data null (missing)?\n- col_vals_null:\n    columns: [column_name]             # REQUIRED: Column(s) to validate\n    pre: |                             # OPTIONAL: Data preprocessing\n      lambda df: df.filter(condition)\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"Values must be NULL\"       # OPTIONAL: Step description\ncol_vals_not_null: are column data not null (not missing)?\n- col_vals_not_null:\n    columns: [column_name]\n    # ... (same parameters as col_vals_null)\n\n\n3.13.1.5 Pattern Matching Methods\ncol_vals_regex: do string-based column data match a regular expression?\n- col_vals_regex:\n    columns: [column_name]             # REQUIRED: Column(s) to validate\n    pattern: \"^[A-Z]{2,3}$\"            # REQUIRED: Regular expression pattern\n    na_pass: false                     # OPTIONAL: Pass NULL values\n    pre: |                             # OPTIONAL: Data preprocessing\n      lambda df: df.filter(condition)\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"Values match pattern\"      # OPTIONAL: Step description\ncol_vals_within_spec: do column data conform to a specification (email, URL, postal codes, etc.)?\n- col_vals_within_spec:\n    columns: [column_name]             # REQUIRED: Column(s) to validate\n    spec: \"email\"                      # REQUIRED: Specification type\n    na_pass: false                     # OPTIONAL: Pass NULL values\n    pre: |                             # OPTIONAL: Data preprocessing\n      lambda df: df.filter(condition)\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"Values match spec\"         # OPTIONAL: Step description\nAvailable specification types:\n\n\"email\" - Email addresses\n\"url\" - Internet URLs\n\"phone\" - Phone numbers\n\"ipv4\" - IPv4 addresses\n\"ipv6\" - IPv6 addresses\n\"mac\" - MAC addresses\n\"isbn\" - International Standard Book Numbers (10 or 13 digit)\n\"vin\" - Vehicle Identification Numbers\n\"credit_card\" - Credit card numbers (uses Luhn algorithm)\n\"swift\" - Business Identifier Codes (SWIFT-BIC)\n\"postal_code[&lt;country_code&gt;]\" - Postal codes for specific countries (e.g., \"postal_code[US]\", \"postal_code[CA]\")\n\"zip\" - Alias for US ZIP codes (\"postal_code[US]\")\n\"iban[&lt;country_code&gt;]\" - International Bank Account Numbers (e.g., \"iban[DE]\", \"iban[FR]\")\n\nExamples:\n# Email validation\n- col_vals_within_spec:\n    columns: user_email\n    spec: \"email\"\n\n# US postal codes\n- col_vals_within_spec:\n    columns: zip_code\n    spec: \"postal_code[US]\"\n\n# German IBAN\n- col_vals_within_spec:\n    columns: account_number\n    spec: \"iban[DE]\"\n\n\n3.13.1.6 Custom Expression Methods\ncol_vals_expr: do column data agree with a predicate expression?\n- col_vals_expr:\n    expr:                              # REQUIRED: Custom validation expression\n      python: |\n        pl.when(pl.col(\"status\") == \"active\")\n        .then(pl.col(\"value\") &gt; 0)\n        .otherwise(pl.lit(True))\n    pre: |                             # OPTIONAL: Data preprocessing\n      lambda df: df.filter(condition)\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"Custom validation rule\"    # OPTIONAL: Step description\n\n\n3.13.1.7 Trend Validation Methods\ncol_vals_increasing: are column data increasing row-by-row?\n- col_vals_increasing:\n    columns: [column_name]             # REQUIRED: Column(s) to validate\n    allow_stationary: false            # OPTIONAL: Allow consecutive equal values (default: false)\n    decreasing_tol: 0.5                # OPTIONAL: Tolerance for negative movement (default: null)\n    na_pass: false                     # OPTIONAL: Pass NULL values\n    pre: |                             # OPTIONAL: Data preprocessing\n      lambda df: df.filter(condition)\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"Values must increase\"      # OPTIONAL: Step description\nThis validation checks whether values in a column increase as you move down the rows. Useful for validating time-series data, sequence numbers, or any monotonically increasing values.\nParameters:\n\nallow_stationary: If true, allows consecutive values to be equal (stationary phases). For example, [1, 2, 2, 3] would pass when true but fail at the third value when false.\ndecreasing_tol: Absolute tolerance for negative movement. Setting this to 0.5 means values can decrease by up to 0.5 units and still pass. Setting any value also sets allow_stationary to true.\n\nExamples:\n# Strict increasing validation\n- col_vals_increasing:\n    columns: timestamp_seconds\n    brief: \"Timestamps must strictly increase\"\n\n# Allow stationary values\n- col_vals_increasing:\n    columns: version_number\n    allow_stationary: true\n    brief: \"Version numbers should increase (ties allowed)\"\n\n# With tolerance for small decreases\n- col_vals_increasing:\n    columns: temperature\n    decreasing_tol: 0.1\n    brief: \"Temperature trend (small drops allowed)\"\ncol_vals_decreasing: are column data decreasing row-by-row?\n- col_vals_decreasing:\n    columns: [column_name]             # REQUIRED: Column(s) to validate\n    allow_stationary: false            # OPTIONAL: Allow consecutive equal values (default: false)\n    increasing_tol: 0.5                # OPTIONAL: Tolerance for positive movement (default: null)\n    na_pass: false                     # OPTIONAL: Pass NULL values\n    pre: |                             # OPTIONAL: Data preprocessing\n      lambda df: df.filter(condition)\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"Values must decrease\"      # OPTIONAL: Step description\nThis validation checks whether values in a column decrease as you move down the rows. Useful for countdown timers, inventory depletion, or any monotonically decreasing values.\nParameters:\n\nallow_stationary: If true, allows consecutive values to be equal (stationary phases). For example, [10, 8, 8, 5] would pass when true but fail at the third value when false.\nincreasing_tol: Absolute tolerance for positive movement. Setting this to 0.5 means values can increase by up to 0.5 units and still pass. Setting any value also sets allow_stationary to true.\n\nExamples:\n# Strict decreasing validation\n- col_vals_decreasing:\n    columns: countdown_timer\n    brief: \"Timer must strictly decrease\"\n\n# Allow stationary values\n- col_vals_decreasing:\n    columns: priority_score\n    allow_stationary: true\n    brief: \"Priority scores should decrease (ties allowed)\"\n\n# With tolerance for small increases\n- col_vals_decreasing:\n    columns: stock_level\n    increasing_tol: 5\n    brief: \"Stock levels decrease (small restocks allowed)\"\n\n\n\n3.13.2 Row-based Validations\nrows_distinct: are row data distinct?\n- rows_distinct                        # Simple form\n\n- rows_distinct:                       # With parameters\n    columns_subset: [col1, col2]       # OPTIONAL: Check subset of columns\n    pre: |                             # OPTIONAL: Data preprocessing\n      lambda df: df.filter(condition)\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"No duplicate rows\"         # OPTIONAL: Step description\nrows_complete: are row data complete?\n- rows_complete                        # Simple form\n\n- rows_complete:                       # With parameters\n    columns_subset: [col1, col2]       # OPTIONAL: Check subset of columns\n    pre: |                             # OPTIONAL: Data preprocessing\n      lambda df: df.filter(condition)\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"Complete rows only\"        # OPTIONAL: Step description\n\n\n3.13.3 Structure Validations\ncol_exists: does column exist in the table?\n- col_exists:\n    columns: [col1, col2, col3]        # REQUIRED: Column(s) that must exist\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"Required columns exist\"    # OPTIONAL: Step description\ncol_schema_match: does the table have expected column names and data types?\n- col_schema_match:\n    schema:                            # REQUIRED: Expected schema\n      columns:\n        - [column_name, \"data_type\"]   # Column with type validation\n        - column_name                  # Column name only (no type check)\n        - [column_name]                # Alternative syntax\n    complete: true                     # OPTIONAL: Require exact column set\n    in_order: true                     # OPTIONAL: Require exact column order\n    case_sensitive_colnames: true      # OPTIONAL: Case-sensitive column names\n    case_sensitive_dtypes: true        # OPTIONAL: Case-sensitive data types\n    full_match_dtypes: true            # OPTIONAL: Exact type matching\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"Schema validation\"         # OPTIONAL: Step description\nrow_count_match: does the table have n rows?\n- row_count_match:\n    count: 1000                        # REQUIRED: Expected row count\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"Expected row count\"        # OPTIONAL: Step description\ncol_count_match: does the table have n columns?\n- col_count_match:\n    count: 10                          # REQUIRED: Expected column count\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"Expected column count\"     # OPTIONAL: Step description\ntbl_match: does the table match a comparison table?\n- tbl_match:\n    tbl_compare:                       # REQUIRED: Comparison table\n      python: |\n        pb.load_dataset(\"reference_table\", tbl_type=\"polars\")\n    pre: |                             # OPTIONAL: Data preprocessing\n      lambda df: df.filter(condition)\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.0\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"Table structure matches\"   # OPTIONAL: Step description\nThis validation performs a comprehensive comparison between the target table and a comparison table, using progressively stricter checks:\n\nColumn count match: both tables have the same number of columns\nRow count match: both tables have the same number of rows\nSchema match (loose): column names and dtypes match (case-insensitive, any order)\nSchema match (order): columns in correct order (case-insensitive names)\nSchema match (exact): column names match exactly (case-sensitive, correct order)\nData match: values in corresponding cells are identical\n\nThe validation fails at the first check that doesn’t pass, making it easy to diagnose mismatches. This operates over a single test unit (pass/fail for complete table match).\nCross-backend validation: tbl_match() supports automatic backend coercion when comparing tables from different backends (e.g., Polars vs. Pandas, DuckDB vs. SQLite). The comparison table is automatically converted to match the target table’s backend.\nExamples:\n# Compare against reference dataset\n- tbl_match:\n    tbl_compare:\n      python: |\n        pb.load_dataset(\"expected_output\", tbl_type=\"polars\")\n    brief: \"Output matches expected results\"\n\n# Compare against CSV file\n- tbl_match:\n    tbl_compare:\n      python: |\n        pl.read_csv(\"reference_data.csv\")\n    brief: \"Matches reference CSV\"\n\n# Compare with preprocessing on target table only\n- tbl_match:\n    tbl_compare:\n      python: |\n        pb.load_dataset(\"reference_table\", tbl_type=\"polars\")\n    pre: |\n      lambda df: df.select([\"id\", \"name\", \"value\"])\n    brief: \"Selected columns match reference\"\n\n\n3.13.4 Special Validation Methods\nconjointly: are multiple validations having a joint dependency?\n- conjointly:\n    expressions:                       # REQUIRED: List of lambda expressions\n      - \"lambda df: df['d'] &gt; df['a']\"\n      - \"lambda df: df['a'] &gt; 0\"\n      - \"lambda df: df['a'] + df['d'] &lt; 12000\"\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"All conditions must pass\"  # OPTIONAL: Step description\nspecially: do table data pass a custom validation function?\n- specially:\n    expr:                              # REQUIRED: Custom validation function\n      \"lambda df: df.select(pl.col('a') + pl.col('d') &gt; 0)\"\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"Custom validation\"         # OPTIONAL: Step description\nAlternative syntax with Python expressions:\n- specially:\n    expr:\n      python: |\n        lambda df: df.select(pl.col('amount') &gt; 0)\nFor Pandas DataFrames (when using df_library: pandas):\n- specially:\n    expr: \"lambda df: df.assign(is_valid=df['a'] + df['d'] &gt; 0)\"\n\n\n3.13.5 AI-Powered Validation\nprompt: validate rows using AI/LLM-powered analysis\n- prompt:\n    prompt: \"Values should be positive and realistic\"  # REQUIRED: Natural language criteria\n    model: \"anthropic:claude-sonnet-4\"                 # REQUIRED: Model identifier\n    columns_subset: [column1, column2]                 # OPTIONAL: Columns to validate\n    batch_size: 1000                                   # OPTIONAL: Rows per batch (default: 1000)\n    max_concurrent: 3                                  # OPTIONAL: Concurrent API requests (default: 3)\n    pre: |                                             # OPTIONAL: Data preprocessing\n      lambda df: df.filter(condition)\n    thresholds:                                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"AI validation\"                             # OPTIONAL: Step description\nThis validation method uses Large Language Models (LLMs) to validate rows of data based on natural language criteria. Each row becomes a test unit that either passes or fails the validation criteria, producing binary True/False results that integrate with standard Pointblank reporting.\nSupported models:\n\nAnthropic: \"anthropic:claude-sonnet-4\", \"anthropic:claude-opus-4\"\nOpenAI: \"openai:gpt-4\", \"openai:gpt-4-turbo\", \"openai:gpt-3.5-turbo\"\nOllama: \"ollama:&lt;model-name&gt;\" (e.g., \"ollama:llama3\")\nBedrock: \"bedrock:&lt;model-name&gt;\"\n\nAuthentication: API keys are automatically loaded from environment variables or .env files:\n\nOpenAI: Set OPENAI_API_KEY environment variable or add to .env file\nAnthropic: Set ANTHROPIC_API_KEY environment variable or add to .env file\nOllama: No API key required (runs locally)\nBedrock: Configure AWS credentials through standard AWS methods\n\nExample .env file:\nANTHROPIC_API_KEY=\"your_anthropic_api_key_here\"\nOPENAI_API_KEY=\"your_openai_api_key_here\"\nPerformance optimization: The validation process uses row signature memoization to avoid redundant LLM calls. When multiple rows have identical values in the selected columns, only one representative row is validated, and the result is applied to all matching rows. This dramatically reduces API costs and processing time for datasets with repetitive patterns.\nExamples:\n# Basic AI validation\n- prompt:\n    prompt: \"Email addresses should look realistic and professional\"\n    model: \"anthropic:claude-sonnet-4\"\n    columns_subset: [email]\n\n# Complex semantic validation\n- prompt:\n    prompt: \"Product descriptions should mention the product category and include at least one benefit\"\n    model: \"openai:gpt-4\"\n    columns_subset: [product_name, description, category]\n    batch_size: 500\n    max_concurrent: 5\n\n# Sentiment analysis\n- prompt:\n    prompt: \"Customer feedback should express positive sentiment\"\n    model: \"anthropic:claude-sonnet-4\"\n    columns_subset: [feedback_text, rating]\n\n# Context-dependent validation\n- prompt:\n    prompt: \"For high-value transactions (amount &gt; 1000), a detailed justification should be provided\"\n    model: \"openai:gpt-4\"\n    columns_subset: [amount, justification, approver]\n    thresholds:\n      warning: 0.05\n      error: 0.15\n\n# Local model with Ollama\n- prompt:\n    prompt: \"Transaction descriptions should be clear and professional\"\n    model: \"ollama:llama3\"\n    columns_subset: [description]\nBest practices for AI validation:\n\nBe specific and clear in your prompt criteria\nInclude only necessary columns in columns_subset to reduce API costs\nStart with smaller batch_size for testing, increase for production\nAdjust max_concurrent based on API rate limits\nUse thresholds appropriate for probabilistic validation results\nConsider cost implications for large datasets\nTest prompts on sample data before full deployment\n\nWhen to use AI validation:\n\nSemantic checks (e.g., “does the description match the category?”)\nContext-dependent validation (e.g., “is the justification appropriate for the amount?”)\nSubjective quality assessment (e.g., “is the text professional?”)\nPattern recognition that’s hard to express programmatically\nNatural language understanding tasks\n\nWhen NOT to use AI validation:\n\nSimple numeric comparisons (use col_vals_gt, col_vals_lt, etc.)\nExact pattern matching (use col_vals_regex)\nSchema validation (use col_schema_match)\nPerformance-critical validations with large datasets\nWhen deterministic results are required"
  },
  {
    "objectID": "user-guide-pdf.html#column-selection-patterns-1",
    "href": "user-guide-pdf.html#column-selection-patterns-1",
    "title": "CLI Reference",
    "section": "3.14 Column Selection Patterns",
    "text": "3.14 Column Selection Patterns\nAll validation methods that accept a columns parameter support these selection patterns:\n# Single column\ncolumns: column_name\n\n# Multiple columns as list\ncolumns: [col1, col2, col3]\n\n# Column selector functions (when used in Python expressions)\ncolumns:\n  python: |\n    starts_with(\"prefix_\")\n\n# Examples of common patterns\ncolumns: [customer_id, order_id]     # Specific columns\ncolumns: user_email                  # Single column"
  },
  {
    "objectID": "user-guide-pdf.html#parameter-details",
    "href": "user-guide-pdf.html#parameter-details",
    "title": "CLI Reference",
    "section": "3.15 Parameter Details",
    "text": "3.15 Parameter Details\n\n3.15.1 Common Parameters\nThese parameters are available for most validation methods:\n\ncolumns: column selection (string, list, or selector expression)\nna_pass: whether to pass NULL/missing values (boolean, default: false)\npre: data preprocessing function (Python lambda expression)\nthresholds: step-level failure thresholds (dict)\nactions: step-level failure actions (dict)\nbrief: step description (string, boolean, or template)\n\n\n\n3.15.2 Brief Parameter Options\nThe brief parameter supports several formats:\nbrief: \"Custom description\"          # Custom text\nbrief: true                         # Auto-generated description\nbrief: false                        # No description\nbrief: \"Step {step}: {auto}\"        # Template with auto-generated text\nbrief: \"Column '{col}' validation\"  # Template with variables\ntemplate variables: {step}, {col}, {value}, {set}, {pattern}, {auto}\n\n\n3.15.3 Python Expressions\nSeveral parameters support Python expressions using the python: block syntax:\n# Data source loading\ntbl:\n  python: |\n    pl.scan_csv(\"data.csv\").filter(pl.col(\"active\") == True)\n\n# Preprocessing\npre:\n  python: |\n    lambda df: df.filter(pl.col(\"date\") &gt;= \"2024-01-01\")\n\n# Custom expressions\nexpr:\n  python: |\n    pl.col(\"value\").is_between(0, 100)\n\n# Callable actions\nactions:\n  error:\n    python: |\n      lambda: print(\"VALIDATION ERROR: Critical data quality issue detected!\")\nNote: The Python environment in YAML is restricted for security. Only built-in functions (print, len, str, etc.), Path from pathlib, and available DataFrame libraries (pl, pd) are accessible. You cannot import additional modules like requests, logging, or custom libraries.\nYou can also use the shortcut syntax for lambda expressions:\n# Shortcut syntax (equivalent to python: block)\npre: |\n  lambda df: df.filter(pl.col(\"status\") == \"active\")\n\n\n3.15.4 Restricted Python Environment\nFor security reasons, the Python environment in YAML configurations is restricted to a safe subset of functionality. The available namespace includes:\nBuilt-in functions:\n\nbasic types: str, int, float, bool, list, dict, tuple, set\nmath functions: sum, min, max, abs, round, len\niteration: range, enumerate, zip\noutput: print\n\nAvailable modules:\n\nPath from pathlib for file path operations\npb (pointblank) for dataset loading and validation functions\npl (polars) if available on the system\npd (pandas) if available on the system\n\nRestrictions:\n\ncannot import external libraries (requests, logging, os, sys, etc.)\ncannot use __import__, exec, eval, or other dynamic execution functions\nfile operations are limited to Path functionality\n\nExamples of valid callable actions:\n# Simple output with built-in functions\nactions:\n  warning:\n    python: |\n      lambda: print(f\"WARNING: {sum([1, 2, 3])} validation issues detected\")\n\n# Using available variables and string formatting\nactions:\n  error:\n    python: |\n      lambda: print(\"ERROR: Data validation failed at \" + str(len(\"validation\")))\n\n# Multiple statements in lambda (using parentheses)\nactions:\n  critical:\n    python: |\n      lambda: (\n          print(\"CRITICAL ALERT:\"),\n          print(\"Immediate attention required\"),\n          print(\"Contact data team\")\n      )[-1]  # Return the last value\nFor complex alerting, logging, or external system integration, use string template actions instead of callable actions, and handle the external communication in your application code after validation completes."
  },
  {
    "objectID": "user-guide-pdf.html#best-practices-3",
    "href": "user-guide-pdf.html#best-practices-3",
    "title": "CLI Reference",
    "section": "3.16 Best Practices",
    "text": "3.16 Best Practices\n\n3.16.1 Organization\n\nuse descriptive tbl_name and label values\nadd brief descriptions for complex validations\ngroup related validations logically\nuse consistent indentation and formatting\n\n\n\n3.16.2 Performance\n\napply pre filters early to reduce data volume\norder validations from fast to slow\nuse columns_subset for row-based validations when appropriate\nconsider data source location (local vs. remote)\nchoose df_library based on data size and operations:\n\npolars: fastest for large datasets and analytical operations\npandas: best for complex transformations and data science workflows\nduckdb: optimal for analytical queries on very large datasets\n\n\n\n\n3.16.3 Maintainability\n\nstore YAML files in version control\nuse template variables in actions and briefs\ndocument expected failures with comments\ntest configurations with validate_yaml() before deployment\nspecify df_library explicitly when using library-specific validation expressions\nkeep DataFrame library choice consistent within related validation workflows\n\n\n\n3.16.4 Error Handling\n\nset appropriate thresholds based on data patterns\nuse actions for monitoring and alerting\nstart with conservative thresholds and adjust\nconsider using highest_only: false for comprehensive reporting"
  },
  {
    "objectID": "user-guide-pdf.html#viewing-the-validation-report",
    "href": "user-guide-pdf.html#viewing-the-validation-report",
    "title": "CLI Reference",
    "section": "4.1 Viewing the Validation Report",
    "text": "4.1 Viewing the Validation Report\nThe most straightforward way to view a validation report is to simply print the Validate object after calling interrogate():\n\nimport pointblank as pb\nimport polars as pl\n\n# Sample data\ndata = pl.DataFrame({\n    \"id\": range(1, 11),\n    \"value\": [120, 85, 47, 210, 30, 155, 175, 95, 205, 140],\n    \"category\": [\"A\", \"B\", \"C\", \"A\", \"D\", \"B\", \"A\", \"E\", \"A\", \"C\"],\n    \"ratio\": [0.5, 0.7, 0.3, 1.2, 0.8, 0.9, 0.4, 1.5, 0.6, 0.2],\n})\n\n# Create and interrogate a validation\nvalidation = (\n    pb.Validate(data=data, tbl_name=\"sales_data\")\n    .col_vals_gt(columns=\"value\", value=50, brief=True)\n    .col_vals_in_set(columns=\"category\", set=[\"A\", \"B\", \"C\"], brief=True)\n    .col_exists(columns=[\"id\", \"value\"], brief=True)\n    .interrogate()\n)\n\n# Display the validation report\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:44Polarssales_data\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Expect that values in value should be &gt; 50.\n\n        \n    value\n    50\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Expect that values in category should be in the set of A, B, C.\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column id exists.\n\n        \n    id\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column value exists.\n\n        \n    value\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nIn a notebook or interactive environment, simply typing the validation object name displays the report automatically. In a script or REPL, you might need to explicitly call validation.get_tabular_report().show() to display the table.\n\n\n\n\n\n\nNote\n\n\n\nYou can display a validation report even before calling interrogate(). The report will show your validation plan with all the steps you’ve defined, but it won’t contain any interrogation results. Additionally, validation steps that use column selection patterns (like validating multiple columns at once) won’t be expanded into individual rows yet, as that expansion happens during interrogation."
  },
  {
    "objectID": "user-guide-pdf.html#understanding-report-components",
    "href": "user-guide-pdf.html#understanding-report-components",
    "title": "CLI Reference",
    "section": "4.2 Understanding Report Components",
    "text": "4.2 Understanding Report Components\nThe validation report table consists of several key components that work together to provide a complete picture of your data quality:\n\n4.2.0.1 Report Header\nThe report header (title and subtitle area) contains important metadata about the validation:\n\nTitle: by default, shows “Pointblank Validation” but can be customized\nLabel: your custom label for the validation (if provided via the label= parameter)\nTable Information: the table name and type (Polars, Pandas, DuckDB, etc.)\nThresholds: the warning, error, and critical threshold values used\n\nThis header information provides essential context for interpreting the validation results, especially when sharing reports with stakeholders or reviewing historical validations.\n\n\n4.2.0.2 Report Footer\nThe report footer contains a timestamp showing when the interrogation was performed. This timestamp helps track when data quality checks were executed, which is especially useful when archiving reports or monitoring data quality over time.\n\n\n\n\n\n\nNote\n\n\n\nThroughout this documentation, the footer is hidden in example reports for brevity. This is controlled through a global option (see the section on controlling header and footer display later in this guide). In practice, including the footer provides valuable timestamp information for tracking when validations were executed.\n\n\n\n\n4.2.1 Report Columns\nThe validation report table includes the following columns, each providing specific information about the validation steps:\n\n4.2.1.1 Status Indicator (first column, unlabeled)\nThe first column is an unlabeled vertical colored bar that provides instant visual feedback about each step’s status:\n\nGreen: all test units passed the validation\nLight green (semi-transparent): some test units failed but no thresholds were exceeded\nGray: the ‘warning’ threshold was exceeded\nYellow: the ‘error’ threshold was exceeded\nRed: the ‘critical’ threshold was exceeded\n\nThis visual indicator allows you to quickly scan the report and identify problem areas.\n\n\n4.2.1.2 Step Number (second column, unlabeled)\nThe second column is unlabeled and contains the sequential step number, starting from 1. This number is used when referencing specific steps in other methods like get_step_report(i=2) or when extracting data from specific validation steps.\n\n\n4.2.1.3 TYPE\nThe TYPE column displays the validation method name along with an icon that visually represents the type of validation being performed. The validation method indicates what aspect of data quality is being checked, such as:\n\ncol_vals_gt(): column values greater than\ncol_vals_in_set(): column values in a set\ncol_exists(): column existence check\nrows_distinct(): row uniqueness check\nand many others…\n\nWhen you provide a brief message (via brief=True for auto-generated briefs or brief=\"custom text\" for custom messages), it appears within the TYPE column below the validation method name. These briefs provide human-readable explanations of what each validation step is checking, making the report more accessible to non-technical stakeholders.\n\n# Example showing brief messages in the TYPE column\nvalidation_with_briefs = (\n    pb.Validate(data=data, tbl_name=\"sales_data\")\n    .col_vals_gt(\n        columns=\"value\",\n        value=50,\n        brief=\"Sales values should always exceed the $50 threshold\"\n    )\n    .col_vals_in_set(\n        columns=\"category\",\n        set=[\"A\", \"B\", \"C\"],\n        brief=True  # Auto-generated brief\n    )\n    .interrogate()\n)\n\nvalidation_with_briefs\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:45Polarssales_data\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Sales values should always exceed the $50 threshold\n\n        \n    value\n    50\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Expect that values in category should be in the set of A, B, C.\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nIn the above report, you’ll see the custom brief message appear below the col_vals_gt method name in the first step, and an automatically generated brief below col_vals_in_set in the second step.\n\n\n4.2.1.4 COLUMNS\nThe column(s) being validated in this step. For validation methods that don’t target specific columns (like row_count_match), this will show an em dash (—).\n\n\n4.2.1.5 VALUES\nThe comparison value(s) or criteria used in the validation. For example:\n\nfor col_vals_gt(value=100), this shows 100\nfor col_vals_in_set(set=[\"A\", \"B\", \"C\"]), this shows A | B | C\nfor existence checks, this shows an em dash (—)\n\n\n\n4.2.1.6 TBL\nIcons indicating whether any preprocessing or segmentation was applied:\n\nTable icon: standard validation on the original data\nTransformation icon: preprocessing function was applied via pre=\nSegmentation icon: data was segmented via segments=\n\nThese icons help you understand if you’re validating transformed or segmented data.\n\n\n4.2.1.7 EVAL\nIndicates whether the validation step was evaluated:\n\nCheckmark: step was successfully evaluated\nError icon: an evaluation error occurred (e.g., column not found)\nInactive icon: step was marked as inactive\n\nThis column is crucial for identifying validation steps that couldn’t be executed properly.\n\n\n4.2.1.8 UNITS\nThe number of units tested in this validation step. A ‘test unit’ is the atomic unit being validated, which varies by validation type:\n\nfor column value checks: each cell in the target column(s)\nfor row checks: each row\nfor table checks: typically 1 (the table itself)\n\nThis number is formatted with locale-appropriate thousand separators for readability. Also, since space is limited, values are often abbreviated so a figure like 43,534 will appear as 43.5K.\n\n\n4.2.1.9 PASS\nThe number and fraction of test units that passed the validation, displayed as:\nn_passed\nf_passed\nFor example, the cell with\n8\n0.80\nmeans 8 test units passed out of the total, representing an 80% success rate (though f_passed is always expressed as a fractional value from 0 to 1).\n\n\n4.2.1.10 FAIL\nThe number and fraction of test units that failed the validation, displayed similarly to PASS:\nn_failed\nf_failed\nFor example, the cell with\n2\n0.20\nmeans 2 test units failed, representing a 20% failure rate from a fractional value of 0.20. Note that this fractional f_failed value is what’s used to set failure thresholds for ‘warning’, ‘error’, and ‘critical’ states.\n\n\n4.2.1.11 W, E, C (Warning, Error, Critical)\nThree columns showing whether each threshold level was exceeded for the three different states.\n\nLong dash: threshold wasn’t set for a state\nEmpty colored circle: threshold was set but wasn’t exceeded for a given state\nFilled colored circle: threshold was set and exceeded\n\nIn terms of colors, the ‘warning’ state is gray, the ‘error’ state is yellow, and the ‘critical’ state is red.\nHaving visual indicators makes it easy to identify which validation steps have crossed into warning, error, or critical territory.\n\n\n4.2.1.12 EXT\nIndicates whether failing row data was extracted for this step:\n\nEm dash (—): no extract available\nDownload button: click to download failing rows as CSV\n\nWhen extracts are available, you can download them directly from the report for further analysis or to share with data stewards who need to fix the issues."
  },
  {
    "objectID": "user-guide-pdf.html#understanding-validation-status",
    "href": "user-guide-pdf.html#understanding-validation-status",
    "title": "CLI Reference",
    "section": "4.3 Understanding Validation Status",
    "text": "4.3 Understanding Validation Status\nThe validation report helps you quickly understand the overall status of your data:\n\nAll green status indicators: all validations passed completely\nLight green indicators: minor failures below warning threshold\nGray, yellow, or red indicators: threshold exceedances requiring attention\nError icons in EVAL column: validation steps that couldn’t be evaluated\n\nBy scanning the status indicators column, you can immediately identify which validation steps need attention and prioritize your data quality efforts accordingly."
  },
  {
    "objectID": "user-guide-pdf.html#customizing-the-report-title",
    "href": "user-guide-pdf.html#customizing-the-report-title",
    "title": "CLI Reference",
    "section": "4.4 Customizing the Report Title",
    "text": "4.4 Customizing the Report Title\nYou can customize the validation report’s title using the title= parameter in get_tabular_report(). This is particularly useful when generating multiple reports or when you want to provide more context:\n\n# Default title\nvalidation.get_tabular_report()\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:44Polarssales_data\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Expect that values in value should be &gt; 50.\n\n        \n    value\n    50\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Expect that values in category should be in the set of A, B, C.\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column id exists.\n\n        \n    id\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column value exists.\n\n        \n    value\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\n\n# Use the table name as the title\nvalidation.get_tabular_report(title=\":tbl_name:\")\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    sales_data\n  \n  \n    2025-11-23|00:08:44Polarssales_data\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Expect that values in value should be &gt; 50.\n\n        \n    value\n    50\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Expect that values in category should be in the set of A, B, C.\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column id exists.\n\n        \n    id\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column value exists.\n\n        \n    value\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\n\n# Provide a custom title (supports Markdown)\nvalidation.get_tabular_report(title=\"**Sales Data** Quality Report\")\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Sales Data Quality Report\n\n  \n  \n    2025-11-23|00:08:44Polarssales_data\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Expect that values in value should be &gt; 50.\n\n        \n    value\n    50\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Expect that values in category should be in the set of A, B, C.\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column id exists.\n\n        \n    id\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column value exists.\n\n        \n    value\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\n\n# No title\nvalidation.get_tabular_report(title=\":none:\")\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    \n  \n  \n    2025-11-23|00:08:44Polarssales_data\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Expect that values in value should be &gt; 50.\n\n        \n    value\n    50\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Expect that values in category should be in the set of A, B, C.\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column id exists.\n\n        \n    id\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column value exists.\n\n        \n    value\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe title customization options are:\n\n\":default:\" (default): shows \"Pointblank Validation\"\n\":tbl_name:\": uses the table name from tbl_name= parameter\n\":none:\": hides the title completely\nAny string: custom title text (Markdown is supported)"
  },
  {
    "objectID": "user-guide-pdf.html#customizing-with-great-tables",
    "href": "user-guide-pdf.html#customizing-with-great-tables",
    "title": "CLI Reference",
    "section": "4.5 Customizing with Great Tables",
    "text": "4.5 Customizing with Great Tables\nSince the validation report is a Great Tables object, you can leverage the full power of Great Tables to customize its appearance. This allows you to match your organization’s branding, highlight specific information, or adjust the presentation for different audiences.\n\n4.5.1 Guide to Internal Column Names\nWhen working with Great Tables methods to customize the validation report, you’ll need to use the internal column names rather than the display labels you see in the rendered table. This is because Great Tables operates on the underlying data table structure, where columns have technical names that differ from their user-facing labels.\nFor example, the column labeled \"STEP\" in the report is actually stored internally as \"i\", and the \"TYPE\" column is internally named \"type_upd\". Most Great Tables methods that target specific columns (like tab_style(), cols_width(), cols_hide(), etc.) require these internal names.\nHere’s the complete mapping from display labels to internal column names:\n\nStatus indicator (no label): \"status_color\"\nStep number (no label): \"i\"\nTYPE: \"type_upd\"\nCOLUMNS: \"columns_upd\"\nVALUES: \"values_upd\"\nTBL: \"tbl\"\nEVAL: \"eval\"\nUNITS: \"test_units\"\nPASS: \"pass\"\nFAIL: \"fail\"\nW: \"w_upd\"\nE: \"e_upd\"\nC: \"c_upd\"\nEXT: \"extract_upd\"\n\nAlways use these internal names when calling Great Tables methods. Using the display labels (like \"STEP\" or \"TYPE\") will result in errors since these labels only exist in the rendered output, not in the underlying data structure.\nIn the examples that follow, you’ll see how to use these internal column names to customize various aspects of the validation report.\n\n\n4.5.2 Adding Custom Styling\nYou can apply custom styles to the report table:\n\nfrom great_tables import style, loc\n\n# Get the report as a Great Tables object\nreport = validation.get_tabular_report()\n\n# Add custom styling using internal column names\nreport = (\n    report\n    .tab_style(\n        style=style.fill(color=\"#F0F8FF\"),\n        locations=loc.body(columns=\"i\")  # Internal name for step number\n    )\n    .tab_style(\n        style=style.text(weight=\"bold\"),\n        locations=loc.body(columns=\"type_upd\")  # Internal name for TYPE\n    )\n)\n\nreport\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:44Polarssales_data\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Expect that values in value should be &gt; 50.\n\n        \n    value\n    50\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Expect that values in category should be in the set of A, B, C.\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column id exists.\n\n        \n    id\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column value exists.\n\n        \n    value\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\n\n\n4.5.3 Modifying Column Widths\nAdjust column widths to optimize the layout:\n\nreport = (\n    validation\n    .get_tabular_report()\n    .cols_width(\n        cases={\n            \"status_color\": \"20px\", # Status indicator column\n            \"i\": \"40px\",            # Step number column\n            \"type_upd\": \"170px\",    # TYPE column\n            \"columns_upd\": \"100px\", # COLUMNS column\n        }\n    )\n)\n\nreport\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:44Polarssales_data\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Expect that values in value should be &gt; 50.\n\n        \n    value\n    50\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Expect that values in category should be in the set of A, B, C.\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column id exists.\n\n        \n    id\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column value exists.\n\n        \n    value\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\n\n\n4.5.4 Hiding Columns\nHide specific columns that aren’t relevant for your audience:\n\n# Hide the TBL and EVAL columns for a cleaner presentation (using internal names)\nreport = (\n    validation\n    .get_tabular_report()\n    .cols_hide(columns=[\"tbl\", \"eval\"])  # Use internal column names\n)\n\nreport\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:44Polarssales_data\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Expect that values in value should be &gt; 50.\n\n        \n    value\n    50\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Expect that values in category should be in the set of A, B, C.\n\n        \n    category\n    A, B, C\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column id exists.\n\n        \n    id\n    —\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column value exists.\n\n        \n    value\n    —\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\n\n\n4.5.5 Adding a Source Note\nAdd information about data source or validation context:\n\nreport = (\n    validation\n    .get_tabular_report()\n    .tab_source_note(\n        source_note=\"Data validated on 2025-10-10 | Production database snapshot\"\n    )\n)\n\nreport\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:44Polarssales_data\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Expect that values in value should be &gt; 50.\n\n        \n    value\n    50\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Expect that values in category should be in the set of A, B, C.\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column id exists.\n\n        \n    id\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column value exists.\n\n        \n    value\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    Data validated on 2025-10-10 | Production database snapshot"
  },
  {
    "objectID": "user-guide-pdf.html#exporting-the-report",
    "href": "user-guide-pdf.html#exporting-the-report",
    "title": "CLI Reference",
    "section": "4.6 Exporting the Report",
    "text": "4.6 Exporting the Report\nGreat Tables provides multiple export options for sharing validation reports:\n# Save as a standalone HTML file\nvalidation.get_tabular_report().write_raw_html(\"validation_report.html\")\n\n# Save as a PNG image\nvalidation.get_tabular_report().save(\"validation_report.png\")\n\n# Open in browser\nvalidation.get_tabular_report().show(\"browser\")"
  },
  {
    "objectID": "user-guide-pdf.html#controlling-header-and-footer-display",
    "href": "user-guide-pdf.html#controlling-header-and-footer-display",
    "title": "CLI Reference",
    "section": "4.7 Controlling Header and Footer Display",
    "text": "4.7 Controlling Header and Footer Display\nYou can control whether the header and footer appear in the validation report:\n\n# Hide the footer\nvalidation.get_tabular_report(incl_footer=False)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:08:44Polarssales_data\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Expect that values in value should be &gt; 50.\n\n        \n    value\n    50\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Expect that values in category should be in the set of A, B, C.\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column id exists.\n\n        \n    id\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column value exists.\n\n        \n    value\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\n\n# Hide the header\nvalidation.get_tabular_report(incl_header=False)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Expect that values in value should be &gt; 50.\n\n        \n    value\n    50\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Expect that values in category should be in the set of A, B, C.\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column id exists.\n\n        \n    id\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column value exists.\n\n        \n    value\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\n\n# Hide both\nvalidation.get_tabular_report(incl_header=False, incl_footer=False)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Expect that values in value should be &gt; 50.\n\n        \n    value\n    50\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        Expect that values in category should be in the set of A, B, C.\n\n        \n    category\n    A, B, C\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    80.80\n    20.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column id exists.\n\n        \n    id\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Expect that column value exists.\n\n        \n    value\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nYou can also set these preferences globally using pb.config():\n# Set global preferences\npb.config(report_incl_header=True, report_incl_footer=False)"
  },
  {
    "objectID": "user-guide-pdf.html#best-practices-for-validation-reports",
    "href": "user-guide-pdf.html#best-practices-for-validation-reports",
    "title": "CLI Reference",
    "section": "4.8 Best Practices for Validation Reports",
    "text": "4.8 Best Practices for Validation Reports\nHere are some guidelines for creating effective validation reports:\n\n4.8.0.1 1. Use Descriptive Table Names and Labels\nProvide meaningful names and labels to make reports self-documenting:\nvalidation = pb.Validate(\n    data=sales_df,\n    tbl_name=\"Q3_2025_sales\",\n    label=\"Quarterly sales data validation for financial reporting\"\n)\n\n\n4.8.0.2 2. Add Brief Messages for Stakeholder Reports\nWhen sharing reports with non-technical stakeholders, always include briefs:\n.col_vals_between(\n    columns=\"price\",\n    left=0, right=10000,\n    brief=\"Product prices must be between $0 and $10,000\"\n)\n\n\n4.8.0.3 3. Set Appropriate Thresholds\nConfigure thresholds that align with your data quality requirements:\nvalidation = pb.Validate(\n    data=data,\n    tbl_name=\"customer_data\",\n    thresholds=pb.Thresholds(\n        warning=0.01,  # 1% failure triggers warning\n        error=0.05,    # 5% failure triggers error\n        critical=0.10  # 10% failure triggers critical\n    )\n)\n\n\n4.8.0.4 4. Customize for Your Audience\nTailor the report presentation to your audience:\n\nTechnical teams: include all columns, show preprocessing indicators\nManagement: hide technical columns, emphasize status indicators\nData stewards: include extract download buttons, detailed briefs\n\n\n\n4.8.0.5 5. Combine with Other Reporting Tools\nUse validation reports alongside other Pointblank features:\n\nStep reports: drill down into specific failing steps with get_step_report()\nExtracts: use get_data_extracts() to get all failing data for analysis\nSundered data: use get_sundered_data() to split data into passing/failing sets\n\n\n\n4.8.0.6 6. Archive Reports for Trend Analysis\nSave validation reports over time to track data quality trends:\nfrom datetime import datetime\n\n# Save with timestamp\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nvalidation.get_tabular_report().write_raw_html(f\"validation_report_{timestamp}.html\")"
  },
  {
    "objectID": "user-guide-pdf.html#conclusion-12",
    "href": "user-guide-pdf.html#conclusion-12",
    "title": "CLI Reference",
    "section": "4.9 Conclusion",
    "text": "4.9 Conclusion\nThe validation report is your primary interface for understanding data quality after running a validation. By providing a comprehensive overview of all validation steps, visual status indicators, and detailed statistics, it enables you to:\n\nquickly assess overall data quality across multiple dimensions\nidentify specific validation steps that need attention\ncommunicate data quality status to technical and non-technical stakeholders\ntrack threshold exceedances and their severity levels\naccess failing data through extract downloads\n\nCombined with customization options from Great Tables, you can create reports that perfectly match your organization’s needs and workflows. Whether you’re validating data in an interactive notebook, generating automated quality reports, or presenting findings to stakeholders, the validation report provides the clarity and detail you need to maintain high data quality standards.\nWhile validation reports provide a comprehensive overview of all validation steps, sometimes you need to focus on a specific validation step in greater detail. This is where step reports come in. A step report is a detailed examination of a single validation step, providing in-depth information about the test units that were validated and their pass/fail status.\nStep reports are especially useful when debugging validation failures, investigating problematic data, or communicating detailed findings to colleagues who are responsible for specific data quality issues."
  },
  {
    "objectID": "user-guide-pdf.html#creating-a-step-report",
    "href": "user-guide-pdf.html#creating-a-step-report",
    "title": "CLI Reference",
    "section": "4.10 Creating a Step Report",
    "text": "4.10 Creating a Step Report\nTo create a step report, you first need to run a validation and then use the get_step_report() method, specifying which validation step you want to examine:\n\nimport pointblank as pb\nimport polars as pl\n\n# Sample data as a Polars DataFrame\ndata = pl.DataFrame({\n    \"id\": range(1, 11),\n    \"value\": [10, 20, 3, 35, 50, 2, 70, 8, 20, 4],\n    \"category\": [\"A\", \"B\", \"C\", \"A\", \"D\", \"F\", \"A\", \"E\", \"H\", \"G\"],\n    \"ratio\": [0.5, 0.7, 0.3, 1.2, 0.8, 0.9, 0.4, 1.5, 0.6, 0.2],\n    \"status\": [\"active\", \"active\", \"inactive\", \"active\", \"inactive\",\n               \"active\", \"inactive\", \"active\", \"active\", \"inactive\"]\n})\n\n# Create a validation\nvalidation = (\n    pb.Validate(data=data, tbl_name=\"example_data\")\n    .col_vals_gt(\n        columns=\"value\",\n        value=10\n    )\n    .col_vals_in_set(\n        columns=\"category\",\n        set=[\"A\", \"B\", \"C\"]\n    )\n    .interrogate()\n)\n\n# Get step report for the second validation step (i=2)\nstep_report = validation.get_step_report(i=2)\n\nstep_report\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 2ASSERTION category ∈ {A, B, C}5 / 10 TEST UNIT FAILURES IN COLUMN 3 EXTRACT OF ALL 5 ROWS (WITH TEST UNIT FAILURES IN RED):\n  \n\n  \n  idInt64\n  valueInt64\n  categoryString\n  ratioFloat64\n  statusString\n\n\n\n  \n    5\n    5\n    50\n    D\n    0.8\n    inactive\n  \n  \n    6\n    6\n    2\n    F\n    0.9\n    active\n  \n  \n    8\n    8\n    8\n    E\n    1.5\n    active\n  \n  \n    9\n    9\n    20\n    H\n    0.6\n    active\n  \n  \n    10\n    10\n    4\n    G\n    0.2\n    inactive\n  \n\n\n\n\n\n\n        \n\n\nIn this example, we first create and interrogate a validation object with two steps. We then generate a step report for the second validation step (i=2), which checks if the values in the category column are in the set [\"A\", \"B\", \"C\"].\nNote that step numbers in Pointblank start at 1, matching what you see in the validation report’s STEP column (i.e., not 0-based indexing). So the first step is referred to with i=1, the second step with i=2, and so on."
  },
  {
    "objectID": "user-guide-pdf.html#understanding-step-report-components",
    "href": "user-guide-pdf.html#understanding-step-report-components",
    "title": "CLI Reference",
    "section": "4.11 Understanding Step Report Components",
    "text": "4.11 Understanding Step Report Components\nA step report consists of several key components that provide detailed information about the validation step:\n\nHeader: displays the validation step number, type of validation, and a brief description\nTable Body: presents either the failing rows, a sample of completely passing data, or an expected/actual comparison (for a col_schema_match() step)\n\nThe step report table highlights passing and failing rows, making it easy to identify problematic data points. This is especially useful for diagnosing issues when dealing with large datasets."
  },
  {
    "objectID": "user-guide-pdf.html#different-types-of-step-reports",
    "href": "user-guide-pdf.html#different-types-of-step-reports",
    "title": "CLI Reference",
    "section": "4.12 Different Types of Step Reports",
    "text": "4.12 Different Types of Step Reports\nIt’s important to note that step reports vary in appearance and structure depending on the type of validation method used:\n\nValue-based validations (like col_vals_gt(), col_vals_in_set()): show individual rows that failed validation\nUniqueness checks (rows_distinct()): group together the duplicate records in order of appearance\nSchema validations (col_schema_match()): display column-level information about expected vs. actual data types\n\nAdditionally, step reports for value-based validations and uniqueness checks operate in two distinct modes:\n\nWhen errors are present: The report shows only the failing rows and, for value-based validations, clearly highlights the column under study\nWhen no errors exist: The report header clearly indicates success, and a sample of the data is shown (along with the studied column highlighted, for value-based validations)\n\nThis variation in reporting style allows step reports to effectively communicate the specific type of validation being performed and display relevant information in the most appropriate format. When you’re working with different validation types, expect to see different step report layouts optimized for each context.\n\n4.12.1 Value-Based Validation Step Reports\nValue-based step reports focus on showing individual rows where values in the target column failed the validation check. These reports highlight the specific column being validated and clearly display which values violated the condition.\n\n# Create sample data with some validation failures\ndata = pl.DataFrame({\n    \"id\": range(1, 8),\n    \"value\": [120, 85, 47, 210, 30, 10, 5],\n    \"category\": [\"A\", \"B\", \"C\", \"A\", \"D\", \"B\", \"E\"]\n})\n\n# Create a validation with a value-based check\nvalidation_values = (\n    pb.Validate(data=data, tbl_name=\"sales_data\")\n    .col_vals_gt(\n        columns=\"value\",\n        value=50,\n        brief=\"Sales values should exceed $50\"\n    )\n    .interrogate()\n)\n\n# Display the step report for the value-based validation\nvalidation_values.get_step_report(i=1)\n\n\n\n\n\n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 1ASSERTION value &gt; 504 / 7 TEST UNIT FAILURES IN COLUMN 2 EXTRACT OF ALL 4 ROWS (WITH TEST UNIT FAILURES IN RED):\n  \n\n  \n  idInt64\n  valueInt64\n  categoryString\n\n\n\n  \n    3\n    3\n    47\n    C\n  \n  \n    5\n    5\n    30\n    D\n  \n  \n    6\n    6\n    10\n    B\n  \n  \n    7\n    7\n    5\n    E\n  \n\n\n\n\n\n\n        \n\n\nThis report clearly identifies which rows contain values that don’t meet our threshold, making it easy to investigate these specific data points.\n\n\n4.12.2 Uniqueness Validation Step Reports\nUniqueness checks produce a different type of step report that groups duplicate records together. This format makes it easy to identify patterns in duplicate data.\n\n# Create sample data with some duplicate rows based on the combination of columns\ndata = pl.DataFrame({\n    \"customer_id\": [101, 102, 103, 101, 104, 105, 102],\n    \"order_date\": [\"2023-01-15\", \"2023-01-16\", \"2023-01-16\",\n                   \"2023-01-15\", \"2023-01-17\", \"2023-01-18\", \"2023-01-19\"],\n    \"product\": [\"Laptop\", \"Phone\", \"Tablet\", \"Laptop\",\n                \"Monitor\", \"Keyboard\", \"Headphones\"]\n})\n\n# Create a validation checking for unique customer-product combinations\nvalidation_duplicates = (\n    pb.Validate(data=data, tbl_name=\"order_data\")\n    .rows_distinct(\n        columns_subset=[\"customer_id\", \"product\"],\n        brief=\"Customer should not order the same product twice\"\n    )\n    .interrogate()\n)\n\n# Display the step report for the uniqueness validation\nvalidation_duplicates.get_step_report(i=1)\n\n\n\n\n\n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 1Rows are distinct across a subset of columns2 / 7 TEST UNIT FAILURESEXTRACT OF ALL 2 ROWS:\n  \n\n  \n  customer_idInt64\n  productString\n\n\n\n  \n    1\n    101\n    Laptop\n  \n  \n    4\n    101\n    Laptop\n  \n\n\n\n\n\n\n        \n\n\nThe report organizes duplicate records together, making it easy to see which combinations are repeated and how many times they appear.\n\n\n4.12.3 Schema Validation Step Reports\nSchema validation step reports have a completely different structure, comparing expected versus actual column data types and presence.\n\nschema = pb.Schema(\n    columns=[\n        (\"date_time\", \"timestamp\"),\n        (\"dates\", \"date\"),\n        (\"a\", \"int64\"),\n        (\"b\",),\n        (\"c\",),\n        (\"d\", \"float64\"),\n        (\"e\", [\"bool\", \"boolean\"]),\n        (\"f\", \"str\"),\n    ]\n)\n\nvalidation_schema = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"duckdb\"),\n        tbl_name=\"small_table\",\n        label=\"Step report for a schema check\"\n    )\n    .col_schema_match(schema=schema)\n    .interrogate()\n)\n\n# Display the step report for the schema validation\nvalidation_schema.get_step_report(i=1)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 1 ✗COLUMN SCHEMA MATCHCOMPLETEIN ORDERCOLUMN ≠ columnDTYPE ≠ dtypefloat ≠ float64\n  \n\n  \n    TARGET\n  \n  \n    EXPECTED\n  \n\n\n  \n  COLUMN\n  DATA TYPE\n  \n  COLUMN\n  \n  DATA TYPE\n  \n\n\n\n  \n    1\n    date_time\n    timestamp(6)\n    1\n    date_time\n    ✓\n    timestamp\n    ✗\n  \n  \n    2\n    date\n    date\n    2\n    dates\n    ✗\n    date\n    —\n  \n  \n    3\n    a\n    int64\n    3\n    a\n    ✓\n    int64\n    ✓\n  \n  \n    4\n    b\n    string\n    4\n    b\n    ✓\n    —\n    \n  \n  \n    5\n    c\n    int64\n    5\n    c\n    ✓\n    —\n    \n  \n  \n    6\n    d\n    float64\n    6\n    d\n    ✓\n    float64\n    ✓\n  \n  \n    7\n    e\n    boolean\n    7\n    e\n    ✓\n    bool | boolean\n    ✓\n  \n  \n    8\n    f\n    string\n    8\n    f\n    ✓\n    str\n    ✗\n  \n\n  \n  \n  \n    Supplied Column Schema:[('date_time', 'timestamp'), ('dates', 'date'), ('a', 'int64'), ('b',), ('c',), ('d', 'float64'), ('e', ['bool', 'boolean']), ('f', 'str')]\n  \n\n\n\n\n\n\n        \n\n\nThis report style focuses on comparing the expected schema against the actual table structure, highlighting mismatches in data types or missing/extra columns. The table format makes it easy to see exactly where the schema expectations differ from reality."
  },
  {
    "objectID": "user-guide-pdf.html#customizing-step-reports",
    "href": "user-guide-pdf.html#customizing-step-reports",
    "title": "CLI Reference",
    "section": "4.13 Customizing Step Reports",
    "text": "4.13 Customizing Step Reports\nStep reports can be customized with several parameters to better focus your analysis and tailor the output to your specific needs. The get_step_report() method offers multiple customization options to help you create more effective reports.\nWhen a dataset has many columns, you might want to focus on just those relevant to your analysis. You can create a step report containing only a subset of the columns in the target table:\n\nvalidation.get_step_report(\n    i=2,\n\n    # Only show these columns ---\n    columns_subset=[\"id\", \"category\", \"status\"]\n)\n\n\n\n\n\n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 2ASSERTION category ∈ {A, B, C}5 / 10 TEST UNIT FAILURES IN COLUMN 3 EXTRACT OF ALL 5 ROWS (WITH TEST UNIT FAILURES IN RED):\n  \n\n  \n  idInt64\n  categoryString\n  statusString\n\n\n\n  \n    5\n    5\n    D\n    inactive\n  \n  \n    6\n    6\n    F\n    active\n  \n  \n    8\n    8\n    E\n    active\n  \n  \n    9\n    9\n    H\n    active\n  \n  \n    10\n    10\n    G\n    inactive\n  \n\n\n\n\n\n\n        \n\n\nThis approach makes step reports much easier to interpret by highlighting just the essential columns that help understand the validation failures.\nFor large datasets with many failing rows, you might want to use limit= to set a cap on the number of rows shown in the report:\n\nvalidation.get_step_report(\n    i=2,\n\n    # Only show up to 2 failing rows ---\n    limit=2\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 2ASSERTION category ∈ {A, B, C}5 / 10 TEST UNIT FAILURES IN COLUMN 3 EXTRACT OF FIRST 2 ROWS (WITH TEST UNIT FAILURES IN RED):\n  \n\n  \n  idInt64\n  valueInt64\n  categoryString\n  ratioFloat64\n  statusString\n\n\n\n  \n    5\n    5\n    50\n    D\n    0.8\n    inactive\n  \n  \n    6\n    6\n    2\n    F\n    0.9\n    active\n  \n\n\n\n\n\n\n        \n\n\nThe report header can also be extensively customized to provide more specific context. You can replace the default header with plain text or Markdown formatting:\n\nvalidation.get_step_report(\n    i=2,\n    header=\"Category Values Validation: *Critical Analysis*\"\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Category Values Validation: Critical Analysis\n  \n\n  \n  idInt64\n  valueInt64\n  categoryString\n  ratioFloat64\n  statusString\n\n\n\n  \n    5\n    5\n    50\n    D\n    0.8\n    inactive\n  \n  \n    6\n    6\n    2\n    F\n    0.9\n    active\n  \n  \n    8\n    8\n    8\n    E\n    1.5\n    active\n  \n  \n    9\n    9\n    20\n    H\n    0.6\n    active\n  \n  \n    10\n    10\n    4\n    G\n    0.2\n    inactive\n  \n\n\n\n\n\n\n        \n\n\nFor more advanced header customization, you can use the templating system with the {title} and {details} elements to retain parts of the default header while adding your own content. The {title} template is the default title whereas {details} provides information on the assertion, number of failures, etc. Let’s move away from the default template of {title}{details} and provide a custom title to go with the details text:\n\nvalidation.get_step_report(\n    i=2,\n    header=\"Custom Category Validation Report {details}\"\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Custom Category Validation Report ASSERTION category ∈ {A, B, C}5 / 10 TEST UNIT FAILURES IN COLUMN 3 EXTRACT OF ALL 5 ROWS (WITH TEST UNIT FAILURES IN RED):\n  \n\n  \n  idInt64\n  valueInt64\n  categoryString\n  ratioFloat64\n  statusString\n\n\n\n  \n    5\n    5\n    50\n    D\n    0.8\n    inactive\n  \n  \n    6\n    6\n    2\n    F\n    0.9\n    active\n  \n  \n    8\n    8\n    8\n    E\n    1.5\n    active\n  \n  \n    9\n    9\n    20\n    H\n    0.6\n    active\n  \n  \n    10\n    10\n    4\n    G\n    0.2\n    inactive\n  \n\n\n\n\n\n\n        \n\n\nWe can keep {title} and {details} and add some more context in between the two:\n\nvalidation.get_step_report(\n    i=2,\n    header=(\n        \"{title}&lt;br&gt;\"\n        \"&lt;span style='font-size: 0.75em;'&gt;\"\n        \"This validation is critical for our data quality standards.\"\n        \"&lt;/span&gt;&lt;br&gt;\"\n        \"{details}\"\n    )\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 2This validation is critical for our data quality standards.ASSERTION category ∈ {A, B, C}5 / 10 TEST UNIT FAILURES IN COLUMN 3 EXTRACT OF ALL 5 ROWS (WITH TEST UNIT FAILURES IN RED):\n  \n\n  \n  idInt64\n  valueInt64\n  categoryString\n  ratioFloat64\n  statusString\n\n\n\n  \n    5\n    5\n    50\n    D\n    0.8\n    inactive\n  \n  \n    6\n    6\n    2\n    F\n    0.9\n    active\n  \n  \n    8\n    8\n    8\n    E\n    1.5\n    active\n  \n  \n    9\n    9\n    20\n    H\n    0.6\n    active\n  \n  \n    10\n    10\n    4\n    G\n    0.2\n    inactive\n  \n\n\n\n\n\n\n        \n\n\nYou could always use more HTML and CSS to do a lot of customization:\n\nvalidation.get_step_report(\n    i=2,\n    header=(\n        \"VALIDATION SUMMARY\\n\\n{details}\\n\\n\"\n        \"&lt;hr style='color: lightblue;'&gt;\"\n        \"&lt;div style='font-size: smaller; padding-bottom: 5px; text-transform: uppercase'&gt;\"\n        \"{title}\"\n        \"&lt;/div&gt;\"\n    )\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    VALIDATION SUMMARY\nASSERTION category ∈ {A, B, C}5 / 10 TEST UNIT FAILURES IN COLUMN 3 EXTRACT OF ALL 5 ROWS (WITH TEST UNIT FAILURES IN RED):\nReport for Validation Step 2\n\n  \n\n  \n  idInt64\n  valueInt64\n  categoryString\n  ratioFloat64\n  statusString\n\n\n\n  \n    5\n    5\n    50\n    D\n    0.8\n    inactive\n  \n  \n    6\n    6\n    2\n    F\n    0.9\n    active\n  \n  \n    8\n    8\n    8\n    E\n    1.5\n    active\n  \n  \n    9\n    9\n    20\n    H\n    0.6\n    active\n  \n  \n    10\n    10\n    4\n    G\n    0.2\n    inactive\n  \n\n\n\n\n\n\n        \n\n\nIf you prefer no header at all, simply set header=None:\n\nvalidation.get_step_report(\n    i=2,\n    header=None\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  idInt64\n  valueInt64\n  categoryString\n  ratioFloat64\n  statusString\n\n\n\n  \n    5\n    5\n    50\n    D\n    0.8\n    inactive\n  \n  \n    6\n    6\n    2\n    F\n    0.9\n    active\n  \n  \n    8\n    8\n    8\n    E\n    1.5\n    active\n  \n  \n    9\n    9\n    20\n    H\n    0.6\n    active\n  \n  \n    10\n    10\n    4\n    G\n    0.2\n    inactive\n  \n\n\n\n\n\n\n        \n\n\nThese customization options can be combined to create highly focused reports tailored to specific needs:\n\nvalidation.get_step_report(\n    i=2,\n    columns_subset=[\"id\", \"category\"],\n    header=\"*Category Validation:* Top Issues\",\n    limit=2\n)\n\n\n\n\n\n  \n  \n  \n\n\n\n\n  \n    Category Validation: Top Issues\n  \n\n  \n  idInt64\n  categoryString\n\n\n\n  \n    5\n    5\n    D\n  \n  \n    6\n    6\n    F\n  \n\n\n\n\n\n\n        \n\n\nThrough these customization options, you can craft step reports that effectively communicate the most important information to different audiences. Technical teams might benefit from seeing all columns but with a limited number of examples. Business stakeholders might prefer a focused view with only the most relevant columns. For documentation purposes, custom headers provide important context about what’s being validated.\nRemember that customizing your step reports is about more than aesthetics: it’s about making complex validation information more accessible and actionable for all stakeholders involved in data quality."
  },
  {
    "objectID": "user-guide-pdf.html#using-step-reports-for-data-investigation",
    "href": "user-guide-pdf.html#using-step-reports-for-data-investigation",
    "title": "CLI Reference",
    "section": "4.14 Using Step Reports for Data Investigation",
    "text": "4.14 Using Step Reports for Data Investigation\nStep reports can be powerful tools for investigating data quality issues. Let’s look at a more complex example:\n\n# Create a more complex dataset with multiple issues\ncomplex_data = pl.DataFrame({\n    \"id\": range(1, 11),\n    \"value\": [10, 20, 3, 40, 50, 2, 70, 80, 90, 7],\n    \"ratio\": [0.1, 0.2, 0.3, 1.4, 0.5, 0.6, 0.7, 0.8, 1.2, 0.9],\n    \"category\": [\"A\", \"B\", \"C\", \"A\", \"D\", \"B\", \"A\", \"C\", \"B\", \"E\"]\n})\n\n# Create a validation with multiple steps\nvalidation_complex = (\n    pb.Validate(data=complex_data, tbl_name=\"complex_data\")\n    .col_vals_gt(columns=\"value\", value=10)\n    .col_vals_le(columns=\"ratio\", value=1.0)\n    .col_vals_in_set(columns=\"category\", set=[\"A\", \"B\", \"C\"])\n    .interrogate()\n)\n\n# Get step report for the ratio validation (step 2)\nratio_report = validation_complex.get_step_report(i=2)\n\nratio_report\n\n\n\n\n\n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 2ASSERTION ratio ≤ 1.02 / 10 TEST UNIT FAILURES IN COLUMN 3 EXTRACT OF ALL 2 ROWS (WITH TEST UNIT FAILURES IN RED):\n  \n\n  \n  idInt64\n  valueInt64\n  ratioFloat64\n  categoryString\n\n\n\n  \n    4\n    4\n    40\n    1.4\n    A\n  \n  \n    9\n    9\n    90\n    1.2\n    B\n  \n\n\n\n\n\n\n        \n\n\nIn this example, we’re investigating issues with the ratio column by generating a step report specifically for that validation step. The step report shows exactly which rows have values that exceed our maximum threshold of 1.0."
  },
  {
    "objectID": "user-guide-pdf.html#combining-step-reports-with-extracts",
    "href": "user-guide-pdf.html#combining-step-reports-with-extracts",
    "title": "CLI Reference",
    "section": "4.15 Combining Step Reports with Extracts",
    "text": "4.15 Combining Step Reports with Extracts\nFor more advanced analysis, you can extract the actual data from a step report into a DataFrame:\n\n# Extract the data from the step report\nfailing_ratios = validation_complex.get_data_extracts(i=2)\n\nfailing_ratios\n\n{2: shape: (2, 5)\n ┌───────────┬─────┬───────┬───────┬──────────┐\n │ _row_num_ ┆ id  ┆ value ┆ ratio ┆ category │\n │ ---       ┆ --- ┆ ---   ┆ ---   ┆ ---      │\n │ u32       ┆ i64 ┆ i64   ┆ f64   ┆ str      │\n ╞═══════════╪═════╪═══════╪═══════╪══════════╡\n │ 4         ┆ 4   ┆ 40    ┆ 1.4   ┆ A        │\n │ 9         ┆ 9   ┆ 90    ┆ 1.2   ┆ B        │\n └───────────┴─────┴───────┴───────┴──────────┘}\n\n\nThis extracts the failing rows from the validation step, which you can then further analyze or fix as needed. Note that the parameter i=2 corresponds directly to the step number shown in the validation report; it’s the same numbering system used for get_step_report().\nThese extracts are particularly valuable for analysts who need to:\n\nperform additional calculations on problematic data\nfeed failing records into correction pipelines\ncreate visualizations of data patterns that led to validation failures\nexport problem records to share with data owners\n\nIt’s worth noting that the validation report itself includes export buttons on the far right of each row that allow you to download CSV files of the failing data directly. This serves as a convenient delivery mechanism for sharing extracts with colleagues who may not be working in Python, making the validation report not just a visual tool but also a practical means of distributing problematic data for further investigation."
  },
  {
    "objectID": "user-guide-pdf.html#step-reports-with-segmented-data",
    "href": "user-guide-pdf.html#step-reports-with-segmented-data",
    "title": "CLI Reference",
    "section": "4.16 Step Reports with Segmented Data",
    "text": "4.16 Step Reports with Segmented Data\nWhen working with segmented validation, step reports become even more valuable as they allow you to investigate issues within specific segments:\n\n# Create data with different regions\nsegmented_data = pl.DataFrame({\n    \"id\": range(1, 10),\n    \"value\": [10, 20, 3, 40, 50, 2, 6, 8, 60],\n    \"region\": [\"North\", \"North\", \"South\", \"South\", \"East\", \"East\", \"West\", \"West\", \"West\"]\n})\n\n# Create a validation with segments\nsegmented_validation = (\n    pb.Validate(data=segmented_data, tbl_name=\"regional_data\")\n    .col_vals_gt(\n        columns=\"value\",\n        value=10,\n        segments=\"region\"  # Segment by region\n    )\n    .interrogate()\n)\n\n# Get step report for a specific segment (the 'West' region)\n# For segmented validations, each segment gets its own step number\nnorth_report = segmented_validation.get_step_report(i=4)\n\nnorth_report\n\n\n\n\n\n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 4ASSERTION value &gt; 102 / 3 TEST UNIT FAILURES IN COLUMN 2 EXTRACT OF ALL 2 ROWS (WITH TEST UNIT FAILURES IN RED):\n  \n\n  \n  idInt64\n  valueInt64\n  regionString\n\n\n\n  \n    1\n    7\n    6\n    West\n  \n  \n    2\n    8\n    8\n    West\n  \n\n\n\n\n\n\n        \n\n\nFor segmented validations, each segment is treated as a separate validation step with its own step number. This allows you to investigate issues specific to each data segment using the appropriate step number from the validation report."
  },
  {
    "objectID": "user-guide-pdf.html#best-practices-for-using-step-reports",
    "href": "user-guide-pdf.html#best-practices-for-using-step-reports",
    "title": "CLI Reference",
    "section": "4.17 Best Practices for Using Step Reports",
    "text": "4.17 Best Practices for Using Step Reports\nHere are some guidelines for effectively using step reports in your data validation workflow:\n\nGenerate step reports selectively: create reports only for steps that require detailed investigation rather than for all steps\nUse the limit= parameter for large datasets: when working with large datasets, focus only on a subset of failing rows to avoid information overload\nShare specific step reports with stakeholders: when collaborating with domain experts, share relevant step reports to help them understand and address specific data quality issues (and customize the header to improve clarity)\nCombine with extracts for deeper analysis: use the get_data_extracts() method to extract the failing rows for further analysis or correction\nDocument findings from step reports: when you discover patterns or insights from step reports, document them to inform future data quality improvements\n\nRemember that step reports are most valuable when used strategically as part of a broader data quality framework. By following these best practices, you can use step reports not just for troubleshooting, but to develop a deeper understanding of your data’s characteristics and quality patterns over time. This approach transforms step reports from simple debugging tools into strategic assets for continuous data quality improvement."
  },
  {
    "objectID": "user-guide-pdf.html#conclusion-13",
    "href": "user-guide-pdf.html#conclusion-13",
    "title": "CLI Reference",
    "section": "4.18 Conclusion",
    "text": "4.18 Conclusion\nStep reports provide a focused lens into specific validation steps, allowing you to investigate data quality issues in detail. By generating targeted reports for specific validation steps, you can:\n\npinpoint exactly which data points are causing validation failures\ncommunicate specific issues to relevant stakeholders\ngather insights that might be missed in the aggregate validation report\ntrack improvements in specific aspects of data quality over time\n\nWhether you’re debugging validation failures, investigating edge cases, or communicating specific data quality issues to colleagues, step reports can give you the detailed information you need to understand and resolve data quality problems effectively.\nWhen validating data, identifying exactly which rows failed is critical for diagnosing and resolving data quality issues. This is where data extracts come in. Data extracts consist of target table rows containing at least one cell that failed validation. While the validation report provides an overview of pass/fail statistics, data extracts give you the actual problematic records for deeper investigation.\nThis article will cover:\n\nwhich validation methods collect data extracts\nmultiple ways to access and work with data extracts\npractical examples of using extracts for data quality improvement\nadvanced techniques for analyzing extract patterns"
  },
  {
    "objectID": "user-guide-pdf.html#the-validation-methods-that-work-with-data-extracts",
    "href": "user-guide-pdf.html#the-validation-methods-that-work-with-data-extracts",
    "title": "CLI Reference",
    "section": "4.19 The Validation Methods that Work with Data Extracts",
    "text": "4.19 The Validation Methods that Work with Data Extracts\nThe following validation methods operate on column values and will have rows extracted when there are failing test units in those rows:\n\ncol_vals_gt()\ncol_vals_lt()\ncol_vals_ge()\ncol_vals_le()\ncol_vals_eq()\ncol_vals_ne()\ncol_vals_between()\ncol_vals_outside()\ncol_vals_in_set()\ncol_vals_not_in_set()\ncol_vals_null()\ncol_vals_not_null()\ncol_vals_regex()\ncol_vals_expr()\nconjointly()\n\nThese row-based validation methods will also have rows extracted should there be failing rows:\n\nrows_distinct()\nrows_complete()\n\nNote that some validation methods like col_exists() and col_schema_match() don’t generate data extracts because they validate structural aspects of the table rather than checking column values."
  },
  {
    "objectID": "user-guide-pdf.html#accessing-data-extracts",
    "href": "user-guide-pdf.html#accessing-data-extracts",
    "title": "CLI Reference",
    "section": "4.20 Accessing Data Extracts",
    "text": "4.20 Accessing Data Extracts\nThere are three primary ways to access data extracts in Pointblank:\n\nthe CSV buttons in validation reports\nthrough the get_data_extracts() method\ninspecting a subset of failed rows in step reports\n\nLet’s explore each approach using examples.\n\n4.20.1 CSV Data from Validation Reports\nData extracts are embedded within validation report tables. Let’s look at an example, using the small_table dataset, where data extracts are collected in a single validation step due to failing test units:\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .col_vals_lt( columns=\"d\", value=3000)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    d\n    3000\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    90.69\n    40.31\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe single validation step checks whether values in d are less than 3000. Within that column, values range from 108.34 to 9999.99 so it makes sense that we can see 4 failing test units in the FAIL column.\nIf you look at the far right of the validation report you’ll find there’s a CSV button. Pressing it initiates the download of a CSV file, and that file contains the data extract for this validation step. The CSV button only appears when:\n\nthere is a non-zero number of failing test units\nthe validation step is based on the use of a column-value or a row-based validation method (the methods outlined in the section entitled The Validation Methods that Work with Data Extracts)\n\nAccess to CSV data for the test unit errors is useful when the validation report is shared with other data quality stakeholders, since it is easily accessible and doesn’t require further use of Pointblank. The stakeholder can simply open the downloaded CSV in their preferred spreadsheet software, import it into a different analysis environment like R or Julia, or process it with any tool that supports CSV files. This cross-platform compatibility makes the CSV export particularly valuable in mixed-language data teams where different members might be working with different tools.\n\n\n4.20.2 get_data_extracts()\nFor programmatic access to data extracts, Pointblank provides the get_data_extracts() method. This allows you to work with extract data directly in your Python workflow:\n\n# Get data extracts from step 1\nextract_1 = validation.get_data_extracts(i=1, frame=True)\n\nextract_1\n\n\nshape: (4, 9)_row_num_date_timedateabcdefu32datetime[μs]datei64stri64f64boolstr12016-01-04 11:00:002016-01-042\"1-bcd-345\"33423.29true\"high\"22016-01-04 00:32:002016-01-043\"5-egh-163\"89999.99true\"low\"42016-01-06 17:23:002016-01-062\"5-jdo-903\"null3892.4false\"mid\"62016-01-11 06:15:002016-01-114\"2-dhe-923\"43291.03true\"mid\"\n\n\nThe extracted table is of the same type (a Polars DataFrame) as the target table. Previously we used load_dataset() with the tbl_type=\"polars\" option to fetch the dataset in that form.\nNote these important details about using get_data_extracts():\n\nthe parameter i=1 corresponds to the step number shown in the validation report (1-indexed, not 0-indexed)\nsetting frame=True returns the data as a DataFrame rather than a dictionary (only works when i is a single integer)\nthe extract includes all columns from the original data, not just the column being validated\nan additional _row_num_ column is added to identify the original row positions\n\n\n\n4.20.3 Step Reports\nStep reports provide another way to access and visualize failing data. When you generate a step report for a validation step that has failing rows, those failing rows are displayed directly in the report:\n\n# Get a step report for the first validation step\nstep_report = validation.get_step_report(i=1)\n\nstep_report\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 1ASSERTION d &lt; 30004 / 13 TEST UNIT FAILURES IN COLUMN 6 EXTRACT OF ALL 4 ROWS (WITH TEST UNIT FAILURES IN RED):\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    None\n    3892.4\n    False\n    mid\n  \n  \n    6\n    2016-01-11 06:15:00\n    2016-01-11\n    4\n    2-dhe-923\n    4\n    3291.03\n    True\n    mid\n  \n\n\n\n\n\n\n        \n\n\nStep reports offer several advantages for working with data extracts as they:\n\nprovide immediate visual context by highlighting the specific column being validated\nformat the data for better readability, especially useful when sharing results with colleagues\ninclude additional metadata about the validation step and failure statistics\n\nFor steps with many failures, you can customize how many rows to display:\n\n# Limit to just 2 rows of failing data\nlimited_report = validation.get_step_report(i=1, limit=2)\n\nlimited_report\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 1ASSERTION d &lt; 30004 / 13 TEST UNIT FAILURES IN COLUMN 6 EXTRACT OF FIRST 2 ROWS (WITH TEST UNIT FAILURES IN RED):\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n\n\n\n\n\n\n        \n\n\nStep reports are particularly valuable when you want to quickly inspect the failing data without extracting it into a separate DataFrame. They provide a bridge between the high-level validation report and the detailed data extracts."
  },
  {
    "objectID": "user-guide-pdf.html#viewing-data-extracts-with-preview",
    "href": "user-guide-pdf.html#viewing-data-extracts-with-preview",
    "title": "CLI Reference",
    "section": "4.21 Viewing Data Extracts with preview()",
    "text": "4.21 Viewing Data Extracts with preview()\nTo get a consistent HTML representation of any data extract (regardless of the table type), we can use the preview() function:\n\npb.preview(data=extract_1)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows4Columns9\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    None\n    3892.4\n    False\n    mid\n  \n  \n    6\n    2016-01-11 06:15:00\n    2016-01-11\n    4\n    2-dhe-923\n    4\n    3291.03\n    True\n    mid\n  \n\n\n\n\n\n\n        \n\n\nThe view is optimized for readability, with column names and data types displayed in a compact format. Notice that the _row_num_ column is now part of the table stub and doesn’t steal focus from the table’s original columns.\nThe preview() function is designed to provide the head and tail (5 rows each) of the table so very large extracts won’t overflow the display."
  },
  {
    "objectID": "user-guide-pdf.html#working-with-multiple-validation-steps",
    "href": "user-guide-pdf.html#working-with-multiple-validation-steps",
    "title": "CLI Reference",
    "section": "4.22 Working with Multiple Validation Steps",
    "text": "4.22 Working with Multiple Validation Steps\nWhen validating data with multiple steps, you can extract failing rows from any step or combine extracts from multiple steps:\n\n# Create a validation with multiple steps\nmulti_validation = (\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n    .col_vals_gt(columns=\"a\", value=3)                                  # Step 1\n    .col_vals_lt(columns=\"d\", value=3000)                               # Step 2\n    .col_vals_regex(columns=\"b\", pattern=\"^[0-9]-[a-z]{3}-[0-9]{3}$\")   # Step 3\n    .interrogate()\n)\n\nmulti_validation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    a\n    3\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    60.46\n    70.54\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    d\n    3000\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    90.69\n    40.31\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    b\n    ^[0-9]-[a-z]{3}-[0-9]{3}$\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\n\n4.22.1 Extracting Data from a Specific Step\nYou can access extracts from any specific validation step:\n\n# Get extracts from step 2 (`d &lt; 3000` validation)\nless_than_failures = multi_validation.get_data_extracts(i=2, frame=True)\n\nless_than_failures\n\n\nshape: (4, 9)_row_num_date_timedateabcdefu32datetime[μs]datei64stri64f64boolstr12016-01-04 11:00:002016-01-042\"1-bcd-345\"33423.29true\"high\"22016-01-04 00:32:002016-01-043\"5-egh-163\"89999.99true\"low\"42016-01-06 17:23:002016-01-062\"5-jdo-903\"null3892.4false\"mid\"62016-01-11 06:15:002016-01-114\"2-dhe-923\"43291.03true\"mid\"\n\n\nUsing frame=True means that returned value will be a DataFrame (not a dictionary that contains a single DataFrame).\nIf a step has no failing rows, an empty DataFrame will be returned:\n\n# Get extracts from step 3 (regex check)\nregex_failures = multi_validation.get_data_extracts(i=3, frame=True)\n\nregex_failures\n\n\nshape: (0, 9)_row_num_date_timedateabcdefu32datetime[μs]datei64stri64f64boolstr\n\n\n\n\n4.22.2 Getting All Extracts at Once\nTo retrieve extracts from all steps with failures in one command:\n\n# Get all extracts ()\nall_extracts = multi_validation.get_data_extracts()\n\n# Display the step numbers that have extracts\nprint(f\"Steps with data extracts: {list(all_extracts.keys())}\")\n\nSteps with data extracts: [1, 2, 3]\n\n\nA dictionary of DataFrames is returned and only steps with failures will appear in this dictionary.\n\n\n4.22.3 Getting Specific Extracts\nYou can also retrieve data extracts from several specified steps as a dictionary:\n\n# Get extracts from steps 1 and 2 as a dictionary\nextract_dict = multi_validation.get_data_extracts(i=[1, 2])\n\n# The keys are the step numbers\nprint(f\"Dictionary keys: {list(extract_dict.keys())}\")\n\n# Get the number of failing rows in each extract\nfor step, extract in extract_dict.items():\n    print(f\"Step {step}: {len(extract)} failing rows\")\n\nDictionary keys: [1, 2]\nStep 1: 7 failing rows\nStep 2: 4 failing rows\n\n\nNote that frame=True cannot be used when retrieving multiple extracts."
  },
  {
    "objectID": "user-guide-pdf.html#applications-of-data-extracts",
    "href": "user-guide-pdf.html#applications-of-data-extracts",
    "title": "CLI Reference",
    "section": "4.23 Applications of Data Extracts",
    "text": "4.23 Applications of Data Extracts\nOnce you have extracted the failing data, there are numerous ways to analyze and use this information to improve data quality. Let’s explore some practical applications.\n\n4.23.1 Finding Patterns Across Validation Steps\nYou can analyze patterns across different validation steps by combining extracts:\n\n# Get a consolidated view of all rows that failed any validation\nall_failure_rows = set()\nfor step, extract in all_extracts.items():\n    if len(extract) &gt; 0:\n        all_failure_rows.update(extract[\"_row_num_\"])\n\nprint(f\"Total unique rows with failures: {len(all_failure_rows)}\")\nprint(f\"Row numbers with failures: {sorted(all_failure_rows)}\")\n\nTotal unique rows with failures: 8\nRow numbers with failures: [1, 2, 4, 6, 9, 10, 12, 13]\n\n\n\n\n4.23.2 Identifying Rows with Multiple Failures\nYou might want to find rows that failed multiple validation checks, as these often represent more serious data quality issues:\n\n# Get row numbers from each extract\nstep1_rows = set(multi_validation.get_data_extracts(i=1, frame=True)[\"_row_num_\"])\nstep2_rows = set(multi_validation.get_data_extracts(i=2, frame=True)[\"_row_num_\"])\n\n# Find rows that failed both validations\ncommon_failures = step1_rows.intersection(step2_rows)\nprint(f\"Rows failing both step 1 and step 2: {common_failures}\")\n\nRows failing both step 1 and step 2: {1, 2, 4}\n\n\n\n\n4.23.3 Statistical Analysis of Failing Values\nOnce you have data extracts, you can perform statistical analysis to identify patterns in the failing data:\n\n# Get extracts from step 2\nd_value_failures = multi_validation.get_data_extracts(i=2, frame=True)\n\n# Basic statistical analysis of the failing values\nif len(d_value_failures) &gt; 0:\n    print(f\"Min failing value: {d_value_failures['d'].min()}\")\n    print(f\"Max failing value: {d_value_failures['d'].max()}\")\n    print(f\"Mean failing value: {d_value_failures['d'].mean()}\")\n\nMin failing value: 3291.03\nMax failing value: 9999.99\nMean failing value: 5151.6775\n\n\nThese analysis techniques help you thoroughly investigate data quality issues by examining failing data from multiple perspectives. Rather than treating failures as isolated incidents, you can identify patterns that might indicate systematic problems in your data pipeline.\n\n\n4.23.4 Detailed Analysis with col_summary_tbl()\nFor a more comprehensive view of the statistical properties of your extract data, you can use the col_summary_tbl() function:\n\n# Get extracts from step 2\nd_value_failures = multi_validation.get_data_extracts(i=2, frame=True)\n\n# Generate a comprehensive statistical summary of the failing data\npb.col_summary_tbl(d_value_failures)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows4Columns9\n  \n\n  \n  Column\n  NA\n  UQ\n  Mean\n  SD\n  Min\n  P5\n  Q1\n  Med\n  Q3\n  P95\n  Max\n  IQR\n\n\n\n  \n    \n    numeric\n    \n        \n            \n            \n                \n            \n        \n    \n\n    _row_num_UInt32\n    00\n    41\n    3.25\n    2.22\n    1\n    1.01\n    1.75\n    3\n    4.5\n    5.7\n    6\n    2.75\n  \n  \n    \n    date\n    \n        \n            \n            \n                \n            \n        \n    \n\n    date_timeDatetime(time_unit='us', time_zone=None)\n    00\n    41\n    -\n    -\n    20160104 00:32:00\n    -\n    -\n    -\n    -\n    -\n    20160111 06:15:00\n    -\n  \n  \n    \n    date\n    \n        \n            \n            \n                \n            \n        \n    \n\n    dateDate\n    00\n    30.75\n    -\n    -\n    20160104\n    -\n    -\n    -\n    -\n    -\n    20160111\n    -\n  \n  \n    \n    numeric\n    \n        \n            \n            \n                \n            \n        \n    \n\n    aInt64\n    00\n    30.75\n    2.75\n    0.96\n    2\n    2\n    2\n    2.5\n    3.25\n    3.85\n    4\n    1.25\n  \n  \n    \n    string\n    \n        \n            \n            \n                \n            \n        \n    \n\n    bString\n    00\n    41\n    9\n    0\n    9\n    9\n    9\n    9\n    9\n    9\n    9\n    0\n  \n  \n    \n    numeric\n    \n        \n            \n            \n                \n            \n        \n    \n\n    cInt64\n    10.25\n    41\n    5\n    2.65\n    3\n    3.01\n    3.5\n    4\n    6\n    7.6\n    8\n    2.5\n  \n  \n    \n    numeric\n    \n        \n            \n            \n                \n            \n        \n    \n\n    dFloat64\n    00\n    41\n    5,151.68\n    3,242.49\n    3291.03\n    3,293.01\n    3,390.22\n    3,657.85\n    5,419.3\n    9,083.85\n    9999.99\n    2,029.07\n  \n  \n    \n    boolean\n    \n        \n            \n            \n                \n            \n            \n                \n            \n            \n        \n    \n\n    eBoolean\n    00\n    T0.75F0.25\n    -\n    -\n    -\n    -\n    -\n    -\n    -\n    -\n    -\n    -\n  \n  \n    \n    string\n    \n        \n            \n            \n                \n            \n        \n    \n\n    fString\n    00\n    30.75\n    3.25\n    0.5\n    3\n    3\n    3\n    3\n    3.25\n    3.85\n    4\n    0.25\n  \n\n  \n  \n  \n    String columns statistics regard the string's length.\n  \n\n\n\n\n\n\n        \n\n\nThis statistical overview provides:\n\na count of values (including missing values)\ntype information for each column\ndistribution metrics like min, max, mean, and quartiles for numeric columns\nfrequency of common values for categorical columns\nmissing value counts and proportions\n\nUsing col_summary_tbl() on data extracts lets you quickly understand the characteristics of failing data without writing custom analysis code. This approach is particularly valuable when:\n\nYou need to understand the statistical properties of failing records\nYou want to compare distributions of failing vs passing data\nYou’re looking for anomalies or unexpected patterns within the failing rows\n\nFor example, if values failing a validation check are concentrated at certain quantiles or have an unusual distribution shape, this might indicate a systematic data collection or processing issue rather than random errors."
  },
  {
    "objectID": "user-guide-pdf.html#using-extracts-for-data-quality-improvement",
    "href": "user-guide-pdf.html#using-extracts-for-data-quality-improvement",
    "title": "CLI Reference",
    "section": "4.24 Using Extracts for Data Quality Improvement",
    "text": "4.24 Using Extracts for Data Quality Improvement\nData extracts are especially valuable for:\n\nRoot Cause Analysis: examining the full context of failing rows to understand why they failed\nData Cleaning: creating targeted cleanup scripts that focus only on problematic records\nFeedback Loops: sharing specific examples with data providers to improve upstream quality\nPattern Recognition: identifying systemic issues by analyzing groups of failing records\n\nHere’s an example of using extracts to create a corrective action plan:\n\nimport polars as pl\n\n# Create a new sample of an extract DF\nsample_extract = pl.DataFrame({\n    \"id\": range(1, 11),\n    \"value\": [3500, 4200, 3800, 9800, 5500, 7200, 8300, 4100, 7600, 3200],\n    \"category\": [\"A\", \"B\", \"A\", \"C\", \"B\", \"A\", \"C\", \"B\", \"A\", \"B\"],\n    \"region\": [\n        \"South\", \"South\", \"North\", \"East\", \"South\",\n        \"South\", \"East\", \"South\", \"West\", \"South\"\n    ]\n})\n\n# Identify which regions have the most failures\nregion_counts = (\n    sample_extract\n    .group_by(\"region\")\n    .agg(pl.len().alias(\"failure_count\"))\n    .sort(\"failure_count\", descending=True)\n)\n\nregion_counts\n\n\nshape: (4, 2)regionfailure_countstru32\"South\"6\"East\"2\"North\"1\"West\"1\n\n\nAnalysis shows that 6 out of 10 failing records (60%) are from the \"South\" region, making it the highest priority area for data quality investigation. This suggests a potential systemic issue with data collection or processing in that specific region."
  },
  {
    "objectID": "user-guide-pdf.html#best-practices-for-working-with-data-extracts",
    "href": "user-guide-pdf.html#best-practices-for-working-with-data-extracts",
    "title": "CLI Reference",
    "section": "4.25 Best Practices for Working with Data Extracts",
    "text": "4.25 Best Practices for Working with Data Extracts\nWhen incorporating data extracts into your data quality workflow:\n\nUse extracts for investigation, not just reporting: the real value is in the insights you gain from analyzing the problematic data\nCombine with other Pointblank features: data extracts work well with step reports and can inform threshold settings for future validations\nConsider sampling for very large datasets: if your extracts contain thousands of rows, focus your investigation on a representative sample\nLook beyond individual validation steps: cross-reference extracts from different steps to identify complex issues that span multiple validation rules\nDocument patterns in failing data: record and share insights about common failure modes to build organizational knowledge about data quality issues.\n\nBy integrating these practices into your data validation workflow, you’ll transform data extracts from simple error lists into powerful diagnostic tools. The most successful data quality initiatives treat extracts as the starting point for investigation rather than the end result of validation. When systematically analyzed and documented, patterns in failing data can reveal underlying issues in data systems, collection methods, or business processes that might otherwise remain hidden. Remember that the ultimate goal isn’t just to identify problematic records, but to use that information to implement targeted improvements that prevent similar issues from occurring in the future."
  },
  {
    "objectID": "user-guide-pdf.html#conclusion-14",
    "href": "user-guide-pdf.html#conclusion-14",
    "title": "CLI Reference",
    "section": "4.26 Conclusion",
    "text": "4.26 Conclusion\nData extracts bridge the gap between high-level validation statistics and the detailed context needed to fix data quality issues. By providing access to the actual failing records, Pointblank enables you to:\n\npinpoint exactly which data points caused validation failures\nunderstand the full context around problematic values\ndevelop targeted strategies for data cleanup and quality improvement\ncommunicate specific examples to stakeholders\n\nWhether you’re accessing extracts through CSV downloads, the get_data_extracts() method, or step reports, this feature provides the detail needed to move from identifying problems to implementing solutions.\nSundering data? First off, let’s get the correct meaning across here. Sundering is really just splitting, dividing, cutting into two pieces. And it’s a useful thing we can do in Pointblank to any data that we are validating. When you interrogate the data, you learn about which rows have test failures within them. With more validation steps, we get an even better picture of this simply by virtue of more testing.\nThe power of sundering lies in its ability to separate your data into two distinct categories:\n\nrows that pass all validation checks (clean data)\nrows that fail one or more validation checks (problematic data)\n\nThis approach allows you to:\n\nfocus your analysis on clean, reliable data\nisolate problematic records for investigation or correction\ncreate pipelines that handle good and bad data differently\n\nLet’s use the small_table in our examples to show just how sundering is done. Here’s that table:\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows13Columns8\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05\n    6\n    8-kdg-938\n    3\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    None\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09\n    8\n    3-ldm-038\n    7\n    283.94\n    True\n    low\n  \n  \n    6\n    2016-01-11 06:15:00\n    2016-01-11\n    4\n    2-dhe-923\n    4\n    3291.03\n    True\n    mid\n  \n  \n    7\n    2016-01-15 18:46:00\n    2016-01-15\n    7\n    1-knw-093\n    3\n    843.34\n    True\n    high\n  \n  \n    8\n    2016-01-17 11:27:00\n    2016-01-17\n    4\n    5-boe-639\n    2\n    1035.64\n    False\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26\n    4\n    2-dmx-010\n    7\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28\n    2\n    7-dmx-010\n    8\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30\n    1\n    3-dka-303\n    None\n    2230.09\n    True\n    high"
  },
  {
    "objectID": "user-guide-pdf.html#a-simple-example-where-data-is-torn-asunder",
    "href": "user-guide-pdf.html#a-simple-example-where-data-is-torn-asunder",
    "title": "CLI Reference",
    "section": "4.27 A Simple Example Where Data is Torn Asunder",
    "text": "4.27 A Simple Example Where Data is Torn Asunder\nWe’ll begin with a very simple validation plan, having only a single step. There will be failing test units here.\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\"))\n    .col_vals_ge(columns=\"d\", value=1000)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_ge\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_ge()\n        \n        \n        \n    d\n    1000\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    70.54\n    60.46\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nWe see six failing test units in FAIL column of the above validation report table. There is a data extract (collection of failing rows) available. Let’s use the get_data_extracts() method to have a look at it.\n\nvalidation.get_data_extracts(i=1, frame=True)\n\n\nshape: (6, 9)_row_num_date_timedateabcdefu32datetime[μs]datei64stri64f64boolstr52016-01-09 12:36:002016-01-098\"3-ldm-038\"7283.94true\"low\"72016-01-15 18:46:002016-01-157\"1-knw-093\"3843.34true\"high\"92016-01-20 04:30:002016-01-203\"5-bce-642\"9837.93false\"high\"102016-01-20 04:30:002016-01-203\"5-bce-642\"9837.93false\"high\"112016-01-26 20:07:002016-01-264\"2-dmx-010\"7833.98true\"low\"122016-01-28 02:51:002016-01-282\"7-dmx-010\"8108.34false\"low\"\n\n\nThis is six rows of data that had failing test units in column d. Indeed we can see that all values in that column are less than 1000 (and we asserted that values should be greater than or equal to 1000). This is the ‘bad’ data, if you will. Using the get_sundered_data() method, we get the ‘good’ part:\n\nvalidation.get_sundered_data()\n\n\nshape: (7, 8)date_timedateabcdefdatetime[μs]datei64stri64f64boolstr2016-01-04 11:00:002016-01-042\"1-bcd-345\"33423.29true\"high\"2016-01-04 00:32:002016-01-043\"5-egh-163\"89999.99true\"low\"2016-01-05 13:32:002016-01-056\"8-kdg-938\"32343.23true\"high\"2016-01-06 17:23:002016-01-062\"5-jdo-903\"null3892.4false\"mid\"2016-01-11 06:15:002016-01-114\"2-dhe-923\"43291.03true\"mid\"2016-01-17 11:27:002016-01-174\"5-boe-639\"21035.64false\"low\"2016-01-30 11:23:002016-01-301\"3-dka-303\"null2230.09true\"high\"\n\n\nThis is a Polars DataFrame of seven rows. All values in d were passing test units (i.e., fulfilled the expectation outlined in the validation step) and, in many ways, this is like a ‘good extract’.\nYou can always collect the failing rows with get_sundered_data() by using the type=\"fail\" option. Let’s try that here:\n\nvalidation.get_sundered_data(type=\"fail\")\n\n\nshape: (6, 8)date_timedateabcdefdatetime[μs]datei64stri64f64boolstr2016-01-09 12:36:002016-01-098\"3-ldm-038\"7283.94true\"low\"2016-01-15 18:46:002016-01-157\"1-knw-093\"3843.34true\"high\"2016-01-20 04:30:002016-01-203\"5-bce-642\"9837.93false\"high\"2016-01-20 04:30:002016-01-203\"5-bce-642\"9837.93false\"high\"2016-01-26 20:07:002016-01-264\"2-dmx-010\"7833.98true\"low\"2016-01-28 02:51:002016-01-282\"7-dmx-010\"8108.34false\"low\"\n\n\nIt gives us the same rows as in the DataFrame obtained from using validation.get_data_extracts(i=1, frame=True). Two important things to know about get_sundered_data() are that the table rows returned from type=pass (the default) and type=fail are:\n\nthe sum of rows across these returned tables will be equal to that of the original table\nthe rows in each split table are mutually exclusive (i.e., you won’t find the same row in both)\n\nYou can think of sundered data as a filtered version of the original dataset based on validation results. While the simple example illustrates how this process works on a basic level, the value of the method is better seen in a slightly more complex example."
  },
  {
    "objectID": "user-guide-pdf.html#using-get_sundered_data-with-a-more-comprehensive-validation",
    "href": "user-guide-pdf.html#using-get_sundered_data-with-a-more-comprehensive-validation",
    "title": "CLI Reference",
    "section": "4.28 Using get_sundered_data() with a More Comprehensive Validation",
    "text": "4.28 Using get_sundered_data() with a More Comprehensive Validation\nThe previous example used exactly one validation step. You’re likely to use more than that in standard practice so let’s see how get_sundered_data() works in those common situations. Here’s a validation with three steps:\n\nvalidation_2 = (\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\"))\n    .col_vals_ge(\n        columns=\"d\",\n        value=1000\n    )\n    .col_vals_not_null(columns=\"c\")\n    .col_vals_gt(\n        columns=\"a\",\n        value=2\n    )\n    .interrogate()\n)\n\nvalidation_2\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_ge\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_ge()\n        \n        \n        \n    d\n    1000\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    70.54\n    60.46\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    c\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    3\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    a\n    2\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    90.69\n    40.31\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThere are quite a few failures here across the three validation steps. In the FAIL column of the validation report table, there are 12 failing test units if we were to tally them up. So if the input table has 13 rows in total, does this mean there would be one row in the table returned by get_sundered_data()? Not so:\n\nvalidation_2.get_sundered_data()\n\n\nshape: (4, 8)date_timedateabcdefdatetime[μs]datei64stri64f64boolstr2016-01-04 00:32:002016-01-043\"5-egh-163\"89999.99true\"low\"2016-01-05 13:32:002016-01-056\"8-kdg-938\"32343.23true\"high\"2016-01-11 06:15:002016-01-114\"2-dhe-923\"43291.03true\"mid\"2016-01-17 11:27:002016-01-174\"5-boe-639\"21035.64false\"low\"\n\n\nThere are four rows. This is because the different validation steps tested values in different columns of the table. Some of the failing test units had to have occurred in more than once in certain rows. The rows that didn’t have any failing test units across the three different tests (in three different columns) are the ones seen above. This brings us to the third important thing about the sundering process:\n\nthe absence of test-unit failures in a row across all validation steps means those rows are returned as the ‘passing’ set, all others are placed in the ‘failing’ set\n\nIn validations where many validation steps are used, we can be more confident about the level of data quality for those rows returned in the passing set. But not every type of validation step is considered within this splitting procedure. The next section will explain the rules on that."
  },
  {
    "objectID": "user-guide-pdf.html#the-validation-methods-considered-when-sundering",
    "href": "user-guide-pdf.html#the-validation-methods-considered-when-sundering",
    "title": "CLI Reference",
    "section": "4.29 The Validation Methods Considered When Sundering",
    "text": "4.29 The Validation Methods Considered When Sundering\nThe sundering procedure relies on row-level validation types to be used. This makes sense as it’s impossible to judge the quality of a row when using the col_exists() validation method, for example. Luckily, we have many row-level validation methods; here’s a list:\n\ncol_vals_gt()\ncol_vals_lt()\ncol_vals_ge()\ncol_vals_le()\ncol_vals_eq()\ncol_vals_ne()\ncol_vals_between()\ncol_vals_outside()\ncol_vals_in_set()\ncol_vals_not_in_set()\ncol_vals_null()\ncol_vals_not_null()\ncol_vals_regex()\ncol_vals_expr()\nrows_distinct()\nrows_complete()\nconjointly()\n\nThis is the same list of validation methods that are considered when creating data extracts.\nThere are some additional caveats though. Even if using a validation method drawn from the set above, the validation step won’t be used for sundering if:\n\nthe active= parameter for that step has been set to False\nthe pre= parameter has been used\n\nThe first one makes intuitive sense (you decided to skip this validation step entirely), the second one requires some explanation. Using pre= allows you to modify the target table, there’s no easy or practical way to compare rows in a mutated table compared to the original table (e.g., a mutation may drastically reduce the number of rows)."
  },
  {
    "objectID": "user-guide-pdf.html#practical-applications-of-sundering",
    "href": "user-guide-pdf.html#practical-applications-of-sundering",
    "title": "CLI Reference",
    "section": "4.30 Practical Applications of Sundering",
    "text": "4.30 Practical Applications of Sundering\n\n4.30.1 1. Creating Clean Datasets for Analysis\nOne of the most common use cases for sundering is preparing validated data for downstream analysis:\n\n# Comprehensive validation for analysis-ready data\nanalysis_validation = (\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\"))\n    .col_vals_not_null(columns=[\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"])  # No missing values\n    .col_vals_gt(columns=\"a\", value=0)                          # Positive values only\n    .col_vals_lt(columns=\"d\", value=10000)                      # No extreme outliers\n    .interrogate()\n)\n\n# Extract only the clean data that passed all checks\nclean_data = analysis_validation.get_sundered_data(type=\"pass\")\n\n# Use the clean data for your analysis\npb.preview(clean_data)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows11Columns8\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05\n    6\n    8-kdg-938\n    3\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-09 12:36:00\n    2016-01-09\n    8\n    3-ldm-038\n    7\n    283.94\n    True\n    low\n  \n  \n    5\n    2016-01-11 06:15:00\n    2016-01-11\n    4\n    2-dhe-923\n    4\n    3291.03\n    True\n    mid\n  \n  \n    7\n    2016-01-17 11:27:00\n    2016-01-17\n    4\n    5-boe-639\n    2\n    1035.64\n    False\n    low\n  \n  \n    8\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-26 20:07:00\n    2016-01-26\n    4\n    2-dmx-010\n    7\n    833.98\n    True\n    low\n  \n  \n    11\n    2016-01-28 02:51:00\n    2016-01-28\n    2\n    7-dmx-010\n    8\n    108.34\n    False\n    low\n  \n\n\n\n\n\n\n        \n\n\nThis approach ensures that any subsequent analysis is based on data that meets your quality standards, reducing the risk of misleading results or spurious conclusions due to problematic records. By making validation an explicit step in your analytical workflow, you create a natural quality gate that prevents invalid data from influencing your findings.\n\n\n4.30.2 2. Creating Parallel Workflows for Clean and Problematic Data\nYou can use sundering to create parallel processing paths:\n\n# Get both clean and problematic data\nclean_data = analysis_validation.get_sundered_data(type=\"pass\")\nproblem_data = analysis_validation.get_sundered_data(type=\"fail\")\n\n# Process clean data (in real applications, you'd do more here)\nprint(f\"Clean data size: {len(clean_data)} rows\")\n\n# Log problematic data for investigation\nprint(f\"Problematic data size: {len(problem_data)} rows\")\n\nClean data size: 11 rows\nProblematic data size: 2 rows\n\n\nThis approach enables you to build robust data processing pathways with separate handling for clean and problematic data. In production environments, you could save problematic records to a separate location for further investigation, generate detailed logs of validation failures, and trigger automated notifications to data stewards when issues arise. By establishing clear protocols for handling both data streams, you create a systematic approach to data quality that balances immediate analytical needs with longer-term data improvement goals.\n\n\n4.30.3 3. Data Quality Monitoring and Improvement\nTracking the ratio of passing to failing rows over time can help monitor data quality trends:\n\n# Calculate data quality metrics\ntotal_rows = len(pb.load_dataset(dataset=\"small_table\"))\npassing_rows = len(clean_data)\nquality_score = passing_rows / total_rows\n\nprint(f\"Data quality score: {quality_score:.2%}\")\nprint(f\"Passing rows: {passing_rows} out of {total_rows}\")\n\nData quality score: 84.62%\nPassing rows: 11 out of 13\n\n\nBy tracking these metrics over time, you can measure the impact of your data quality improvement efforts and communicate progress to stakeholders. This approach transforms sundering from a one-time filtering tool into an ongoing data quality management system, where improving the ratio of passing rows becomes a measurable business objective aligned with broader data governance goals."
  },
  {
    "objectID": "user-guide-pdf.html#best-practices-for-using-sundered-data",
    "href": "user-guide-pdf.html#best-practices-for-using-sundered-data",
    "title": "CLI Reference",
    "section": "4.31 Best Practices for Using Sundered Data",
    "text": "4.31 Best Practices for Using Sundered Data\nWhen incorporating data sundering into your workflow, consider these best practices:\n\nBe comprehensive in your validation: the more validation steps you include (assuming they’re meaningful), the more confidence you can have in your passing dataset\nDocument your validation criteria: when sharing sundered data with others, always document the criteria used to determine passing rows\nConsider traceability: for audit purposes, it may be valuable to add a column indicating whether a record was originally in the passing or failing set\nBalance strictness and practicality: if you’re too strict with validation rules, you might end up with very few passing rows; consider the appropriate level of strictness for your use case\nUse sundering as part of a pipeline: automate the process of validation, sundering, and subsequent handling of the two resulting datasets\nContinually refine validation rules: as you learn more about your data and domain, update your validation rules to improve the accuracy of your sundering process\n\nBy following these best practices, data scientists and engineers can transform sundering from a simple utility into a strategic component of their data quality framework. When implemented thoughtfully, sundering enables a shift from reactive data cleaning to proactive quality management, where validation criteria evolve alongside your understanding of the data.\nThe ultimate goal isn’t just to separate good data from bad, but to gradually improve your entire dataset over time by addressing the root causes of validation failures that appear in the failing set. This approach turns data validation from a gatekeeper function into a continuous improvement process."
  },
  {
    "objectID": "user-guide-pdf.html#conclusion-15",
    "href": "user-guide-pdf.html#conclusion-15",
    "title": "CLI Reference",
    "section": "4.32 Conclusion",
    "text": "4.32 Conclusion\nData sundering provides a powerful way to separate your data based on validation results. While the concept is simple (splitting data into passing and failing sets) the feature can very useful in many data workflows. By integrating sundering into your data pipeline, you can:\n\nensure that downstream analysis only works with validated data\ncreate focused datasets for different purposes\nimprove overall data quality through systematic identification and isolation of problematic records\nbuild more robust data pipelines that explicitly handle data quality issues\n\nSo long as you’re aware of the rules and limitations of sundering, you’re likely to find it to be a simple and useful way to filter your input table on the basis of a validation plan, turning data validation from a passive reporting tool into an active component of your data processing workflow."
  },
  {
    "objectID": "user-guide-pdf.html#viewing-a-table-with-preview",
    "href": "user-guide-pdf.html#viewing-a-table-with-preview",
    "title": "CLI Reference",
    "section": "5.1 Viewing a Table with preview()",
    "text": "5.1 Viewing a Table with preview()\nLet’s look at how preview() works. It requires only a table and, for this first example, let’s use the nycflights dataset:\n\nimport pointblank as pb\n\nnycflights = pb.load_dataset(dataset=\"nycflights\", tbl_type=\"polars\")\n\npb.preview(nycflights)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows336,776Columns18\n  \n\n  \n  yearInt64\n  monthInt64\n  dayInt64\n  dep_timeInt64\n  sched_dep_timeInt64\n  dep_delayInt64\n  arr_timeInt64\n  sched_arr_timeInt64\n  arr_delayInt64\n  carrierString\n  flightInt64\n  tailnumString\n  originString\n  destString\n  air_timeInt64\n  distanceInt64\n  hourInt64\n  minuteInt64\n\n\n\n  \n    1\n    2013\n    1\n    1\n    517\n    515\n    2\n    830\n    819\n    11\n    UA\n    1545\n    N14228\n    EWR\n    IAH\n    227\n    1400\n    5\n    15\n  \n  \n    2\n    2013\n    1\n    1\n    533\n    529\n    4\n    850\n    830\n    20\n    UA\n    1714\n    N24211\n    LGA\n    IAH\n    227\n    1416\n    5\n    29\n  \n  \n    3\n    2013\n    1\n    1\n    542\n    540\n    2\n    923\n    850\n    33\n    AA\n    1141\n    N619AA\n    JFK\n    MIA\n    160\n    1089\n    5\n    40\n  \n  \n    4\n    2013\n    1\n    1\n    544\n    545\n    -1\n    1004\n    1022\n    -18\n    B6\n    725\n    N804JB\n    JFK\n    BQN\n    183\n    1576\n    5\n    45\n  \n  \n    5\n    2013\n    1\n    1\n    554\n    600\n    -6\n    812\n    837\n    -25\n    DL\n    461\n    N668DN\n    LGA\n    ATL\n    116\n    762\n    6\n    0\n  \n  \n    336772\n    2013\n    9\n    30\n    None\n    1455\n    None\n    None\n    1634\n    None\n    9E\n    3393\n    None\n    JFK\n    DCA\n    None\n    213\n    14\n    55\n  \n  \n    336773\n    2013\n    9\n    30\n    None\n    2200\n    None\n    None\n    2312\n    None\n    9E\n    3525\n    None\n    LGA\n    SYR\n    None\n    198\n    22\n    0\n  \n  \n    336774\n    2013\n    9\n    30\n    None\n    1210\n    None\n    None\n    1330\n    None\n    MQ\n    3461\n    N535MQ\n    LGA\n    BNA\n    None\n    764\n    12\n    10\n  \n  \n    336775\n    2013\n    9\n    30\n    None\n    1159\n    None\n    None\n    1344\n    None\n    MQ\n    3572\n    N511MQ\n    LGA\n    CLE\n    None\n    419\n    11\n    59\n  \n  \n    336776\n    2013\n    9\n    30\n    None\n    840\n    None\n    None\n    1020\n    None\n    MQ\n    3531\n    N839MQ\n    LGA\n    RDU\n    None\n    431\n    8\n    40\n  \n\n\n\n\n\n\n        \n\n\nThis is an HTML table using the style of the other reporting tables in the library. The header is more minimal here, only showing the type of table we’re looking at (POLARS in this case) along with the table dimensions. The column headers provide both the column names and the column data types.\nBy default, we’re getting the first five rows and the last five rows. Row numbers (from the original dataset) provide an indication of which rows are the head and tail rows. The blue lines provide additional demarcation of the column containing the row numbers and the head and tail row groups. Finally, any cells with missing values are prominently styled with red lettering and a lighter red background.\nIf you’d rather not see the row numbers in the table, you can use the show_row_numbers=False option. Let’s try that with the game_revenue dataset as a DuckDB table:\n\ngame_revenue = pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"duckdb\")\n\npb.preview(game_revenue, show_row_numbers=False)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    DuckDBRows2,000Columns11\n  \n\n  player_idstring\n  session_idstring\n  session_starttimestamp\n  timetimestamp\n  item_typestring\n  item_namestring\n  item_revenuefloat64\n  session_durationfloat64\n  start_daydate\n  acquisitionstring\n  countrystring\n\n\n\n  \n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:31:27+00:00\n    iap\n    offer2\n    8.99\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:36:57+00:00\n    iap\n    gems3\n    22.49\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:37:45+00:00\n    iap\n    gold7\n    107.99\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:42:33+00:00\n    ad\n    ad_20sec\n    0.76\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-hdu9jkls\n    2015-01-01 11:50:02+00:00\n    2015-01-01 11:55:20+00:00\n    ad\n    ad_5sec\n    0.03\n    35.2\n    2015-01-01\n    google\n    Germany\n  \n  \n    NAOJRDMCSEBI281\n    NAOJRDMCSEBI281-j2vs9ilp\n    2015-01-21 01:57:50+00:00\n    2015-01-21 02:02:50+00:00\n    ad\n    ad_survey\n    1.332\n    25.8\n    2015-01-11\n    organic\n    Norway\n  \n  \n    NAOJRDMCSEBI281\n    NAOJRDMCSEBI281-j2vs9ilp\n    2015-01-21 01:57:50+00:00\n    2015-01-21 02:22:14+00:00\n    ad\n    ad_survey\n    1.35\n    25.8\n    2015-01-11\n    organic\n    Norway\n  \n  \n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-vbhcsmtr\n    2015-01-21 02:39:48+00:00\n    2015-01-21 02:40:00+00:00\n    ad\n    ad_5sec\n    0.03\n    8.4\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-vbhcsmtr\n    2015-01-21 02:39:48+00:00\n    2015-01-21 02:47:12+00:00\n    iap\n    offer5\n    26.09\n    8.4\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    GJCXNTWEBIPQ369\n    GJCXNTWEBIPQ369-9elq67md\n    2015-01-21 03:59:23+00:00\n    2015-01-21 04:06:29+00:00\n    ad\n    ad_5sec\n    0.12\n    18.5\n    2015-01-14\n    organic\n    United States\n  \n\n\n\n\n\n\n        \n\n\nWith the above preview, the row numbers are gone. The horizontal blue line still serves to divide the top and bottom rows of the table, however."
  },
  {
    "objectID": "user-guide-pdf.html#adjusting-the-number-of-rows-shown",
    "href": "user-guide-pdf.html#adjusting-the-number-of-rows-shown",
    "title": "CLI Reference",
    "section": "5.2 Adjusting the Number of Rows Shown",
    "text": "5.2 Adjusting the Number of Rows Shown\nIt could be that displaying the five top and bottom rows is not preferred. This can be changed with the n_head= and n_tail=. Maybe, you want three from the top along with the last row? Let’s try that out with the small_table dataset as a Pandas DataFrame:\n\nsmall_table = pb.load_dataset(dataset=\"small_table\", tbl_type=\"pandas\")\n\npb.preview(small_table, n_head=3, n_tail=1)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PandasRows13Columns8\n  \n\n  \n  date_timedatetime64[ns]\n  datedatetime64[ns]\n  aint64\n  bobject\n  cfloat64\n  dfloat64\n  ebool\n  fobject\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04 00:00:00\n    2\n    1-bcd-345\n    3.0\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04 00:00:00\n    3\n    5-egh-163\n    8.0\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05 00:00:00\n    6\n    8-kdg-938\n    3.0\n    2343.23\n    True\n    high\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30 00:00:00\n    1\n    3-dka-303\n    NA\n    2230.09\n    True\n    high\n  \n\n\n\n\n\n\n        \n\n\nIf you’re looking at a small table and want to see the entirety of it, you can enlarge the n_head= and n_tail= values:\n\nsmall_table = pb.load_dataset(dataset=\"small_table\", tbl_type=\"pandas\")\n\npb.preview(small_table, n_head=10, n_tail=10)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PandasRows13Columns8\n  \n\n  \n  date_timedatetime64[ns]\n  datedatetime64[ns]\n  aint64\n  bobject\n  cfloat64\n  dfloat64\n  ebool\n  fobject\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04 00:00:00\n    2\n    1-bcd-345\n    3.0\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04 00:00:00\n    3\n    5-egh-163\n    8.0\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05 00:00:00\n    6\n    8-kdg-938\n    3.0\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06 00:00:00\n    2\n    5-jdo-903\n    NA\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09 00:00:00\n    8\n    3-ldm-038\n    7.0\n    283.94\n    True\n    low\n  \n  \n    6\n    2016-01-11 06:15:00\n    2016-01-11 00:00:00\n    4\n    2-dhe-923\n    4.0\n    3291.03\n    True\n    mid\n  \n  \n    7\n    2016-01-15 18:46:00\n    2016-01-15 00:00:00\n    7\n    1-knw-093\n    3.0\n    843.34\n    True\n    high\n  \n  \n    8\n    2016-01-17 11:27:00\n    2016-01-17 00:00:00\n    4\n    5-boe-639\n    2.0\n    1035.64\n    False\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20 00:00:00\n    3\n    5-bce-642\n    9.0\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20 00:00:00\n    3\n    5-bce-642\n    9.0\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26 00:00:00\n    4\n    2-dmx-010\n    7.0\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28 00:00:00\n    2\n    7-dmx-010\n    8.0\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30 00:00:00\n    1\n    3-dka-303\n    NA\n    2230.09\n    True\n    high\n  \n\n\n\n\n\n\n        \n\n\nGiven that the table has 13 rows, asking for 20 rows to be displayed effectively shows the entire table."
  },
  {
    "objectID": "user-guide-pdf.html#previewing-a-subset-of-columns",
    "href": "user-guide-pdf.html#previewing-a-subset-of-columns",
    "title": "CLI Reference",
    "section": "5.3 Previewing a Subset of Columns",
    "text": "5.3 Previewing a Subset of Columns\nThe preview scales well to tables that have many columns by allowing for a horizontal scroll. However, previewing data from all columns can be impractical if you’re only concerned with a key set of them. To preview only a subset of a table’s columns, we can use the columns_subset= argument. Let’s do this with the nycflights dataset and provide a list of six columns from that table.\n\npb.preview(\n    nycflights,\n    columns_subset=[\"hour\", \"minute\", \"sched_dep_time\", \"year\", \"month\", \"day\"]\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows336,776Columns18\n  \n\n  \n  hourInt64\n  minuteInt64\n  sched_dep_timeInt64\n  yearInt64\n  monthInt64\n  dayInt64\n\n\n\n  \n    1\n    5\n    15\n    515\n    2013\n    1\n    1\n  \n  \n    2\n    5\n    29\n    529\n    2013\n    1\n    1\n  \n  \n    3\n    5\n    40\n    540\n    2013\n    1\n    1\n  \n  \n    4\n    5\n    45\n    545\n    2013\n    1\n    1\n  \n  \n    5\n    6\n    0\n    600\n    2013\n    1\n    1\n  \n  \n    336772\n    14\n    55\n    1455\n    2013\n    9\n    30\n  \n  \n    336773\n    22\n    0\n    2200\n    2013\n    9\n    30\n  \n  \n    336774\n    12\n    10\n    1210\n    2013\n    9\n    30\n  \n  \n    336775\n    11\n    59\n    1159\n    2013\n    9\n    30\n  \n  \n    336776\n    8\n    40\n    840\n    2013\n    9\n    30\n  \n\n\n\n\n\n\n        \n\n\nWhat we see are the six columns we specified from the nycflights dataset.\nNote that the columns are displayed in the order provided in the columns_subset= list. This can be useful for making quick, side-by-side comparisons. In the example above, we placed hour and minute next to the sched_dep_time column. In the original dataset, sched_dep_time is far apart from the other two columns, but, it’s useful to have them next to each other in the preview since hour and minute are derived from sched_dep_time (and this lets us spot check any issues).\nWe can also use column selectors within columns_subset=. Suppose we want to only see those columns that have \"dep_\" or \"arr_\" in the name. To do that, we use the matches() column selector function:\n\npb.preview(nycflights, columns_subset=pb.matches(\"dep_|arr_\"))\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows336,776Columns18\n  \n\n  \n  dep_timeInt64\n  sched_dep_timeInt64\n  dep_delayInt64\n  arr_timeInt64\n  sched_arr_timeInt64\n  arr_delayInt64\n\n\n\n  \n    1\n    517\n    515\n    2\n    830\n    819\n    11\n  \n  \n    2\n    533\n    529\n    4\n    850\n    830\n    20\n  \n  \n    3\n    542\n    540\n    2\n    923\n    850\n    33\n  \n  \n    4\n    544\n    545\n    -1\n    1004\n    1022\n    -18\n  \n  \n    5\n    554\n    600\n    -6\n    812\n    837\n    -25\n  \n  \n    336772\n    None\n    1455\n    None\n    None\n    1634\n    None\n  \n  \n    336773\n    None\n    2200\n    None\n    None\n    2312\n    None\n  \n  \n    336774\n    None\n    1210\n    None\n    None\n    1330\n    None\n  \n  \n    336775\n    None\n    1159\n    None\n    None\n    1344\n    None\n  \n  \n    336776\n    None\n    840\n    None\n    None\n    1020\n    None\n  \n\n\n\n\n\n\n        \n\n\nSeveral selectors can be combined together through use of the col() function and operators such as & (and), | (or), - (difference), and ~ (not). Let’s look at a column selection case where:\n\nthe first three columns are selected\nall columns containing \"dep_\" or \"arr_\" are selected\nany columns beginning with \"sched\" are omitted\n\nThis is how we put that together within col():\n\npb.preview(\n    nycflights,\n    columns_subset=pb.col((pb.first_n(3) | pb.matches(\"dep_|arr_\")) & ~ pb.starts_with(\"sched\"))\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows336,776Columns18\n  \n\n  \n  yearInt64\n  monthInt64\n  dayInt64\n  dep_timeInt64\n  dep_delayInt64\n  arr_timeInt64\n  arr_delayInt64\n\n\n\n  \n    1\n    2013\n    1\n    1\n    517\n    2\n    830\n    11\n  \n  \n    2\n    2013\n    1\n    1\n    533\n    4\n    850\n    20\n  \n  \n    3\n    2013\n    1\n    1\n    542\n    2\n    923\n    33\n  \n  \n    4\n    2013\n    1\n    1\n    544\n    -1\n    1004\n    -18\n  \n  \n    5\n    2013\n    1\n    1\n    554\n    -6\n    812\n    -25\n  \n  \n    336772\n    2013\n    9\n    30\n    None\n    None\n    None\n    None\n  \n  \n    336773\n    2013\n    9\n    30\n    None\n    None\n    None\n    None\n  \n  \n    336774\n    2013\n    9\n    30\n    None\n    None\n    None\n    None\n  \n  \n    336775\n    2013\n    9\n    30\n    None\n    None\n    None\n    None\n  \n  \n    336776\n    2013\n    9\n    30\n    None\n    None\n    None\n    None\n  \n\n\n\n\n\n\n        \n\n\nThis gives us a preview with only the columns that fit the specific selection rules. Incidentally, using selectors with a dataset through preview() is a good way to test out the use of selectors more generally. Since they are primarily used to select columns for validation, trying them beforehand with preview() can help verify that your selection logic is sound.\nWhile previewing a table with preview() is undoubtedly a good thing to do, sometimes you need more. This is where summarizing a table comes in. When you view a summary of a table, the column-by-column info can quickly increase your understanding of a dataset. Plus, it allows you to quickly catch anomalies in your data (e.g., the maximum value of a column could be far outside the realm of possibility).\nPointblank provides a function to make it extremely easy to view column-level summaries in a single table. That function is called col_summary_tbl() and, just like preview() does, it supports the use of any table that Pointblank can use for validation. And no matter what the input data is, the resultant reporting table is consistent in its design and construction."
  },
  {
    "objectID": "user-guide-pdf.html#trying-out-col_summary_tbl",
    "href": "user-guide-pdf.html#trying-out-col_summary_tbl",
    "title": "CLI Reference",
    "section": "5.4 Trying out col_summary_tbl()",
    "text": "5.4 Trying out col_summary_tbl()\nThe function only requires a table. Let’s use the small_table dataset (a very simple table) to start us off:\n\nimport pointblank as pb\n\nsmall_table = pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\")\n\npb.col_summary_tbl(small_table)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows13Columns8\n  \n\n  \n  Column\n  NA\n  UQ\n  Mean\n  SD\n  Min\n  P5\n  Q1\n  Med\n  Q3\n  P95\n  Max\n  IQR\n\n\n\n  \n    \n    date\n    \n        \n            \n            \n                \n            \n        \n    \n\n    date_timeDatetime(time_unit='us', time_zone=None)\n    00\n    120.92\n    -\n    -\n    20160104 00:32:00\n    -\n    -\n    -\n    -\n    -\n    20160130 11:23:00\n    -\n  \n  \n    \n    date\n    \n        \n            \n            \n                \n            \n        \n    \n\n    dateDate\n    00\n    110.85\n    -\n    -\n    20160104\n    -\n    -\n    -\n    -\n    -\n    20160130\n    -\n  \n  \n    \n    numeric\n    \n        \n            \n            \n                \n            \n        \n    \n\n    aInt64\n    00\n    70.54\n    3.77\n    2.09\n    1\n    1.06\n    2\n    3\n    4\n    7.4\n    8\n    2\n  \n  \n    \n    string\n    \n        \n            \n            \n                \n            \n        \n    \n\n    bString\n    00\n    120.92\n    9\n    0\n    9\n    9\n    9\n    9\n    9\n    9\n    9\n    0\n  \n  \n    \n    numeric\n    \n        \n            \n            \n                \n            \n        \n    \n\n    cInt64\n    20.15\n    70.54\n    5.73\n    2.72\n    2\n    2.05\n    3\n    7\n    8\n    9\n    9\n    5\n  \n  \n    \n    numeric\n    \n        \n            \n            \n                \n            \n        \n    \n\n    dFloat64\n    00\n    120.92\n    2,304.7\n    2,631.36\n    108.34\n    118.88\n    837.93\n    1,035.64\n    3,291.03\n    6,335.44\n    9999.99\n    2,453.1\n  \n  \n    \n    boolean\n    \n        \n            \n            \n                \n            \n            \n                \n            \n            \n        \n    \n\n    eBoolean\n    00\n    T0.62F0.38\n    -\n    -\n    -\n    -\n    -\n    -\n    -\n    -\n    -\n    -\n  \n  \n    \n    string\n    \n        \n            \n            \n                \n            \n        \n    \n\n    fString\n    00\n    30.23\n    3.46\n    0.52\n    3\n    3\n    3\n    3\n    4\n    4\n    4\n    1\n  \n\n  \n  \n  \n    String columns statistics regard the string's length.\n  \n\n\n\n\n\n\n        \n\n\nThe header provides the type of table we’re looking at (POLARS, since this is a Polars DataFrame) and the table dimensions. The rest of the table focuses on the column-level summaries. As such, each row represents a summary of a column in the small_table dataset. There’s a lot of information in this summary table to digest. Some of it is intuitive since this sort of table summarization isn’t all that uncommon, but other aspects of it could also give some pause. So we’ll carefully wade through how to interpret this report."
  },
  {
    "objectID": "user-guide-pdf.html#data-categories-in-the-column-summary-table",
    "href": "user-guide-pdf.html#data-categories-in-the-column-summary-table",
    "title": "CLI Reference",
    "section": "5.5 Data Categories in the Column Summary Table",
    "text": "5.5 Data Categories in the Column Summary Table\nOn the left side of the table are icons of different colors. These represent categories that the columns fall into. There are only five categories and columns can only be of one type. The categories (and their letter marks) are:\n\nN: numeric\nS: string-based\nD: date/datetime\nT/F: boolean\nO: object\n\nThe numeric category (N) takes data types such as floats and integers. The S category is for string-based columns. Date or datetime values are lumped into the D category. Boolean columns (T/F) have their own category and are not considered numeric (e.g., 0/1). The O category is a catchall for all other types of columns. Given the disparity of these categories and that we want them in the same table, some statistical measures will be sensible for certain column categories but not for others. Given that, we’ll explain how each category is represented in the column summary table."
  },
  {
    "objectID": "user-guide-pdf.html#numeric-data",
    "href": "user-guide-pdf.html#numeric-data",
    "title": "CLI Reference",
    "section": "5.6 Numeric Data",
    "text": "5.6 Numeric Data\nThree columns in small_table are numeric: a (Int64), c (Int64), and d (Float64). The common measures of the missing count/proportion (NA) and the unique value count/proportion (UQ) are provided for the numeric data type. For these two measures, the top number is the absolute count of missing values and the count of unique values. The bottom number is a proportion of the absolute count divided by the row count; this makes each proportion a value between 0 and 1 (bounds included).\nThe next two columns represent the mean (Mean) and the standard deviation (SD). The minumum (Min), maximum, (Max) and a set of quantiles occupy the next few columns (includes P5, Q1, Med for median, Q3, and P95). Finally, the interquartile range (IQR: Q3 - Q1) is the last measure provided."
  },
  {
    "objectID": "user-guide-pdf.html#string-data",
    "href": "user-guide-pdf.html#string-data",
    "title": "CLI Reference",
    "section": "5.7 String Data",
    "text": "5.7 String Data\nString data is present in small_table, being in columns b and f. The missing value (NA) and uniqueness (UQ) measures are accounted for here. The statistical measures are all based on string lengths, so what happens is that all strings in a column are converted to those numeric values and a subset of stats values is presented. To avoid some understandable confusion when reading the table, the stats values in each of the cells with values are annotated with the text \"SL\". It makes less sense to provide a full suite of quantile values so only the minimum (Min), median (Med), and maximum (Max) are provided."
  },
  {
    "objectID": "user-guide-pdf.html#datedatetime-data-and-boolean-data",
    "href": "user-guide-pdf.html#datedatetime-data-and-boolean-data",
    "title": "CLI Reference",
    "section": "5.8 Date/Datetime Data and Boolean Data",
    "text": "5.8 Date/Datetime Data and Boolean Data\nWe see that in the first two rows of our summary table there are summaries of the date_time and date columns. The summaries we provide for a date/datetime category (notice the green D to the left of the column names) are:\n\nthe missing count/proportion (NA)\nthe unique value count/proportion (UQ)\nthe minimum and maximum dates/datetimes\n\nOne column, e, is of the Boolean type. Because columns of this type could only have True, False, or missing values, we provide summary data for missingness (under NA) and proportions of True and False values (under UQ).\nSometimes values just aren’t there: they’re missing. This can either be expected or another thing to worry about. Either way, we can dig a little deeper if need be and use the missing_vals_tbl() function to generate a summary table that can elucidate how many values are missing, and roughly where."
  },
  {
    "objectID": "user-guide-pdf.html#using-and-understanding-missing_vals_tbl",
    "href": "user-guide-pdf.html#using-and-understanding-missing_vals_tbl",
    "title": "CLI Reference",
    "section": "5.9 Using and Understanding missing_vals_tbl()",
    "text": "5.9 Using and Understanding missing_vals_tbl()\nThe missing values table is arranged a lot like the column summary table (generated via the col_summary_tbl() function) in that columns of the input table are arranged as rows in the reporting table. Let’s use missing_vals_tbl() on the nycflights dataset, which has a lot of missing values:\n\nimport pointblank as pb\n\nnycflights = pb.load_dataset(dataset=\"nycflights\", tbl_type=\"polars\")\n\npb.missing_vals_tbl(nycflights)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Missing Values   46,595 in total\n  \n  \n    PolarsRows336,776Columns18\n  \n\n  Column\n  \n    Row Sector\n  \n\n\n  1\n  2\n  3\n  4\n  5\n  6\n  7\n  8\n  9\n  10\n\n\n\n  \n    year\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    month\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    day\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    dep_time\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    sched_dep_time\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    dep_delay\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    arr_time\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    sched_arr_time\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    arr_delay\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    carrier\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    flight\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    tailnum\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    origin\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    dest\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    air_time\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    distance\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    hour\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    minute\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n\n  \n  \n  \n    NO MISSING VALUES     PROPORTION MISSING:  0%100%ROW SECTORS1 – 3367733678 – 6735467355 – 101031101032 – 134708134709 – 168385168386 – 202062202063 – 235739235740 – 269416269417 – 303093303094 – 336776\n  \n\n\n\n\n\n\n        \n\n\nThere are 18 columns in nycflights and they’re arranged down the missing values table as rows. To the right we see column headers indicating 10 columns that are row sectors. Row sectors are groups of rows and each sector contains a tenth of the total rows in the table. The leftmost sectors are the rows at the top of the table whereas the sectors on the right are closer to the bottom. If you’d like to know which rows make up each row sector, there are details on this in the table footer area (click the ROW SECTORS text or the disclosure triangle).\nNow that we know about row sectors, we need to understand the visuals here. A light blue cell indicates there are no (0) missing values within a given row sector of a column. For nycflights we can see that several columns have no missing values at all (i.e., the light blue color makes up the entire row in the missing values table).\nWhen there are missing values in a column’s row sector, you’ll be met with a grayscale color. The proportion of missing values corresponds to the color ramp from light gray to solid black. Interestingly, most of the columns that have missing values appear to be related to each other in terms of the extent of missing values (i.e., the appearance in the reporting table looks roughly the same, indicating a sort of systematic missingness). These columns are dep_time, dep_delay, arr_time, arr_delay, and air_time.\nThe odd column out with regard to the distribution of missing values is tailnum. By scanning the row and observing that the grayscale color values are all a little different we see that the degree of missingness of more variable and not related to the other columns containing missing values."
  },
  {
    "objectID": "user-guide-pdf.html#missing-value-tables-from-the-other-datasets",
    "href": "user-guide-pdf.html#missing-value-tables-from-the-other-datasets",
    "title": "CLI Reference",
    "section": "5.10 Missing Value Tables from the Other Datasets",
    "text": "5.10 Missing Value Tables from the Other Datasets\nThe small_table dataset has only 13 rows to it. Let’s use that as a Pandas DataFrame with missing_vals_tbl():\n\nsmall_table = pb.load_dataset(dataset=\"small_table\", tbl_type=\"pandas\")\n\npb.missing_vals_tbl(small_table)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Missing Values   2 in total\n  \n  \n    PandasRows13Columns8\n  \n\n  Column\n  \n    Row Sector\n  \n\n\n  1\n  2\n  3\n  4\n  5\n  6\n  7\n  8\n  9\n  10\n\n\n\n  \n    date_time\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    date\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    a\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    b\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    c\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    d\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    e\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    f\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n\n  \n  \n  \n    NO MISSING VALUES     PROPORTION MISSING:  0%100%ROW SECTORS1 – 12 – 23 – 34 – 45 – 56 – 67 – 78 – 89 – 910 – 13\n  \n\n\n\n\n\n\n        \n\n\nIt appears that only column c has missing values. And since the table is very small in terms of row count, most of the row sectors contain only a single row.\nThe game_revenue dataset has no missing values. And this can be easily proven by using missing_vals_tbl() with it:\n\ngame_revenue = pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"duckdb\")\n\npb.missing_vals_tbl(game_revenue)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Missing Values ✓\n  \n  \n    DuckDBRows2,000Columns11\n  \n\n  Column\n  \n    Row Sector\n  \n\n\n  1\n  2\n  3\n  4\n  5\n  6\n  7\n  8\n  9\n  10\n\n\n\n  \n    player_id\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    session_id\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    session_start\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    time\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    item_type\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    item_name\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    item_revenue\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    session_duration\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    start_day\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    acquisition\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    country\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n\n  \n  \n  \n    NO MISSING VALUES     PROPORTION MISSING:  0%100%ROW SECTORS1 – 200201 – 400401 – 600601 – 800801 – 10001001 – 12001201 – 14001401 – 16001601 – 18001801 – 2000\n  \n\n\n\n\n\n\n        \n\n\nWe see nothing but light blue in this report! The header also indicates that there are no missing values by displaying a large green check mark (the other report tables provided a count of total missing values across all columns)."
  },
  {
    "objectID": "user-guide-pdf.html#pb-info-inspecting-the-data-structure",
    "href": "user-guide-pdf.html#pb-info-inspecting-the-data-structure",
    "title": "CLI Reference",
    "section": "6.1 pb info: Inspecting the Data Structure",
    "text": "6.1 pb info: Inspecting the Data Structure\nUse pb info to display basic information about your data source. Here’s how this works with a local CSV file:\npb info worldcities.csv\n\nThis command shows the (1) table type (e.g., pandas, polars, etc.), (2) the number of rows and columns, and (3) the data source path or identifier.\nThat example used a local CSV file. The same file is also present in Pointblank’s GitHub repository (in the data-raw directory) and the CLI is able to load the data from there as well:\npb info https://github.com/posit-dev/pointblank/blob/main/data_raw/worldcities.csv\n\nThe pb info command is useful before running validations to confirm your data source’s dimensions, and, whether it can even be loaded.\n\nYou can inspect a wide variety of data sources using the CLI! Here are some examples with pb info:\npb info small_table         # built in dataset\npb info worldcities.csv     # single CSV file\npb info meteo.parquet       # single Parquet file\npb info \"*.parquet\"         # several Parquet files\npb info \"data/*.parquet\"    # partitioned Parquet files\npb info \"duckdb:///warehouse/analytics.ddb::customer_metrics\" # DB table via connection string\npb info https://github.com/posit-dev/pointblank/blob/main/data_raw/global_sales.csv # GitHub URL\nAnd these input schemes work with all other commands that accept a DATA_SOURCE."
  },
  {
    "objectID": "user-guide-pdf.html#pb-preview-previewing-data",
    "href": "user-guide-pdf.html#pb-preview-previewing-data",
    "title": "CLI Reference",
    "section": "6.2 pb preview: Previewing Data",
    "text": "6.2 pb preview: Previewing Data\nUse pb preview to view the first and last rows of your data. Let’s try it out with the worldcities.csv file:\npb preview worldcities.csv\n\nAs can be seen, pb preview gives you a preview of the dataset as a table in the console. The dataset has 41K rows but we’re electing to show only five rows from the head and from the tail.\nLet’s go over some features of the table preview. First off, the table header provides information on the data source and the DataFrame library that handled the reading of the CSV. Below the column names are simplified representations of the data types (e.g., &lt;obj&gt; for object, &lt;f64&gt; for Float64). We provide row numbers (in gray) in the table stub to indicate which of the rows are from the head or the tail (and a divider helps to distinguish these row groups). If you’d prefer to eliminate the row numbers, use the --no-row-numbers option:\npb preview worldcities.csv --no-row-numbers\n\nWhile pb preview purposefully displays only a few rows, the number of columns shown can be more than you might need. Furthermore, if a table has a lot of columns, you’ll only see some of the first and some of the last columns. This is where column selection becomes useful and there are a few methods available for subsetting the preview table’s columns. A good one (provided you know the column names) is to use the --columns option along with a comma-delimted set of column names. Let’s look at a preview of the included game_revenue dataset before subsetting the columns:\npb preview game_revenue\n\nThat’s 11 columns in total and while the all columns are shown (i.e., none in the middle are truncated from view), we start to see some necessary instances of abbreviating via … within the column names and in the displayed values.\nLet’s now use the --columns with a set of column names:\npb preview game_revenue -columns \"player_id, item_type, item_name, start_day\"\n\nWith that, the few columns that are displayed no longer have to abbreviate their data values. This is an important consideration since a selective display of column becomes more necessary if column content is large or if the width of the terminal (in terms of characters) cannot be increased.\nYou may want to view ranges of columns by their indices. This is convenient when you want to get a closer look at a few side-by-side columns and you don’t want to bother with getting the set of column names exactly right (i.e., for quick inspection). For this, we need to use the --col-range option with the desired left/right column bounds separated by a colon:\npb preview game_revenue —-col-range \"3:6\"\n\nIn the case that you want to save a table preview as an HTML table in a standalone file, you can add in the --output-html option (just add a path/filename with an .html extension).\nAnd there are many more options that allow for quick iteration while previewing a table. Use pb preview --help to get a helpful listing."
  },
  {
    "objectID": "user-guide-pdf.html#pb-scan-getting-column-summaries",
    "href": "user-guide-pdf.html#pb-scan-getting-column-summaries",
    "title": "CLI Reference",
    "section": "6.3 pb scan: Getting Column Summaries",
    "text": "6.3 pb scan: Getting Column Summaries\nWe can use pb scan for fairly comprehensive summaries of column data, including:\n\ndata types\nmissing value counts\nunique value counts\nsummary statistics (mean, standard deviation, min, max, quartiles, and the interquartile range)\n\nLet’s use this on the worldcities.csv dataset:\npb scan worldcities.csv\n\nEach row in the summary table represents a column in the input dataset. Just as in pb preview we get simplified dtypes (in the Type column). The NA and UQ indicate how many missing and unique values are in the column. The remaining columns are statistical measures and there’s an important thing to note here: the values provided for any string-based columns (here, city_name and country) are derived from string lengths.\nWhen using pb scan, it’s helpful to know that large numbers in the summary table are automatically abbreviated for readability, so you’ll see values like 39.8k or 38.0M instead of long numbers that would require many more characters. For the best experience, try to use a terminal window that’s at least 150 characters wide. This will help ensure that all column values are fully visible and not adversely abbreviated by the underlying table mechanism.\nIf your table has many columns, that’s not much of a problem for the reporting! Each column is represented as a row in the report, so you’ll simply see more lines in the output (and you could always limit the number of columns reported).\nThere are two options for pb scan:\n\n--columns \"col1,col2\": scan only specified columns\n--output-html \"file.html\": save scan as an HTML file\n\nBoth of these options are also in the pb preview command and they behave the same way here."
  },
  {
    "objectID": "user-guide-pdf.html#pb-missing-reporting-on-missing-values",
    "href": "user-guide-pdf.html#pb-missing-reporting-on-missing-values",
    "title": "CLI Reference",
    "section": "6.4 pb missing: Reporting on Missing Values",
    "text": "6.4 pb missing: Reporting on Missing Values\nUse pb missing to generate a missing values report, visualizing missingness across columns and 10 row sectors. Here’s an example using worldcities.csv:\npb missing worldcities.csv\n\nThis report is arranged similarly to that of pb scan, where each column in the input table gets a row in this report table. Each of the 10 row sectors represents 1/10 of the rows in the dataset, where sector 1 encompasses the head of the table, and 10 the tail.\nMore often than not, we expect few missing values so a filled green circle signifies that the collection of rows in a sector (for a column) has no missing values. We don’t see any red circles in the worldcities.csv-based example but, if we did, that would mean that sectors for a given column are entirely filled with missing values.\nWhat’s in between the no-missing and completely-missing cases are percentages of missing values. For instance, we can see that row sector 3 of the population column has 18% missing values (which is very odd for a table with the sole purpose of providing population values).\nWe also have cases where we see &lt;1% of values in a row sector missing. The reporting of pb missing is very careful not to ‘round down’ in cases where there could be very few missing values (or even just one) in a large table.\nSeeing this type of missing value report can be really important! You might not expect any missing values but finding them will inform decisions on whether to institute checks for them. Another case is that missing values will pop up in specific sectors, indicating a change in how data is processed and appended to the table.\nBy way of options, there’s only one for pb missing and it is --output-html. With that (as in the previous two commands discussed), we can write the missing values report to a standalone HTML file."
  },
  {
    "objectID": "user-guide-pdf.html#wrapping-up-1",
    "href": "user-guide-pdf.html#wrapping-up-1",
    "title": "CLI Reference",
    "section": "6.5 Wrapping Up",
    "text": "6.5 Wrapping Up\nPointblank’s CLI provides a set of commands that make it easy to inspect, understand, and diagnose your data before you move on to validation or analysis. Using these tools can help you catch issues early and gain confidence in your data sources.\n\nuse pb info and before running validations to confirm your data source can be loaded\nuse pb preview to quickly understand what the data looks like\nuse pb scan for a quick data profile and to spot outliers or data quality issues\nuse pb missing to visualize and diagnose missing data patterns\n\nBy incorporating these commands into your workflow, you’ll be better equipped to work efficiently with your data (and avoid surprises down the line).\nValidating data directly in the terminal with the Pointblank CLI offers a fast, scriptable, and repeatable way to check your data. This approach is especially useful for quick checks, CI/CD pipelines, and automation workflows, where you want immediate feedback and clear pass/fail results.\nThe CLI commands are designed for efficiency: you can run validations with a single line, integrate them easily into shell scripts or data pipelines, and benefit from clear, color-coded output that’s easy to interpret at a glance.\nThe pb validate command lets you perform common validation checks directly on your data source with a simple command-line interface. This works well both for quick, one-off checks and for use in automated pipelines.\nFor more complex validation logic, the pb run command serves as a runner for validation scripts written with the Pointblank Python API, allowing you to execute custom validation workflows from the command line."
  },
  {
    "objectID": "user-guide-pdf.html#pb-validate-quick-one-line-data-checks",
    "href": "user-guide-pdf.html#pb-validate-quick-one-line-data-checks",
    "title": "CLI Reference",
    "section": "6.6 pb validate: Quick, One-Line Data Checks",
    "text": "6.6 pb validate: Quick, One-Line Data Checks\nThe pb validate command is your go-to for running common validation checks directly on your data source. It’s perfect for quick, one-off checks or for use in automated pipelines. You specify exactly which check you want to run using the --check option, making your intent clear and your validation explicit.\nHere’s how you construct a validation command:\npb validate worldcities.csv --check &lt;check-name&gt; [other options]\nYou always provide the data source first, then specify one or more checks with --check. Each check can have its own options, such as --column or --value, depending on what you want to validate.\n\n6.6.1 Checking for Duplicate and Complete Rows\nTo check for duplicate rows, use the rows-distinct check:\npb validate worldcities.csv --check rows-distinct\n\nThe output shows you whether your data contains any duplicate rows, how many rows were checked, and if any duplicates were found. The color-coding of the results helps you quickly interpret the results, using green for pass and red for fail. Here, no duplicate rows were detected out of the 41K rows checked.\nTo check that every row is complete (i.e., no missing values in any column), use the rows-complete check:\npb validate worldcities.csv --check rows-complete\n\nWith this check we see that the worldcities.csv dataset has 739 rows containing at least one Null/missing value. And with any dataset, it’s easy to quickly spot if there are any rows with missing data using this command.\n\n\n6.6.2 Checking for Nulls and Value Ranges\nYou can easily check for missing values in a column, or ensure that values fall within a certain range. Here’s how to check that all values in the population column are not null:\npb validate worldcities.csv --check col-vals-not-null --column city_name\n\nPerhaps surprisingly, we find that one row has a missing city name.\nLet’s now check whether all values in the population column are greater than zero:\npb validate worldcities.csv --check col-vals-gt --column population --value 0\n\nWith that we find that there are 741 rows where the population value is not greater than 0 (note that this check also fails when cells are null or missing).\n\n\n6.6.3 Multiple Checks in One Command\nYou can chain several checks together in a single command. This is handy for comprehensive data quality checks:\npb validate worldcities.csv --check rows-distinct --check col-vals-not-null --column city_name --check col-vals-gt --column population --value 0\n\nEach check is shown one after the other in the terminal output, so you can review the result of each validation step individually as the command proceeds.\n\n\n6.6.4 Seeing and Saving Failing Rows\nIf a check fails, you might want to see which rows caused the failure. Use the --show-extract option to display failing rows right in the terminal:\npb validate worldcities.csv --check rows-complete --show-extract\n\nOr, save the failing rows to a CSV file for further investigation:\npb validate worldcities.csv --check rows-complete --show-extract --write-extract incomplete_failing_rows\n\nNote here in the output the additional lines stating that failing rows were saved to a folder (incomplete_failing_rows) and, within that folder the step_01_rows_complete.csv file was written. Using a folder for extracts is necessary in practice since there may be multiple validations defined in a pb validate command.\n\n\n6.6.5 Advanced Options and CI/CD Integration\n\nuse --exit-code to make the command exit with a non-zero code if any check fails; useful for CI/CD pipelines\nuse --limit to control how many failing rows are shown or saved\nuse --list-checks to see all available validation checks and their options\n\npb validate worldcities.csv --check col-vals-not-null --column city_name --exit-code"
  },
  {
    "objectID": "user-guide-pdf.html#pb-run-custom-validation-workflows-with-python",
    "href": "user-guide-pdf.html#pb-run-custom-validation-workflows-with-python",
    "title": "CLI Reference",
    "section": "6.7 pb run: Custom Validation Workflows with Python",
    "text": "6.7 pb run: Custom Validation Workflows with Python\nFor more complex validation logic, use the pb run command. This lets you execute a Python script containing Pointblank validation steps, combining the flexibility of the Python API with the convenience of the CLI.\nYou can always scaffold a template script using the pb make-template command:\npb make-template my_validation.py\n\nBut for our example, we’ll elect to make our own worldcities_validation.py file from scratch. It will:\n\nuse the worldcities.csv file\napply two thresholds (one for ‘warning’, another for ‘error’)\nhave six validation steps\n\nHere’s what it looks like:\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(\n        data=\"worldcities.csv\",\n        thresholds=pb.Thresholds(\n            warning=1,  # 1 failure\n            error=0.05,  # 5% of rows failing\n        ),\n    )\n    .col_schema_match(\n        schema=pb.Schema(\n            columns=[\n                (\"city_name\", \"object\"),\n                (\"latitude\", \"float64\"),\n                (\"longitude\", \"float64\"),\n                (\"country\", \"object\"),\n                (\"population\", \"float64\"),\n            ]\n        ),\n    )\n    .col_vals_not_null(columns=\"city_name\")\n    .col_vals_not_null(columns=\"population\")\n    .col_vals_gt(columns=\"population\", value=0, na_pass=True)\n    .col_vals_between(columns=\"latitude\", left=-90, right=90)\n    .col_vals_between(columns=\"longitude\", left=-180, right=180)\n    .interrogate()\n)\nNow, we’ll run the .py script from the terminal:\npb run worldcities_validation.py\n\nYou’ll see a summary table that lists all of the steps and their results and you can include as many steps and as much logic as you need.\n\n6.7.1 Output Options\nYou could save the validation report as HTML or JSON (or both) for the purposes of sharing or for automation:\npb run worldcities_validation.py --output-html report.html --output-json report.json\n\nThere are also the options to produce extracts (subset of failing rows) with --show-extract or --write-extract (just like with pb validate). Let’s do both in the following example:\npb run worldcities_validation.py --show-extract --write-extract worldcities_failures\n\nThis shows a preview of each extract for those validation steps where extracts were produced (steps 2, 3, and 4). Individual CSV files with extracted rows for those steps were written to the worldcities_failures directory.\n\n\n6.7.2 Controlling Failure Behavior\nIt’s possible to use the --fail-on option to control when the command should exit with an error, based on the severity of validation failures. This is especially useful for automated workflows and CI/CD pipelines.\nLet’s try that with our worldcities_validation.py validation, which we’ve seen exeeds the ‘warning’ in steps 2, 3, and 4:\npb run worldcities_validation.py --fail-on warning\n\nNotice the final line states Exiting with error due to warning, error, or critical validation failures. Because we applied --fail-on warning, any presence of `warning’ (or higher levels such as ‘error’ or ‘critical’) will yield a non-zero exit code that should stop a pipeline process. We can prove this by running the following lines in the terminal\npb run worldcities_validation.py --fail-on warning &gt; /dev/null 2&gt;&1\necho $?\nwhich returns 1."
  },
  {
    "objectID": "user-guide-pdf.html#wrapping-up-2",
    "href": "user-guide-pdf.html#wrapping-up-2",
    "title": "CLI Reference",
    "section": "6.8 Wrapping Up",
    "text": "6.8 Wrapping Up\nPointblank’s CLI gives you powerful tools for validating your data, whether you need a quick check or a custom workflow. Use pb validate for fast, one-liner checks and pb run for more advanced, scriptable validation logic. With clear output and flexible options, you can catch data issues early and keep your workflows running smoothly.\nThis page provides a complete reference for all Pointblank CLI commands. Each section shows the full help text as it appears in the terminal, giving you quick access to all available options and examples.\nFor practical usage examples and workflows, see the CLI Data Validation and CLI Data Inspection guides."
  },
  {
    "objectID": "user-guide-pdf.html#pb---main-command",
    "href": "user-guide-pdf.html#pb---main-command",
    "title": "CLI Reference",
    "section": "6.9 pb - Main Command",
    "text": "6.9 pb - Main Command\nThe main entry point for all Pointblank CLI operations:\n\nUsage: pb [OPTIONS] COMMAND [ARGS]...\n\n  Pointblank CLI: Data validation and quality tools for data engineers.\n\n  Use this CLI to validate data quality, explore datasets, and generate\n  comprehensive reports for CSV, Parquet, and database sources. Suitable for\n  data pipelines, ETL validation, and exploratory data analysis from the\n  command line.\n\n  Quick Examples:\n\n    pb preview data.csv              Preview your data\n    pb scan data.csv                 Generate data profile\n    pb validate data.csv             Run basic validation\n\n  Use pb COMMAND --help for detailed help on any command.\n\nOptions:\n  -v, --version  Show the version and exit.\n  -h, --help     Show this message and exit.\n\nCommands:\n  info           Display information about a data source.\n  preview        Preview a data table showing head and tail rows.\n  scan           Generate a data scan profile report.\n  missing        Generate a missing values report for a data table.\n  validate       Perform single or multiple data validations.\n  run            Run a Pointblank validation script or YAML configuration.\n  make-template  Create a validation script or YAML configuration template.\n  pl             Execute Polars expressions and display results.\n  datasets       List available built-in datasets.\n  requirements   Check installed dependencies and their availability."
  },
  {
    "objectID": "user-guide-pdf.html#pb-info---data-source-information",
    "href": "user-guide-pdf.html#pb-info---data-source-information",
    "title": "CLI Reference",
    "section": "6.10 pb info - Data Source Information",
    "text": "6.10 pb info - Data Source Information\nDisplay basic information about a data source:\n\nUsage: pb info [OPTIONS] [DATA_SOURCE]\n\n  Display information about a data source.\n\n  Shows table type, dimensions, column names, and data types.\n\n  DATA_SOURCE can be:\n\n  - CSV file path (e.g., data.csv)\n  - Parquet file path or pattern (e.g., data.parquet, data/*.parquet)\n  - GitHub URL to CSV/Parquet (e.g., https://github.com/user/repo/blob/main/data.csv)\n  - Database connection string (e.g., duckdb:///path/to/db.ddb::table_name)\n  - Dataset name from pointblank (small_table, game_revenue, nycflights, global_sales)\n\nOptions:\n  --help  Show this message and exit."
  },
  {
    "objectID": "user-guide-pdf.html#pb-preview---data-table-preview",
    "href": "user-guide-pdf.html#pb-preview---data-table-preview",
    "title": "CLI Reference",
    "section": "6.11 pb preview - Data Table Preview",
    "text": "6.11 pb preview - Data Table Preview\nPreview data showing head and tail rows:\n\nUsage: pb preview [OPTIONS] [DATA_SOURCE]\n\n  Preview a data table showing head and tail rows.\n\n  DATA_SOURCE can be:\n\n  - CSV file path (e.g., data.csv)\n  - Parquet file path or pattern (e.g., data.parquet, data/*.parquet)\n  - GitHub URL to CSV/Parquet (e.g., https://github.com/user/repo/blob/main/data.csv)\n  - Database connection string (e.g., duckdb:///path/to/db.ddb::table_name)\n  - Dataset name from pointblank (small_table, game_revenue, nycflights, global_sales)\n  - Piped data from pb pl command\n\n  COLUMN SELECTION OPTIONS:\n\n  For tables with many columns, use these options to control which columns are\n  displayed:\n\n  - --columns: Specify exact columns (e.g., --columns \"name,age,email\")\n  - --col-range: Select column range (e.g., --col-range \"1:10\", --col-range \"5:\", --col-range \":15\")\n  - --col-first: Show first N columns (e.g., --col-first 5)\n  - --col-last: Show last N columns (e.g., --col-last 3)\n\n  Tables with &gt;15 columns automatically show first 7 and last 7 columns with\n  indicators.\n\nOptions:\n  --columns TEXT             Comma-separated list of columns to display\n  --col-range TEXT           Column range like '1:10' or '5:' or ':15'\n                             (1-based indexing)\n  --col-first INTEGER        Show first N columns\n  --col-last INTEGER         Show last N columns\n  --head INTEGER             Number of rows from the top (default: 5)\n  --tail INTEGER             Number of rows from the bottom (default: 5)\n  --limit INTEGER            Maximum total rows to display (default: 50)\n  --no-row-numbers           Hide row numbers\n  --max-col-width INTEGER    Maximum column width in pixels (default: 250)\n  --min-table-width INTEGER  Minimum table width in pixels (default: 500)\n  --no-header                Hide table header\n  --output-html PATH         Save HTML output to file\n  --help                     Show this message and exit."
  },
  {
    "objectID": "user-guide-pdf.html#pb-scan---data-profile-reports",
    "href": "user-guide-pdf.html#pb-scan---data-profile-reports",
    "title": "CLI Reference",
    "section": "6.12 pb scan - Data Profile Reports",
    "text": "6.12 pb scan - Data Profile Reports\nGenerate comprehensive data profiles:\n\nUsage: pb scan [OPTIONS] [DATA_SOURCE]\n\n  Generate a data scan profile report.\n\n  Produces a comprehensive data profile including:\n\n  - Column types and distributions\n  - Missing value patterns\n  - Basic statistics\n  - Data quality indicators\n\n  DATA_SOURCE can be:\n\n  - CSV file path (e.g., data.csv)\n  - Parquet file path or pattern (e.g., data.parquet, data/*.parquet)\n  - GitHub URL to CSV/Parquet (e.g., https://github.com/user/repo/blob/main/data.csv)\n  - Database connection string (e.g., duckdb:///path/to/db.ddb::table_name)\n  - Dataset name from pointblank (small_table, game_revenue, nycflights, global_sales)\n  - Piped data from pb pl command\n\nOptions:\n  --output-html PATH  Save HTML scan report to file\n  -c, --columns TEXT  Comma-separated list of columns to scan\n  --help              Show this message and exit."
  },
  {
    "objectID": "user-guide-pdf.html#pb-missing---missing-values-reports",
    "href": "user-guide-pdf.html#pb-missing---missing-values-reports",
    "title": "CLI Reference",
    "section": "6.13 pb missing - Missing Values Reports",
    "text": "6.13 pb missing - Missing Values Reports\nGenerate reports focused on missing values:\n\nUsage: pb missing [OPTIONS] [DATA_SOURCE]\n\n  Generate a missing values report for a data table.\n\n  DATA_SOURCE can be:\n\n  - CSV file path (e.g., data.csv)\n  - Parquet file path or pattern (e.g., data.parquet, data/*.parquet)\n  - GitHub URL to CSV/Parquet (e.g., https://github.com/user/repo/blob/main/data.csv)\n  - Database connection string (e.g., duckdb:///path/to/db.ddb::table_name)\n  - Dataset name from pointblank (small_table, game_revenue, nycflights, global_sales)\n  - Piped data from pb pl command\n\nOptions:\n  --output-html PATH  Save HTML output to file\n  --help              Show this message and exit."
  },
  {
    "objectID": "user-guide-pdf.html#pb-validate---quick-data-validations",
    "href": "user-guide-pdf.html#pb-validate---quick-data-validations",
    "title": "CLI Reference",
    "section": "6.14 pb validate - Quick Data Validations",
    "text": "6.14 pb validate - Quick Data Validations\nPerform single or multiple data validations:\n\nUsage: pb validate [OPTIONS] [DATA_SOURCE]\n\n  Perform single or multiple data validations.\n\n  Run one or more validation checks on your data in a single command. Use\n  multiple --check options to perform multiple validations.\n\n  DATA_SOURCE can be:\n\n  - CSV file path (e.g., data.csv)\n  - Parquet file path or pattern (e.g., data.parquet, data/*.parquet)\n  - GitHub URL to CSV/Parquet (e.g., https://github.com/user/repo/blob/main/data.csv)\n  - Database connection string (e.g., duckdb:///path/to/db.ddb::table_name)\n  - Dataset name from pointblank (small_table, game_revenue, nycflights, global_sales)\n\n  AVAILABLE CHECK_TYPES:\n\n  Require no additional options:\n\n  - rows-distinct: Check if all rows in the dataset are unique (no duplicates)\n  - rows-complete: Check if all rows are complete (no missing values in any column)\n\n  Require --column:\n\n  - col-exists: Check if a specific column exists in the dataset\n  - col-vals-not-null: Check if all values in a column are not null/missing\n\n  Require --column and --value:\n\n  - col-vals-gt: Check if column values are greater than a fixed value\n  - col-vals-ge: Check if column values are greater than or equal to a fixed value\n  - col-vals-lt: Check if column values are less than a fixed value\n  - col-vals-le: Check if column values are less than or equal to a fixed value\n\n  Require --column and --set:\n\n  - col-vals-in-set: Check if column values are in an allowed set\n\n  Use --list-checks to see all available validation methods with examples. The\n  default CHECK_TYPE is 'rows-distinct' which checks for duplicate rows.\n\n  Examples:\n\n  pb validate data.csv                               # Uses default validation (rows-distinct)\n  pb validate data.csv --list-checks                 # Show all available checks\n  pb validate data.csv --check rows-distinct\n  pb validate data.csv --check rows-distinct --show-extract\n  pb validate data.csv --check rows-distinct --write-extract failing_rows_folder\n  pb validate data.csv --check rows-distinct --exit-code\n  pb validate data.csv --check col-exists --column price\n  pb validate data.csv --check col-vals-not-null --column email\n  pb validate data.csv --check col-vals-gt --column score --value 50\n  pb validate data.csv --check col-vals-in-set --column status --set \"active,inactive,pending\"\n\n  Multiple validations in one command: pb validate data.csv --check rows-\n  distinct --check rows-complete\n\nOptions:\n  --list-checks         List available validation checks and exit\n  --check CHECK_TYPE    Type of validation check to perform. Can be used\n                        multiple times for multiple checks.\n  --column TEXT         Column name or integer position as #N (1-based index)\n                        for validation.\n  --set TEXT            Comma-separated allowed values for col-vals-in-set\n                        checks.\n  --value FLOAT         Numeric value for comparison checks.\n  --show-extract        Show extract of failing rows if validation fails\n  --write-extract TEXT  Save failing rows to folder. Provide base name for\n                        folder.\n  --limit INTEGER       Maximum number of failing rows to save to CSV\n                        (default: 500)\n  --exit-code           Exit with non-zero code if validation fails\n  --help                Show this message and exit."
  },
  {
    "objectID": "user-guide-pdf.html#pb-run---validation-scripts-and-yaml",
    "href": "user-guide-pdf.html#pb-run---validation-scripts-and-yaml",
    "title": "CLI Reference",
    "section": "6.15 pb run - Validation Scripts and YAML",
    "text": "6.15 pb run - Validation Scripts and YAML\nRun Python validation scripts or YAML configurations:\n\nUsage: pb run [OPTIONS] [VALIDATION_FILE]\n\n  Run a Pointblank validation script or YAML configuration.\n\n  VALIDATION_FILE can be: - A Python file (.py) that defines validation logic\n  - A YAML configuration file (.yaml, .yml) that defines validation steps\n\n  Python scripts should load their own data and create validation objects.\n  YAML configurations define data sources and validation steps declaratively.\n\n  If --data is provided, it will automatically replace the data source in your\n  validation objects (Python scripts) or override the 'tbl' field (YAML\n  configs).\n\n  To get started quickly, use 'pb make-template' to create templates.\n\n  DATA can be:\n\n  - CSV file path (e.g., data.csv)\n  - Parquet file path or pattern (e.g., data.parquet, data/*.parquet)\n  - GitHub URL to CSV/Parquet (e.g., https://github.com/user/repo/blob/main/data.csv)\n  - Database connection string (e.g., duckdb:///path/to/db.ddb::table_name)\n  - Dataset name from pointblank (small_table, game_revenue, nycflights, global_sales)\n\n  Examples:\n\n  pb make-template my_validation.py  # Create a Python template\n  pb run validation_script.py\n  pb run validation_config.yaml\n  pb run validation_script.py --data data.csv\n  pb run validation_config.yaml --data small_table --output-html report.html\n  pb run validation_script.py --show-extract --fail-on error\n  pb run validation_config.yaml --write-extract extracts_folder --fail-on critical\n\nOptions:\n  --data TEXT                     Data source to replace in validation objects\n                                  (Python scripts and YAML configs)\n  --output-html PATH              Save HTML validation report to file\n  --output-json PATH              Save JSON validation summary to file\n  --show-extract                  Show extract of failing rows if validation\n                                  fails\n  --write-extract TEXT            Save failing rows to folders (one CSV per\n                                  step). Provide base name for folder.\n  --limit INTEGER                 Maximum number of failing rows to save to\n                                  CSV (default: 500)\n  --fail-on [critical|error|warning|any]\n                                  Exit with non-zero code when validation\n                                  reaches this threshold level\n  --help                          Show this message and exit."
  },
  {
    "objectID": "user-guide-pdf.html#pb-make-template---template-generation",
    "href": "user-guide-pdf.html#pb-make-template---template-generation",
    "title": "CLI Reference",
    "section": "6.16 pb make-template - Template Generation",
    "text": "6.16 pb make-template - Template Generation\nCreate validation script or YAML configuration templates:\n\nUsage: pb make-template [OPTIONS] [OUTPUT_FILE]\n\n  Create a validation script or YAML configuration template.\n\n  Creates a sample Python script or YAML configuration with examples showing\n  how to use Pointblank for data validation. The template type is determined\n  by the file extension: - .py files create Python script templates -\n  .yaml/.yml files create YAML configuration templates\n\n  Edit the template to add your own data loading and validation rules, then\n  run it with 'pb run'.\n\n  OUTPUT_FILE is the path where the template will be created.\n\n  Examples:\n\n  pb make-template my_validation.py        # Creates Python script template\n  pb make-template my_validation.yaml      # Creates YAML config template\n  pb make-template validation_template.yml # Creates YAML config template\n\nOptions:\n  --help  Show this message and exit."
  },
  {
    "objectID": "user-guide-pdf.html#pb-pl---polars-expression-execution",
    "href": "user-guide-pdf.html#pb-pl---polars-expression-execution",
    "title": "CLI Reference",
    "section": "6.17 pb pl - Polars Expression Execution",
    "text": "6.17 pb pl - Polars Expression Execution\nExecute Polars expressions and display results:\n\nUsage: pb pl [OPTIONS] [POLARS_EXPRESSION]\n\n  Execute Polars expressions and display results.\n\n  Execute Polars DataFrame operations from the command line and display the\n  results using Pointblank's visualization tools.\n\n  POLARS_EXPRESSION should be a valid Polars expression that returns a\n  DataFrame. The 'pl' module is automatically imported and available.\n\n  Examples:\n\n  # Direct expression\n  pb pl \"pl.read_csv('data.csv')\"\n  pb pl \"pl.read_csv('data.csv').select(['name', 'age'])\"\n  pb pl \"pl.read_csv('data.csv').filter(pl.col('age') &gt; 25)\"\n\n  # Multi-line with editor (supports multiple statements)\n  pb pl --edit\n\n  # Multi-statement code example in editor:\n  # csv = pl.read_csv('data.csv')\n  # result = csv.select(['name', 'age']).filter(pl.col('age') &gt; 25)\n\n  # Multi-line with a specific editor\n  pb pl --edit --editor nano\n  pb pl --edit --editor code\n  pb pl --edit --editor micro\n\n  # From file\n  pb pl --file query.py\n\n  Piping to other pb commands\n  pb pl \"pl.read_csv('data.csv').head(20)\" --pipe | pb validate --check rows-distinct\n  pb pl --edit --pipe | pb preview --head 10\n  pb pl --edit --pipe | pb scan --output-html report.html\n  pb pl --edit --pipe | pb missing --output-html missing_report.html\n\n  Use --output-format to change how results are displayed:\n  pb pl \"pl.read_csv('data.csv')\" --output-format scan\n  pb pl \"pl.read_csv('data.csv')\" --output-format missing\n  pb pl \"pl.read_csv('data.csv')\" --output-format info\n\n  Note: For multi-statement code, assign your final result to a variable like\n  'result', 'df', 'data', or ensure it's the last expression.\n\nOptions:\n  -e, --edit                      Open editor for multi-line input\n  -f, --file PATH                 Read query from file\n  --editor TEXT                   Editor to use for --edit mode (overrides\n                                  $EDITOR and auto-detection)\n  -o, --output-format [preview|scan|missing|info]\n                                  Output format for the result\n  --preview-head INTEGER          Number of head rows for preview\n  --preview-tail INTEGER          Number of tail rows for preview\n  --output-html PATH              Save HTML output to file\n  --pipe                          Output data in a format suitable for piping\n                                  to other pb commands\n  --pipe-format [parquet|csv]     Format for piped output (default: parquet)\n  --help                          Show this message and exit."
  },
  {
    "objectID": "user-guide-pdf.html#pb-datasets---built-in-datasets",
    "href": "user-guide-pdf.html#pb-datasets---built-in-datasets",
    "title": "CLI Reference",
    "section": "6.18 pb datasets - Built-in Datasets",
    "text": "6.18 pb datasets - Built-in Datasets\nList available built-in datasets:\n\nUsage: pb datasets [OPTIONS]\n\n  List available built-in datasets.\n\nOptions:\n  --help  Show this message and exit."
  },
  {
    "objectID": "user-guide-pdf.html#pb-requirements---dependency-check",
    "href": "user-guide-pdf.html#pb-requirements---dependency-check",
    "title": "CLI Reference",
    "section": "6.19 pb requirements - Dependency Check",
    "text": "6.19 pb requirements - Dependency Check\nCheck installed dependencies and their availability:\n\nUsage: pb requirements [OPTIONS]\n\n  Check installed dependencies and their availability.\n\nOptions:\n  --help  Show this message and exit."
  },
  {
    "objectID": "user-guide-pdf.html#common-data-source-types",
    "href": "user-guide-pdf.html#common-data-source-types",
    "title": "CLI Reference",
    "section": "6.20 Common Data Source Types",
    "text": "6.20 Common Data Source Types\nAll commands that accept a DATA_SOURCE parameter support these formats:\n\nCSV files: data.csv, path/to/data.csv\nParquet files: data.parquet, data/*.parquet (patterns supported)\nGitHub URLs: https://github.com/user/repo/blob/main/data.csv\nDatabase connections: duckdb:///path/to/db.ddb::table_name\nBuilt-in datasets: small_table, game_revenue, nycflights, global_sales\nPiped data: Output from pb pl command (where supported)"
  },
  {
    "objectID": "user-guide-pdf.html#exit-codes-and-automation",
    "href": "user-guide-pdf.html#exit-codes-and-automation",
    "title": "CLI Reference",
    "section": "6.21 Exit Codes and Automation",
    "text": "6.21 Exit Codes and Automation\nMany commands support options useful for automation and CI/CD:\n\n--exit-code: Exit with non-zero code on validation failure\n--fail-on [critical|error|warning|any]: Control failure thresholds\n--output-html, --output-json: Save reports for external consumption\n--write-extract: Save failing rows for investigation\n\nThese features make Pointblank CLI commands suitable for integration into data pipelines, quality gates, and automated workflows."
  },
  {
    "objectID": "reference/Validate.html",
    "href": "reference/Validate.html",
    "title": "Validate",
    "section": "",
    "text": "Validate(\n    data,\n    tbl_name=None,\n    label=None,\n    thresholds=None,\n    actions=None,\n    final_actions=None,\n    brief=None,\n    lang=None,\n    locale=None,\n)\nWorkflow for defining a set of validations on a table and interrogating for results.\nThe Validate class is used for defining a set of validation steps on a table and interrogating the table with the validation plan. This class is the main entry point for the data quality reporting workflow. The overall aim of this workflow is to generate comprehensive reporting information to assess the level of data quality for a target table.\nWe can supply as many validation steps as needed, and having a large number of them should increase the validation coverage for a given table. The validation methods (e.g., col_vals_gt(), col_vals_between(), etc.) translate to discrete validation steps, where each step will be sequentially numbered (useful when viewing the reporting data). This process of calling validation methods is known as developing a validation plan.\nThe validation methods, when called, are merely instructions up to the point the concluding interrogate() method is called. That kicks off the process of acting on the validation plan by querying the target table getting reporting results for each step. Once the interrogation process is complete, we can say that the workflow now has reporting information. We can then extract useful information from the reporting data to understand the quality of the table. Printing the Validate object (or using the get_tabular_report() method) will return a table with the results of the interrogation and get_sundered_data() allows for the splitting of the table based on passing and failing rows."
  },
  {
    "objectID": "reference/Validate.html#parameters",
    "href": "reference/Validate.html#parameters",
    "title": "Validate",
    "section": "Parameters",
    "text": "Parameters\n\ndata : FrameT | Any\n\nThe table to validate, which could be a DataFrame object, an Ibis table object, a CSV file path, a Parquet file path, a GitHub URL pointing to a CSV or Parquet file, or a database connection string. When providing a CSV or Parquet file path (as a string or pathlib.Path object), the file will be automatically loaded using an available DataFrame library (Polars or Pandas). Parquet input also supports glob patterns, directories containing .parquet files, and Spark-style partitioned datasets. GitHub URLs are automatically transformed to raw content URLs and downloaded. Connection strings enable direct database access via Ibis with optional table specification using the ::table_name suffix. Read the Supported Input Table Types section for details on the supported table types.\n\ntbl_name : str | None = None\n\nAn optional name to assign to the input table object. If no value is provided, a name will be generated based on whatever information is available. This table name will be displayed in the header area of the tabular report.\n\nlabel : str | None = None\n\nAn optional label for the validation plan. If no value is provided, a label will be generated based on the current system date and time. Markdown can be used here to make the label more visually appealing (it will appear in the header area of the tabular report).\n\nthresholds : int | float | bool | tuple | dict | Thresholds | None = None\n\nGenerate threshold failure levels so that all validation steps can report and react accordingly when exceeding the set levels. The thresholds are set at the global level and can be overridden at the validation step level (each validation step has its own thresholds= parameter). The default is None, which means that no thresholds will be set. Look at the Thresholds section for information on how to set threshold levels.\n\nactions : Actions | None = None\n\nThe actions to take when validation steps meet or exceed any set threshold levels. These actions are paired with the threshold levels and are executed during the interrogation process when there are exceedances. The actions are executed right after each step is evaluated. Such actions should be provided in the form of an Actions object. If None then no global actions will be set. View the Actions section for information on how to set actions.\n\nfinal_actions : FinalActions | None = None\n\nThe actions to take when the validation process is complete and the final results are available. This is useful for sending notifications or reporting the overall status of the validation process. The final actions are executed after all validation steps have been processed and the results have been collected. The final actions are not tied to any threshold levels, they are executed regardless of the validation results. Such actions should be provided in the form of a FinalActions object. If None then no finalizing actions will be set. Please see the Actions section for information on how to set final actions.\n\nbrief : str | bool | None = None\n\nA global setting for briefs, which are optional brief descriptions for validation steps (they be displayed in the reporting table). For such a global setting, templating elements like \"{step}\" (to insert the step number) or \"{auto}\" (to include an automatically generated brief) are useful. If True then each brief will be automatically generated. If None (the default) then briefs aren’t globally set.\n\nlang : str | None = None\n\nThe language to use for various reporting elements. By default, None will select English (\"en\") as the but other options include French (\"fr\"), German (\"de\"), Italian (\"it\"), Spanish (\"es\"), and several more. Have a look at the Reporting Languages section for the full list of supported languages and information on how the language setting is utilized.\n\nlocale : str | None = None\n\nAn optional locale ID to use for formatting values in the reporting table according the locale’s rules. Examples include \"en-US\" for English (United States) and \"fr-FR\" for French (France). More simply, this can be a language identifier without a designation of territory, like \"es\" for Spanish."
  },
  {
    "objectID": "reference/Validate.html#returns",
    "href": "reference/Validate.html#returns",
    "title": "Validate",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nA Validate object with the table and validations to be performed."
  },
  {
    "objectID": "reference/Validate.html#supported-input-table-types",
    "href": "reference/Validate.html#supported-input-table-types",
    "title": "Validate",
    "section": "Supported Input Table Types",
    "text": "Supported Input Table Types\nThe data= parameter can be given any of the following table types:\n\nPolars DataFrame (\"polars\")\nPandas DataFrame (\"pandas\")\nPySpark table (\"pyspark\")\nDuckDB table (\"duckdb\")*\nMySQL table (\"mysql\")*\nPostgreSQL table (\"postgresql\")*\nSQLite table (\"sqlite\")*\nMicrosoft SQL Server table (\"mssql\")*\nSnowflake table (\"snowflake\")*\nDatabricks table (\"databricks\")*\nBigQuery table (\"bigquery\")*\nParquet table (\"parquet\")*\nCSV files (string path or pathlib.Path object with .csv extension)\nParquet files (string path, pathlib.Path object, glob pattern, directory with .parquet extension, or partitioned dataset)\nDatabase connection strings (URI format with optional table specification)\n\nThe table types marked with an asterisk need to be prepared as Ibis tables (with type of ibis.expr.types.relations.Table). Furthermore, the use of Validate with such tables requires the Ibis library v9.5.0 and above to be installed. If the input table is a Polars or Pandas DataFrame, the Ibis library is not required.\nTo use a CSV file, ensure that a string or pathlib.Path object with a .csv extension is provided. The file will be automatically detected and loaded using the best available DataFrame library. The loading preference is Polars first, then Pandas as a fallback.\nConnection strings follow database URL formats and must also specify a table using the ::table_name suffix. Examples include:\n\"duckdb:///path/to/database.ddb::table_name\"\n\"sqlite:///path/to/database.db::table_name\"\n\"postgresql://user:password@localhost:5432/database::table_name\"\n\"mysql://user:password@localhost:3306/database::table_name\"\n\"bigquery://project/dataset::table_name\"\n\"snowflake://user:password@account/database/schema::table_name\"\nWhen using connection strings, the Ibis library with the appropriate backend driver is required."
  },
  {
    "objectID": "reference/Validate.html#thresholds",
    "href": "reference/Validate.html#thresholds",
    "title": "Validate",
    "section": "Thresholds",
    "text": "Thresholds\nThe thresholds= parameter is used to set the failure-condition levels for all validation steps. They are set here at the global level but can be overridden at the validation step level (each validation step has its own local thresholds= parameter).\nThere are three threshold levels: ‘warning’, ‘error’, and ‘critical’. The threshold values can either be set as a proportion failing of all test units (a value between 0 to 1), or, the absolute number of failing test units (as integer that’s 1 or greater).\nThresholds can be defined using one of these input schemes:\n\nuse the Thresholds class (the most direct way to create thresholds)\nprovide a tuple of 1-3 values, where position 0 is the ‘warning’ level, position 1 is the ‘error’ level, and position 2 is the ‘critical’ level\ncreate a dictionary of 1-3 value entries; the valid keys: are ‘warning’, ‘error’, and ‘critical’\na single integer/float value denoting absolute number or fraction of failing test units for the ‘warning’ level only\n\nIf the number of failing test units for a validation step exceeds set thresholds, the validation step will be marked as ‘warning’, ‘error’, or ‘critical’. All of the threshold levels don’t need to be set, you’re free to set any combination of them.\nAside from reporting failure conditions, thresholds can be used to determine the actions to take for each level of failure (using the actions= parameter)."
  },
  {
    "objectID": "reference/Validate.html#actions",
    "href": "reference/Validate.html#actions",
    "title": "Validate",
    "section": "Actions",
    "text": "Actions\nThe actions= and final_actions= parameters provide mechanisms to respond to validation results. These actions can be used to notify users of validation failures, log issues, or trigger other processes when problems are detected.\nStep Actions\nThe actions= parameter allows you to define actions that are triggered when validation steps exceed specific threshold levels (warning, error, or critical). These actions are executed during the interrogation process, right after each step is evaluated.\nStep actions should be provided using the Actions class, which lets you specify different actions for different severity levels:\n# Define an action that logs a message when warning threshold is exceeded\ndef log_warning():\n    metadata = pb.get_action_metadata()\n    print(f\"WARNING: Step {metadata['step']} failed with type {metadata['type']}\")\n\n# Define actions for different threshold levels\nactions = pb.Actions(\n    warning = log_warning,\n    error = lambda: send_email(\"Error in validation\"),\n    critical = \"CRITICAL FAILURE DETECTED\"\n)\n\n# Use in Validate\nvalidation = pb.Validate(\n    data=my_data,\n    actions=actions  # Global actions for all steps\n)\nYou can also provide step-specific actions in individual validation methods:\nvalidation.col_vals_gt(\n    columns=\"revenue\",\n    value=0,\n    actions=pb.Actions(warning=log_warning)  # Only applies to this step\n)\nStep actions have access to step-specific context through the get_action_metadata() function, which provides details about the current validation step that triggered the action.\nFinal Actions\nThe final_actions= parameter lets you define actions that execute after all validation steps have completed. These are useful for providing summaries, sending notifications based on overall validation status, or performing cleanup operations.\nFinal actions should be provided using the FinalActions class:\ndef send_report():\n    summary = pb.get_validation_summary()\n    if summary[\"status\"] == \"CRITICAL\":\n        send_alert_email(\n            subject=f\"CRITICAL validation failures in {summary['tbl_name']}\",\n            body=f\"{summary['critical_steps']} steps failed with critical severity.\"\n        )\n\nvalidation = pb.Validate(\n    data=my_data,\n    final_actions=pb.FinalActions(send_report)\n)\nFinal actions have access to validation-wide summary information through the get_validation_summary() function, which provides a comprehensive overview of the entire validation process.\nThe combination of step actions and final actions provides a flexible system for responding to data quality issues at both the individual step level and the overall validation level."
  },
  {
    "objectID": "reference/Validate.html#reporting-languages",
    "href": "reference/Validate.html#reporting-languages",
    "title": "Validate",
    "section": "Reporting Languages",
    "text": "Reporting Languages\nVarious pieces of reporting in Pointblank can be localized to a specific language. This is done by setting the lang= parameter in Validate. Any of the following languages can be used (just provide the language code):\n\nEnglish (\"en\")\nFrench (\"fr\")\nGerman (\"de\")\nItalian (\"it\")\nSpanish (\"es\")\nPortuguese (\"pt\")\nDutch (\"nl\")\nSwedish (\"sv\")\nDanish (\"da\")\nNorwegian Bokmål (\"nb\")\nIcelandic (\"is\")\nFinnish (\"fi\")\nPolish (\"pl\")\nCzech (\"cs\")\nRomanian (\"ro\")\nGreek (\"el\")\nRussian (\"ru\")\nTurkish (\"tr\")\nArabic (\"ar\")\nHindi (\"hi\")\nSimplified Chinese (\"zh-Hans\")\nTraditional Chinese (\"zh-Hant\")\nJapanese (\"ja\")\nKorean (\"ko\")\nVietnamese (\"vi\")\nIndonesian (\"id\")\nUkrainian (\"uk\")\nBulgarian (\"bg\")\nCroatian (\"hr\")\nEstonian (\"et\")\nHungarian (\"hu\")\nIrish (\"ga\")\nLatvian (\"lv\")\nLithuanian (\"lt\")\nMaltese (\"mt\")\nSlovak (\"sk\")\nSlovenian (\"sl\")\nHebrew (\"he\")\nThai (\"th\")\nPersian (\"fa\")\n\nAutomatically generated briefs (produced by using brief=True or brief=\"...{auto}...\") will be written in the selected language. The language setting will also used when generating the validation report table through get_tabular_report() (or printing the Validate object in a notebook environment)."
  },
  {
    "objectID": "reference/Validate.html#examples",
    "href": "reference/Validate.html#examples",
    "title": "Validate",
    "section": "Examples",
    "text": "Examples\n\nCreating a validation plan and interrogating\nLet’s walk through a data quality analysis of an extremely small table. It’s actually called \"small_table\" and it’s accessible through the load_dataset() function.\n\nimport pointblank as pb\n\n# Load the `small_table` dataset\nsmall_table = pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\")\n\n# Preview the table\npb.preview(small_table)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows13Columns8\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05\n    6\n    8-kdg-938\n    3\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    None\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09\n    8\n    3-ldm-038\n    7\n    283.94\n    True\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26\n    4\n    2-dmx-010\n    7\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28\n    2\n    7-dmx-010\n    8\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30\n    1\n    3-dka-303\n    None\n    2230.09\n    True\n    high\n  \n\n\n\n\n\n\n        \n\n\nWe ought to think about what’s tolerable in terms of data quality so let’s designate proportional failure thresholds to the ‘warning’, ‘error’, and ‘critical’ states. This can be done by using the Thresholds class.\n\nthresholds = pb.Thresholds(warning=0.10, error=0.25, critical=0.35)\n\nNow, we use the Validate class and give it the thresholds object (which serves as a default for all validation steps but can be overridden). The static thresholds provided in thresholds= will make the reporting a bit more useful. We also need to provide a target table and we’ll use small_table for this.\n\nvalidation = (\n    pb.Validate(\n        data=small_table,\n        tbl_name=\"small_table\",\n        label=\"`Validate` example.\",\n        thresholds=thresholds\n    )\n)\n\nThen, as with any Validate object, we can add steps to the validation plan by using as many validation methods as we want. To conclude the process (and actually query the data table), we use the interrogate() method.\n\nvalidation = (\n    validation\n    .col_vals_gt(columns=\"d\", value=100)\n    .col_vals_le(columns=\"c\", value=5)\n    .col_vals_between(columns=\"c\", left=3, right=10, na_pass=True)\n    .col_vals_regex(columns=\"b\", pattern=r\"[0-9]-[a-z]{3}-[0-9]{3}\")\n    .col_exists(columns=[\"date\", \"date_time\"])\n    .interrogate()\n)\n\nThe validation object can be printed as a reporting table.\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    `Validate` example.Polarssmall_tableWARNING0.1ERROR0.25CRITICAL0.35\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    100\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #FF3300\n    2\n    \n        \n            \n\n    col_vals_le\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_le()\n        \n        \n        \n    c\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    50.38\n    80.62\n    ●\n    ●\n    ●\n    CSV\n  \n  \n    #4CA64C66\n    3\n    \n        \n            \n\n    col_vals_between\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_between()\n        \n        \n        \n    c\n    [3, 10]\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    120.92\n    10.08\n    ○\n    ○\n    ○\n    CSV\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    b\n    [0-9]-[a-z]{3}-[0-9]{3}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C\n    5\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    date\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C\n    6\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    date_time\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:10:56 UTC&lt; 1 s2025-11-23 00:10:56 UTC\n  \n\n\n\n\n\n\n        \n\n\nThe report could be further customized by using the get_tabular_report() method, which contains options for modifying the display of the table.\n\n\nAdding briefs\nBriefs are short descriptions of the validation steps. While they can be set for each step individually, they can also be set globally. The global setting is done by using the brief= argument in Validate. The global setting can be as simple as True to have automatically-generated briefs for each step. Alternatively, we can use templating elements like \"{step}\" (to insert the step number) or \"{auto}\" (to include an automatically generated brief). Here’s an example of a global setting for briefs:\n\nvalidation_2 = (\n    pb.Validate(\n        data=pb.load_dataset(),\n        tbl_name=\"small_table\",\n        label=\"Validation example with briefs\",\n        brief=\"Step {step}: {auto}\",\n    )\n    .col_vals_gt(columns=\"d\", value=100)\n    .col_vals_between(columns=\"c\", left=3, right=10, na_pass=True)\n    .col_vals_regex(\n        columns=\"b\",\n        pattern=r\"[0-9]-[a-z]{3}-[0-9]{3}\",\n        brief=\"Regex check for column {col}\"\n    )\n    .interrogate()\n)\n\nvalidation_2\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Validation example with briefsPolarssmall_table\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Step 1: Expect that values in d should be &gt; 100.\n\n        \n    d\n    100\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_between\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_between()\n        \n        Step 2: Expect that values in c should be between 3 and 10.\n\n        \n    c\n    [3, 10]\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    120.92\n    10.08\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        Regex check for column b\n\n        \n    b\n    [0-9]-[a-z]{3}-[0-9]{3}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:10:56 UTC&lt; 1 s2025-11-23 00:10:56 UTC\n  \n\n\n\n\n\n\n        \n\n\nWe see the text of the briefs appear in the STEP column of the reporting table. Furthermore, the global brief’s template (\"Step {step}: {auto}\") is applied to all steps except for the final step, where the step-level brief= argument provided an override.\nIf you should want to cancel the globally-defined brief for one or more validation steps, you can set brief=False in those particular steps.\n\n\nPost-interrogation methods\nThe Validate class has a number of post-interrogation methods that can be used to extract useful information from the validation results. For example, the get_data_extracts() method can be used to get the data extracts for each validation step.\n\nvalidation_2.get_data_extracts()\n\n{1: shape: (0, 9)\n ┌───────────┬──────────────┬──────┬─────┬───┬─────┬─────┬──────┬─────┐\n │ _row_num_ ┆ date_time    ┆ date ┆ a   ┆ … ┆ c   ┆ d   ┆ e    ┆ f   │\n │ ---       ┆ ---          ┆ ---  ┆ --- ┆   ┆ --- ┆ --- ┆ ---  ┆ --- │\n │ u32       ┆ datetime[μs] ┆ date ┆ i64 ┆   ┆ i64 ┆ f64 ┆ bool ┆ str │\n ╞═══════════╪══════════════╪══════╪═════╪═══╪═════╪═════╪══════╪═════╡\n └───────────┴──────────────┴──────┴─────┴───┴─────┴─────┴──────┴─────┘,\n 2: shape: (1, 9)\n ┌───────────┬─────────────────────┬────────────┬─────┬───┬─────┬─────────┬───────┬─────┐\n │ _row_num_ ┆ date_time           ┆ date       ┆ a   ┆ … ┆ c   ┆ d       ┆ e     ┆ f   │\n │ ---       ┆ ---                 ┆ ---        ┆ --- ┆   ┆ --- ┆ ---     ┆ ---   ┆ --- │\n │ u32       ┆ datetime[μs]        ┆ date       ┆ i64 ┆   ┆ i64 ┆ f64     ┆ bool  ┆ str │\n ╞═══════════╪═════════════════════╪════════════╪═════╪═══╪═════╪═════════╪═══════╪═════╡\n │ 8         ┆ 2016-01-17 11:27:00 ┆ 2016-01-17 ┆ 4   ┆ … ┆ 2   ┆ 1035.64 ┆ false ┆ low │\n └───────────┴─────────────────────┴────────────┴─────┴───┴─────┴─────────┴───────┴─────┘,\n 3: shape: (0, 9)\n ┌───────────┬──────────────┬──────┬─────┬───┬─────┬─────┬──────┬─────┐\n │ _row_num_ ┆ date_time    ┆ date ┆ a   ┆ … ┆ c   ┆ d   ┆ e    ┆ f   │\n │ ---       ┆ ---          ┆ ---  ┆ --- ┆   ┆ --- ┆ --- ┆ ---  ┆ --- │\n │ u32       ┆ datetime[μs] ┆ date ┆ i64 ┆   ┆ i64 ┆ f64 ┆ bool ┆ str │\n ╞═══════════╪══════════════╪══════╪═════╪═══╪═════╪═════╪══════╪═════╡\n └───────────┴──────────────┴──────┴─────┴───┴─────┴─────┴──────┴─────┘}\n\n\nWe can also view step reports for each validation step using the get_step_report() method. This method adapts to the type of validation step and shows the relevant information for a step’s validation.\n\nvalidation_2.get_step_report(i=2)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 2ASSERTION 3 ≤ c ≤ 101 / 13 TEST UNIT FAILURES IN COLUMN 5 EXTRACT OF ALL 1 ROWS (WITH TEST UNIT FAILURES IN RED):\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    8\n    2016-01-17 11:27:00\n    2016-01-17\n    4\n    5-boe-639\n    2\n    1035.64\n    False\n    low\n  \n\n\n\n\n\n\n        \n\n\nThe Validate class also has a method for getting the sundered data, which is the data that passed or failed the validation steps. This can be done using the get_sundered_data() method.\n\npb.preview(validation_2.get_sundered_data())\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows12Columns8\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05\n    6\n    8-kdg-938\n    3\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    None\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09\n    8\n    3-ldm-038\n    7\n    283.94\n    True\n    low\n  \n  \n    8\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-26 20:07:00\n    2016-01-26\n    4\n    2-dmx-010\n    7\n    833.98\n    True\n    low\n  \n  \n    11\n    2016-01-28 02:51:00\n    2016-01-28\n    2\n    7-dmx-010\n    8\n    108.34\n    False\n    low\n  \n  \n    12\n    2016-01-30 11:23:00\n    2016-01-30\n    1\n    3-dka-303\n    None\n    2230.09\n    True\n    high\n  \n\n\n\n\n\n\n        \n\n\nThe sundered data is a DataFrame that contains the rows that passed or failed the validation. The default behavior is to return the rows that failed the validation, as shown above.\n\n\nWorking with CSV Files\nThe Validate class can directly accept CSV file paths, making it easy to validate data stored in CSV files without manual loading:\n\n# Get a path to a CSV file from the package data\ncsv_path = pb.get_data_path(\"global_sales\", \"csv\")\n\nvalidation_3 = (\n    pb.Validate(\n        data=csv_path,\n        label=\"CSV validation example\"\n    )\n    .col_exists([\"customer_id\", \"product_id\", \"revenue\"])\n    .col_vals_not_null([\"customer_id\", \"product_id\"])\n    .col_vals_gt(columns=\"revenue\", value=0)\n    .interrogate()\n)\n\nvalidation_3\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    CSV validation examplePolars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    customer_id\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    product_id\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    revenue\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C66\n    4\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    customer_id\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    50.0K\n    49.7K0.99\n    3340.01\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    5\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    product_id\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    50.0K\n    49.7K0.99\n    3350.01\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    6\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    revenue\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    50.0K\n    50.0K1.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:10:56 UTC&lt; 1 s2025-11-23 00:10:56 UTC\n  \n\n\n\n\n\n\n        \n\n\nYou can also use a Path object to specify the CSV file. Here’s an example of how to do that:\n\nfrom pathlib import Path\n\ncsv_file = Path(pb.get_data_path(\"game_revenue\", \"csv\"))\n\nvalidation_4 = (\n    pb.Validate(data=csv_file, label=\"Game Revenue Validation\")\n    .col_exists([\"player_id\", \"session_id\", \"item_name\"])\n    .col_vals_regex(\n        columns=\"session_id\",\n        pattern=r\"[A-Z0-9]{8}-[A-Z0-9]{4}-[A-Z0-9]{4}-[A-Z0-9]{4}-[A-Z0-9]{12}\"\n    )\n    .col_vals_gt(columns=\"item_revenue\", value=0, na_pass=True)\n    .interrogate()\n)\n\nvalidation_4\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Game Revenue ValidationPolars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    player_id\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    session_id\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    item_name\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C66\n    4\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    session_id\n    [A-Z0-9]{8}-[A-Z0-9]{4}-[A-Z0-9]{4}-[A-Z0-9]{4}-[A-Z0-9]{12}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    00.00\n    20001.00\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    5\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    item_revenue\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:10:57 UTC&lt; 1 s2025-11-23 00:10:57 UTC\n  \n\n\n\n\n\n\n        \n\n\nThe CSV loading is automatic, so when a string or Path with a .csv extension is provided, Pointblank will automatically load the file using the best available DataFrame library (Polars preferred, Pandas as fallback). The loaded data can then be used with all validation methods just like any other supported table type.\n\n\nWorking with Parquet Files\nThe Validate class can directly accept Parquet files and datasets in various formats. The following examples illustrate how to validate Parquet files:\n\n# Single Parquet file from package data\nparquet_path = pb.get_data_path(\"nycflights\", \"parquet\")\n\nvalidation_5 = (\n    pb.Validate(\n        data=parquet_path,\n        tbl_name=\"NYC Flights Data\"\n    )\n    .col_vals_not_null([\"carrier\", \"origin\", \"dest\"])\n    .col_vals_gt(columns=\"distance\", value=0)\n    .interrogate()\n)\n\nvalidation_5\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:10:57PolarsNYC Flights Data\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    carrier\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    337K\n    337K1.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    origin\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    337K\n    337K1.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    dest\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    337K\n    337K1.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    distance\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    337K\n    337K1.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:10:57 UTC&lt; 1 s2025-11-23 00:10:57 UTC\n  \n\n\n\n\n\n\n        \n\n\nYou can also use glob patterns and directories. Here are some examples for how to:\n\nload multiple Parquet files\nload a Parquet-containing directory\nload a partitioned Parquet dataset\n\n# Multiple Parquet files with glob patterns\nvalidation_6 = pb.Validate(data=\"data/sales_*.parquet\")\n\n# Directory containing Parquet files\nvalidation_7 = pb.Validate(data=\"parquet_data/\")\n\n# Partitioned Parquet dataset\nvalidation_8 = (\n    pb.Validate(data=\"sales_data/\")  # Contains year=2023/quarter=Q1/region=US/sales.parquet\n    .col_exists([\"transaction_id\", \"amount\", \"year\", \"quarter\", \"region\"])\n    .interrogate()\n)\nWhen you point to a directory that contains a partitioned Parquet dataset (with subdirectories like year=2023/quarter=Q1/region=US/), Pointblank will automatically:\n\ndiscover all Parquet files recursively\nextract partition column values from directory paths\nadd partition columns to the final DataFrame\ncombine all partitions into a single table for validation\n\nBoth Polars and Pandas handle partitioned datasets natively, so this works seamlessly with either DataFrame library. The loading preference is Polars first, then Pandas as a fallback.\n\n\nWorking with Database Connection Strings\nThe Validate class supports database connection strings for direct validation of database tables. Connection strings must specify a table using the ::table_name suffix:\n\n# Get path to a DuckDB database file from package data\nduckdb_path = pb.get_data_path(\"game_revenue\", \"duckdb\")\n\nvalidation_9 = (\n    pb.Validate(\n        data=f\"duckdb:///{duckdb_path}::game_revenue\",\n        label=\"DuckDB Game Revenue Validation\"\n    )\n    .col_exists([\"player_id\", \"session_id\", \"item_revenue\"])\n    .col_vals_gt(columns=\"item_revenue\", value=0)\n    .interrogate()\n)\n\nvalidation_9\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    DuckDB Game Revenue ValidationDuckDB\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    player_id\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    session_id\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    item_revenue\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    item_revenue\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:10:58 UTC&lt; 1 s2025-11-23 00:10:58 UTC\n  \n\n\n\n\n\n\n        \n\n\nFor comprehensive documentation on supported connection string formats, error handling, and installation requirements, see the connect_to_table() function. This function handles all the connection logic and provides helpful error messages when table specifications are missing or backend dependencies are not installed."
  },
  {
    "objectID": "reference/expr_col.html",
    "href": "reference/expr_col.html",
    "title": "expr_col",
    "section": "",
    "text": "expr_col(column_name)\nCreate a column expression for use in conjointly() validation.\nThis function returns a ColumnExpression object that supports operations like &gt;, &lt;, +, etc. for use in conjointly() validation expressions."
  },
  {
    "objectID": "reference/expr_col.html#parameters",
    "href": "reference/expr_col.html#parameters",
    "title": "expr_col",
    "section": "Parameters",
    "text": "Parameters\n\ncolumn_name : str\n\nThe name of the column to reference."
  },
  {
    "objectID": "reference/expr_col.html#returns",
    "href": "reference/expr_col.html#returns",
    "title": "expr_col",
    "section": "Returns",
    "text": "Returns\n\n : ColumnExpression\n\nA column expression that can be used in comparisons and operations."
  },
  {
    "objectID": "reference/expr_col.html#examples",
    "href": "reference/expr_col.html#examples",
    "title": "expr_col",
    "section": "Examples",
    "text": "Examples\nLet’s say we have a table with three columns: a, b, and c. We want to validate that:\n\nThe values in column a are greater than 2.\nThe values in column b are less than 7.\nThe sum of columns a and b is less than the values in column c.\n\nWe can use the expr_col() function to create a column expression for each of these conditions.\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [5, 7, 1, 3, 9, 4],\n        \"b\": [6, 3, 0, 5, 8, 2],\n        \"c\": [10, 4, 8, 9, 10, 5],\n    }\n)\n\n# Using expr_col() to create backend-agnostic validation expressions\nvalidation = (\n    pb.Validate(data=tbl)\n    .conjointly(\n        lambda df: pb.expr_col(\"a\") &gt; 2,\n        lambda df: pb.expr_col(\"b\") &lt; 7,\n        lambda df: pb.expr_col(\"a\") + pb.expr_col(\"b\") &lt; pb.expr_col(\"c\")\n    )\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    conjointly\n    \n        \n            \n            \n        \n    \n\n        \n        \n            conjointly()\n        \n        \n        \n    \n    COLUMN EXPR\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    10.17\n    50.83\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe above code creates a validation object that checks the specified conditions using the expr_col() function. The resulting validation table will show whether each condition was satisfied for each row in the table."
  },
  {
    "objectID": "reference/expr_col.html#see-also",
    "href": "reference/expr_col.html#see-also",
    "title": "expr_col",
    "section": "See Also",
    "text": "See Also\nThe conjointly() validation method, which is where this function should be used."
  },
  {
    "objectID": "reference/Validate.col_vals_regex.html",
    "href": "reference/Validate.col_vals_regex.html",
    "title": "Validate.col_vals_regex",
    "section": "",
    "text": "Validate.col_vals_regex(\n    columns,\n    pattern,\n    na_pass=False,\n    inverse=False,\n    pre=None,\n    segments=None,\n    thresholds=None,\n    actions=None,\n    brief=None,\n    active=True,\n)\nValidate whether column values match a regular expression pattern.\nThe col_vals_regex() validation method checks whether column values in a table correspond to a pattern= matching expression. This validation will operate over the number of test units that is equal to the number of rows in the table (determined after any pre= mutation has been applied)."
  },
  {
    "objectID": "reference/Validate.col_vals_regex.html#parameters",
    "href": "reference/Validate.col_vals_regex.html#parameters",
    "title": "Validate.col_vals_regex",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns : str | list[str] | Column | ColumnSelector | ColumnSelectorNarwhals\n\nA single column or a list of columns to validate. Can also use col() with column selectors to specify one or more columns. If multiple columns are supplied or resolved, there will be a separate validation step generated for each column.\n\npattern : str\n\nA regular expression pattern to compare against.\n\nna_pass : bool = False\n\nShould any encountered None, NA, or Null values be considered as passing test units? By default, this is False. Set to True to pass test units with missing values.\n\ninverse : bool = False\n\nShould the validation step be inverted? If True, then the expectation is that column values should not match the specified pattern= regex.\n\npre : Callable | None = None\n\nAn optional preprocessing function or lambda to apply to the data table during interrogation. This function should take a table as input and return a modified table. Have a look at the Preprocessing section for more information on how to use this argument.\n\nsegments : SegmentSpec | None = None\n\nAn optional directive on segmentation, which serves to split a validation step into multiple (one step per segment). Can be a single column name, a tuple that specifies a column name and its corresponding values to segment on, or a combination of both (provided as a list). Read the Segmentation section for usage information.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nSet threshold failure levels for reporting and reacting to exceedences of the levels. The thresholds are set at the step level and will override any global thresholds set in Validate(thresholds=...). The default is None, which means that no thresholds will be set locally and global thresholds (if any) will take effect. Look at the Thresholds section for information on how to set threshold levels.\n\nactions : Actions | None = None\n\nOptional actions to take when the validation step(s) meets or exceeds any set threshold levels. If provided, the Actions class should be used to define the actions.\n\nbrief : str | bool | None = None\n\nAn optional brief description of the validation step that will be displayed in the reporting table. You can use the templating elements like \"{step}\" to insert the step number, or \"{auto}\" to include an automatically generated brief. If True the entire brief will be automatically generated. If None (the default) then there won’t be a brief.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.col_vals_regex.html#returns",
    "href": "reference/Validate.col_vals_regex.html#returns",
    "title": "Validate.col_vals_regex",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.col_vals_regex.html#preprocessing",
    "href": "reference/Validate.col_vals_regex.html#preprocessing",
    "title": "Validate.col_vals_regex",
    "section": "Preprocessing",
    "text": "Preprocessing\nThe pre= argument allows for a preprocessing function or lambda to be applied to the data table during interrogation. This function should take a table as input and return a modified table. This is useful for performing any necessary transformations or filtering on the data before the validation step is applied.\nThe preprocessing function can be any callable that takes a table as input and returns a modified table. For example, you could use a lambda function to filter the table based on certain criteria or to apply a transformation to the data. Note that you can refer to a column via columns= that is expected to be present in the transformed table, but may not exist in the table before preprocessing. Regarding the lifetime of the transformed table, it only exists during the validation step and is not stored in the Validate object or used in subsequent validation steps."
  },
  {
    "objectID": "reference/Validate.col_vals_regex.html#segmentation",
    "href": "reference/Validate.col_vals_regex.html#segmentation",
    "title": "Validate.col_vals_regex",
    "section": "Segmentation",
    "text": "Segmentation\nThe segments= argument allows for the segmentation of a validation step into multiple segments. This is useful for applying the same validation step to different subsets of the data. The segmentation can be done based on a single column or specific fields within a column.\nProviding a single column name will result in a separate validation step for each unique value in that column. For example, if you have a column called \"region\" with values \"North\", \"South\", and \"East\", the validation step will be applied separately to each region.\nAlternatively, you can provide a tuple that specifies a column name and its corresponding values to segment on. For example, if you have a column called \"date\" and you want to segment on only specific dates, you can provide a tuple like (\"date\", [\"2023-01-01\", \"2023-01-02\"]). Any other values in the column will be disregarded (i.e., no validation steps will be created for them).\nA list with a combination of column names and tuples can be provided as well. This allows for more complex segmentation scenarios. The following inputs are both valid:\n# Segments from all unique values in the `region` column\n# and specific dates in the `date` column\nsegments=[\"region\", (\"date\", [\"2023-01-01\", \"2023-01-02\"])]\n\n# Segments from all unique values in the `region` and `date` columns\nsegments=[\"region\", \"date\"]\nThe segmentation is performed during interrogation, and the resulting validation steps will be numbered sequentially. Each segment will have its own validation step, and the results will be reported separately. This allows for a more granular analysis of the data and helps identify issues within specific segments.\nImportantly, the segmentation process will be performed after any preprocessing of the data table. Because of this, one can conceivably use the pre= argument to generate a column that can be used for segmentation. For example, you could create a new column called \"segment\" through use of pre= and then use that column for segmentation."
  },
  {
    "objectID": "reference/Validate.col_vals_regex.html#thresholds",
    "href": "reference/Validate.col_vals_regex.html#thresholds",
    "title": "Validate.col_vals_regex",
    "section": "Thresholds",
    "text": "Thresholds\nThe thresholds= parameter is used to set the failure-condition levels for the validation step. If they are set here at the step level, these thresholds will override any thresholds set at the global level in Validate(thresholds=...).\nThere are three threshold levels: ‘warning’, ‘error’, and ‘critical’. The threshold values can either be set as a proportion failing of all test units (a value between 0 to 1), or, the absolute number of failing test units (as integer that’s 1 or greater).\nThresholds can be defined using one of these input schemes:\n\nuse the Thresholds class (the most direct way to create thresholds)\nprovide a tuple of 1-3 values, where position 0 is the ‘warning’ level, position 1 is the ‘error’ level, and position 2 is the ‘critical’ level\ncreate a dictionary of 1-3 value entries; the valid keys: are ‘warning’, ‘error’, and ‘critical’\na single integer/float value denoting absolute number or fraction of failing test units for the ‘warning’ level only\n\nIf the number of failing test units exceeds set thresholds, the validation step will be marked as ‘warning’, ‘error’, or ‘critical’. All of the threshold levels don’t need to be set, you’re free to set any combination of them.\nAside from reporting failure conditions, thresholds can be used to determine the actions to take for each level of failure (using the actions= parameter)."
  },
  {
    "objectID": "reference/Validate.col_vals_regex.html#examples",
    "href": "reference/Validate.col_vals_regex.html#examples",
    "title": "Validate.col_vals_regex",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with two string columns (a and b). The table is shown below:\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [\"rb-0343\", \"ra-0232\", \"ry-0954\", \"rc-1343\"],\n        \"b\": [\"ra-0628\", \"ra-583\", \"rya-0826\", \"rb-0735\"],\n    }\n)\n\npb.preview(tbl)\n\n\n\n\n\n  \n  \n  \n\n\n\n\n\n  \n  aString\n  bString\n\n\n\n  \n    1\n    rb-0343\n    ra-0628\n  \n  \n    2\n    ra-0232\n    ra-583\n  \n  \n    3\n    ry-0954\n    rya-0826\n  \n  \n    4\n    rc-1343\n    rb-0735\n  \n\n\n\n\n\n\n        \n\n\nLet’s validate that all of the values in column a match a particular regex pattern. We’ll determine if this validation had any failing test units (there are four test units, one for each row).\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_regex(columns=\"a\", pattern=r\"r[a-z]-[0-9]{4}\")\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    a\n    r[a-z]-[0-9]{4}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    41.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nPrinting the validation object shows the validation table in an HTML viewing environment. The validation table shows the single entry that corresponds to the validation step created by using col_vals_regex(). All test units passed, and there are no failing test units.\nNow, let’s use the same regex for a validation on column b.\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_regex(columns=\"b\", pattern=r\"r[a-z]-[0-9]{4}\")\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    b\n    r[a-z]-[0-9]{4}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    20.50\n    20.50\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe validation table reports two failing test units. The specific failing cases are for the string values of rows 1 and 2 in column b."
  },
  {
    "objectID": "reference/Validate.assert_below_threshold.html",
    "href": "reference/Validate.assert_below_threshold.html",
    "title": "Validate.assert_below_threshold",
    "section": "",
    "text": "Validate.assert_below_threshold(level='warning', i=None, message=None)\nRaise an AssertionError if validation steps exceed a specified threshold level.\nThe assert_below_threshold() method checks whether validation steps’ failure rates are below a given threshold level (\"warning\", \"error\", or \"critical\"). This is particularly useful in automated testing environments where you want to ensure your data quality meets minimum standards before proceeding.\nIf any validation step exceeds the specified threshold level, an AssertionError will be raised with details about which steps failed. If the validation has not yet been interrogated, this method will automatically call interrogate() with default parameters."
  },
  {
    "objectID": "reference/Validate.assert_below_threshold.html#parameters",
    "href": "reference/Validate.assert_below_threshold.html#parameters",
    "title": "Validate.assert_below_threshold",
    "section": "Parameters",
    "text": "Parameters\n\nlevel : str = 'warning'\n\nThe threshold level to check against, which could be any of \"warning\" (the default), \"error\", or \"critical\". An AssertionError will be raised if any validation step exceeds this level.\n\ni : int | None = None\n\nSpecific validation step number(s) to check. Can be provided as a single integer or a list of integers. If None (the default), all steps are checked.\n\nmessage : str | None = None\n\nCustom error message to use if assertion fails. If None, a default message will be generated that lists the specific steps that exceeded the threshold."
  },
  {
    "objectID": "reference/Validate.assert_below_threshold.html#returns",
    "href": "reference/Validate.assert_below_threshold.html#returns",
    "title": "Validate.assert_below_threshold",
    "section": "Returns",
    "text": "Returns\n\n : None"
  },
  {
    "objectID": "reference/Validate.assert_below_threshold.html#raises",
    "href": "reference/Validate.assert_below_threshold.html#raises",
    "title": "Validate.assert_below_threshold",
    "section": "Raises",
    "text": "Raises\n\n: AssertionError\n\nIf any specified validation step exceeds the given threshold level.\n\n: ValueError\n\nIf an invalid threshold level is provided."
  },
  {
    "objectID": "reference/Validate.assert_below_threshold.html#examples",
    "href": "reference/Validate.assert_below_threshold.html#examples",
    "title": "Validate.assert_below_threshold",
    "section": "Examples",
    "text": "Examples\nBelow are some examples of how to use the assert_below_threshold() method. First, we’ll create a simple Polars DataFrame with two columns (a and b).\n\nimport polars as pl\n\ntbl = pl.DataFrame({\n    \"a\": [7, 4, 9, 7, 12],\n    \"b\": [9, 8, 10, 5, 10]\n})\n\nThen a validation plan will be created with thresholds (warning=0.1, error=0.2, critical=0.3). After interrogating, we display the validation report table:\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(data=tbl, thresholds=(0.1, 0.2, 0.3))\n    .col_vals_gt(columns=\"a\", value=5)   # 1 failing test unit\n    .col_vals_lt(columns=\"b\", value=10)  # 2 failing test units\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #EBBC14\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    a\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    40.80\n    10.20\n    ●\n    ●\n    ○\n    CSV\n  \n  \n    #FF3300\n    2\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    b\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    30.60\n    20.40\n    ●\n    ●\n    ●\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nUsing assert_below_threshold(level=\"warning\") will raise an AssertionError if any step exceeds the ‘warning’ threshold:\n\ntry:\n    validation.assert_below_threshold(level=\"warning\")\nexcept AssertionError as e:\n    print(f\"Assertion failed: {e}\")\n\nAssertion failed: The following steps exceeded the warning threshold level:\nStep 1: Expect that values in `a` should be &gt; `5`.\nStep 2: Expect that values in `b` should be &lt; `10`.\n\n\nCheck a specific step against the ‘critical’ threshold using the i= parameter:\n\nvalidation.assert_below_threshold(level=\"critical\", i=1)  # Won't raise an error\n\nAs the first step is below the ‘critical’ threshold (it exceeds the ‘warning’ and ‘error’ thresholds), no error is raised and nothing is printed.\nWe can also provide a custom error message with the message= parameter. Let’s try that here:\n\ntry:\n    validation.assert_below_threshold(\n        level=\"error\",\n        message=\"Data quality too low for processing!\"\n    )\nexcept AssertionError as e:\n    print(f\"Custom error: {e}\")\n\nCustom error: Data quality too low for processing!"
  },
  {
    "objectID": "reference/Validate.assert_below_threshold.html#see-also",
    "href": "reference/Validate.assert_below_threshold.html#see-also",
    "title": "Validate.assert_below_threshold",
    "section": "See Also",
    "text": "See Also\n\nwarning(): get the ‘warning’ status for each validation step\nerror(): get the ‘error’ status for each validation step\ncritical(): get the ‘critical’ status for each validation step\nassert_passing(): assert all validations pass completely"
  },
  {
    "objectID": "reference/assistant.html",
    "href": "reference/assistant.html",
    "title": "assistant",
    "section": "",
    "text": "assistant(model, data=None, tbl_name=None, api_key=None, display=None)\nChat with the PbA (Pointblank Assistant) about your data validation needs.\nThe assistant() function provides an interactive chat session with the PbA (Pointblank Assistant) to help you with your data validation needs. The PbA can help you with constructing validation plans, suggesting validation methods, and providing code snippets for using the Pointblank Python package. Feel free to ask the PbA about any aspect of the Pointblank package and it will do its best to assist you.\nThe PbA can also help you with constructing validation plans for your data tables. If you provide a data table to the PbA, it will internally generate a JSON summary of the table and use that information to suggest validation methods that can be used with the Pointblank package. If using a Polars table as the data source, the PbA will be knowledgeable about the Polars API and can smartly suggest validation steps that use aggregate measures with up-to-date Polars methods.\nThe PbA can be used with models from the following providers:\n\nAnthropic\nOpenAI\nOllama\nAmazon Bedrock\n\nThe PbA can be displayed in a browser (the default) or in the terminal. You can choose one or the other by setting the display= parameter to \"browser\" or \"terminal\".\n\n\n\n\n\n\nWarning\n\n\n\nThe assistant() function is still experimental. Please report any issues you encounter in the Pointblank issue tracker.\n\n\n\n\n\nmodel : str\n\nThe model to be used. This should be in the form of provider:model (e.g., \"anthropic:claude-sonnet-4-5\"). Supported providers are \"anthropic\", \"openai\", \"ollama\", and \"bedrock\".\n\ndata : FrameT | Any | None = None\n\nAn optional data table to focus on during discussion with the PbA, which could be a DataFrame object, an Ibis table object, a CSV file path, a Parquet file path, or a database connection string. Read the Supported Input Table Types section for details on the supported table types.\n\ntbl_name : str = None\n\nThe name of the data table. This is optional and is only used to provide a more detailed prompt to the PbA.\n\napi_key : str = None\n\nThe API key to be used for the model.\n\ndisplay : str = None\n\nThe display mode to use for the chat session. Supported values are \"browser\" and \"terminal\". If not provided, the default value is \"browser\".\n\n\n\n\n\n\n : None\n\nNothing is returned. Rather, you get an an interactive chat session with the PbA, which is displayed in a browser or in the terminal.\n\n\n\n\n\nThe model= argument should be constructed using the provider and model name separated by a colon (provider:model). The provider text can any of:\n\n\"anthropic\" (Anthropic)\n\"openai\" (OpenAI)\n\"ollama\" (Ollama)\n\"bedrock\" (Amazon Bedrock)\n\nThe model name should be the specific model to be used from the provider. Model names are subject to change so consult the provider’s documentation for the most up-to-date model names.\n\n\n\nProviding a valid API key as a string in the api_key argument is adequate for getting started but you should consider using a more secure method for handling API keys.\nOne way to do this is to load the API key from an environent variable and retrieve it using the os module (specifically the os.getenv() function). Places to store the API key might include .bashrc, .bash_profile, .zshrc, or .zsh_profile.\nAnother solution is to store one or more model provider API keys in an .env file (in the root of your project). If the API keys have correct names (e.g., ANTHROPIC_API_KEY or OPENAI_API_KEY) then DraftValidation will automatically load the API key from the .env file and there’s no need to provide the api_key argument. An .env file might look like this:\nANTHROPIC_API_KEY=\"your_anthropic_api_key_here\"\nOPENAI_API_KEY=\"your_openai_api_key_here\"\nThere’s no need to have the python-dotenv package installed when using .env files in this way.\n\n\n\nIf data= is provided then that data is sent to the model provider is a JSON summary of the table. This data summary is generated internally by use of the DataScan class. The summary includes the following information:\n\nthe number of rows and columns in the table\nthe type of dataset (e.g., Polars, DuckDB, Pandas, etc.)\nthe column names and their types\ncolumn level statistics such as the number of missing values, min, max, mean, and median, etc.\na short list of data values in each column\n\nThe JSON summary is used to provide the model with the necessary information be knowledgable about the data table. Compared to the size of the entire table, the JSON summary is quite small and can be safely sent to the model provider.\nThe Amazon Bedrock provider is a special case since it is a self-hosted model and security controls are in place to ensure that data is kept within the user’s AWS environment. If using an Ollama model all data is handled locally.\n\n\n\nThe data= parameter can be given any of the following table types:\n\nPolars DataFrame (\"polars\")\nPandas DataFrame (\"pandas\")\nPySpark table (\"pyspark\")\nDuckDB table (\"duckdb\")*\nMySQL table (\"mysql\")*\nPostgreSQL table (\"postgresql\")*\nSQLite table (\"sqlite\")*\nMicrosoft SQL Server table (\"mssql\")*\nSnowflake table (\"snowflake\")*\nDatabricks table (\"databricks\")*\nBigQuery table (\"bigquery\")*\nParquet table (\"parquet\")*\nCSV files (string path or pathlib.Path object with .csv extension)\nParquet files (string path, pathlib.Path object, glob pattern, directory with .parquet extension, or partitioned dataset)\nDatabase connection strings (URI format with optional table specification)\n\nThe table types marked with an asterisk need to be prepared as Ibis tables (with type of ibis.expr.types.relations.Table). Furthermore, using assistant() with these types of tables requires the Ibis library (v9.5.0 or above) to be installed. If the input table is a Polars or Pandas DataFrame, the availability of Ibis is not needed.\nTo use a CSV file, ensure that a string or pathlib.Path object with a .csv extension is provided. The file will be automatically detected and loaded using the best available DataFrame library. The loading preference is Polars first, then Pandas as a fallback."
  },
  {
    "objectID": "reference/assistant.html#parameters",
    "href": "reference/assistant.html#parameters",
    "title": "assistant",
    "section": "",
    "text": "model : str\n\nThe model to be used. This should be in the form of provider:model (e.g., \"anthropic:claude-sonnet-4-5\"). Supported providers are \"anthropic\", \"openai\", \"ollama\", and \"bedrock\".\n\ndata : FrameT | Any | None = None\n\nAn optional data table to focus on during discussion with the PbA, which could be a DataFrame object, an Ibis table object, a CSV file path, a Parquet file path, or a database connection string. Read the Supported Input Table Types section for details on the supported table types.\n\ntbl_name : str = None\n\nThe name of the data table. This is optional and is only used to provide a more detailed prompt to the PbA.\n\napi_key : str = None\n\nThe API key to be used for the model.\n\ndisplay : str = None\n\nThe display mode to use for the chat session. Supported values are \"browser\" and \"terminal\". If not provided, the default value is \"browser\"."
  },
  {
    "objectID": "reference/assistant.html#returns",
    "href": "reference/assistant.html#returns",
    "title": "assistant",
    "section": "",
    "text": ": None\n\nNothing is returned. Rather, you get an an interactive chat session with the PbA, which is displayed in a browser or in the terminal."
  },
  {
    "objectID": "reference/assistant.html#constructing-the-model-argument",
    "href": "reference/assistant.html#constructing-the-model-argument",
    "title": "assistant",
    "section": "",
    "text": "The model= argument should be constructed using the provider and model name separated by a colon (provider:model). The provider text can any of:\n\n\"anthropic\" (Anthropic)\n\"openai\" (OpenAI)\n\"ollama\" (Ollama)\n\"bedrock\" (Amazon Bedrock)\n\nThe model name should be the specific model to be used from the provider. Model names are subject to change so consult the provider’s documentation for the most up-to-date model names."
  },
  {
    "objectID": "reference/assistant.html#notes-on-authentication",
    "href": "reference/assistant.html#notes-on-authentication",
    "title": "assistant",
    "section": "",
    "text": "Providing a valid API key as a string in the api_key argument is adequate for getting started but you should consider using a more secure method for handling API keys.\nOne way to do this is to load the API key from an environent variable and retrieve it using the os module (specifically the os.getenv() function). Places to store the API key might include .bashrc, .bash_profile, .zshrc, or .zsh_profile.\nAnother solution is to store one or more model provider API keys in an .env file (in the root of your project). If the API keys have correct names (e.g., ANTHROPIC_API_KEY or OPENAI_API_KEY) then DraftValidation will automatically load the API key from the .env file and there’s no need to provide the api_key argument. An .env file might look like this:\nANTHROPIC_API_KEY=\"your_anthropic_api_key_here\"\nOPENAI_API_KEY=\"your_openai_api_key_here\"\nThere’s no need to have the python-dotenv package installed when using .env files in this way."
  },
  {
    "objectID": "reference/assistant.html#notes-on-data-sent-to-the-model-provider",
    "href": "reference/assistant.html#notes-on-data-sent-to-the-model-provider",
    "title": "assistant",
    "section": "",
    "text": "If data= is provided then that data is sent to the model provider is a JSON summary of the table. This data summary is generated internally by use of the DataScan class. The summary includes the following information:\n\nthe number of rows and columns in the table\nthe type of dataset (e.g., Polars, DuckDB, Pandas, etc.)\nthe column names and their types\ncolumn level statistics such as the number of missing values, min, max, mean, and median, etc.\na short list of data values in each column\n\nThe JSON summary is used to provide the model with the necessary information be knowledgable about the data table. Compared to the size of the entire table, the JSON summary is quite small and can be safely sent to the model provider.\nThe Amazon Bedrock provider is a special case since it is a self-hosted model and security controls are in place to ensure that data is kept within the user’s AWS environment. If using an Ollama model all data is handled locally."
  },
  {
    "objectID": "reference/assistant.html#supported-input-table-types",
    "href": "reference/assistant.html#supported-input-table-types",
    "title": "assistant",
    "section": "",
    "text": "The data= parameter can be given any of the following table types:\n\nPolars DataFrame (\"polars\")\nPandas DataFrame (\"pandas\")\nPySpark table (\"pyspark\")\nDuckDB table (\"duckdb\")*\nMySQL table (\"mysql\")*\nPostgreSQL table (\"postgresql\")*\nSQLite table (\"sqlite\")*\nMicrosoft SQL Server table (\"mssql\")*\nSnowflake table (\"snowflake\")*\nDatabricks table (\"databricks\")*\nBigQuery table (\"bigquery\")*\nParquet table (\"parquet\")*\nCSV files (string path or pathlib.Path object with .csv extension)\nParquet files (string path, pathlib.Path object, glob pattern, directory with .parquet extension, or partitioned dataset)\nDatabase connection strings (URI format with optional table specification)\n\nThe table types marked with an asterisk need to be prepared as Ibis tables (with type of ibis.expr.types.relations.Table). Furthermore, using assistant() with these types of tables requires the Ibis library (v9.5.0 or above) to be installed. If the input table is a Polars or Pandas DataFrame, the availability of Ibis is not needed.\nTo use a CSV file, ensure that a string or pathlib.Path object with a .csv extension is provided. The file will be automatically detected and loaded using the best available DataFrame library. The loading preference is Polars first, then Pandas as a fallback."
  },
  {
    "objectID": "reference/Validate.f_passed.html",
    "href": "reference/Validate.f_passed.html",
    "title": "Validate.f_passed",
    "section": "",
    "text": "Validate.f_passed(i=None, scalar=False)\nProvides a dictionary of the fraction of test units that passed for each validation step.\nA measure of the fraction of test units that passed is provided by the f_passed attribute. This is the fraction of test units that passed the validation step over the total number of test units. Given this is a fractional value, it will always be in the range of 0 to 1.\nTest units are the atomic units of the validation process. Different validations can have different numbers of test units. For example, a validation that checks for the presence of a column in a table will have a single test unit. A validation that checks for the presence of a value in a column will have as many test units as there are rows in the table.\nThis method provides a dictionary of the fraction of passing test units for each validation step. If the scalar=True argument is provided and i= is a scalar, the value is returned as a scalar instead of a dictionary. Furthermore, a value obtained here will be the complement to the analogous value returned by the f_failed() method (i.e., 1 - f_failed())."
  },
  {
    "objectID": "reference/Validate.f_passed.html#parameters",
    "href": "reference/Validate.f_passed.html#parameters",
    "title": "Validate.f_passed",
    "section": "Parameters",
    "text": "Parameters\n\ni : int | list[int] | None = None\n\nThe validation step number(s) from which the fraction of passing test units is obtained. Can be provided as a list of integers or a single integer. If None, all steps are included.\n\nscalar : bool = False\n\nIf True and i= is a scalar, return the value as a scalar instead of a dictionary."
  },
  {
    "objectID": "reference/Validate.f_passed.html#returns",
    "href": "reference/Validate.f_passed.html#returns",
    "title": "Validate.f_passed",
    "section": "Returns",
    "text": "Returns\n\n : dict[int, float] | float\n\nA dictionary of the fraction of passing test units for each validation step or a scalar value."
  },
  {
    "objectID": "reference/Validate.f_passed.html#examples",
    "href": "reference/Validate.f_passed.html#examples",
    "title": "Validate.f_passed",
    "section": "Examples",
    "text": "Examples\nIn the example below, we’ll use a simple Polars DataFrame with three columns (a, b, and c). There will be three validation steps, all having some failing test units. After interrogation, the f_passed() method is used to determine the fraction of passing test units for each validation step.\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [7, 4, 9, 7, 12, 3, 10],\n        \"b\": [9, 8, 10, 5, 10, 6, 2],\n        \"c\": [\"a\", \"b\", \"c\", \"a\", \"b\", \"d\", \"c\"]\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(columns=\"a\", value=5)\n    .col_vals_gt(columns=\"b\", value=pb.col(\"a\"))\n    .col_vals_in_set(columns=\"c\", set=[\"a\", \"b\"])\n    .interrogate()\n)\n\nvalidation.f_passed()\n\n{1: 0.7142857142857143, 2: 0.5714285714285714, 3: 0.5714285714285714}\n\n\nThe returned dictionary shows the fraction of passing test units for each validation step. The values are all less than 1 since there were failing test units in each step.\nIf we wanted to check the fraction of passing test units for a single validation step, we can provide the step number. Also, we could have the value returned as a scalar by setting scalar=True (ensuring that i= is a scalar).\n\nvalidation.f_passed(i=1)\n\n{1: 0.7142857142857143}\n\n\nThe returned value is the proportion of passing test units for the first validation step (5 passing test units out of 7 total test units)."
  },
  {
    "objectID": "reference/Validate.col_vals_null.html",
    "href": "reference/Validate.col_vals_null.html",
    "title": "Validate.col_vals_null",
    "section": "",
    "text": "Validate.col_vals_null(\n    columns,\n    pre=None,\n    segments=None,\n    thresholds=None,\n    actions=None,\n    brief=None,\n    active=True,\n)\nValidate whether values in a column are Null.\nThe col_vals_null() validation method checks whether column values in a table are Null. This validation will operate over the number of test units that is equal to the number of rows in the table."
  },
  {
    "objectID": "reference/Validate.col_vals_null.html#parameters",
    "href": "reference/Validate.col_vals_null.html#parameters",
    "title": "Validate.col_vals_null",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns : str | list[str] | Column | ColumnSelector | ColumnSelectorNarwhals\n\nA single column or a list of columns to validate. Can also use col() with column selectors to specify one or more columns. If multiple columns are supplied or resolved, there will be a separate validation step generated for each column.\n\npre : Callable | None = None\n\nAn optional preprocessing function or lambda to apply to the data table during interrogation. This function should take a table as input and return a modified table. Have a look at the Preprocessing section for more information on how to use this argument.\n\nsegments : SegmentSpec | None = None\n\nAn optional directive on segmentation, which serves to split a validation step into multiple (one step per segment). Can be a single column name, a tuple that specifies a column name and its corresponding values to segment on, or a combination of both (provided as a list). Read the Segmentation section for usage information.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nSet threshold failure levels for reporting and reacting to exceedences of the levels. The thresholds are set at the step level and will override any global thresholds set in Validate(thresholds=...). The default is None, which means that no thresholds will be set locally and global thresholds (if any) will take effect. Look at the Thresholds section for information on how to set threshold levels.\n\nactions : Actions | None = None\n\nOptional actions to take when the validation step(s) meets or exceeds any set threshold levels. If provided, the Actions class should be used to define the actions.\n\nbrief : str | bool | None = None\n\nAn optional brief description of the validation step that will be displayed in the reporting table. You can use the templating elements like \"{step}\" to insert the step number, or \"{auto}\" to include an automatically generated brief. If True the entire brief will be automatically generated. If None (the default) then there won’t be a brief.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.col_vals_null.html#returns",
    "href": "reference/Validate.col_vals_null.html#returns",
    "title": "Validate.col_vals_null",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.col_vals_null.html#preprocessing",
    "href": "reference/Validate.col_vals_null.html#preprocessing",
    "title": "Validate.col_vals_null",
    "section": "Preprocessing",
    "text": "Preprocessing\nThe pre= argument allows for a preprocessing function or lambda to be applied to the data table during interrogation. This function should take a table as input and return a modified table. This is useful for performing any necessary transformations or filtering on the data before the validation step is applied.\nThe preprocessing function can be any callable that takes a table as input and returns a modified table. For example, you could use a lambda function to filter the table based on certain criteria or to apply a transformation to the data. Note that you can refer to a column via columns= that is expected to be present in the transformed table, but may not exist in the table before preprocessing. Regarding the lifetime of the transformed table, it only exists during the validation step and is not stored in the Validate object or used in subsequent validation steps."
  },
  {
    "objectID": "reference/Validate.col_vals_null.html#segmentation",
    "href": "reference/Validate.col_vals_null.html#segmentation",
    "title": "Validate.col_vals_null",
    "section": "Segmentation",
    "text": "Segmentation\nThe segments= argument allows for the segmentation of a validation step into multiple segments. This is useful for applying the same validation step to different subsets of the data. The segmentation can be done based on a single column or specific fields within a column.\nProviding a single column name will result in a separate validation step for each unique value in that column. For example, if you have a column called \"region\" with values \"North\", \"South\", and \"East\", the validation step will be applied separately to each region.\nAlternatively, you can provide a tuple that specifies a column name and its corresponding values to segment on. For example, if you have a column called \"date\" and you want to segment on only specific dates, you can provide a tuple like (\"date\", [\"2023-01-01\", \"2023-01-02\"]). Any other values in the column will be disregarded (i.e., no validation steps will be created for them).\nA list with a combination of column names and tuples can be provided as well. This allows for more complex segmentation scenarios. The following inputs are both valid:\n# Segments from all unique values in the `region` column\n# and specific dates in the `date` column\nsegments=[\"region\", (\"date\", [\"2023-01-01\", \"2023-01-02\"])]\n\n# Segments from all unique values in the `region` and `date` columns\nsegments=[\"region\", \"date\"]\nThe segmentation is performed during interrogation, and the resulting validation steps will be numbered sequentially. Each segment will have its own validation step, and the results will be reported separately. This allows for a more granular analysis of the data and helps identify issues within specific segments.\nImportantly, the segmentation process will be performed after any preprocessing of the data table. Because of this, one can conceivably use the pre= argument to generate a column that can be used for segmentation. For example, you could create a new column called \"segment\" through use of pre= and then use that column for segmentation."
  },
  {
    "objectID": "reference/Validate.col_vals_null.html#thresholds",
    "href": "reference/Validate.col_vals_null.html#thresholds",
    "title": "Validate.col_vals_null",
    "section": "Thresholds",
    "text": "Thresholds\nThe thresholds= parameter is used to set the failure-condition levels for the validation step. If they are set here at the step level, these thresholds will override any thresholds set at the global level in Validate(thresholds=...).\nThere are three threshold levels: ‘warning’, ‘error’, and ‘critical’. The threshold values can either be set as a proportion failing of all test units (a value between 0 to 1), or, the absolute number of failing test units (as integer that’s 1 or greater).\nThresholds can be defined using one of these input schemes:\n\nuse the Thresholds class (the most direct way to create thresholds)\nprovide a tuple of 1-3 values, where position 0 is the ‘warning’ level, position 1 is the ‘error’ level, and position 2 is the ‘critical’ level\ncreate a dictionary of 1-3 value entries; the valid keys: are ‘warning’, ‘error’, and ‘critical’\na single integer/float value denoting absolute number or fraction of failing test units for the ‘warning’ level only\n\nIf the number of failing test units exceeds set thresholds, the validation step will be marked as ‘warning’, ‘error’, or ‘critical’. All of the threshold levels don’t need to be set, you’re free to set any combination of them.\nAside from reporting failure conditions, thresholds can be used to determine the actions to take for each level of failure (using the actions= parameter)."
  },
  {
    "objectID": "reference/Validate.col_vals_null.html#examples",
    "href": "reference/Validate.col_vals_null.html#examples",
    "title": "Validate.col_vals_null",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with two numeric columns (a and b). The table is shown below:\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [None, None, None, None],\n        \"b\": [None, 2, None, 9],\n    }\n).with_columns(pl.col(\"a\").cast(pl.Int64))\n\npb.preview(tbl)\n\n\n\n\n\n  \n  \n  \n\n\n\n\n\n  \n  aInt64\n  bInt64\n\n\n\n  \n    1\n    None\n    None\n  \n  \n    2\n    None\n    2\n  \n  \n    3\n    None\n    None\n  \n  \n    4\n    None\n    9\n  \n\n\n\n\n\n\n        \n\n\nLet’s validate that values in column a are all Null values. We’ll determine if this validation had any failing test units (there are four test units, one for each row).\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_null(columns=\"a\")\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_null\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_null()\n        \n        \n        \n    a\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    41.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nPrinting the validation object shows the validation table in an HTML viewing environment. The validation table shows the single entry that corresponds to the validation step created by using col_vals_null(). All test units passed, and there are no failing test units.\nNow, let’s use that same set of values for a validation on column b.\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_null(columns=\"b\")\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_null\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_null()\n        \n        \n        \n    b\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    20.50\n    20.50\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe validation table reports two failing test units. The specific failing cases are for the two non-Null values in column b."
  },
  {
    "objectID": "reference/Validate.n_passed.html",
    "href": "reference/Validate.n_passed.html",
    "title": "Validate.n_passed",
    "section": "",
    "text": "Validate.n_passed(i=None, scalar=False)\nProvides a dictionary of the number of test units that passed for each validation step.\nThe n_passed() method provides the number of test units that passed for each validation step. This is the number of test units that passed in the the validation step. It is always some integer value between 0 and the total number of test units.\nTest units are the atomic units of the validation process. Different validations can have different numbers of test units. For example, a validation that checks for the presence of a column in a table will have a single test unit. A validation that checks for the presence of a value in a column will have as many test units as there are rows in the table.\nThe method provides a dictionary of the number of passing test units for each validation step. If the scalar=True argument is provided and i= is a scalar, the value is returned as a scalar instead of a dictionary. Furthermore, a value obtained here will be the complement to the analogous value returned by the n_passed() method (i.e., n - n_failed)."
  },
  {
    "objectID": "reference/Validate.n_passed.html#parameters",
    "href": "reference/Validate.n_passed.html#parameters",
    "title": "Validate.n_passed",
    "section": "Parameters",
    "text": "Parameters\n\ni : int | list[int] | None = None\n\nThe validation step number(s) from which the number of passing test units is obtained. Can be provided as a list of integers or a single integer. If None, all steps are included.\n\nscalar : bool = False\n\nIf True and i= is a scalar, return the value as a scalar instead of a dictionary."
  },
  {
    "objectID": "reference/Validate.n_passed.html#returns",
    "href": "reference/Validate.n_passed.html#returns",
    "title": "Validate.n_passed",
    "section": "Returns",
    "text": "Returns\n\n : dict[int, int] | int\n\nA dictionary of the number of passing test units for each validation step or a scalar value."
  },
  {
    "objectID": "reference/Validate.n_passed.html#examples",
    "href": "reference/Validate.n_passed.html#examples",
    "title": "Validate.n_passed",
    "section": "Examples",
    "text": "Examples\nIn the example below, we’ll use a simple Polars DataFrame with three columns (a, b, and c). There will be three validation steps and, as it turns out, all of them will have failing test units. After interrogation, the n_passed() method is used to determine the number of passing test units for each validation step.\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [7, 4, 9, 7, 12],\n        \"b\": [9, 8, 10, 5, 10],\n        \"c\": [\"a\", \"b\", \"c\", \"a\", \"b\"]\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(columns=\"a\", value=5)\n    .col_vals_gt(columns=\"b\", value=pb.col(\"a\"))\n    .col_vals_in_set(columns=\"c\", set=[\"a\", \"b\"])\n    .interrogate()\n)\n\nvalidation.n_passed()\n\n{1: 4, 2: 3, 3: 4}\n\n\nThe returned dictionary shows that all validation steps had no passing test units (each value was less than 5, which is the total number of test units for each step).\nIf we wanted to check the number of passing test units for a single validation step, we can provide the step number. Also, we could forego the dictionary and get a scalar value by setting scalar=True (ensuring that i= is a scalar).\n\nvalidation.n_passed(i=1)\n\n{1: 4}\n\n\nThe returned value of 4 is the number of passing test units for the first validation step."
  },
  {
    "objectID": "reference/index.html",
    "href": "reference/index.html",
    "title": "API Reference",
    "section": "",
    "text": "When performing data validation, you’ll need the Validate class to get the process started. It’s given the target table and you can optionally provide some metadata and/or failure thresholds (using the Thresholds class or through shorthands for this task). The Validate class has numerous methods for defining validation steps and for obtaining post-interrogation metrics and data.\n\n\n\nValidate\nWorkflow for defining a set of validations on a table and interrogating for results.\n\n\nThresholds\nDefinition of threshold values.\n\n\nActions\nDefinition of action values.\n\n\nFinalActions\nDefine actions to be taken after validation is complete.\n\n\nSchema\nDefinition of a schema object.\n\n\nDraftValidation\nDraft a validation plan for a given table using an LLM.\n\n\n\n\n\n\nValidation steps can be thought of as sequential validations on the target data. We call Validate’s validation methods to build up a validation plan: a collection of steps that, in the aggregate, provides good validation coverage.\n\n\n\nValidate.col_vals_gt\nAre column data greater than a fixed value or data in another column?\n\n\nValidate.col_vals_lt\nAre column data less than a fixed value or data in another column?\n\n\nValidate.col_vals_ge\nAre column data greater than or equal to a fixed value or data in another column?\n\n\nValidate.col_vals_le\nAre column data less than or equal to a fixed value or data in another column?\n\n\nValidate.col_vals_eq\nAre column data equal to a fixed value or data in another column?\n\n\nValidate.col_vals_ne\nAre column data not equal to a fixed value or data in another column?\n\n\nValidate.col_vals_between\nDo column data lie between two specified values or data in other columns?\n\n\nValidate.col_vals_outside\nDo column data lie outside of two specified values or data in other columns?\n\n\nValidate.col_vals_in_set\nValidate whether column values are in a set of values.\n\n\nValidate.col_vals_not_in_set\nValidate whether column values are not in a set of values.\n\n\nValidate.col_vals_increasing\nAre column data increasing by row?\n\n\nValidate.col_vals_decreasing\nAre column data decreasing by row?\n\n\nValidate.col_vals_null\nValidate whether values in a column are Null.\n\n\nValidate.col_vals_not_null\nValidate whether values in a column are not Null.\n\n\nValidate.col_vals_regex\nValidate whether column values match a regular expression pattern.\n\n\nValidate.col_vals_within_spec\nValidate whether column values fit within a specification.\n\n\nValidate.col_vals_expr\nValidate column values using a custom expression.\n\n\nValidate.rows_distinct\nValidate whether rows in the table are distinct.\n\n\nValidate.rows_complete\nValidate whether row data are complete by having no missing values.\n\n\nValidate.col_exists\nValidate whether one or more columns exist in the table.\n\n\nValidate.col_schema_match\nDo columns in the table (and their types) match a predefined schema?\n\n\nValidate.row_count_match\nValidate whether the row count of the table matches a specified count.\n\n\nValidate.col_count_match\nValidate whether the column count of the table matches a specified count.\n\n\nValidate.tbl_match\nValidate whether the target table matches a comparison table.\n\n\nValidate.conjointly\nPerform multiple row-wise validations for joint validity.\n\n\nValidate.specially\nPerform a specialized validation with customized logic.\n\n\nValidate.prompt\nValidate rows using AI/LLM-powered analysis.\n\n\n\n\n\n\nA flexible way to select columns for validation is to use the col() function along with column selection helper functions. A combination of col() + starts_with(), matches(), etc., allows for the selection of multiple target columns (mapping a validation across many steps). Furthermore, the col() function can be used to declare a comparison column (e.g., for the value= argument in many col_vals_*() methods) when you can’t use a fixed value for comparison.\n\n\n\ncol\nHelper function for referencing a column in the input table.\n\n\nstarts_with\nSelect columns that start with specified text.\n\n\nends_with\nSelect columns that end with specified text.\n\n\ncontains\nSelect columns that contain specified text.\n\n\nmatches\nSelect columns that match a specified regular expression pattern.\n\n\neverything\nSelect all columns.\n\n\nfirst_n\nSelect the first n columns in the column list.\n\n\nlast_n\nSelect the last n columns in the column list.\n\n\nexpr_col\nCreate a column expression for use in conjointly() validation.\n\n\n\n\n\n\nCombine multiple values into a single segment using seg_*() helper functions.\n\n\n\nseg_group\nGroup together values for segmentation.\n\n\n\n\n\n\nThe validation plan is put into action when interrogate() is called. The workflow for performing a comprehensive validation is then: (1) Validate(), (2) adding validation steps, (3) interrogate(). After interrogation of the data, we can view a validation report table (by printing the object or using get_tabular_report()), extract key metrics, or we can split the data based on the validation results (with get_sundered_data()).\n\n\n\nValidate.interrogate\nExecute each validation step against the table and store the results.\n\n\nValidate.set_tbl\nSet or replace the table associated with the Validate object.\n\n\nValidate.get_tabular_report\nValidation report as a GT table.\n\n\nValidate.get_step_report\nGet a detailed report for a single validation step.\n\n\nValidate.get_json_report\nGet a report of the validation results as a JSON-formatted string.\n\n\nValidate.get_sundered_data\nGet the data that passed or failed the validation steps.\n\n\nValidate.get_data_extracts\nGet the rows that failed for each validation step.\n\n\nValidate.all_passed\nDetermine if every validation step passed perfectly, with no failing test units.\n\n\nValidate.assert_passing\nRaise an AssertionError if all tests are not passing.\n\n\nValidate.assert_below_threshold\nRaise an AssertionError if validation steps exceed a specified threshold level.\n\n\nValidate.above_threshold\nCheck if any validation steps exceed a specified threshold level.\n\n\nValidate.n\nProvides a dictionary of the number of test units for each validation step.\n\n\nValidate.n_passed\nProvides a dictionary of the number of test units that passed for each validation step.\n\n\nValidate.n_failed\nProvides a dictionary of the number of test units that failed for each validation step.\n\n\nValidate.f_passed\nProvides a dictionary of the fraction of test units that passed for each validation step.\n\n\nValidate.f_failed\nProvides a dictionary of the fraction of test units that failed for each validation step.\n\n\nValidate.warning\nGet the ‘warning’ level status for each validation step.\n\n\nValidate.error\nGet the ‘error’ level status for each validation step.\n\n\nValidate.critical\nGet the ‘critical’ level status for each validation step.\n\n\n\n\n\n\nThe Inspection and Assistance group contains functions that are helpful for getting to grips on a new data table. Use the DataScan class to get a quick overview of the data, preview() to see the first and last few rows of a table, col_summary_tbl() for a column-level summary of a table, and missing_vals_tbl() to see where there are missing values in a table. Several datasets included in the package can be accessed via the load_dataset() function. On the assistance side, the assistant() function can be used to get help with Pointblank.\n\n\n\nDataScan\nGet a summary of a dataset.\n\n\npreview\nDisplay a table preview that shows some rows from the top, some from the bottom.\n\n\ncol_summary_tbl\nGenerate a column-level summary table of a dataset.\n\n\nmissing_vals_tbl\nDisplay a table that shows the missing values in the input table.\n\n\nassistant\nChat with the PbA (Pointblank Assistant) about your data validation needs.\n\n\nload_dataset\nLoad a dataset hosted in the library as specified table type.\n\n\nget_data_path\nGet the file path to a dataset included with the Pointblank package.\n\n\nconnect_to_table\nConnect to a database table using a connection string.\n\n\nprint_database_tables\nList all tables in a database from a connection string.\n\n\n\n\n\n\nThe YAML group contains functions that allow for the use of YAML to orchestrate validation workflows. The yaml_interrogate() function can be used to run a validation workflow from YAML strings or files. The validate_yaml() function checks if the YAML configuration passes its own validity checks. The yaml_to_python() function converts YAML configuration to equivalent Python code.\n\n\n\nyaml_interrogate\nExecute a YAML-based validation workflow.\n\n\nvalidate_yaml\nValidate YAML configuration against the expected structure.\n\n\nyaml_to_python\nConvert YAML validation configuration to equivalent Python code.\n\n\n\n\n\n\nThe Utility Functions group contains functions that are useful accessing metadata about the target data. Use get_column_count() or get_row_count() to get the number of columns or rows in a table. The get_action_metadata() function is useful when building custom actions since it returns metadata about the validation step that’s triggering the action. Lastly, the config() utility lets us set global configuration parameters.\n\n\n\nget_column_count\nGet the number of columns in a table.\n\n\nget_row_count\nGet the number of rows in a table.\n\n\nget_action_metadata\nAccess step-level metadata when authoring custom actions.\n\n\nget_validation_summary\nAccess validation summary information when authoring final actions.\n\n\nwrite_file\nWrite a Validate object to disk as a serialized file.\n\n\nread_file\nRead a Validate object from disk that was previously saved with write_file().\n\n\nconfig\nConfiguration settings for the Pointblank library.\n\n\n\n\n\n\nThe Prebuilt Actions group contains a function that can be used to send a Slack notification when validation steps exceed failure threshold levels or just to provide a summary of the validation results, including the status, number of steps, passing and failing steps, table information, and timing details.\n\n\n\nsend_slack_notification\nCreate a Slack notification function using a webhook URL."
  },
  {
    "objectID": "reference/index.html#validate",
    "href": "reference/index.html#validate",
    "title": "API Reference",
    "section": "",
    "text": "When performing data validation, you’ll need the Validate class to get the process started. It’s given the target table and you can optionally provide some metadata and/or failure thresholds (using the Thresholds class or through shorthands for this task). The Validate class has numerous methods for defining validation steps and for obtaining post-interrogation metrics and data.\n\n\n\nValidate\nWorkflow for defining a set of validations on a table and interrogating for results.\n\n\nThresholds\nDefinition of threshold values.\n\n\nActions\nDefinition of action values.\n\n\nFinalActions\nDefine actions to be taken after validation is complete.\n\n\nSchema\nDefinition of a schema object.\n\n\nDraftValidation\nDraft a validation plan for a given table using an LLM."
  },
  {
    "objectID": "reference/index.html#validation-steps",
    "href": "reference/index.html#validation-steps",
    "title": "API Reference",
    "section": "",
    "text": "Validation steps can be thought of as sequential validations on the target data. We call Validate’s validation methods to build up a validation plan: a collection of steps that, in the aggregate, provides good validation coverage.\n\n\n\nValidate.col_vals_gt\nAre column data greater than a fixed value or data in another column?\n\n\nValidate.col_vals_lt\nAre column data less than a fixed value or data in another column?\n\n\nValidate.col_vals_ge\nAre column data greater than or equal to a fixed value or data in another column?\n\n\nValidate.col_vals_le\nAre column data less than or equal to a fixed value or data in another column?\n\n\nValidate.col_vals_eq\nAre column data equal to a fixed value or data in another column?\n\n\nValidate.col_vals_ne\nAre column data not equal to a fixed value or data in another column?\n\n\nValidate.col_vals_between\nDo column data lie between two specified values or data in other columns?\n\n\nValidate.col_vals_outside\nDo column data lie outside of two specified values or data in other columns?\n\n\nValidate.col_vals_in_set\nValidate whether column values are in a set of values.\n\n\nValidate.col_vals_not_in_set\nValidate whether column values are not in a set of values.\n\n\nValidate.col_vals_increasing\nAre column data increasing by row?\n\n\nValidate.col_vals_decreasing\nAre column data decreasing by row?\n\n\nValidate.col_vals_null\nValidate whether values in a column are Null.\n\n\nValidate.col_vals_not_null\nValidate whether values in a column are not Null.\n\n\nValidate.col_vals_regex\nValidate whether column values match a regular expression pattern.\n\n\nValidate.col_vals_within_spec\nValidate whether column values fit within a specification.\n\n\nValidate.col_vals_expr\nValidate column values using a custom expression.\n\n\nValidate.rows_distinct\nValidate whether rows in the table are distinct.\n\n\nValidate.rows_complete\nValidate whether row data are complete by having no missing values.\n\n\nValidate.col_exists\nValidate whether one or more columns exist in the table.\n\n\nValidate.col_schema_match\nDo columns in the table (and their types) match a predefined schema?\n\n\nValidate.row_count_match\nValidate whether the row count of the table matches a specified count.\n\n\nValidate.col_count_match\nValidate whether the column count of the table matches a specified count.\n\n\nValidate.tbl_match\nValidate whether the target table matches a comparison table.\n\n\nValidate.conjointly\nPerform multiple row-wise validations for joint validity.\n\n\nValidate.specially\nPerform a specialized validation with customized logic.\n\n\nValidate.prompt\nValidate rows using AI/LLM-powered analysis."
  },
  {
    "objectID": "reference/index.html#column-selection",
    "href": "reference/index.html#column-selection",
    "title": "API Reference",
    "section": "",
    "text": "A flexible way to select columns for validation is to use the col() function along with column selection helper functions. A combination of col() + starts_with(), matches(), etc., allows for the selection of multiple target columns (mapping a validation across many steps). Furthermore, the col() function can be used to declare a comparison column (e.g., for the value= argument in many col_vals_*() methods) when you can’t use a fixed value for comparison.\n\n\n\ncol\nHelper function for referencing a column in the input table.\n\n\nstarts_with\nSelect columns that start with specified text.\n\n\nends_with\nSelect columns that end with specified text.\n\n\ncontains\nSelect columns that contain specified text.\n\n\nmatches\nSelect columns that match a specified regular expression pattern.\n\n\neverything\nSelect all columns.\n\n\nfirst_n\nSelect the first n columns in the column list.\n\n\nlast_n\nSelect the last n columns in the column list.\n\n\nexpr_col\nCreate a column expression for use in conjointly() validation."
  },
  {
    "objectID": "reference/index.html#segment-groups",
    "href": "reference/index.html#segment-groups",
    "title": "API Reference",
    "section": "",
    "text": "Combine multiple values into a single segment using seg_*() helper functions.\n\n\n\nseg_group\nGroup together values for segmentation."
  },
  {
    "objectID": "reference/index.html#interrogation-and-reporting",
    "href": "reference/index.html#interrogation-and-reporting",
    "title": "API Reference",
    "section": "",
    "text": "The validation plan is put into action when interrogate() is called. The workflow for performing a comprehensive validation is then: (1) Validate(), (2) adding validation steps, (3) interrogate(). After interrogation of the data, we can view a validation report table (by printing the object or using get_tabular_report()), extract key metrics, or we can split the data based on the validation results (with get_sundered_data()).\n\n\n\nValidate.interrogate\nExecute each validation step against the table and store the results.\n\n\nValidate.set_tbl\nSet or replace the table associated with the Validate object.\n\n\nValidate.get_tabular_report\nValidation report as a GT table.\n\n\nValidate.get_step_report\nGet a detailed report for a single validation step.\n\n\nValidate.get_json_report\nGet a report of the validation results as a JSON-formatted string.\n\n\nValidate.get_sundered_data\nGet the data that passed or failed the validation steps.\n\n\nValidate.get_data_extracts\nGet the rows that failed for each validation step.\n\n\nValidate.all_passed\nDetermine if every validation step passed perfectly, with no failing test units.\n\n\nValidate.assert_passing\nRaise an AssertionError if all tests are not passing.\n\n\nValidate.assert_below_threshold\nRaise an AssertionError if validation steps exceed a specified threshold level.\n\n\nValidate.above_threshold\nCheck if any validation steps exceed a specified threshold level.\n\n\nValidate.n\nProvides a dictionary of the number of test units for each validation step.\n\n\nValidate.n_passed\nProvides a dictionary of the number of test units that passed for each validation step.\n\n\nValidate.n_failed\nProvides a dictionary of the number of test units that failed for each validation step.\n\n\nValidate.f_passed\nProvides a dictionary of the fraction of test units that passed for each validation step.\n\n\nValidate.f_failed\nProvides a dictionary of the fraction of test units that failed for each validation step.\n\n\nValidate.warning\nGet the ‘warning’ level status for each validation step.\n\n\nValidate.error\nGet the ‘error’ level status for each validation step.\n\n\nValidate.critical\nGet the ‘critical’ level status for each validation step."
  },
  {
    "objectID": "reference/index.html#inspection-and-assistance",
    "href": "reference/index.html#inspection-and-assistance",
    "title": "API Reference",
    "section": "",
    "text": "The Inspection and Assistance group contains functions that are helpful for getting to grips on a new data table. Use the DataScan class to get a quick overview of the data, preview() to see the first and last few rows of a table, col_summary_tbl() for a column-level summary of a table, and missing_vals_tbl() to see where there are missing values in a table. Several datasets included in the package can be accessed via the load_dataset() function. On the assistance side, the assistant() function can be used to get help with Pointblank.\n\n\n\nDataScan\nGet a summary of a dataset.\n\n\npreview\nDisplay a table preview that shows some rows from the top, some from the bottom.\n\n\ncol_summary_tbl\nGenerate a column-level summary table of a dataset.\n\n\nmissing_vals_tbl\nDisplay a table that shows the missing values in the input table.\n\n\nassistant\nChat with the PbA (Pointblank Assistant) about your data validation needs.\n\n\nload_dataset\nLoad a dataset hosted in the library as specified table type.\n\n\nget_data_path\nGet the file path to a dataset included with the Pointblank package.\n\n\nconnect_to_table\nConnect to a database table using a connection string.\n\n\nprint_database_tables\nList all tables in a database from a connection string."
  },
  {
    "objectID": "reference/index.html#yaml",
    "href": "reference/index.html#yaml",
    "title": "API Reference",
    "section": "",
    "text": "The YAML group contains functions that allow for the use of YAML to orchestrate validation workflows. The yaml_interrogate() function can be used to run a validation workflow from YAML strings or files. The validate_yaml() function checks if the YAML configuration passes its own validity checks. The yaml_to_python() function converts YAML configuration to equivalent Python code.\n\n\n\nyaml_interrogate\nExecute a YAML-based validation workflow.\n\n\nvalidate_yaml\nValidate YAML configuration against the expected structure.\n\n\nyaml_to_python\nConvert YAML validation configuration to equivalent Python code."
  },
  {
    "objectID": "reference/index.html#utility-functions",
    "href": "reference/index.html#utility-functions",
    "title": "API Reference",
    "section": "",
    "text": "The Utility Functions group contains functions that are useful accessing metadata about the target data. Use get_column_count() or get_row_count() to get the number of columns or rows in a table. The get_action_metadata() function is useful when building custom actions since it returns metadata about the validation step that’s triggering the action. Lastly, the config() utility lets us set global configuration parameters.\n\n\n\nget_column_count\nGet the number of columns in a table.\n\n\nget_row_count\nGet the number of rows in a table.\n\n\nget_action_metadata\nAccess step-level metadata when authoring custom actions.\n\n\nget_validation_summary\nAccess validation summary information when authoring final actions.\n\n\nwrite_file\nWrite a Validate object to disk as a serialized file.\n\n\nread_file\nRead a Validate object from disk that was previously saved with write_file().\n\n\nconfig\nConfiguration settings for the Pointblank library."
  },
  {
    "objectID": "reference/index.html#prebuilt-actions",
    "href": "reference/index.html#prebuilt-actions",
    "title": "API Reference",
    "section": "",
    "text": "The Prebuilt Actions group contains a function that can be used to send a Slack notification when validation steps exceed failure threshold levels or just to provide a summary of the validation results, including the status, number of steps, passing and failing steps, table information, and timing details.\n\n\n\nsend_slack_notification\nCreate a Slack notification function using a webhook URL."
  },
  {
    "objectID": "reference/seg_group.html",
    "href": "reference/seg_group.html",
    "title": "seg_group",
    "section": "",
    "text": "seg_group(values)\nGroup together values for segmentation.\nMany validation methods have a segments= argument that can be used to specify one or more columns, or certain values within a column, to create segments for validation (e.g., col_vals_gt(), col_vals_regex(), etc.). When passing in a column, or a tuple with a column and certain values, a segment will be created for each individual value within the column or given values. The seg_group() selector enables values to be grouped together into a segment. For example, if you were to create a segment for a column “region”, investigating just “North” and “South” regions, a typical segment would look like:\nsegments=(\"region\", [\"North\", \"South\"])\nThis would create two validation steps, one for each of the regions. If you wanted to group these two regions into a single segment, you could use the seg_group() function like this:\nsegments=(\"region\", pb.seg_group([\"North\", \"South\"]))\nYou could create a second segment for “East” and “West” regions like this:\nsegments=(\"region\", pb.seg_group([[\"North\", \"South\"], [\"East\", \"West\"]]))\nThere will be a validation step created for every segment. Note that if there aren’t any segments created using seg_group() (or any other segment expression), the validation step will fail to be evaluated during the interrogation process. Such a failure to evaluate will be reported in the validation results but it won’t affect the interrogation process overall (i.e., the process won’t be halted)."
  },
  {
    "objectID": "reference/seg_group.html#parameters",
    "href": "reference/seg_group.html#parameters",
    "title": "seg_group",
    "section": "Parameters",
    "text": "Parameters\n\nvalues : list[Any]\n\nA list of values to be grouped into a segment. This can be a single list or a list of lists."
  },
  {
    "objectID": "reference/seg_group.html#returns",
    "href": "reference/seg_group.html#returns",
    "title": "seg_group",
    "section": "Returns",
    "text": "Returns\n\n : Segment\n\nA Segment object, which can be used to combine values into a segment."
  },
  {
    "objectID": "reference/seg_group.html#examples",
    "href": "reference/seg_group.html#examples",
    "title": "seg_group",
    "section": "Examples",
    "text": "Examples\nLet’s say we’re analyzing sales from our local bookstore, and want to check the number of books sold for the month exceeds a certain threshold. We could pass in the argument segments=\"genre\", which would return a segment for each unique genre in the datasets. We could also pass in segments=(\"genre\", [\"Fantasy\", \"Science Fiction\"]), to only create segments for those two genres. However, if we wanted to group these two genres into a single segment, we could use the seg_group() function.\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"title\": [\n            \"The Hobbit\",\n            \"Harry Potter and the Sorcerer's Stone\",\n            \"The Lord of the Rings\",\n            \"A Game of Thrones\",\n            \"The Name of the Wind\",\n            \"The Girl with the Dragon Tattoo\",\n            \"The Da Vinci Code\",\n            \"The Hitchhiker's Guide to the Galaxy\",\n            \"The Martian\",\n            \"Brave New World\"\n        ],\n        \"genre\": [\n            \"Fantasy\",\n            \"Fantasy\",\n            \"Fantasy\",\n            \"Fantasy\",\n            \"Fantasy\",\n            \"Mystery\",\n            \"Mystery\",\n            \"Science Fiction\",\n            \"Science Fiction\",\n            \"Science Fiction\",\n        ],\n        \"units_sold\": [875, 932, 756, 623, 445, 389, 678, 534, 712, 598],\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(\n        columns=\"units_sold\",\n        value=500,\n        segments=(\"genre\", pb.seg_group([\"Fantasy\", \"Science Fiction\"]))\n    )\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    SEGMENT  genre / ['Fantasy', 'Science Fiction'] \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    units_sold\n    500\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    8\n    70.88\n    10.12\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nWhat’s more, we can create multiple segments, combining the genres in different ways.\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(\n        columns=\"units_sold\",\n        value=500,\n        segments=(\"genre\", pb.seg_group([\n            [\"Fantasy\", \"Science Fiction\"],\n            [\"Fantasy\", \"Mystery\"],\n            [\"Mystery\", \"Science Fiction\"]\n        ]))\n    )\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    SEGMENT  genre / ['Fantasy', 'Science Fiction'] \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    units_sold\n    500\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    8\n    70.88\n    10.12\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    SEGMENT  genre / ['Fantasy', 'Mystery'] \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    units_sold\n    500\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    7\n    50.71\n    20.29\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    3\n    SEGMENT  genre / ['Mystery', 'Science Fiction'] \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    units_sold\n    500\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    40.80\n    10.20\n    —\n    —\n    —\n    CSV"
  },
  {
    "objectID": "reference/Validate.col_vals_between.html",
    "href": "reference/Validate.col_vals_between.html",
    "title": "Validate.col_vals_between",
    "section": "",
    "text": "Validate.col_vals_between(\n    columns,\n    left,\n    right,\n    inclusive=(True, True),\n    na_pass=False,\n    pre=None,\n    segments=None,\n    thresholds=None,\n    actions=None,\n    brief=None,\n    active=True,\n)\nDo column data lie between two specified values or data in other columns?\nThe col_vals_between() validation method checks whether column values in a table fall within a range. The range is specified with three arguments: left=, right=, and inclusive=. The left= and right= values specify the lower and upper bounds. These bounds can be specified as literal values or as column names provided within col(). The validation will operate over the number of test units that is equal to the number of rows in the table (determined after any pre= mutation has been applied)."
  },
  {
    "objectID": "reference/Validate.col_vals_between.html#parameters",
    "href": "reference/Validate.col_vals_between.html#parameters",
    "title": "Validate.col_vals_between",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns : str | list[str] | Column | ColumnSelector | ColumnSelectorNarwhals\n\nA single column or a list of columns to validate. Can also use col() with column selectors to specify one or more columns. If multiple columns are supplied or resolved, there will be a separate validation step generated for each column.\n\nleft : float | int | Column\n\nThe lower bound of the range. This can be a single value or a single column name given in col(). The latter option allows for a column-to-column comparison for this bound. See the What Can Be Used in left= and right=? section for details on this.\n\nright : float | int | Column\n\nThe upper bound of the range. This can be a single value or a single column name given in col(). The latter option allows for a column-to-column comparison for this bound. See the What Can Be Used in left= and right=? section for details on this.\n\ninclusive : tuple[bool, bool] = (True, True)\n\nA tuple of two boolean values indicating whether the comparison should be inclusive. The position of the boolean values correspond to the left= and right= values, respectively. By default, both values are True.\n\nna_pass : bool = False\n\nShould any encountered None, NA, or Null values be considered as passing test units? By default, this is False. Set to True to pass test units with missing values.\n\npre : Callable | None = None\n\nAn optional preprocessing function or lambda to apply to the data table during interrogation. This function should take a table as input and return a modified table. Have a look at the Preprocessing section for more information on how to use this argument.\n\nsegments : SegmentSpec | None = None\n\nAn optional directive on segmentation, which serves to split a validation step into multiple (one step per segment). Can be a single column name, a tuple that specifies a column name and its corresponding values to segment on, or a combination of both (provided as a list). Read the Segmentation section for usage information.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nSet threshold failure levels for reporting and reacting to exceedences of the levels. The thresholds are set at the step level and will override any global thresholds set in Validate(thresholds=...). The default is None, which means that no thresholds will be set locally and global thresholds (if any) will take effect. Look at the Thresholds section for information on how to set threshold levels.\n\nactions : Actions | None = None\n\nOptional actions to take when the validation step(s) meets or exceeds any set threshold levels. If provided, the Actions class should be used to define the actions.\n\nbrief : str | bool | None = None\n\nAn optional brief description of the validation step that will be displayed in the reporting table. You can use the templating elements like \"{step}\" to insert the step number, or \"{auto}\" to include an automatically generated brief. If True the entire brief will be automatically generated. If None (the default) then there won’t be a brief.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.col_vals_between.html#returns",
    "href": "reference/Validate.col_vals_between.html#returns",
    "title": "Validate.col_vals_between",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.col_vals_between.html#what-can-be-used-in-left-and-right",
    "href": "reference/Validate.col_vals_between.html#what-can-be-used-in-left-and-right",
    "title": "Validate.col_vals_between",
    "section": "What Can Be Used in left= and right=?",
    "text": "What Can Be Used in left= and right=?\nThe left= and right= arguments both allow for a variety of input types. The most common are:\n\na single numeric value\na single date or datetime value\nA col() object that represents a column in the target table\n\nWhen supplying a number as the basis of comparison, keep in mind that all resolved columns must also be numeric. Should you have columns that are of the date or datetime types, you can supply a date or datetime value within left= and right=. There is flexibility in how you provide the date or datetime values for the bounds; they can be:\n\nstring-based dates or datetimes (e.g., \"2023-10-01\", \"2023-10-01 13:45:30\", etc.)\ndate or datetime objects using the datetime module (e.g., datetime.date(2023, 10, 1), datetime.datetime(2023, 10, 1, 13, 45, 30), etc.)\n\nFinally, when supplying a column name in either left= or right= (or both), it must be specified within col(). This facilitates column-to-column comparisons and, crucially, the columns being compared to either/both of the bounds must be of the same type as the column data (e.g., all numeric, all dates, etc.)."
  },
  {
    "objectID": "reference/Validate.col_vals_between.html#preprocessing",
    "href": "reference/Validate.col_vals_between.html#preprocessing",
    "title": "Validate.col_vals_between",
    "section": "Preprocessing",
    "text": "Preprocessing\nThe pre= argument allows for a preprocessing function or lambda to be applied to the data table during interrogation. This function should take a table as input and return a modified table. This is useful for performing any necessary transformations or filtering on the data before the validation step is applied.\nThe preprocessing function can be any callable that takes a table as input and returns a modified table. For example, you could use a lambda function to filter the table based on certain criteria or to apply a transformation to the data. Note that you can refer to columns via columns= and left=col(...)/right=col(...) that are expected to be present in the transformed table, but may not exist in the table before preprocessing. Regarding the lifetime of the transformed table, it only exists during the validation step and is not stored in the Validate object or used in subsequent validation steps."
  },
  {
    "objectID": "reference/Validate.col_vals_between.html#segmentation",
    "href": "reference/Validate.col_vals_between.html#segmentation",
    "title": "Validate.col_vals_between",
    "section": "Segmentation",
    "text": "Segmentation\nThe segments= argument allows for the segmentation of a validation step into multiple segments. This is useful for applying the same validation step to different subsets of the data. The segmentation can be done based on a single column or specific fields within a column.\nProviding a single column name will result in a separate validation step for each unique value in that column. For example, if you have a column called \"region\" with values \"North\", \"South\", and \"East\", the validation step will be applied separately to each region.\nAlternatively, you can provide a tuple that specifies a column name and its corresponding values to segment on. For example, if you have a column called \"date\" and you want to segment on only specific dates, you can provide a tuple like (\"date\", [\"2023-01-01\", \"2023-01-02\"]). Any other values in the column will be disregarded (i.e., no validation steps will be created for them).\nA list with a combination of column names and tuples can be provided as well. This allows for more complex segmentation scenarios. The following inputs are both valid:\n# Segments from all unique values in the `region` column\n# and specific dates in the `date` column\nsegments=[\"region\", (\"date\", [\"2023-01-01\", \"2023-01-02\"])]\n\n# Segments from all unique values in the `region` and `date` columns\nsegments=[\"region\", \"date\"]\nThe segmentation is performed during interrogation, and the resulting validation steps will be numbered sequentially. Each segment will have its own validation step, and the results will be reported separately. This allows for a more granular analysis of the data and helps identify issues within specific segments.\nImportantly, the segmentation process will be performed after any preprocessing of the data table. Because of this, one can conceivably use the pre= argument to generate a column that can be used for segmentation. For example, you could create a new column called \"segment\" through use of pre= and then use that column for segmentation."
  },
  {
    "objectID": "reference/Validate.col_vals_between.html#thresholds",
    "href": "reference/Validate.col_vals_between.html#thresholds",
    "title": "Validate.col_vals_between",
    "section": "Thresholds",
    "text": "Thresholds\nThe thresholds= parameter is used to set the failure-condition levels for the validation step. If they are set here at the step level, these thresholds will override any thresholds set at the global level in Validate(thresholds=...).\nThere are three threshold levels: ‘warning’, ‘error’, and ‘critical’. The threshold values can either be set as a proportion failing of all test units (a value between 0 to 1), or, the absolute number of failing test units (as integer that’s 1 or greater).\nThresholds can be defined using one of these input schemes:\n\nuse the Thresholds class (the most direct way to create thresholds)\nprovide a tuple of 1-3 values, where position 0 is the ‘warning’ level, position 1 is the ‘error’ level, and position 2 is the ‘critical’ level\ncreate a dictionary of 1-3 value entries; the valid keys: are ‘warning’, ‘error’, and ‘critical’\na single integer/float value denoting absolute number or fraction of failing test units for the ‘warning’ level only\n\nIf the number of failing test units exceeds set thresholds, the validation step will be marked as ‘warning’, ‘error’, or ‘critical’. All of the threshold levels don’t need to be set, you’re free to set any combination of them.\nAside from reporting failure conditions, thresholds can be used to determine the actions to take for each level of failure (using the actions= parameter)."
  },
  {
    "objectID": "reference/Validate.col_vals_between.html#examples",
    "href": "reference/Validate.col_vals_between.html#examples",
    "title": "Validate.col_vals_between",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with three numeric columns (a, b, and c). The table is shown below:\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [2, 3, 2, 4, 3, 4],\n        \"b\": [5, 6, 1, 6, 8, 5],\n        \"c\": [9, 8, 8, 7, 7, 8],\n    }\n)\n\npb.preview(tbl)\n\n\n\n\n\n  \n  \n  \n  \n\n\n\n\n\n  \n  aInt64\n  bInt64\n  cInt64\n\n\n\n  \n    1\n    2\n    5\n    9\n  \n  \n    2\n    3\n    6\n    8\n  \n  \n    3\n    2\n    1\n    8\n  \n  \n    4\n    4\n    6\n    7\n  \n  \n    5\n    3\n    8\n    7\n  \n  \n    6\n    4\n    5\n    8\n  \n\n\n\n\n\n\n        \n\n\nLet’s validate that values in column a are all between the fixed boundary values of 1 and 5. We’ll determine if this validation had any failing test units (there are six test units, one for each row).\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_between(columns=\"a\", left=1, right=5)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_between\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_between()\n        \n        \n        \n    a\n    [1, 5]\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    61.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nPrinting the validation object shows the validation table in an HTML viewing environment. The validation table shows the single entry that corresponds to the validation step created by using col_vals_between(). All test units passed, and there are no failing test units.\nAside from checking a column against two literal values representing the lower and upper bounds, we can also provide column names to the left= and/or right= arguments (by using the helper function col(). In this way, we can perform three additional comparison types:\n\nleft=column, right=column\nleft=literal, right=column\nleft=column, right=literal\n\nFor the next example, we’ll use col_vals_between() to check whether the values in column b are between than corresponding values in columns a (lower bound) and c (upper bound).\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_between(columns=\"b\", left=pb.col(\"a\"), right=pb.col(\"c\"))\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_between\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_between()\n        \n        \n        \n    b\n    [a, c]\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    40.67\n    20.33\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe validation table reports two failing test units. The specific failing cases are:\n\nRow 2: b is 1 but the bounds are 2 (a) and 8 (c).\nRow 4: b is 8 but the bounds are 3 (a) and 7 (c)."
  },
  {
    "objectID": "reference/Validate.col_vals_not_in_set.html",
    "href": "reference/Validate.col_vals_not_in_set.html",
    "title": "Validate.col_vals_not_in_set",
    "section": "",
    "text": "Validate.col_vals_not_in_set(\n    columns,\n    set,\n    pre=None,\n    segments=None,\n    thresholds=None,\n    actions=None,\n    brief=None,\n    active=True,\n)\nValidate whether column values are not in a set of values.\nThe col_vals_not_in_set() validation method checks whether column values in a table are not part of a specified set= of values. This validation will operate over the number of test units that is equal to the number of rows in the table (determined after any pre= mutation has been applied)."
  },
  {
    "objectID": "reference/Validate.col_vals_not_in_set.html#parameters",
    "href": "reference/Validate.col_vals_not_in_set.html#parameters",
    "title": "Validate.col_vals_not_in_set",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns : str | list[str] | Column | ColumnSelector | ColumnSelectorNarwhals\n\nA single column or a list of columns to validate. Can also use col() with column selectors to specify one or more columns. If multiple columns are supplied or resolved, there will be a separate validation step generated for each column.\n\nset : Collection[Any]\n\nA collection of values to compare against. Can be a list of values, a Python Enum class, or a collection containing Enum instances. When an Enum class is provided, all enum values will be used. When a collection contains Enum instances, their values will be extracted automatically.\n\npre : Callable | None = None\n\nAn optional preprocessing function or lambda to apply to the data table during interrogation. This function should take a table as input and return a modified table. Have a look at the Preprocessing section for more information on how to use this argument.\n\nsegments : SegmentSpec | None = None\n\nAn optional directive on segmentation, which serves to split a validation step into multiple (one step per segment). Can be a single column name, a tuple that specifies a column name and its corresponding values to segment on, or a combination of both (provided as a list). Read the Segmentation section for usage information.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nSet threshold failure levels for reporting and reacting to exceedences of the levels. The thresholds are set at the step level and will override any global thresholds set in Validate(thresholds=...). The default is None, which means that no thresholds will be set locally and global thresholds (if any) will take effect. Look at the Thresholds section for information on how to set threshold levels.\n\nactions : Actions | None = None\n\nOptional actions to take when the validation step(s) meets or exceeds any set threshold levels. If provided, the Actions class should be used to define the actions.\n\nbrief : str | bool | None = None\n\nAn optional brief description of the validation step that will be displayed in the reporting table. You can use the templating elements like \"{step}\" to insert the step number, or \"{auto}\" to include an automatically generated brief. If True the entire brief will be automatically generated. If None (the default) then there won’t be a brief.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.col_vals_not_in_set.html#returns",
    "href": "reference/Validate.col_vals_not_in_set.html#returns",
    "title": "Validate.col_vals_not_in_set",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.col_vals_not_in_set.html#preprocessing",
    "href": "reference/Validate.col_vals_not_in_set.html#preprocessing",
    "title": "Validate.col_vals_not_in_set",
    "section": "Preprocessing",
    "text": "Preprocessing\nThe pre= argument allows for a preprocessing function or lambda to be applied to the data table during interrogation. This function should take a table as input and return a modified table. This is useful for performing any necessary transformations or filtering on the data before the validation step is applied.\nThe preprocessing function can be any callable that takes a table as input and returns a modified table. For example, you could use a lambda function to filter the table based on certain criteria or to apply a transformation to the data. Note that you can refer to a column via columns= that is expected to be present in the transformed table, but may not exist in the table before preprocessing. Regarding the lifetime of the transformed table, it only exists during the validation step and is not stored in the Validate object or used in subsequent validation steps."
  },
  {
    "objectID": "reference/Validate.col_vals_not_in_set.html#segmentation",
    "href": "reference/Validate.col_vals_not_in_set.html#segmentation",
    "title": "Validate.col_vals_not_in_set",
    "section": "Segmentation",
    "text": "Segmentation\nThe segments= argument allows for the segmentation of a validation step into multiple segments. This is useful for applying the same validation step to different subsets of the data. The segmentation can be done based on a single column or specific fields within a column.\nProviding a single column name will result in a separate validation step for each unique value in that column. For example, if you have a column called \"region\" with values \"North\", \"South\", and \"East\", the validation step will be applied separately to each region.\nAlternatively, you can provide a tuple that specifies a column name and its corresponding values to segment on. For example, if you have a column called \"date\" and you want to segment on only specific dates, you can provide a tuple like (\"date\", [\"2023-01-01\", \"2023-01-02\"]). Any other values in the column will be disregarded (i.e., no validation steps will be created for them).\nA list with a combination of column names and tuples can be provided as well. This allows for more complex segmentation scenarios. The following inputs are both valid:\n# Segments from all unique values in the `region` column\n# and specific dates in the `date` column\nsegments=[\"region\", (\"date\", [\"2023-01-01\", \"2023-01-02\"])]\n\n# Segments from all unique values in the `region` and `date` columns\nsegments=[\"region\", \"date\"]\nThe segmentation is performed during interrogation, and the resulting validation steps will be numbered sequentially. Each segment will have its own validation step, and the results will be reported separately. This allows for a more granular analysis of the data and helps identify issues within specific segments.\nImportantly, the segmentation process will be performed after any preprocessing of the data table. Because of this, one can conceivably use the pre= argument to generate a column that can be used for segmentation. For example, you could create a new column called \"segment\" through use of pre= and then use that column for segmentation."
  },
  {
    "objectID": "reference/Validate.col_vals_not_in_set.html#thresholds",
    "href": "reference/Validate.col_vals_not_in_set.html#thresholds",
    "title": "Validate.col_vals_not_in_set",
    "section": "Thresholds",
    "text": "Thresholds\nThe thresholds= parameter is used to set the failure-condition levels for the validation step. If they are set here at the step level, these thresholds will override any thresholds set at the global level in Validate(thresholds=...).\nThere are three threshold levels: ‘warning’, ‘error’, and ‘critical’. The threshold values can either be set as a proportion failing of all test units (a value between 0 to 1), or, the absolute number of failing test units (as integer that’s 1 or greater).\nThresholds can be defined using one of these input schemes:\n\nuse the Thresholds class (the most direct way to create thresholds)\nprovide a tuple of 1-3 values, where position 0 is the ‘warning’ level, position 1 is the ‘error’ level, and position 2 is the ‘critical’ level\ncreate a dictionary of 1-3 value entries; the valid keys: are ‘warning’, ‘error’, and ‘critical’\na single integer/float value denoting absolute number or fraction of failing test units for the ‘warning’ level only\n\nIf the number of failing test units exceeds set thresholds, the validation step will be marked as ‘warning’, ‘error’, or ‘critical’. All of the threshold levels don’t need to be set, you’re free to set any combination of them.\nAside from reporting failure conditions, thresholds can be used to determine the actions to take for each level of failure (using the actions= parameter)."
  },
  {
    "objectID": "reference/Validate.col_vals_not_in_set.html#examples",
    "href": "reference/Validate.col_vals_not_in_set.html#examples",
    "title": "Validate.col_vals_not_in_set",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with two numeric columns (a and b). The table is shown below:\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [7, 8, 1, 9, 1, 7],\n        \"b\": [1, 8, 2, 6, 9, 1],\n    }\n)\n\npb.preview(tbl)\n\n\n\n\n\n  \n  \n  \n\n\n\n\n\n  \n  aInt64\n  bInt64\n\n\n\n  \n    1\n    7\n    1\n  \n  \n    2\n    8\n    8\n  \n  \n    3\n    1\n    2\n  \n  \n    4\n    9\n    6\n  \n  \n    5\n    1\n    9\n  \n  \n    6\n    7\n    1\n  \n\n\n\n\n\n\n        \n\n\nLet’s validate that none of the values in column a are in the set of [2, 3, 4, 5, 6]. We’ll determine if this validation had any failing test units (there are six test units, one for each row).\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_not_in_set(columns=\"a\", set=[2, 3, 4, 5, 6])\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_not_in_set\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_in_set()\n        \n        \n        \n    a\n    2, 3, 4, 5, 6\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    61.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nPrinting the validation object shows the validation table in an HTML viewing environment. The validation table shows the single entry that corresponds to the validation step created by using col_vals_not_in_set(). All test units passed, and there are no failing test units.\nNow, let’s use that same set of values for a validation on column b.\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_not_in_set(columns=\"b\", set=[2, 3, 4, 5, 6])\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_not_in_set\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_in_set()\n        \n        \n        \n    b\n    2, 3, 4, 5, 6\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    40.67\n    20.33\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe validation table reports two failing test units. The specific failing cases are for the column b values of 2 and 6, both of which are in the set of [2, 3, 4, 5, 6].\nUsing Python Enums\nLike col_vals_in_set(), this method also supports Python Enum classes and instances:\n\nfrom enum import Enum\n\nclass InvalidStatus(Enum):\n    DELETED = \"deleted\"\n    ARCHIVED = \"archived\"\n\n# Create a table with status data\nstatus_table = pl.DataFrame({\n    \"product\": [\"widget\", \"gadget\", \"tool\", \"device\"],\n    \"status\": [\"active\", \"pending\", \"deleted\", \"active\"]\n})\n\n# Validate that no values are in the invalid status set\nvalidation = (\n    pb.Validate(data=status_table)\n    .col_vals_not_in_set(columns=\"status\", set=InvalidStatus)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_not_in_set\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_in_set()\n        \n        \n        \n    status\n    deleted, archived\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    30.75\n    10.25\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThis \"deleted\" value in the status column will fail since it matches one of the invalid statuses in the InvalidStatus enum."
  },
  {
    "objectID": "reference/col.html",
    "href": "reference/col.html",
    "title": "col",
    "section": "",
    "text": "col(exprs)\nHelper function for referencing a column in the input table.\nMany of the validation methods (i.e., col_vals_*() methods) in Pointblank have a value= argument. These validations are comparisons between column values and a literal value, or, between column values and adjacent values in another column. The col() helper function is used to specify that it is a column being referenced, not a literal value.\nThe col() doesn’t check that the column exists in the input table. It acts to signal that the value being compared is a column value. During validation (i.e., when interrogate() is called), Pointblank will then check that the column exists in the input table.\nFor creating expressions to use with the conjointly() validation method, use the expr_col() function instead."
  },
  {
    "objectID": "reference/col.html#parameters",
    "href": "reference/col.html#parameters",
    "title": "col",
    "section": "Parameters",
    "text": "Parameters\n\nexprs : str | ColumnSelector | ColumnSelectorNarwhals\n\nEither the name of a single column in the target table, provided as a string, or, an expression involving column selector functions (e.g., starts_with(\"a\"), ends_with(\"e\") \\| starts_with(\"a\"), etc.)."
  },
  {
    "objectID": "reference/col.html#returns",
    "href": "reference/col.html#returns",
    "title": "col",
    "section": "Returns",
    "text": "Returns\n\n : Column | ColumnLiteral | ColumnSelectorNarwhals:\n\nA column object or expression representing the column reference."
  },
  {
    "objectID": "reference/col.html#usage-with-the-columns-argument",
    "href": "reference/col.html#usage-with-the-columns-argument",
    "title": "col",
    "section": "Usage with the columns= Argument",
    "text": "Usage with the columns= Argument\nThe col() function can be used in the columns= argument of the following validation methods:\n\ncol_vals_gt()\ncol_vals_lt()\ncol_vals_ge()\ncol_vals_le()\ncol_vals_eq()\ncol_vals_ne()\ncol_vals_between()\ncol_vals_outside()\ncol_vals_in_set()\ncol_vals_not_in_set()\ncol_vals_increasing()\ncol_vals_decreasing()\ncol_vals_null()\ncol_vals_not_null()\ncol_vals_regex()\ncol_vals_within_spec()\ncol_exists()\n\nIf specifying a single column with certainty (you have the exact name), col() is not necessary since you can just pass the column name as a string (though it is still valid to use col(\"column_name\"), if preferred). However, if you want to select columns based on complex logic involving multiple column selector functions (e.g., columns that start with \"a\" but don’t end with \"e\"), you need to use col() to wrap expressions involving column selector functions and logical operators such as &, |, -, and ~.\nHere is an example of such usage with the col_vals_gt() validation method:\ncol_vals_gt(columns=col(starts_with(\"a\") & ~ends_with(\"e\")), value=10)\nIf using only a single column selector function, you can pass the function directly to the columns= argument of the validation method, or, you can use col() to wrap the function (either is valid though the first is more concise). Here is an example of that simpler usage:\ncol_vals_gt(columns=starts_with(\"a\"), value=10)"
  },
  {
    "objectID": "reference/col.html#usage-with-the-value-left-and-right-arguments",
    "href": "reference/col.html#usage-with-the-value-left-and-right-arguments",
    "title": "col",
    "section": "Usage with the value=, left=, and right= Arguments",
    "text": "Usage with the value=, left=, and right= Arguments\nThe col() function can be used in the value= argument of the following validation methods\n\ncol_vals_gt()\ncol_vals_lt()\ncol_vals_ge()\ncol_vals_le()\ncol_vals_eq()\ncol_vals_ne()\n\nand in the left= and right= arguments (either or both) of these two validation methods\n\ncol_vals_between()\ncol_vals_outside()\n\nYou cannot use column selector functions such as starts_with() in either of the value=, left=, or right= arguments since there would be no guarantee that a single column will be resolved from the target table with this approach. The col() function is used to signal that the value being compared is a column value and not a literal value."
  },
  {
    "objectID": "reference/col.html#available-selectors",
    "href": "reference/col.html#available-selectors",
    "title": "col",
    "section": "Available Selectors",
    "text": "Available Selectors\nThere is a collection of selectors available in pointblank, allowing you to select columns based on attributes of column names and positions. The selectors are:\n\nstarts_with()\nends_with()\ncontains()\nmatches()\neverything()\nfirst_n()\nlast_n()\n\nAlternatively, we support selectors from the Narwhals library! Those selectors can additionally take advantage of the data types of the columns. The selectors are:\n\nboolean()\nby_dtype()\ncategorical()\nmatches()\nnumeric()\nstring()\n\nHave a look at the Narwhals API documentation on selectors for more information."
  },
  {
    "objectID": "reference/col.html#examples",
    "href": "reference/col.html#examples",
    "title": "col",
    "section": "Examples",
    "text": "Examples\nSuppose we have a table with columns a and b and we’d like to validate that the values in column a are greater than the values in column b. We can use the col() helper function to reference the comparison column when creating the validation step.\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [5, 6, 5, 7, 6, 5],\n        \"b\": [4, 2, 3, 3, 4, 3],\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(columns=\"a\", value=pb.col(\"b\"))\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    a\n    b\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    61.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nFrom results of the validation table it can be seen that values in a were greater than values in b for every row (or test unit). Using value=pb.col(\"b\") specified that the greater-than comparison is across columns, not with a fixed literal value.\nIf you want to select an arbitrary set of columns upon which to base a validation, you can use column selector functions (e.g., starts_with(), ends_with(), etc.) to specify columns in the columns= argument of a validation method. Let’s use the starts_with() column selector function to select columns that start with \"paid\" and validate that the values in those columns are greater than 10.\n\ntbl = pl.DataFrame(\n    {\n        \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n        \"paid_2021\": [16.32, 16.25, 15.75],\n        \"paid_2022\": [18.62, 16.95, 18.25],\n        \"person_id\": [\"A123\", \"B456\", \"C789\"],\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(columns=pb.col(pb.starts_with(\"paid\")), value=10)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    paid_2021\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    paid_2022\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nIn the above example the col() function contains the invocation of the starts_with() column selector function. This is not strictly necessary when using a single column selector function, so columns=pb.starts_with(\"paid\") would be equivalent usage here. However, the use of col() is required when using multiple column selector functions with logical operators. Here is an example of that more complex usage:\n\ntbl = pl.DataFrame(\n    {\n        \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n        \"hours_2022\": [160, 180, 160],\n        \"hours_2023\": [182, 168, 175],\n        \"hours_2024\": [200, 165, 190],\n        \"paid_2022\": [18.62, 16.95, 18.25],\n        \"paid_2023\": [19.29, 17.75, 18.35],\n        \"paid_2024\": [20.73, 18.35, 20.10],\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(\n        columns=pb.col(pb.starts_with(\"paid\") & pb.matches(\"2023|2024\")),\n        value=10\n    )\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    paid_2023\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    paid_2024\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nIn the above example the col() function contains the invocation of the starts_with() and matches() column selector functions, combined with the & operator. This is necessary to specify the set of columns that start with \"paid\" and match the text \"2023\" or \"2024\".\nIf you’d like to take advantage of Narwhals selectors, that’s also possible. Here is an example of using the numeric() column selector function to select all numeric columns for validation, checking that their values are greater than 0.\n\nimport narwhals.selectors as ncs\n\ntbl = pl.DataFrame(\n    {\n        \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n        \"hours_2022\": [160, 180, 160],\n        \"hours_2023\": [182, 168, 175],\n        \"hours_2024\": [200, 165, 190],\n        \"paid_2022\": [18.62, 16.95, 18.25],\n        \"paid_2023\": [19.29, 17.75, 18.35],\n        \"paid_2024\": [20.73, 18.35, 20.10],\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_ge(columns=pb.col(ncs.numeric()), value=0)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_ge\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_ge()\n        \n        \n        \n    hours_2022\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_ge\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_ge()\n        \n        \n        \n    hours_2023\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_vals_ge\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_ge()\n        \n        \n        \n    hours_2024\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_vals_ge\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_ge()\n        \n        \n        \n    paid_2022\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    5\n    \n        \n            \n\n    col_vals_ge\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_ge()\n        \n        \n        \n    paid_2023\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    6\n    \n        \n            \n\n    col_vals_ge\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_ge()\n        \n        \n        \n    paid_2024\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nIn the above example the col() function contains the invocation of the numeric() column selector function from Narwhals. As with the other selectors, this is not strictly necessary when using a single column selector, so columns=ncs.numeric() would also be fine here.\nNarwhals selectors can also use operators to combine multiple selectors. Here is an example of using the numeric() and matches() selectors together to select all numeric columns that fit a specific pattern.\n\ntbl = pl.DataFrame(\n    {\n        \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n        \"2022_status\": [\"ft\", \"ft\", \"pt\"],\n        \"2023_status\": [\"ft\", \"pt\", \"ft\"],\n        \"2024_status\": [\"ft\", \"pt\", \"ft\"],\n        \"2022_pay_total\": [18.62, 16.95, 18.25],\n        \"2023_pay_total\": [19.29, 17.75, 18.35],\n        \"2024_pay_total\": [20.73, 18.35, 20.10],\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_lt(columns=pb.col(ncs.numeric() & ncs.matches(\"2023|2024\")), value=30)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    2023_pay_total\n    30\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    2024_pay_total\n    30\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nIn the above example the col() function contains the invocation of the numeric() and matches() column selector functions from Narwhals, combined with the & operator. This is necessary to specify the set of columns that are numeric and match the text \"2023\" or \"2024\"."
  },
  {
    "objectID": "reference/col.html#see-also",
    "href": "reference/col.html#see-also",
    "title": "col",
    "section": "See Also",
    "text": "See Also\nCreate a column expression for use in conjointly() validation with the expr_col() function."
  },
  {
    "objectID": "reference/Thresholds.html",
    "href": "reference/Thresholds.html",
    "title": "Thresholds",
    "section": "",
    "text": "Thresholds(warning=None, error=None, critical=None)\nDefinition of threshold values.\nThresholds are used to set limits on the number of failing test units at different levels. The levels are ‘warning’, ‘error’, and ‘critical’. These levels correspond to different levels of severity when a threshold is reached. The threshold values can be set as absolute counts or as fractions of the total number of test units. When a threshold is reached, an action can be taken (e.g., displaying a message or calling a function) if there is an associated action defined for that level (defined through the Actions class)."
  },
  {
    "objectID": "reference/Thresholds.html#parameters",
    "href": "reference/Thresholds.html#parameters",
    "title": "Thresholds",
    "section": "Parameters",
    "text": "Parameters\n\nwarning : int | float | bool | None = None\n\nThe threshold for the ‘warning’ level. This can be an absolute count or a fraction of the total. Using True will set this threshold value to 1.\n\nerror : int | float | bool | None = None\n\nThe threshold for the ‘error’ level. This can be an absolute count or a fraction of the total. Using True will set this threshold value to 1.\n\ncritical : int | float | bool | None = None\n\nThe threshold for the ‘critical’ level. This can be an absolute count or a fraction of the total. Using True will set this threshold value to 1."
  },
  {
    "objectID": "reference/Thresholds.html#returns",
    "href": "reference/Thresholds.html#returns",
    "title": "Thresholds",
    "section": "Returns",
    "text": "Returns\n\n : Thresholds\n\nA Thresholds object. This can be used when using the Validate class (to set thresholds globally) or when defining validation steps like col_vals_gt() (so that threshold values are scoped to individual validation steps, overriding any global thresholds)."
  },
  {
    "objectID": "reference/Thresholds.html#examples",
    "href": "reference/Thresholds.html#examples",
    "title": "Thresholds",
    "section": "Examples",
    "text": "Examples\nIn a data validation workflow, you can set thresholds for the number of failing test units at different levels. For example, you can set a threshold for the ‘warning’ level when the number of failing test units exceeds 10% of the total number of test units:\n\nthresholds_1 = pb.Thresholds(warning=0.1)\n\nYou can also set thresholds for the ‘error’ and ‘critical’ levels:\n\nthresholds_2 = pb.Thresholds(warning=0.1, error=0.2, critical=0.05)\n\nThresholds can also be set as absolute counts. Here’s an example where the ‘warning’ level is set to 5 failing test units:\n\nthresholds_3 = pb.Thresholds(warning=5)\n\nThe thresholds object can be used to set global thresholds for all validation steps. Or, you can set thresholds for individual validation steps, which will override the global thresholds. Here’s a data validation workflow example where we set global thresholds and then override with different thresholds at the col_vals_gt() step:\n\nvalidation = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\"),\n        label=\"Example Validation\",\n        thresholds=pb.Thresholds(warning=0.1, error=0.2, critical=0.3)\n    )\n    .col_vals_not_null(columns=[\"c\", \"d\"])\n    .col_vals_gt(columns=\"a\", value=3, thresholds=pb.Thresholds(warning=5))\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Example ValidationPolarsWARNING0.1ERROR0.2CRITICAL0.3\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #AAAAAA\n    1\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    c\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    ●\n    ○\n    ○\n    CSV\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    d\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #AAAAAA\n    3\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    a\n    3\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    60.46\n    70.54\n    ●\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nAs can be seen, the last step (col_vals_gt()) has its own thresholds, which override the global thresholds set at the beginning of the validation workflow (in the Validate class)."
  },
  {
    "objectID": "reference/yaml_interrogate.html",
    "href": "reference/yaml_interrogate.html",
    "title": "yaml_interrogate",
    "section": "",
    "text": "yaml_interrogate(yaml, set_tbl=None, namespaces=None)\nExecute a YAML-based validation workflow.\nThis is the main entry point for YAML-based validation workflows. It takes YAML configuration (as a string or file path) and returns a validated Validate object with interrogation results.\nThe YAML configuration defines the data source, validation steps, and optional settings like thresholds and labels. This function automatically loads the data, builds the validation plan, executes all validation steps, and returns the interrogated results."
  },
  {
    "objectID": "reference/yaml_interrogate.html#parameters",
    "href": "reference/yaml_interrogate.html#parameters",
    "title": "yaml_interrogate",
    "section": "Parameters",
    "text": "Parameters\n\nyaml : Union[str, Path]\n\nYAML configuration as string or file path. Can be: (1) a YAML string containing the validation configuration, or (2) a Path object or string path to a YAML file.\n\nset_tbl : Union[FrameT, Any, None] = None\n\nAn optional table to override the table specified in the YAML configuration. This allows you to apply a YAML-defined validation workflow to a different table than what’s specified in the configuration. If provided, this table will replace the table defined in the YAML’s tbl field before executing the validation workflow. This can be any supported table type including DataFrame objects, Ibis table objects, CSV file paths, Parquet file paths, GitHub URLs, or database connection strings.\n\nnamespaces : Optional[Union[Iterable[str], Mapping[str, str]]] = None\n\nOptional module namespaces to make available for Python code execution in YAML configurations. Can be a dictionary mapping aliases to module names or a list of module names. See the “Using Namespaces” section below for detailed examples."
  },
  {
    "objectID": "reference/yaml_interrogate.html#returns",
    "href": "reference/yaml_interrogate.html#returns",
    "title": "yaml_interrogate",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nAn instance of the Validate class that has been configured based on the YAML input. This object contains the results of the validation steps defined in the YAML configuration. It includes metadata like table name, label, language, and thresholds if specified."
  },
  {
    "objectID": "reference/yaml_interrogate.html#raises",
    "href": "reference/yaml_interrogate.html#raises",
    "title": "yaml_interrogate",
    "section": "Raises",
    "text": "Raises\n\n: YAMLValidationError\n\nIf the YAML is invalid, malformed, or execution fails. This includes syntax errors, missing required fields, unknown validation methods, or data loading failures."
  },
  {
    "objectID": "reference/yaml_interrogate.html#using-namespaces",
    "href": "reference/yaml_interrogate.html#using-namespaces",
    "title": "yaml_interrogate",
    "section": "Using Namespaces",
    "text": "Using Namespaces\nThe namespaces= parameter enables custom Python modules and functions in YAML configurations. This is particularly useful for custom action functions and advanced Python expressions.\nNamespace formats:\n\nDictionary format: {\"alias\": \"module.name\"} maps aliases to module names\nList format: [\"module.name\", \"another.module\"] imports modules directly\n\nOption 1: Inline expressions (no namespaces needed)\n\nimport pointblank as pb\n\n# Simple inline custom action\nyaml_config = '''\ntbl: small_table\nthresholds:\n  warning: 0.01\nactions:\n  warning:\n    python: \"lambda: print('Custom warning triggered')\"\nsteps:\n- col_vals_gt:\n    columns: [a]\n    value: 1000\n'''\n\nresult = pb.yaml_interrogate(yaml_config)\nresult\n\nCustom warning triggered\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:12:51PolarsWARNING0.01ERROR—CRITICAL—\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #AAAAAA\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    a\n    1000\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    00.00\n    131.00\n    ●\n    —\n    —\n    CSV\n  \n\n  \n  \n  \n    2025-11-23 00:12:51 UTC&lt; 1 s2025-11-23 00:12:51 UTC\n  \n\n\n\n\n\n\n        \n\n\nOption 2: External functions with namespaces\n\n# Define a custom action function\ndef my_custom_action():\n    print(\"Data validation failed: please check your data.\")\n\n# Add to current module for demo\nimport sys\nsys.modules[__name__].my_custom_action = my_custom_action\n\n# YAML that references the external function\nyaml_config = '''\ntbl: small_table\nthresholds:\n  warning: 0.01\nactions:\n  warning:\n    python: actions.my_custom_action\nsteps:\n- col_vals_gt:\n    columns: [a]\n    value: 1000  # This will fail\n'''\n\n# Use namespaces to make the function available\nresult = pb.yaml_interrogate(yaml_config, namespaces={'actions': '__main__'})\nresult\n\nData validation failed: please check your data.\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:12:51PolarsWARNING0.01ERROR—CRITICAL—\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #AAAAAA\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    a\n    1000\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    00.00\n    131.00\n    ●\n    —\n    —\n    CSV\n  \n\n  \n  \n  \n    2025-11-23 00:12:51 UTC&lt; 1 s2025-11-23 00:12:51 UTC\n  \n\n\n\n\n\n\n        \n\n\nThis approach enables modular, reusable validation workflows with custom business logic."
  },
  {
    "objectID": "reference/yaml_interrogate.html#examples",
    "href": "reference/yaml_interrogate.html#examples",
    "title": "yaml_interrogate",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use YAML configurations to define validation workflows. Let’s start with a basic YAML workflow that validates the built-in small_table dataset.\n\nimport pointblank as pb\n\n# Define a basic YAML validation workflow\nyaml_config = '''\ntbl: small_table\nsteps:\n- rows_distinct\n- col_exists:\n    columns: [date, a, b]\n'''\n\n# Execute the validation workflow\nresult = pb.yaml_interrogate(yaml_config)\nresult\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    rows_distinct\n    \n        \n            \n            \n                \n                \n                \n            \n        \n    \n\n        \n        \n            rows_distinct()\n        \n        \n        \n    ALL COLUMNS\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    90.69\n    20.15\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    date\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    a\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    b\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe validation table shows the results of our YAML-defined workflow. We can see that the rows_distinct() validation failed (because there are duplicate rows in the table), while the column existence checks passed.\nNow let’s create a more comprehensive validation workflow with thresholds and metadata:\n\n# Advanced YAML configuration with thresholds and metadata\nyaml_config = '''\ntbl: small_table\ntbl_name: small_table_demo\nlabel: Comprehensive data validation\nthresholds:\n  warning: 0.1\n  error: 0.25\n  critical: 0.35\nsteps:\n- col_vals_gt:\n    columns: [d]\n    value: 100\n- col_vals_regex:\n    columns: [b]\n    pattern: '[0-9]-[a-z]{3}-[0-9]{3}'\n- col_vals_not_null:\n    columns: [date, a]\n'''\n\n# Execute the validation workflow\nresult = pb.yaml_interrogate(yaml_config)\nprint(f\"Table name: {result.tbl_name}\")\nprint(f\"Label: {result.label}\")\nprint(f\"Total validation steps: {len(result.validation_info)}\")\n\nTable name: small_table_demo\nLabel: Comprehensive data validation\nTotal validation steps: 4\n\n\nThe validation results now include our custom table name and label. The thresholds we defined will determine when validation steps are marked as warnings, errors, or critical failures.\nYou can also load YAML configurations from files. Here’s how you would work with a YAML file:\n\nfrom pathlib import Path\nimport tempfile\n\n# Create a temporary YAML file for demonstration\nyaml_content = '''\ntbl: small_table\ntbl_name: File-based Validation\nsteps:\n- col_vals_between:\n    columns: [c]\n    left: 1\n    right: 10\n- col_vals_in_set:\n    columns: [f]\n    set: [low, mid, high]\n'''\n\nwith tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as f:\n    f.write(yaml_content)\n    yaml_file_path = Path(f.name)\n\n# Load and execute validation from file\nresult = pb.yaml_interrogate(yaml_file_path)\nresult\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_between\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_between()\n        \n        \n        \n    c\n    [1, 10]\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        \n        \n    f\n    low, mid, high\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThis approach is particularly useful for storing validation configurations as part of your data pipeline or version control system, allowing you to maintain validation rules alongside your code.\n\nUsing set_tbl= to Override the Table\nThe set_tbl= parameter allows you to override the table specified in the YAML configuration. This is useful when you have a template validation workflow but want to apply it to different tables:\n\nimport polars as pl\n\n# Create a test table with similar structure to small_table\ntest_table = pl.DataFrame({\n    \"date\": [\"2023-01-01\", \"2023-01-02\", \"2023-01-03\"],\n    \"a\": [1, 2, 3],\n    \"b\": [\"1-abc-123\", \"2-def-456\", \"3-ghi-789\"],\n    \"d\": [150, 200, 250]\n})\n\n# Use the same YAML config but apply it to our test table\nyaml_config = '''\ntbl: small_table  # This will be overridden\ntbl_name: Test Table  # This name will be used\nsteps:\n- col_exists:\n    columns: [date, a, b, d]\n- col_vals_gt:\n    columns: [d]\n    value: 100\n'''\n\n# Execute with table override\nresult = pb.yaml_interrogate(yaml_config, set_tbl=test_table)\nprint(f\"Validation applied to: {result.tbl_name}\")\nresult\n\nValidation applied to: Test Table\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    date\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    a\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    b\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    d\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    5\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    100\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThis feature makes YAML configurations more reusable and flexible, allowing you to define validation logic once and apply it to multiple similar tables."
  },
  {
    "objectID": "reference/DataScan.html",
    "href": "reference/DataScan.html",
    "title": "DataScan",
    "section": "",
    "text": "DataScan(data, tbl_name=None)\nGet a summary of a dataset.\nThe DataScan class provides a way to get a summary of a dataset. The summary includes the following information:\n\nthe name of the table (if provided)\nthe type of the table (e.g., \"polars\", \"pandas\", etc.)\nthe number of rows and columns in the table\ncolumn-level information, including:\n\nthe column name\nthe column type\nmeasures of missingness and distinctness\nmeasures of negative, zero, and positive values (for numerical columns)\na sample of the data (the first 5 values)\nstatistics (if the column contains numbers, strings, or datetimes)\n\n\nTo obtain a dictionary representation of the summary, you can use the to_dict() method. To get a JSON representation of the summary, you can use the to_json() method. To save the JSON text to a file, the save_to_json() method could be used.\n\n\n\n\n\n\nWarning\n\n\n\nThe DataScan() class is still experimental. Please report any issues you encounter in the Pointblank issue tracker.\n\n\n\n\n\ndata : IntoFrameT\n\nThe data to scan and summarize. This could be a DataFrame object, an Ibis table object, a CSV file path, a Parquet file path, a GitHub URL pointing to a CSV or Parquet file, or a database connection string.\n\ntbl_name : str | None = None\n\nOptionally, the name of the table could be provided as tbl_name.\n\n\n\n\n\nFor each column, the following measures are provided:\n\nn_missing_values: the number of missing values in the column\nf_missing_values: the fraction of missing values in the column\nn_unique_values: the number of unique values in the column\nf_unique_values: the fraction of unique values in the column\n\nThe fractions are calculated as the ratio of the measure to the total number of rows in the dataset.\n\n\n\nFor numerical columns, the following measures are provided:\n\nn_negative_values: the number of negative values in the column\nf_negative_values: the fraction of negative values in the column\nn_zero_values: the number of zero values in the column\nf_zero_values: the fraction of zero values in the column\nn_positive_values: the number of positive values in the column\nf_positive_values: the fraction of positive values in the column\n\nThe fractions are calculated as the ratio of the measure to the total number of rows in the dataset.\n\n\n\nFor numerical and string columns, several statistical measures are provided. Please note that for string columms, the statistics are based on the lengths of the strings in the column.\nThe following descriptive statistics are provided:\n\nmean: the mean of the column\nstd_dev: the standard deviation of the column\n\nAdditionally, the following quantiles are provided:\n\nmin: the minimum value in the column\np05: the 5th percentile of the column\nq_1: the first quartile of the column\nmed: the median of the column\nq_3: the third quartile of the column\np95: the 95th percentile of the column\nmax: the maximum value in the column\niqr: the interquartile range of the column\n\n\n\n\nFor date/datetime columns, the following statistics are provided:\n\nmin: the minimum date/datetime in the column\nmax: the maximum date/datetime in the column\n\n\n\n\n\n : DataScan\n\nA DataScan object."
  },
  {
    "objectID": "reference/DataScan.html#parameters",
    "href": "reference/DataScan.html#parameters",
    "title": "DataScan",
    "section": "",
    "text": "data : IntoFrameT\n\nThe data to scan and summarize. This could be a DataFrame object, an Ibis table object, a CSV file path, a Parquet file path, a GitHub URL pointing to a CSV or Parquet file, or a database connection string.\n\ntbl_name : str | None = None\n\nOptionally, the name of the table could be provided as tbl_name."
  },
  {
    "objectID": "reference/DataScan.html#measures-of-missingness-and-distinctness",
    "href": "reference/DataScan.html#measures-of-missingness-and-distinctness",
    "title": "DataScan",
    "section": "",
    "text": "For each column, the following measures are provided:\n\nn_missing_values: the number of missing values in the column\nf_missing_values: the fraction of missing values in the column\nn_unique_values: the number of unique values in the column\nf_unique_values: the fraction of unique values in the column\n\nThe fractions are calculated as the ratio of the measure to the total number of rows in the dataset."
  },
  {
    "objectID": "reference/DataScan.html#counts-and-fractions-of-negative-zero-and-positive-values",
    "href": "reference/DataScan.html#counts-and-fractions-of-negative-zero-and-positive-values",
    "title": "DataScan",
    "section": "",
    "text": "For numerical columns, the following measures are provided:\n\nn_negative_values: the number of negative values in the column\nf_negative_values: the fraction of negative values in the column\nn_zero_values: the number of zero values in the column\nf_zero_values: the fraction of zero values in the column\nn_positive_values: the number of positive values in the column\nf_positive_values: the fraction of positive values in the column\n\nThe fractions are calculated as the ratio of the measure to the total number of rows in the dataset."
  },
  {
    "objectID": "reference/DataScan.html#statistics-for-numerical-and-string-columns",
    "href": "reference/DataScan.html#statistics-for-numerical-and-string-columns",
    "title": "DataScan",
    "section": "",
    "text": "For numerical and string columns, several statistical measures are provided. Please note that for string columms, the statistics are based on the lengths of the strings in the column.\nThe following descriptive statistics are provided:\n\nmean: the mean of the column\nstd_dev: the standard deviation of the column\n\nAdditionally, the following quantiles are provided:\n\nmin: the minimum value in the column\np05: the 5th percentile of the column\nq_1: the first quartile of the column\nmed: the median of the column\nq_3: the third quartile of the column\np95: the 95th percentile of the column\nmax: the maximum value in the column\niqr: the interquartile range of the column"
  },
  {
    "objectID": "reference/DataScan.html#statistics-for-date-and-datetime-columns",
    "href": "reference/DataScan.html#statistics-for-date-and-datetime-columns",
    "title": "DataScan",
    "section": "",
    "text": "For date/datetime columns, the following statistics are provided:\n\nmin: the minimum date/datetime in the column\nmax: the maximum date/datetime in the column"
  },
  {
    "objectID": "reference/DataScan.html#returns",
    "href": "reference/DataScan.html#returns",
    "title": "DataScan",
    "section": "",
    "text": ": DataScan\n\nA DataScan object."
  },
  {
    "objectID": "reference/FinalActions.html",
    "href": "reference/FinalActions.html",
    "title": "FinalActions",
    "section": "",
    "text": "FinalActions(*args)\nDefine actions to be taken after validation is complete.\nFinal actions are executed after all validation steps have been completed. They provide a mechanism to respond to the overall validation results, such as sending alerts when critical failures are detected or generating summary reports.\n\n\n\n*actions : \n\nOne or more actions to execute after validation. An action can be (1) a callable function that will be executed with no arguments, or (2) a string message that will be printed to the console.\n\n\n\n\n\n\n : FinalActions\n\nAn FinalActions object. This can be used when using the Validate class (to set final actions for the validation workflow).\n\n\n\n\n\nFinal actions can be defined in two different ways:\n\nString: A message to be displayed when the validation is complete.\nCallable: A function that is called when the validation is complete.\n\nThe actions are executed at the end of the validation workflow. When providing a string, it will simply be printed to the console. A callable will also be executed at the time of validation completion. Several strings and callables can be provided to the FinalActions class, and they will be executed in the order they are provided.\n\n\n\nWhen creating a callable function to be used as a final action, you can use the get_validation_summary() function to retrieve the summary of the validation results. This summary contains information about the validation workflow, including the number of test units, the number of failing test units, and the threshold levels that were exceeded. You can use this information to craft your final action message or to take specific actions based on the validation results.\n\n\n\nFinal actions provide a powerful way to respond to the overall results of a validation workflow. They’re especially useful for sending notifications, generating reports, or taking corrective actions based on the complete validation outcome.\nThe following example shows how to create a final action that checks for critical failures and sends an alert:\nimport pointblank as pb\n\ndef send_alert():\n    summary = pb.get_validation_summary()\n    if summary[\"highest_severity\"] == \"critical\":\n        print(f\"ALERT: Critical validation failures found in {summary['tbl_name']}\")\n\nvalidation = (\n    pb.Validate(\n        data=my_data,\n        final_actions=pb.FinalActions(send_alert)\n    )\n    .col_vals_gt(columns=\"revenue\", value=0)\n    .interrogate()\n)\nIn this example, the send_alert() function is defined to check the validation summary for critical failures. If any are found, an alert message is printed to the console. The function is passed to the FinalActions class, which ensures it will be executed after all validation steps are complete. Note that we used the get_validation_summary() function to retrieve the summary of the validation results to help craft the alert message.\nMultiple final actions can be provided in a sequence. They will be executed in the order they are specified after all validation steps have completed:\nvalidation = (\n    pb.Validate(\n        data=my_data,\n        final_actions=pb.FinalActions(\n            \"Validation complete.\",  # a string message\n            send_alert,              # a callable function\n            generate_report          # another callable function\n        )\n    )\n    .col_vals_gt(columns=\"revenue\", value=0)\n    .interrogate()\n)\n\n\n\nThe get_validation_summary() function, which can be used to retrieve the summary of the validation results."
  },
  {
    "objectID": "reference/FinalActions.html#parameters",
    "href": "reference/FinalActions.html#parameters",
    "title": "FinalActions",
    "section": "",
    "text": "*actions : \n\nOne or more actions to execute after validation. An action can be (1) a callable function that will be executed with no arguments, or (2) a string message that will be printed to the console."
  },
  {
    "objectID": "reference/FinalActions.html#returns",
    "href": "reference/FinalActions.html#returns",
    "title": "FinalActions",
    "section": "",
    "text": ": FinalActions\n\nAn FinalActions object. This can be used when using the Validate class (to set final actions for the validation workflow)."
  },
  {
    "objectID": "reference/FinalActions.html#types-of-actions",
    "href": "reference/FinalActions.html#types-of-actions",
    "title": "FinalActions",
    "section": "",
    "text": "Final actions can be defined in two different ways:\n\nString: A message to be displayed when the validation is complete.\nCallable: A function that is called when the validation is complete.\n\nThe actions are executed at the end of the validation workflow. When providing a string, it will simply be printed to the console. A callable will also be executed at the time of validation completion. Several strings and callables can be provided to the FinalActions class, and they will be executed in the order they are provided."
  },
  {
    "objectID": "reference/FinalActions.html#crafting-callables-with-get_validation_summary",
    "href": "reference/FinalActions.html#crafting-callables-with-get_validation_summary",
    "title": "FinalActions",
    "section": "",
    "text": "When creating a callable function to be used as a final action, you can use the get_validation_summary() function to retrieve the summary of the validation results. This summary contains information about the validation workflow, including the number of test units, the number of failing test units, and the threshold levels that were exceeded. You can use this information to craft your final action message or to take specific actions based on the validation results."
  },
  {
    "objectID": "reference/FinalActions.html#examples",
    "href": "reference/FinalActions.html#examples",
    "title": "FinalActions",
    "section": "",
    "text": "Final actions provide a powerful way to respond to the overall results of a validation workflow. They’re especially useful for sending notifications, generating reports, or taking corrective actions based on the complete validation outcome.\nThe following example shows how to create a final action that checks for critical failures and sends an alert:\nimport pointblank as pb\n\ndef send_alert():\n    summary = pb.get_validation_summary()\n    if summary[\"highest_severity\"] == \"critical\":\n        print(f\"ALERT: Critical validation failures found in {summary['tbl_name']}\")\n\nvalidation = (\n    pb.Validate(\n        data=my_data,\n        final_actions=pb.FinalActions(send_alert)\n    )\n    .col_vals_gt(columns=\"revenue\", value=0)\n    .interrogate()\n)\nIn this example, the send_alert() function is defined to check the validation summary for critical failures. If any are found, an alert message is printed to the console. The function is passed to the FinalActions class, which ensures it will be executed after all validation steps are complete. Note that we used the get_validation_summary() function to retrieve the summary of the validation results to help craft the alert message.\nMultiple final actions can be provided in a sequence. They will be executed in the order they are specified after all validation steps have completed:\nvalidation = (\n    pb.Validate(\n        data=my_data,\n        final_actions=pb.FinalActions(\n            \"Validation complete.\",  # a string message\n            send_alert,              # a callable function\n            generate_report          # another callable function\n        )\n    )\n    .col_vals_gt(columns=\"revenue\", value=0)\n    .interrogate()\n)"
  },
  {
    "objectID": "reference/FinalActions.html#see-also",
    "href": "reference/FinalActions.html#see-also",
    "title": "FinalActions",
    "section": "",
    "text": "The get_validation_summary() function, which can be used to retrieve the summary of the validation results."
  },
  {
    "objectID": "reference/Validate.col_count_match.html",
    "href": "reference/Validate.col_count_match.html",
    "title": "Validate.col_count_match",
    "section": "",
    "text": "Validate.col_count_match(\n    count,\n    inverse=False,\n    pre=None,\n    thresholds=None,\n    actions=None,\n    brief=None,\n    active=True,\n)\nValidate whether the column count of the table matches a specified count.\nThe col_count_match() method checks whether the column count of the target table matches a specified count. This validation will operate over a single test unit, which is whether the column count matches the specified count.\nWe also have the option to invert the validation step by setting inverse=True. This will make the expectation that column row count of the target table does not match the specified count."
  },
  {
    "objectID": "reference/Validate.col_count_match.html#parameters",
    "href": "reference/Validate.col_count_match.html#parameters",
    "title": "Validate.col_count_match",
    "section": "Parameters",
    "text": "Parameters\n\ncount : int | FrameT | Any\n\nThe expected column count of the table. This can be an integer value, a Polars or Pandas DataFrame object, or an Ibis backend table. If a DataFrame/table is provided, the column count of that object will be used as the expected count.\n\ninverse : bool = False\n\nShould the validation step be inverted? If True, then the expectation is that the column count of the target table should not match the specified count= value.\n\npre : Callable | None = None\n\nAn optional preprocessing function or lambda to apply to the data table during interrogation. This function should take a table as input and return a modified table. Have a look at the Preprocessing section for more information on how to use this argument.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nSet threshold failure levels for reporting and reacting to exceedences of the levels. The thresholds are set at the step level and will override any global thresholds set in Validate(thresholds=...). The default is None, which means that no thresholds will be set locally and global thresholds (if any) will take effect. Look at the Thresholds section for information on how to set threshold levels.\n\nactions : Actions | None = None\n\nOptional actions to take when the validation step meets or exceeds any set threshold levels. If provided, the Actions class should be used to define the actions.\n\nbrief : str | bool | None = None\n\nAn optional brief description of the validation step that will be displayed in the reporting table. You can use the templating elements like \"{step}\" to insert the step number, or \"{auto}\" to include an automatically generated brief. If True the entire brief will be automatically generated. If None (the default) then there won’t be a brief.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.col_count_match.html#returns",
    "href": "reference/Validate.col_count_match.html#returns",
    "title": "Validate.col_count_match",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.col_count_match.html#preprocessing",
    "href": "reference/Validate.col_count_match.html#preprocessing",
    "title": "Validate.col_count_match",
    "section": "Preprocessing",
    "text": "Preprocessing\nThe pre= argument allows for a preprocessing function or lambda to be applied to the data table during interrogation. This function should take a table as input and return a modified table. This is useful for performing any necessary transformations or filtering on the data before the validation step is applied.\nThe preprocessing function can be any callable that takes a table as input and returns a modified table. For example, you could use a lambda function to filter the table based on certain criteria or to apply a transformation to the data. Regarding the lifetime of the transformed table, it only exists during the validation step and is not stored in the Validate object or used in subsequent validation steps."
  },
  {
    "objectID": "reference/Validate.col_count_match.html#thresholds",
    "href": "reference/Validate.col_count_match.html#thresholds",
    "title": "Validate.col_count_match",
    "section": "Thresholds",
    "text": "Thresholds\nThe thresholds= parameter is used to set the failure-condition levels for the validation step. If they are set here at the step level, these thresholds will override any thresholds set at the global level in Validate(thresholds=...).\nThere are three threshold levels: ‘warning’, ‘error’, and ‘critical’. The threshold values can either be set as a proportion failing of all test units (a value between 0 to 1), or, the absolute number of failing test units (as integer that’s 1 or greater).\nThresholds can be defined using one of these input schemes:\n\nuse the Thresholds class (the most direct way to create thresholds)\nprovide a tuple of 1-3 values, where position 0 is the ‘warning’ level, position 1 is the ‘error’ level, and position 2 is the ‘critical’ level\ncreate a dictionary of 1-3 value entries; the valid keys: are ‘warning’, ‘error’, and ‘critical’\na single integer/float value denoting absolute number or fraction of failing test units for the ‘warning’ level only\n\nIf the number of failing test units exceeds set thresholds, the validation step will be marked as ‘warning’, ‘error’, or ‘critical’. All of the threshold levels don’t need to be set, you’re free to set any combination of them.\nAside from reporting failure conditions, thresholds can be used to determine the actions to take for each level of failure (using the actions= parameter)."
  },
  {
    "objectID": "reference/Validate.col_count_match.html#examples",
    "href": "reference/Validate.col_count_match.html#examples",
    "title": "Validate.col_count_match",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use the built in dataset \"game_revenue\". The table can be obtained by calling load_dataset(\"game_revenue\").\n\nimport pointblank as pb\n\ngame_revenue = pb.load_dataset(\"game_revenue\")\n\npb.preview(game_revenue)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows2,000Columns11\n  \n\n  \n  player_idString\n  session_idString\n  session_startDatetime\n  timeDatetime\n  item_typeString\n  item_nameString\n  item_revenueFloat64\n  session_durationFloat64\n  start_dayDate\n  acquisitionString\n  countryString\n\n\n\n  \n    1\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:31:27+00:00\n    iap\n    offer2\n    8.99\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    2\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:36:57+00:00\n    iap\n    gems3\n    22.49\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    3\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:37:45+00:00\n    iap\n    gold7\n    107.99\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    4\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:42:33+00:00\n    ad\n    ad_20sec\n    0.76\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    5\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-hdu9jkls\n    2015-01-01 11:50:02+00:00\n    2015-01-01 11:55:20+00:00\n    ad\n    ad_5sec\n    0.03\n    35.2\n    2015-01-01\n    google\n    Germany\n  \n  \n    1996\n    NAOJRDMCSEBI281\n    NAOJRDMCSEBI281-j2vs9ilp\n    2015-01-21 01:57:50+00:00\n    2015-01-21 02:02:50+00:00\n    ad\n    ad_survey\n    1.332\n    25.8\n    2015-01-11\n    organic\n    Norway\n  \n  \n    1997\n    NAOJRDMCSEBI281\n    NAOJRDMCSEBI281-j2vs9ilp\n    2015-01-21 01:57:50+00:00\n    2015-01-21 02:22:14+00:00\n    ad\n    ad_survey\n    1.35\n    25.8\n    2015-01-11\n    organic\n    Norway\n  \n  \n    1998\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-vbhcsmtr\n    2015-01-21 02:39:48+00:00\n    2015-01-21 02:40:00+00:00\n    ad\n    ad_5sec\n    0.03\n    8.4\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    1999\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-vbhcsmtr\n    2015-01-21 02:39:48+00:00\n    2015-01-21 02:47:12+00:00\n    iap\n    offer5\n    26.09\n    8.4\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    2000\n    GJCXNTWEBIPQ369\n    GJCXNTWEBIPQ369-9elq67md\n    2015-01-21 03:59:23+00:00\n    2015-01-21 04:06:29+00:00\n    ad\n    ad_5sec\n    0.12\n    18.5\n    2015-01-14\n    organic\n    United States\n  \n\n\n\n\n\n\n        \n\n\nLet’s validate that the number of columns in the table matches a fixed value. In this case, we will use the value 11 as the expected column count.\n\nvalidation = (\n    pb.Validate(data=game_revenue)\n    .col_count_match(count=11)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_count_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            col_count_match()\n        \n        \n        \n    —\n    11\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe validation table shows that the expectation value of 11 matches the actual count of columns in the target table. So, the single test unit passed."
  },
  {
    "objectID": "reference/Validate.all_passed.html",
    "href": "reference/Validate.all_passed.html",
    "title": "Validate.all_passed",
    "section": "",
    "text": "Validate.all_passed()\nDetermine if every validation step passed perfectly, with no failing test units.\nThe all_passed() method determines if every validation step passed perfectly, with no failing test units. This method is useful for quickly checking if the table passed all validation steps with flying colors. If there’s even a single failing test unit in any validation step, this method will return False.\nThis validation metric might be overly stringent for some validation plans where failing test units are generally expected (and the strategy is to monitor data quality over time). However, the value of all_passed() could be suitable for validation plans designed to ensure that every test unit passes perfectly (e.g., checks for column presence, null-checking tests, etc.)."
  },
  {
    "objectID": "reference/Validate.all_passed.html#returns",
    "href": "reference/Validate.all_passed.html#returns",
    "title": "Validate.all_passed",
    "section": "Returns",
    "text": "Returns\n\n : bool\n\nTrue if all validation steps had no failing test units, False otherwise."
  },
  {
    "objectID": "reference/Validate.all_passed.html#examples",
    "href": "reference/Validate.all_passed.html#examples",
    "title": "Validate.all_passed",
    "section": "Examples",
    "text": "Examples\nIn the example below, we’ll use a simple Polars DataFrame with three columns (a, b, and c). There will be three validation steps, and the second step will have a failing test unit (the value 10 isn’t less than 9). After interrogation, the all_passed() method is used to determine if all validation steps passed perfectly.\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [1, 2, 9, 5],\n        \"b\": [5, 6, 10, 3],\n        \"c\": [\"a\", \"b\", \"a\", \"a\"],\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(columns=\"a\", value=0)\n    .col_vals_lt(columns=\"b\", value=9)\n    .col_vals_in_set(columns=\"c\", set=[\"a\", \"b\"])\n    .interrogate()\n)\n\nvalidation.all_passed()\n\nFalse\n\n\nThe returned value is False since the second validation step had a failing test unit. If it weren’t for that one failing test unit, the return value would have been True."
  },
  {
    "objectID": "reference/write_file.html",
    "href": "reference/write_file.html",
    "title": "write_file",
    "section": "",
    "text": "write_file(\n    validation,\n    filename,\n    path=None,\n    keep_tbl=False,\n    keep_extracts=False,\n    quiet=False,\n)\nWrite a Validate object to disk as a serialized file.\nWriting a validation object to disk with write_file() can be useful for keeping data validation results close at hand for later retrieval (with read_file()). By default, any data table that the validation object holds will be removed before writing to disk (not applicable if no data table is present). This behavior can be changed by setting keep_tbl=True, but this only works when the table is not of a database type (e.g., DuckDB, PostgreSQL, etc.), as database connections cannot be serialized.\nExtract data from failing validation steps can also be preserved by setting keep_extracts=True, which is useful for later analysis of data quality issues.\nThe serialized file uses Python’s pickle format for storage of the validation object state, including all validation results, metadata, and optionally the source data.\nImportant note. If your validation uses custom preprocessing functions (via the pre= parameter), these functions must be defined at the module level (not interactively or as lambda functions) to ensure they can be properly restored when loading the validation in a different Python session. Read the Creating Serializable Validations section below for more information."
  },
  {
    "objectID": "reference/write_file.html#parameters",
    "href": "reference/write_file.html#parameters",
    "title": "write_file",
    "section": "Parameters",
    "text": "Parameters\n\nvalidation : Validate\n\nThe Validate object to write to disk.\n\nfilename : str\n\nThe filename to create on disk for the validation object. Should not include the file extension as .pkl will be added automatically.\n\npath : str | None = None\n\nAn optional directory path where the file should be saved. If not provided, the file will be saved in the current working directory. The directory will be created if it doesn’t exist.\n\nkeep_tbl : bool = False\n\nAn option to keep the data table that is associated with the validation object. The default is False where the data table is removed before writing to disk. For database tables (e.g., Ibis tables with database backends), the table is always removed even if keep_tbl=True, as database connections cannot be serialized.\n\nkeep_extracts : bool = False\n\nAn option to keep any collected extract data for failing rows from validation steps. By default, this is False (i.e., extract data is removed to save space).\n\nquiet : bool = False\n\nShould the function not inform when the file is written? By default, this is False, so a message will be printed when the file is successfully written."
  },
  {
    "objectID": "reference/write_file.html#returns",
    "href": "reference/write_file.html#returns",
    "title": "write_file",
    "section": "Returns",
    "text": "Returns\n\n : None\n\nThis function doesn’t return anything but saves the validation object to disk."
  },
  {
    "objectID": "reference/write_file.html#creating-serializable-validations",
    "href": "reference/write_file.html#creating-serializable-validations",
    "title": "write_file",
    "section": "Creating Serializable Validations",
    "text": "Creating Serializable Validations\nTo ensure your validations work reliably across different Python sessions, the recommended approach is to use module-Level functions. So, create a separate Python file for your preprocessing functions:\n# preprocessing_functions.py\nimport polars as pl\n\ndef multiply_by_100(df):\n    return df.with_columns(pl.col(\"value\") * 100)\n\ndef add_computed_column(df):\n    return df.with_columns(computed=pl.col(\"value\") * 2 + 10)\nThen import and use them in your validation:\n# your_main_script.py\nimport pointblank as pb\nfrom preprocessing_functions import multiply_by_100, add_computed_column\n\nvalidation = (\n    pb.Validate(data=my_data)\n    .col_vals_gt(columns=\"value\", value=500, pre=multiply_by_100)\n    .col_vals_between(columns=\"computed\", left=50, right=1000, pre=add_computed_column)\n    .interrogate()\n)\n\n# Save validation and it will work reliably across sessions\npb.write_file(validation, \"my_validation\", keep_tbl=True)\n\nProblematic Patterns to Avoid\nDon’t use lambda functions as they will cause immediate errors.\nvalidation = pb.Validate(data).col_vals_gt(\n    columns=\"value\", value=100,\n    pre=lambda df: df.with_columns(pl.col(\"value\") * 2)\n)\nDon’t use interactive function definitions (as they may fail when loading).\ndef my_function(df):  # Defined in notebook/REPL\n    return df.with_columns(pl.col(\"value\") * 2)\n\nvalidation = pb.Validate(data).col_vals_gt(\n    columns=\"value\", value=100, pre=my_function\n)\n\n\nAutomatic Analysis and Guidance\nWhen you call write_file(), it automatically analyzes your validation and provides:\n\nconfirmation when all functions will work reliably\nwarnings for functions that may cause cross-session issues\nclear errors for unsupported patterns (lambda functions)\nspecific recommendations and code examples\nloading instructions tailored to your validation\n\n\n\nLoading Your Validation\nTo load a saved validation in a new Python session:\n# In a new Python session\nimport pointblank as pb\n\n# Import the same preprocessing functions used when creating the validation\nfrom preprocessing_functions import multiply_by_100, add_computed_column\n\n# Upon loading the validation, functions will be automatically restored\nvalidation = pb.read_file(\"my_validation.pkl\")\n** Testing Your Validation:**\nTo verify your validation works across sessions:\n\nsave your validation in one Python session\nstart a fresh Python session (restart kernel/interpreter)\nimport required preprocessing functions\nload the validation using read_file()\ntest that preprocessing functions work as expected\n\n\n\nPerformance and Storage\n\nuse keep_tbl=False (default) to reduce file size when you don’t need the original data\nuse keep_extracts=False (default) to save space by excluding extract data\nset quiet=True to suppress guidance messages in automated scripts\nfiles are saved using pickle’s highest protocol for optimal performance"
  },
  {
    "objectID": "reference/write_file.html#examples",
    "href": "reference/write_file.html#examples",
    "title": "write_file",
    "section": "Examples",
    "text": "Examples\nLet’s create a simple validation and save it to disk:\n\nimport pointblank as pb\n\n# Create a validation\nvalidation = (\n    pb.Validate(data=pb.load_dataset(\"small_table\"), label=\"My validation\")\n    .col_vals_gt(columns=\"d\", value=100)\n    .col_vals_regex(columns=\"b\", pattern=r\"[0-9]-[a-z]{3}-[0-9]{3}\")\n    .interrogate()\n)\n\n# Save to disk (without the original table data)\npb.write_file(validation, \"my_validation\")\n\n  Serialization Analysis:\n   ✓ No preprocessing functions detected\n   ✓ This validation should serialize and load reliably across sessions\n✅ Validation object written to: my_validation.pkl\n   📖 To load: validation = pb.read_file('my_validation.pkl')\n\n\nTo keep the original table data for later analysis:\n\n# Save with the original table data included\npb.write_file(validation, \"my_validation_with_data\", keep_tbl=True)\n\n  Serialization Analysis:\n   ✓ No preprocessing functions detected\n   ✓ This validation should serialize and load reliably across sessions\n✅ Validation object written to: my_validation_with_data.pkl\n   📖 To load: validation = pb.read_file('my_validation_with_data.pkl')\n\n\nYou can also specify a custom directory and keep extract data:\npb.write_file(\n    validation,\n    filename=\"detailed_validation\",\n    path=\"/path/to/validations\",\n    keep_tbl=True,\n    keep_extracts=True\n)\n\nWorking with Preprocessing Functions\nFor validations that use preprocessing functions to be portable across sessions, define your functions in a separate .py file:\n# In `preprocessing_functions.py`\n\nimport polars as pl\n\ndef multiply_by_100(df):\n    return df.with_columns(pl.col(\"value\") * 100)\n\ndef add_computed_column(df):\n    return df.with_columns(computed=pl.col(\"value\") * 2 + 10)\nThen import and use them in your validation:\n# In your main script\n\nimport pointblank as pb\nfrom preprocessing_functions import multiply_by_100, add_computed_column\n\nvalidation = (\n    pb.Validate(data=my_data)\n    .col_vals_gt(columns=\"value\", value=500, pre=multiply_by_100)\n    .col_vals_between(columns=\"computed\", left=50, right=1000, pre=add_computed_column)\n    .interrogate()\n)\n\n# This validation can now be saved and loaded reliably\npb.write_file(validation, \"my_validation\", keep_tbl=True)\nWhen you load this validation in a new session, simply import the preprocessing functions again and they will be automatically restored."
  },
  {
    "objectID": "reference/write_file.html#see-also",
    "href": "reference/write_file.html#see-also",
    "title": "write_file",
    "section": "See Also",
    "text": "See Also\nUse the read_file() function to load a validation object that was previously saved with write_file()."
  },
  {
    "objectID": "reference/Validate.get_json_report.html",
    "href": "reference/Validate.get_json_report.html",
    "title": "Validate.get_json_report",
    "section": "",
    "text": "Validate.get_json_report(use_fields=None, exclude_fields=None)\nGet a report of the validation results as a JSON-formatted string.\nThe get_json_report() method provides a machine-readable report of validation results in JSON format. This is particularly useful for programmatic processing, storing validation results, or integrating with other systems. The report includes detailed information about each validation step, such as assertion type, columns validated, threshold values, test results, and more.\nBy default, all available validation information fields are included in the report. However, you can customize the fields to include or exclude using the use_fields= and exclude_fields= parameters."
  },
  {
    "objectID": "reference/Validate.get_json_report.html#parameters",
    "href": "reference/Validate.get_json_report.html#parameters",
    "title": "Validate.get_json_report",
    "section": "Parameters",
    "text": "Parameters\n\nuse_fields : list[str] | None = None\n\nAn optional list of specific fields to include in the report. If provided, only these fields will be included in the JSON output. If None (the default), all standard validation report fields are included. Have a look at the Available Report Fields section below for a list of fields that can be included in the report.\n\nexclude_fields : list[str] | None = None\n\nAn optional list of fields to exclude from the report. If provided, these fields will be omitted from the JSON output. If None (the default), no fields are excluded. This parameter cannot be used together with use_fields=. The Available Report Fields provides a listing of fields that can be excluded from the report."
  },
  {
    "objectID": "reference/Validate.get_json_report.html#returns",
    "href": "reference/Validate.get_json_report.html#returns",
    "title": "Validate.get_json_report",
    "section": "Returns",
    "text": "Returns\n\n : str\n\nA JSON-formatted string representing the validation report, with each validation step as an object in the report array."
  },
  {
    "objectID": "reference/Validate.get_json_report.html#available-report-fields",
    "href": "reference/Validate.get_json_report.html#available-report-fields",
    "title": "Validate.get_json_report",
    "section": "Available Report Fields",
    "text": "Available Report Fields\nThe JSON report can include any of the standard validation report fields, including:\n\ni: the step number (1-indexed)\ni_o: the original step index from the validation plan (pre-expansion)\nassertion_type: the type of validation assertion (e.g., \"col_vals_gt\", etc.)\ncolumn: the column being validated (or columns used in certain validations)\nvalues: the comparison values or parameters used in the validation\ninclusive: whether the comparison is inclusive (for range-based validations)\nna_pass: whether NA/Null values are considered passing (for certain validations)\npre: preprocessing function applied before validation\nsegments: data segments to which the validation was applied\nthresholds: threshold level statement that was used for the validation step\nlabel: custom label for the validation step\nbrief: a brief description of the validation step\nactive: whether the validation step is active\nall_passed: whether all test units passed in the step\nn: total number of test units\nn_passed, n_failed: number of test units that passed and failed\nf_passed, f_failed: Fraction of test units that passed and failed\nwarning, error, critical: whether the namesake threshold level was exceeded (is null if threshold not set)\ntime_processed: when the validation step was processed (ISO 8601 format)\nproc_duration_s: the processing duration in seconds"
  },
  {
    "objectID": "reference/Validate.get_json_report.html#examples",
    "href": "reference/Validate.get_json_report.html#examples",
    "title": "Validate.get_json_report",
    "section": "Examples",
    "text": "Examples\nLet’s create a validation plan with a few validation steps and generate a JSON report of the results:\n\nimport pointblank as pb\nimport polars as pl\n\n# Create a sample DataFrame\ntbl = pl.DataFrame({\n    \"a\": [5, 7, 8, 9],\n    \"b\": [3, 4, 2, 1]\n})\n\n# Create and execute a validation plan\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(columns=\"a\", value=6)\n    .col_vals_lt(columns=\"b\", value=4)\n    .interrogate()\n)\n\n# Get the full JSON report\njson_report = validation.get_json_report()\n\nprint(json_report)\n\n[\n    {\n        \"i\": 1,\n        \"i_o\": 1,\n        \"assertion_type\": \"col_vals_gt\",\n        \"column\": \"a\",\n        \"values\": 6,\n        \"inclusive\": null,\n        \"na_pass\": false,\n        \"pre\": null,\n        \"segments\": null,\n        \"thresholds\": \"Thresholds(warning=None, error=None, critical=None)\",\n        \"label\": null,\n        \"brief\": null,\n        \"active\": true,\n        \"all_passed\": false,\n        \"n\": 4,\n        \"n_passed\": 3,\n        \"n_failed\": 1,\n        \"f_passed\": 0.75,\n        \"f_failed\": 0.25,\n        \"warning\": null,\n        \"error\": null,\n        \"critical\": null,\n        \"time_processed\": \"2025-11-23T00:13:32.529+00:00\",\n        \"proc_duration_s\": 0.008144\n    },\n    {\n        \"i\": 2,\n        \"i_o\": 2,\n        \"assertion_type\": \"col_vals_lt\",\n        \"column\": \"b\",\n        \"values\": 4,\n        \"inclusive\": null,\n        \"na_pass\": false,\n        \"pre\": null,\n        \"segments\": null,\n        \"thresholds\": \"Thresholds(warning=None, error=None, critical=None)\",\n        \"label\": null,\n        \"brief\": null,\n        \"active\": true,\n        \"all_passed\": false,\n        \"n\": 4,\n        \"n_passed\": 3,\n        \"n_failed\": 1,\n        \"f_passed\": 0.75,\n        \"f_failed\": 0.25,\n        \"warning\": null,\n        \"error\": null,\n        \"critical\": null,\n        \"time_processed\": \"2025-11-23T00:13:32.532+00:00\",\n        \"proc_duration_s\": 0.002707\n    }\n]\n\n\nYou can also customize which fields to include:\n\njson_report = validation.get_json_report(\n    use_fields=[\"i\", \"assertion_type\", \"column\", \"n_passed\", \"n_failed\"]\n)\n\nprint(json_report)\n\n[\n    {\n        \"i\": 1,\n        \"assertion_type\": \"col_vals_gt\",\n        \"column\": \"a\",\n        \"n_passed\": 3,\n        \"n_failed\": 1\n    },\n    {\n        \"i\": 2,\n        \"assertion_type\": \"col_vals_lt\",\n        \"column\": \"b\",\n        \"n_passed\": 3,\n        \"n_failed\": 1\n    }\n]\n\n\nOr which fields to exclude:\n\njson_report = validation.get_json_report(\n    exclude_fields=[\n        \"i_o\", \"thresholds\", \"pre\", \"segments\", \"values\",\n        \"na_pass\", \"inclusive\", \"label\", \"brief\", \"active\",\n        \"time_processed\", \"proc_duration_s\"\n    ]\n)\n\nprint(json_report)\n\n[\n    {\n        \"i\": 1,\n        \"assertion_type\": \"col_vals_gt\",\n        \"column\": \"a\",\n        \"all_passed\": false,\n        \"n\": 4,\n        \"n_passed\": 3,\n        \"n_failed\": 1,\n        \"f_passed\": 0.75,\n        \"f_failed\": 0.25,\n        \"warning\": null,\n        \"error\": null,\n        \"critical\": null\n    },\n    {\n        \"i\": 2,\n        \"assertion_type\": \"col_vals_lt\",\n        \"column\": \"b\",\n        \"all_passed\": false,\n        \"n\": 4,\n        \"n_passed\": 3,\n        \"n_failed\": 1,\n        \"f_passed\": 0.75,\n        \"f_failed\": 0.25,\n        \"warning\": null,\n        \"error\": null,\n        \"critical\": null\n    }\n]\n\n\nThe JSON output can be further processed or analyzed programmatically:\n\nimport json\n\n# Parse the JSON report\nreport_data = json.loads(validation.get_json_report())\n\n# Extract and analyze validation results\nfailing_steps = [step for step in report_data if step[\"n_failed\"] &gt; 0]\nprint(f\"Number of failing validation steps: {len(failing_steps)}\")\n\nNumber of failing validation steps: 2"
  },
  {
    "objectID": "reference/Validate.get_json_report.html#see-also",
    "href": "reference/Validate.get_json_report.html#see-also",
    "title": "Validate.get_json_report",
    "section": "See Also",
    "text": "See Also\n\nget_tabular_report(): Get a formatted HTML report as a GT table\nget_data_extracts(): Get rows that failed validation"
  },
  {
    "objectID": "reference/last_n.html",
    "href": "reference/last_n.html",
    "title": "last_n",
    "section": "",
    "text": "last_n(n, offset=0)\nSelect the last n columns in the column list.\nMany validation methods have a columns= argument that can be used to specify the columns for validation (e.g., col_vals_gt(), col_vals_regex(), etc.). The last_n() selector function can be used to select n columns positioned at the end of the column list. So if the set of table columns consists of\n[age, rev_01, rev_02, profit_01, profit_02]\nand you want to validate the last two columns, you can use columns=last_n(2). This will select the profit_01 and profit_02 columns and a validation step will be created for each.\nThe offset= parameter can be used to skip a certain number of columns from the end of the column list. So if you want to select the third and fourth columns from the end, you can use columns=last_n(2, offset=2)."
  },
  {
    "objectID": "reference/last_n.html#parameters",
    "href": "reference/last_n.html#parameters",
    "title": "last_n",
    "section": "Parameters",
    "text": "Parameters\n\nn : int\n\nThe number of columns to select from the end of the column list. Should be a positive integer value. If n is greater than the number of columns in the table, all columns will be selected.\n\noffset : int = 0\n\nThe offset from the end of the column list. The default is 0. If offset is greater than the number of columns in the table, no columns will be selected."
  },
  {
    "objectID": "reference/last_n.html#returns",
    "href": "reference/last_n.html#returns",
    "title": "last_n",
    "section": "Returns",
    "text": "Returns\n\n : LastN\n\nA LastN object, which can be used to select the last n columns."
  },
  {
    "objectID": "reference/last_n.html#relevant-validation-methods-where-last_n-can-be-used",
    "href": "reference/last_n.html#relevant-validation-methods-where-last_n-can-be-used",
    "title": "last_n",
    "section": "Relevant Validation Methods where last_n() can be Used",
    "text": "Relevant Validation Methods where last_n() can be Used\nThis selector function can be used in the columns= argument of the following validation methods:\n\ncol_vals_gt()\ncol_vals_lt()\ncol_vals_ge()\ncol_vals_le()\ncol_vals_eq()\ncol_vals_ne()\ncol_vals_between()\ncol_vals_outside()\ncol_vals_in_set()\ncol_vals_not_in_set()\ncol_vals_increasing()\ncol_vals_decreasing()\ncol_vals_null()\ncol_vals_not_null()\ncol_vals_regex()\ncol_vals_within_spec()\ncol_exists()\n\nThe last_n() selector function doesn’t need to be used in isolation. Read the next section for information on how to compose it with other column selectors for more refined ways to select columns."
  },
  {
    "objectID": "reference/last_n.html#additional-flexibilty-through-composition-with-other-column-selectors",
    "href": "reference/last_n.html#additional-flexibilty-through-composition-with-other-column-selectors",
    "title": "last_n",
    "section": "Additional Flexibilty through Composition with Other Column Selectors",
    "text": "Additional Flexibilty through Composition with Other Column Selectors\nThe last_n() function can be composed with other column selectors to create fine-grained column selections. For example, to select all column names starting with “rev” along with the last two columns, you can use the last_n() and starts_with() functions together. The only condition is that the expressions are wrapped in the col() function, like this:\ncol(last_n(2) | starts_with(\"rev\"))\nThere are four operators that can be used to compose column selectors:\n\n& (and)\n| (or)\n- (difference)\n~ (not)\n\nThe & operator is used to select columns that satisfy both conditions. The | operator is used to select columns that satisfy either condition. The - operator is used to select columns that satisfy the first condition but not the second. The ~ operator is used to select columns that don’t satisfy the condition. As many selector functions can be used as needed and the operators can be combined to create complex column selection criteria (parentheses can be used to group conditions and control the order of evaluation)."
  },
  {
    "objectID": "reference/last_n.html#examples",
    "href": "reference/last_n.html#examples",
    "title": "last_n",
    "section": "Examples",
    "text": "Examples\nSuppose we have a table with columns name, paid_2021, paid_2022, paid_2023, and paid_2024 and we’d like to validate that the values in the last four columns are greater than 10. We can use the last_n() column selector function to specify that the last four columns in the table are the columns to validate.\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n        \"paid_2021\": [17.94, 16.55, 17.85],\n        \"paid_2022\": [18.62, 16.95, 18.25],\n        \"paid_2023\": [19.29, 17.75, 18.35],\n        \"paid_2024\": [20.73, 18.35, 20.10],\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(columns=pb.last_n(4), value=10)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    paid_2021\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    paid_2022\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    paid_2023\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    paid_2024\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nFrom the results of the validation table we get four validation steps. The values in all those columns were all greater than 10.\nWe can also use the last_n() function in combination with other column selectors (within col()) to create more complex column selection criteria (i.e., to select columns that satisfy multiple conditions). For example, to select the last four columns but also omit those columns that end with \"2023\", we can use the - operator to combine column selectors.\n\ntbl = pl.DataFrame(\n    {\n        \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n        \"paid_2021\": [17.94, 16.55, 17.85],\n        \"paid_2022\": [18.62, 16.95, 18.25],\n        \"paid_2023\": [19.29, 17.75, 18.35],\n        \"paid_2024\": [20.73, 18.35, 20.10],\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(columns=pb.col(pb.last_n(4) - pb.ends_with(\"2023\")), value=10)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    paid_2021\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    paid_2022\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    paid_2024\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nFrom the results of the validation table we get three validation steps, one for paid_2021, paid_2022, and paid_2024."
  },
  {
    "objectID": "reference/get_data_path.html",
    "href": "reference/get_data_path.html",
    "title": "get_data_path",
    "section": "",
    "text": "get_data_path(dataset='small_table', file_type='csv')\nGet the file path to a dataset included with the Pointblank package.\nThis function provides direct access to the file paths of datasets included with Pointblank. These paths can be used in examples and documentation to demonstrate file-based data loading without requiring the actual data files. The returned paths can be used with Validate(data=path) to demonstrate CSV and Parquet file loading capabilities."
  },
  {
    "objectID": "reference/get_data_path.html#parameters",
    "href": "reference/get_data_path.html#parameters",
    "title": "get_data_path",
    "section": "Parameters",
    "text": "Parameters\n\ndataset : Literal['small_table', 'game_revenue', 'nycflights', 'global_sales'] = 'small_table'\n\nThe name of the dataset to get the path for. Current options are \"small_table\", \"game_revenue\", \"nycflights\", and \"global_sales\".\n\nfile_type : Literal['csv', 'parquet', 'duckdb'] = 'csv'\n\nThe file format to get the path for. Options are \"csv\", \"parquet\", or \"duckdb\"."
  },
  {
    "objectID": "reference/get_data_path.html#returns",
    "href": "reference/get_data_path.html#returns",
    "title": "get_data_path",
    "section": "Returns",
    "text": "Returns\n\n : str\n\nThe file path to the requested dataset file."
  },
  {
    "objectID": "reference/get_data_path.html#included-datasets",
    "href": "reference/get_data_path.html#included-datasets",
    "title": "get_data_path",
    "section": "Included Datasets",
    "text": "Included Datasets\nThe available datasets are the same as those in load_dataset():\n\n\"small_table\": A small dataset with 13 rows and 8 columns. Ideal for testing and examples.\n\"game_revenue\": A dataset with 2000 rows and 11 columns. Revenue data for a game company.\n\"nycflights\": A dataset with 336,776 rows and 18 columns. Flight data from NYC airports.\n\"global_sales\": A dataset with 50,000 rows and 20 columns. Global sales data across regions."
  },
  {
    "objectID": "reference/get_data_path.html#file-types",
    "href": "reference/get_data_path.html#file-types",
    "title": "get_data_path",
    "section": "File Types",
    "text": "File Types\nEach dataset is available in multiple formats:\n\n\"csv\": Comma-separated values file (.csv)\n\"parquet\": Parquet file (.parquet)\n\"duckdb\": DuckDB database file (.ddb)"
  },
  {
    "objectID": "reference/get_data_path.html#examples",
    "href": "reference/get_data_path.html#examples",
    "title": "get_data_path",
    "section": "Examples",
    "text": "Examples\nGet the path to a CSV file and use it with Validate:\n\nimport pointblank as pb\n\n# Get path to the small_table CSV file\ncsv_path = pb.get_data_path(\"small_table\", \"csv\")\nprint(csv_path)\n\n# Use the path directly with Validate\nvalidation = (\n    pb.Validate(data=csv_path)\n    .col_exists([\"a\", \"b\", \"c\"])\n    .col_vals_gt(columns=\"d\", value=0)\n    .interrogate()\n)\n\nvalidation\n\n/tmp/tmp0k3pla_4.csv\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:13:49Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    a\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    b\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    c\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:13:49 UTC&lt; 1 s2025-11-23 00:13:49 UTC\n  \n\n\n\n\n\n\n        \n\n\nGet a Parquet file path for validation examples:\n\n# Get path to the game_revenue Parquet file\nparquet_path = pb.get_data_path(dataset=\"game_revenue\", file_type=\"parquet\")\n\n# Validate the Parquet file directly\nvalidation = (\n    pb.Validate(data=parquet_path, label=\"Game Revenue Data Validation\")\n    .col_vals_not_null(columns=[\"player_id\", \"session_id\"])\n    .col_vals_gt(columns=\"item_revenue\", value=0)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Game Revenue Data ValidationPolars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    player_id\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    session_id\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    item_revenue\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:13:49 UTC&lt; 1 s2025-11-23 00:13:49 UTC\n  \n\n\n\n\n\n\n        \n\n\nThis is particularly useful for documentation examples where you want to demonstrate file-based workflows without requiring users to have specific data files:\n\n# Example showing CSV file validation\nsales_csv = pb.get_data_path(dataset=\"global_sales\", file_type=\"csv\")\n\nvalidation = (\n    pb.Validate(data=sales_csv, label=\"Sales Data Validation\")\n    .col_exists([\"customer_id\", \"product_id\", \"amount\"])\n    .col_vals_regex(columns=\"customer_id\", pattern=r\"CUST_[0-9]{6}\")\n    .interrogate()\n)"
  },
  {
    "objectID": "reference/get_data_path.html#see-also",
    "href": "reference/get_data_path.html#see-also",
    "title": "get_data_path",
    "section": "See Also",
    "text": "See Also\nload_dataset() for loading datasets directly as table objects."
  },
  {
    "objectID": "reference/Validate.specially.html",
    "href": "reference/Validate.specially.html",
    "title": "Validate.specially",
    "section": "",
    "text": "Validate.specially(\n    expr,\n    pre=None,\n    thresholds=None,\n    actions=None,\n    brief=None,\n    active=True,\n)\nPerform a specialized validation with customized logic.\nThe specially() validation method allows for the creation of specialized validation expressions that can be used to validate specific conditions or logic in the data. This method provides maximum flexibility by accepting a custom callable that encapsulates your validation logic.\nThe callable function can have one of two signatures:\nThe second form is particularly useful for environment validations that don’t need to inspect the data table.\nThe callable function must ultimately return one of:\nThe validation will operate over the number of test units that is equal to the number of rows in the data table (if returning a table with boolean values). If returning a scalar boolean value, the validation will operate over a single test unit. For a return of a list of boolean values, the length of the list constitutes the number of test units."
  },
  {
    "objectID": "reference/Validate.specially.html#parameters",
    "href": "reference/Validate.specially.html#parameters",
    "title": "Validate.specially",
    "section": "Parameters",
    "text": "Parameters\n\nexpr : Callable\n\nA callable function that defines the specialized validation logic. This function should: (1) accept the target data table as its single argument (though it may ignore it), or (2) take no parameters at all (for environment validations). The function must ultimately return boolean values representing validation results. Design your function to incorporate any custom parameters directly within the function itself using closure variables or default parameters.\n\npre : Callable | None = None\n\nAn optional preprocessing function or lambda to apply to the data table during interrogation. This function should take a table as input and return a modified table. Have a look at the Preprocessing section for more information on how to use this argument.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nSet threshold failure levels for reporting and reacting to exceedences of the levels. The thresholds are set at the step level and will override any global thresholds set in Validate(thresholds=...). The default is None, which means that no thresholds will be set locally and global thresholds (if any) will take effect. Look at the Thresholds section for information on how to set threshold levels.\n\nactions : Actions | None = None\n\nOptional actions to take when the validation step meets or exceeds any set threshold levels. If provided, the Actions class should be used to define the actions.\n\nbrief : str | bool | None = None\n\nAn optional brief description of the validation step that will be displayed in the reporting table. You can use the templating elements like \"{step}\" to insert the step number, or \"{auto}\" to include an automatically generated brief. If True the entire brief will be automatically generated. If None (the default) then there won’t be a brief.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.specially.html#returns",
    "href": "reference/Validate.specially.html#returns",
    "title": "Validate.specially",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.specially.html#preprocessing",
    "href": "reference/Validate.specially.html#preprocessing",
    "title": "Validate.specially",
    "section": "Preprocessing",
    "text": "Preprocessing\nThe pre= argument allows for a preprocessing function or lambda to be applied to the data table during interrogation. This function should take a table as input and return a modified table. This is useful for performing any necessary transformations or filtering on the data before the validation step is applied.\nThe preprocessing function can be any callable that takes a table as input and returns a modified table. For example, you could use a lambda function to filter the table based on certain criteria or to apply a transformation to the data. Regarding the lifetime of the transformed table, it only exists during the validation step and is not stored in the Validate object or used in subsequent validation steps."
  },
  {
    "objectID": "reference/Validate.specially.html#thresholds",
    "href": "reference/Validate.specially.html#thresholds",
    "title": "Validate.specially",
    "section": "Thresholds",
    "text": "Thresholds\nThe thresholds= parameter is used to set the failure-condition levels for the validation step. If they are set here at the step level, these thresholds will override any thresholds set at the global level in Validate(thresholds=...).\nThere are three threshold levels: ‘warning’, ‘error’, and ‘critical’. The threshold values can either be set as a proportion failing of all test units (a value between 0 to 1), or, the absolute number of failing test units (as integer that’s 1 or greater).\nThresholds can be defined using one of these input schemes:\n\nuse the Thresholds class (the most direct way to create thresholds)\nprovide a tuple of 1-3 values, where position 0 is the ‘warning’ level, position 1 is the ‘error’ level, and position 2 is the ‘critical’ level\ncreate a dictionary of 1-3 value entries; the valid keys: are ‘warning’, ‘error’, and ‘critical’\na single integer/float value denoting absolute number or fraction of failing test units for the ‘warning’ level only\n\nIf the number of failing test units exceeds set thresholds, the validation step will be marked as ‘warning’, ‘error’, or ‘critical’. All of the threshold levels don’t need to be set, you’re free to set any combination of them.\nAside from reporting failure conditions, thresholds can be used to determine the actions to take for each level of failure (using the actions= parameter)."
  },
  {
    "objectID": "reference/Validate.specially.html#examples",
    "href": "reference/Validate.specially.html#examples",
    "title": "Validate.specially",
    "section": "Examples",
    "text": "Examples\nThe specially() method offers maximum flexibility for validation, allowing you to create custom validation logic that fits your specific needs. The following examples demonstrate different patterns and use cases for this powerful validation approach.\n\nSimple validation with direct table access\nThis example shows the most straightforward use case where we create a function that directly checks if the sum of two columns is positive.\n\nimport pointblank as pb\nimport polars as pl\n\nsimple_tbl = pl.DataFrame({\n    \"a\": [5, 7, 1, 3, 9, 4],\n    \"b\": [6, 3, 0, 5, 8, 2]\n})\n\n# Simple function that validates directly on the table\ndef validate_sum_positive(data):\n    return data.select(pl.col(\"a\") + pl.col(\"b\") &gt; 0)\n\n(\n    pb.Validate(data=simple_tbl)\n    .specially(expr=validate_sum_positive)\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    specially\n    \n        \n            \n            \n                \n            \n        \n    \n\n        \n        \n            specially()\n        \n        \n        \n    \n    EXPR\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    61.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe function returns a Polars DataFrame with a single boolean column indicating whether the sum of columns a and b is positive for each row. Each row in the resulting DataFrame is a distinct test unit. This pattern works well for simple validations where you don’t need configurable parameters.\n\n\nAdvanced validation with closure variables for parameters\nWhen you need to make your validation configurable, you can use the function factory pattern (also known as closures) to create parameterized validations:\n\n# Create a parameterized validation function using closures\ndef make_column_ratio_validator(col1, col2, min_ratio):\n    def validate_column_ratio(data):\n        return data.select((pl.col(col1) / pl.col(col2)) &gt; min_ratio)\n    return validate_column_ratio\n\n(\n    pb.Validate(data=simple_tbl)\n    .specially(\n        expr=make_column_ratio_validator(col1=\"a\", col2=\"b\", min_ratio=0.5)\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    specially\n    \n        \n            \n            \n                \n            \n        \n    \n\n        \n        \n            specially()\n        \n        \n        \n    \n    EXPR\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    61.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThis approach allows you to create reusable validation functions that can be configured with different parameters without modifying the function itself.\n\n\nValidation function returning a list of booleans\nThis example demonstrates how to create a validation function that returns a list of boolean values, where each element represents a separate test unit:\n\nimport pointblank as pb\nimport polars as pl\nimport random\n\n# Create sample data\ntransaction_tbl = pl.DataFrame({\n    \"transaction_id\": [f\"TX{i:04d}\" for i in range(1, 11)],\n    \"amount\": [120.50, 85.25, 50.00, 240.75, 35.20, 150.00, 85.25, 65.00, 210.75, 90.50],\n    \"category\": [\"food\", \"shopping\", \"entertainment\", \"travel\", \"utilities\",\n                \"food\", \"shopping\", \"entertainment\", \"travel\", \"utilities\"]\n})\n\n# Define a validation function that returns a list of booleans\ndef validate_transaction_rules(data):\n    # Create a list to store individual test results\n    test_results = []\n\n    # Check each row individually against multiple business rules\n    for row in data.iter_rows(named=True):\n        # Rule: transaction IDs must start with \"TX\" and be 6 chars long\n        valid_id = row[\"transaction_id\"].startswith(\"TX\") and len(row[\"transaction_id\"]) == 6\n\n        # Rule: Amounts must be appropriate for their category\n        valid_amount = True\n        if row[\"category\"] == \"food\" and (row[\"amount\"] &lt; 10 or row[\"amount\"] &gt; 200):\n            valid_amount = False\n        elif row[\"category\"] == \"utilities\" and (row[\"amount\"] &lt; 20 or row[\"amount\"] &gt; 300):\n            valid_amount = False\n        elif row[\"category\"] == \"entertainment\" and row[\"amount\"] &gt; 100:\n            valid_amount = False\n\n        # A transaction passes if it satisfies both rules\n        test_results.append(valid_id and valid_amount)\n\n    return test_results\n\n(\n    pb.Validate(data=transaction_tbl)\n    .specially(\n        expr=validate_transaction_rules,\n        brief=\"Validate transaction IDs and amounts by category.\"\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    specially\n    \n        \n            \n            \n                \n            \n        \n    \n\n        \n        \n            specially()\n        \n        Validate transaction IDs and amounts by category.\n\n        \n    \n    EXPR\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    10\n    101.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThis example shows how to create a validation function that applies multiple business rules to each row and returns a list of boolean results. Each boolean in the list represents a separate test unit, and a test unit passes only if all rules are satisfied for a given row.\nThe function iterates through each row in the data table, checking:\n\nif transaction IDs follow the required format\nif transaction amounts are appropriate for their respective categories\n\nThis approach is powerful when you need to apply complex, conditional logic that can’t be easily expressed using the built-in validation functions.\n\n\nTable-level validation returning a single boolean\nSometimes you need to validate properties of the entire table rather than row-by-row. In these cases, your function can return a single boolean value:\n\ndef validate_table_properties(data):\n    # Check if table has at least one row with column 'a' &gt; 10\n    has_large_values = data.filter(pl.col(\"a\") &gt; 10).height &gt; 0\n\n    # Check if mean of column 'b' is positive\n    has_positive_mean = data.select(pl.mean(\"b\")).item() &gt; 0\n\n    # Return a single boolean for the entire table\n    return has_large_values and has_positive_mean\n\n(\n    pb.Validate(data=simple_tbl)\n    .specially(expr=validate_table_properties)\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    specially\n    \n        \n            \n            \n                \n            \n        \n    \n\n        \n        \n            specially()\n        \n        \n        \n    \n    EXPR\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    00.00\n    11.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThis example demonstrates how to perform multiple checks on the table as a whole and combine them into a single validation result.\n\n\nEnvironment validation that doesn’t use the data table\nThe specially() validation method can even be used to validate aspects of your environment that are completely independent of the data:\n\ndef validate_pointblank_version():\n    try:\n        import importlib.metadata\n        version = importlib.metadata.version(\"pointblank\")\n        version_parts = version.split(\".\")\n\n        # Get major and minor components regardless of how many parts there are\n        major = int(version_parts[0])\n        minor = int(version_parts[1])\n\n        # Check both major and minor components for version `0.9+`\n        return (major &gt; 0) or (major == 0 and minor &gt;= 9)\n\n    except Exception as e:\n        # More specific error handling could be added here\n        print(f\"Version check failed: {e}\")\n        return False\n\n(\n    pb.Validate(data=simple_tbl)\n    .specially(\n        expr=validate_pointblank_version,\n        brief=\"Check Pointblank version `&gt;=0.9.0`.\"\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    specially\n    \n        \n            \n            \n                \n            \n        \n    \n\n        \n        \n            specially()\n        \n        Check Pointblank version &gt;=0.9.0.\n\n        \n    \n    EXPR\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    00.00\n    11.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThis pattern shows how to validate external dependencies or environment conditions as part of your validation workflow. Notice that the function doesn’t take any parameters at all, which makes it cleaner when the validation doesn’t need to access the data table.\nBy combining these patterns, you can create sophisticated validation workflows that address virtually any data quality requirement in your organization."
  },
  {
    "objectID": "reference/Validate.n.html",
    "href": "reference/Validate.n.html",
    "title": "Validate.n",
    "section": "",
    "text": "Validate.n(i=None, scalar=False)\nProvides a dictionary of the number of test units for each validation step.\nThe n() method provides the number of test units for each validation step. This is the total number of test units that were evaluated in the validation step. It is always an integer value.\nTest units are the atomic units of the validation process. Different validations can have different numbers of test units. For example, a validation that checks for the presence of a column in a table will have a single test unit. A validation that checks for the presence of a value in a column will have as many test units as there are rows in the table.\nThe method provides a dictionary of the number of test units for each validation step. If the scalar=True argument is provided and i= is a scalar, the value is returned as a scalar instead of a dictionary. The total number of test units for a validation step is the sum of the number of passing and failing test units (i.e., n = n_passed + n_failed)."
  },
  {
    "objectID": "reference/Validate.n.html#parameters",
    "href": "reference/Validate.n.html#parameters",
    "title": "Validate.n",
    "section": "Parameters",
    "text": "Parameters\n\ni : int | list[int] | None = None\n\nThe validation step number(s) from which the number of test units is obtained. Can be provided as a list of integers or a single integer. If None, all steps are included.\n\nscalar : bool = False\n\nIf True and i= is a scalar, return the value as a scalar instead of a dictionary."
  },
  {
    "objectID": "reference/Validate.n.html#returns",
    "href": "reference/Validate.n.html#returns",
    "title": "Validate.n",
    "section": "Returns",
    "text": "Returns\n\n : dict[int, int] | int\n\nA dictionary of the number of test units for each validation step or a scalar value."
  },
  {
    "objectID": "reference/Validate.n.html#examples",
    "href": "reference/Validate.n.html#examples",
    "title": "Validate.n",
    "section": "Examples",
    "text": "Examples\nDifferent types of validation steps can have different numbers of test units. In the example below, we’ll use a simple Polars DataFrame with three columns (a, b, and c). There will be three validation steps, and the number of test units for each step will be a little bit different.\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [1, 2, 9, 5],\n        \"b\": [5, 6, 10, 3],\n        \"c\": [\"a\", \"b\", \"a\", \"a\"],\n    }\n)\n\n# Define a preprocessing function\ndef filter_by_a_gt_1(df):\n    return df.filter(pl.col(\"a\") &gt; 1)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(columns=\"a\", value=0)\n    .col_exists(columns=\"b\")\n    .col_vals_lt(columns=\"b\", value=9, pre=filter_by_a_gt_1)\n    .interrogate()\n)\n\nThe first validation step checks that all values in column a are greater than 0. Let’s use the n() method to determine the number of test units this validation step.\n\nvalidation.n(i=1, scalar=True)\n\n4\n\n\nThe returned value of 4 is the number of test units for the first validation step. This value is the same as the number of rows in the table.\nThe second validation step checks for the existence of column b. Using the n() method we can get the number of test units for this the second step.\n\nvalidation.n(i=2, scalar=True)\n\n1\n\n\nThere’s a single test unit here because the validation step is checking for the presence of a single column.\nThe third validation step checks that all values in column b are less than 9 after filtering the table to only include rows where the value in column a is greater than 1. Because the table is filtered, the number of test units will be less than the total number of rows in the input table. Let’s prove this by using the n() method.\n\nvalidation.n(i=3, scalar=True)\n\n3\n\n\nThe returned value of 3 is the number of test units for the third validation step. When using the pre= argument, the input table can be mutated before performing the validation. The n() method is a good way to determine whether the mutation performed as expected.\nIn all of these examples, the scalar=True argument was used to return the value as a scalar integer value. If scalar=False, the method will return a dictionary with an entry for the validation step number (from the i= argument) and the number of test units. Futhermore, leaving out the i= argument altogether will return a dictionary with filled with the number of test units for each validation step. Here’s what that looks like:\n\nvalidation.n()\n\n{1: 4, 2: 1, 3: 3}"
  },
  {
    "objectID": "reference/Validate.error.html",
    "href": "reference/Validate.error.html",
    "title": "Validate.error",
    "section": "",
    "text": "Validate.error(i=None, scalar=False)\nGet the ‘error’ level status for each validation step.\nThe ‘error’ status for a validation step is True if the fraction of failing test units meets or exceeds the threshold for the ‘error’ level. Otherwise, the status is False.\nThe ascribed name of ‘error’ is semantic and does not imply that the validation process is halted, it is simply a status indicator that could be used to trigger some action to be taken. Here’s how it fits in with other status indicators:\nThis method provides a dictionary of the ‘error’ status for each validation step. If the scalar=True argument is provided and i= is a scalar, the value is returned as a scalar instead of a dictionary."
  },
  {
    "objectID": "reference/Validate.error.html#parameters",
    "href": "reference/Validate.error.html#parameters",
    "title": "Validate.error",
    "section": "Parameters",
    "text": "Parameters\n\ni : int | list[int] | None = None\n\nThe validation step number(s) from which the ‘error’ status is obtained. Can be provided as a list of integers or a single integer. If None, all steps are included.\n\nscalar : bool = False\n\nIf True and i= is a scalar, return the value as a scalar instead of a dictionary."
  },
  {
    "objectID": "reference/Validate.error.html#returns",
    "href": "reference/Validate.error.html#returns",
    "title": "Validate.error",
    "section": "Returns",
    "text": "Returns\n\n : dict[int, bool] | bool\n\nA dictionary of the ‘error’ status for each validation step or a scalar value."
  },
  {
    "objectID": "reference/Validate.error.html#examples",
    "href": "reference/Validate.error.html#examples",
    "title": "Validate.error",
    "section": "Examples",
    "text": "Examples\nIn the example below, we’ll use a simple Polars DataFrame with three columns (a, b, and c). There will be three validation steps, and the first step will have some failing test units, the rest will be completely passing. We’ve set thresholds here for each of the steps by using thresholds=(2, 4, 5), which means:\n\nthe ‘warning’ threshold is 2 failing test units\nthe ‘error’ threshold is 4 failing test units\nthe ‘critical’ threshold is 5 failing test units\n\nAfter interrogation, the error() method is used to determine the ‘error’ status for each validation step.\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [3, 4, 9, 7, 2, 3, 8],\n        \"b\": [9, 8, 10, 5, 10, 6, 2],\n        \"c\": [\"a\", \"b\", \"a\", \"a\", \"b\", \"b\", \"a\"]\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl, thresholds=(2, 4, 5))\n    .col_vals_gt(columns=\"a\", value=5)\n    .col_vals_lt(columns=\"b\", value=15)\n    .col_vals_in_set(columns=\"c\", set=[\"a\", \"b\"])\n    .interrogate()\n)\n\nvalidation.error()\n\n{1: True, 2: False, 3: False}\n\n\nThe returned dictionary provides the ‘error’ status for each validation step. The first step has a True value since the number of failing test units meets the threshold for the ‘error’ level. The second and third steps have False values since the number of failing test units was 0, which is below the threshold for the ‘error’ level.\nWe can also visually inspect the ‘error’ status across all steps by viewing the validation table:\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:14:17PolarsWARNING2ERROR4CRITICAL5\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #EBBC14\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    a\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    7\n    30.43\n    40.57\n    ●\n    ●\n    ○\n    CSV\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    b\n    15\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    7\n    71.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        \n        \n    c\n    a, b\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    7\n    71.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:14:17 UTC&lt; 1 s2025-11-23 00:14:17 UTC\n  \n\n\n\n\n\n\n        \n\n\nWe can see that there are filled gray and yellow circles in the first step (far right side, in the W and E columns) indicating that the ‘warning’ and ‘error’ thresholds were met. The other steps have empty gray and yellow circles. This means that thresholds were ‘set but not met’ in those steps.\nIf we wanted to check the ‘error’ status for a single validation step, we can provide the step number. Also, we could have the value returned as a scalar by setting scalar=True (ensuring that i= is a scalar).\n\nvalidation.error(i=1)\n\n{1: True}\n\n\nThe returned value is True, indicating that the first validation step had the ‘error’ threshold met."
  },
  {
    "objectID": "reference/Validate.tbl_match.html",
    "href": "reference/Validate.tbl_match.html",
    "title": "Validate.tbl_match",
    "section": "",
    "text": "Validate.tbl_match(\n    tbl_compare,\n    pre=None,\n    thresholds=None,\n    actions=None,\n    brief=None,\n    active=True,\n)\nValidate whether the target table matches a comparison table.\nThe tbl_match() method checks whether the target table’s composition matches that of a comparison table. The validation performs a comprehensive comparison using progressively stricter checks (from least to most stringent):\nThis progressive approach helps identify exactly where tables differ. The validation will fail at the first check that doesn’t pass, making it easier to diagnose mismatches. This validation operates over a single test unit (pass/fail for complete table match)."
  },
  {
    "objectID": "reference/Validate.tbl_match.html#parameters",
    "href": "reference/Validate.tbl_match.html#parameters",
    "title": "Validate.tbl_match",
    "section": "Parameters",
    "text": "Parameters\n\ntbl_compare : FrameT | Any\n\nThe comparison table to validate against. This can be a DataFrame object (Polars or Pandas), an Ibis table object, or a callable that returns a table. If a callable is provided, it will be executed during interrogation to obtain the comparison table.\n\npre : Callable | None = None\n\nAn optional preprocessing function or lambda to apply to the data table during interrogation. This function should take a table as input and return a modified table. Have a look at the Preprocessing section for more information on how to use this argument.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nSet threshold failure levels for reporting and reacting to exceedences of the levels. The thresholds are set at the step level and will override any global thresholds set in Validate(thresholds=...). The default is None, which means that no thresholds will be set locally and global thresholds (if any) will take effect. Look at the Thresholds section for information on how to set threshold levels.\n\nactions : Actions | None = None\n\nOptional actions to take when the validation step meets or exceeds any set threshold levels. If provided, the Actions class should be used to define the actions.\n\nbrief : str | bool | None = None\n\nAn optional brief description of the validation step that will be displayed in the reporting table. You can use the templating elements like \"{step}\" to insert the step number, or \"{auto}\" to include an automatically generated brief. If True the entire brief will be automatically generated. If None (the default) then there won’t be a brief.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.tbl_match.html#returns",
    "href": "reference/Validate.tbl_match.html#returns",
    "title": "Validate.tbl_match",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.tbl_match.html#preprocessing",
    "href": "reference/Validate.tbl_match.html#preprocessing",
    "title": "Validate.tbl_match",
    "section": "Preprocessing",
    "text": "Preprocessing\nThe pre= argument allows for a preprocessing function or lambda to be applied to the data table during interrogation. This function should take a table as input and return a modified table. This is useful for performing any necessary transformations or filtering on the data before the validation step is applied.\nThe preprocessing function can be any callable that takes a table as input and returns a modified table. For example, you could use a lambda function to filter the table based on certain criteria or to apply a transformation to the data. Note that the same preprocessing is not applied to the comparison table; only the target table is preprocessed. Regarding the lifetime of the transformed table, it only exists during the validation step and is not stored in the Validate object or used in subsequent validation steps."
  },
  {
    "objectID": "reference/Validate.tbl_match.html#thresholds",
    "href": "reference/Validate.tbl_match.html#thresholds",
    "title": "Validate.tbl_match",
    "section": "Thresholds",
    "text": "Thresholds\nThe thresholds= parameter is used to set the failure-condition levels for the validation step. If they are set here at the step level, these thresholds will override any thresholds set at the global level in Validate(thresholds=...).\nThere are three threshold levels: ‘warning’, ‘error’, and ‘critical’. The threshold values can either be set as a proportion failing of all test units (a value between 0 to 1), or, the absolute number of failing test units (as integer that’s 1 or greater).\nThresholds can be defined using one of these input schemes:\n\nuse the Thresholds class (the most direct way to create thresholds)\nprovide a tuple of 1-3 values, where position 0 is the ‘warning’ level, position 1 is the ‘error’ level, and position 2 is the ‘critical’ level\ncreate a dictionary of 1-3 value entries; the valid keys: are ‘warning’, ‘error’, and ‘critical’\na single integer/float value denoting absolute number or fraction of failing test units for the ‘warning’ level only\n\nIf the number of failing test units exceeds set thresholds, the validation step will be marked as ‘warning’, ‘error’, or ‘critical’. All of the threshold levels don’t need to be set, you’re free to set any combination of them.\nAside from reporting failure conditions, thresholds can be used to determine the actions to take for each level of failure (using the actions= parameter)."
  },
  {
    "objectID": "reference/Validate.tbl_match.html#cross-backend-validation",
    "href": "reference/Validate.tbl_match.html#cross-backend-validation",
    "title": "Validate.tbl_match",
    "section": "Cross-Backend Validation",
    "text": "Cross-Backend Validation\nThe tbl_match() method supports automatic backend coercion when comparing tables from different backends (e.g., comparing a Polars DataFrame against a Pandas DataFrame, or comparing database tables from DuckDB/SQLite against in-memory DataFrames). When tables with different backends are detected, the comparison table is automatically converted to match the data table’s backend before validation proceeds.\nCertified Backend Combinations:\nAll combinations of the following backends have been tested and certified to work (in both directions):\n\nPandas DataFrame\nPolars DataFrame\nDuckDB (native)\nDuckDB (as Ibis table)\nSQLite (via Ibis)\n\nNote that database backends (DuckDB, SQLite, PostgreSQL, MySQL, Snowflake, BigQuery) are automatically materialized during validation:\n\nif comparing against Polars: materialized to Polars\nif comparing against Pandas: materialized to Pandas\nif both tables are database backends: both materialized to Polars\n\nThis ensures optimal performance and type consistency.\nData Types That Work Best in Cross-Backend Validation:\n\nnumeric types: int, float columns (including proper NaN handling)\nstring types: text columns with consistent encodings\nboolean types: True/False values\nnull values: None and NaN are treated as equivalent across backends\nlist columns: nested list structures (with basic types)\n\nKnown Limitations:\nWhile many data types work well in cross-backend validation, there are some known limitations to be aware of:\n\ndate/datetime types: When converting between Polars and Pandas, date objects may be represented differently. For example, datetime.date objects in Pandas may become pd.Timestamp objects when converted from Polars, leading to false mismatches. To work around this, ensure both tables use the same datetime representation before comparison.\ncustom types: User-defined types or complex nested structures may not convert cleanly between backends and could cause unexpected comparison failures.\ncategorical types: Categorical/factor columns may have different internal representations across backends.\ntimezone-aware datetimes: Timezone handling differs between backends and may cause comparison issues.\n\nHere are some ideas to overcome such limitations:\n\nfor date/datetime columns, consider using pre= preprocessing to normalize representations before comparison.\nwhen working with custom types, manually convert tables to the same backend before using tbl_match().\nuse the same datetime precision (e.g., milliseconds vs microseconds) in both tables."
  },
  {
    "objectID": "reference/Validate.tbl_match.html#examples",
    "href": "reference/Validate.tbl_match.html#examples",
    "title": "Validate.tbl_match",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll create two simple tables to demonstrate the tbl_match() validation.\n\nimport pointblank as pb\nimport polars as pl\n\n# Create the first table\ntbl_1 = pl.DataFrame({\n    \"a\": [1, 2, 3, 4],\n    \"b\": [\"w\", \"x\", \"y\", \"z\"],\n    \"c\": [4.0, 5.0, 6.0, 7.0]\n})\n\n# Create an identical table\ntbl_2 = pl.DataFrame({\n    \"a\": [1, 2, 3, 4],\n    \"b\": [\"w\", \"x\", \"y\", \"z\"],\n    \"c\": [4.0, 5.0, 6.0, 7.0]\n})\n\npb.preview(tbl_1)\n\n\n\n\n\n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows4Columns3\n  \n\n  \n  aInt64\n  bString\n  cFloat64\n\n\n\n  \n    1\n    1\n    w\n    4.0\n  \n  \n    2\n    2\n    x\n    5.0\n  \n  \n    3\n    3\n    y\n    6.0\n  \n  \n    4\n    4\n    z\n    7.0\n  \n\n\n\n\n\n\n        \n\n\nLet’s validate that tbl_1 matches tbl_2. Since these tables are identical, the validation should pass.\n\nvalidation = (\n    pb.Validate(data=tbl_1)\n    .tbl_match(tbl_compare=tbl_2)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    tbl_match\n    \n        \n            \n            \n                \n                \n            \n            \n                \n                \n            \n            \n            \n        \n    \n\n        \n        \n            tbl_match()\n        \n        \n        \n    None\n    EXTERNAL TABLE\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe validation table shows that the single test unit passed, indicating that the two tables match completely.\nNow, let’s create a table with a slight difference and see what happens.\n\n# Create a table with one different value\ntbl_3 = pl.DataFrame({\n    \"a\": [1, 2, 3, 4],\n    \"b\": [\"w\", \"x\", \"y\", \"z\"],\n    \"c\": [4.0, 5.5, 6.0, 7.0]  # Changed 5.0 to 5.5\n})\n\nvalidation = (\n    pb.Validate(data=tbl_1)\n    .tbl_match(tbl_compare=tbl_3)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    tbl_match\n    \n        \n            \n            \n                \n                \n            \n            \n                \n                \n            \n            \n            \n        \n    \n\n        \n        \n            tbl_match()\n        \n        \n        \n    None\n    EXTERNAL TABLE\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    00.00\n    11.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe validation table shows that the single test unit failed because the tables don’t match (one value is different in column c)."
  },
  {
    "objectID": "reference/col_summary_tbl.html",
    "href": "reference/col_summary_tbl.html",
    "title": "col_summary_tbl",
    "section": "",
    "text": "col_summary_tbl(data, tbl_name=None)\nGenerate a column-level summary table of a dataset.\nThe col_summary_tbl() function generates a summary table of a dataset, focusing on providing column-level information about the dataset. The summary includes the following information:\nThe summary table is returned as a GT object, which can be displayed in a notebook or saved to an HTML file."
  },
  {
    "objectID": "reference/col_summary_tbl.html#parameters",
    "href": "reference/col_summary_tbl.html#parameters",
    "title": "col_summary_tbl",
    "section": "Parameters",
    "text": "Parameters\n\ndata : FrameT | Any\n\nThe table to summarize, which could be a DataFrame object, an Ibis table object, a CSV file path, a Parquet file path, or a database connection string. Read the Supported Input Table Types section for details on the supported table types.\n\ntbl_name : str | None = None\n\nOptionally, the name of the table could be provided as tbl_name=."
  },
  {
    "objectID": "reference/col_summary_tbl.html#returns",
    "href": "reference/col_summary_tbl.html#returns",
    "title": "col_summary_tbl",
    "section": "Returns",
    "text": "Returns\n\n : GT\n\nA GT object that displays the column-level summaries of the table."
  },
  {
    "objectID": "reference/col_summary_tbl.html#supported-input-table-types",
    "href": "reference/col_summary_tbl.html#supported-input-table-types",
    "title": "col_summary_tbl",
    "section": "Supported Input Table Types",
    "text": "Supported Input Table Types\nThe data= parameter can be given any of the following table types:\n\nPolars DataFrame (\"polars\")\nPandas DataFrame (\"pandas\")\nDuckDB table (\"duckdb\")*\nMySQL table (\"mysql\")*\nPostgreSQL table (\"postgresql\")*\nSQLite table (\"sqlite\")*\nParquet table (\"parquet\")*\nCSV files (string path or pathlib.Path object with .csv extension)\nParquet files (string path, pathlib.Path object, glob pattern, directory with .parquet extension, or partitioned dataset)\nGitHub URLs (direct links to CSV or Parquet files on GitHub)\nDatabase connection strings (URI format with optional table specification)\n\nThe table types marked with an asterisk need to be prepared as Ibis tables (with type of ibis.expr.types.relations.Table). Furthermore, using col_summary_tbl() with these types of tables requires the Ibis library (v9.5.0 or above) to be installed. If the input table is a Polars or Pandas DataFrame, the availability of Ibis is not needed."
  },
  {
    "objectID": "reference/col_summary_tbl.html#examples",
    "href": "reference/col_summary_tbl.html#examples",
    "title": "col_summary_tbl",
    "section": "Examples",
    "text": "Examples\nIt’s easy to get a column-level summary of a table using the col_summary_tbl() function. Here’s an example using the small_table dataset (itself loaded using the load_dataset() function):\n\nimport pointblank as pb\n\nsmall_table = pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\")\n\npb.col_summary_tbl(data=small_table)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows13Columns8\n  \n\n  \n  Column\n  NA\n  UQ\n  Mean\n  SD\n  Min\n  P5\n  Q1\n  Med\n  Q3\n  P95\n  Max\n  IQR\n\n\n\n  \n    \n    date\n    \n        \n            \n            \n                \n            \n        \n    \n\n    date_timeDatetime(time_unit='us', time_zone=None)\n    00\n    120.92\n    -\n    -\n    20160104 00:32:00\n    -\n    -\n    -\n    -\n    -\n    20160130 11:23:00\n    -\n  \n  \n    \n    date\n    \n        \n            \n            \n                \n            \n        \n    \n\n    dateDate\n    00\n    110.85\n    -\n    -\n    20160104\n    -\n    -\n    -\n    -\n    -\n    20160130\n    -\n  \n  \n    \n    numeric\n    \n        \n            \n            \n                \n            \n        \n    \n\n    aInt64\n    00\n    70.54\n    3.77\n    2.09\n    1\n    1.06\n    2\n    3\n    4\n    7.4\n    8\n    2\n  \n  \n    \n    string\n    \n        \n            \n            \n                \n            \n        \n    \n\n    bString\n    00\n    120.92\n    9\n    0\n    9\n    9\n    9\n    9\n    9\n    9\n    9\n    0\n  \n  \n    \n    numeric\n    \n        \n            \n            \n                \n            \n        \n    \n\n    cInt64\n    20.15\n    70.54\n    5.73\n    2.72\n    2\n    2.05\n    3\n    7\n    8\n    9\n    9\n    5\n  \n  \n    \n    numeric\n    \n        \n            \n            \n                \n            \n        \n    \n\n    dFloat64\n    00\n    120.92\n    2,304.7\n    2,631.36\n    108.34\n    118.88\n    837.93\n    1,035.64\n    3,291.03\n    6,335.44\n    9999.99\n    2,453.1\n  \n  \n    \n    boolean\n    \n        \n            \n            \n                \n            \n            \n                \n            \n            \n        \n    \n\n    eBoolean\n    00\n    T0.62F0.38\n    -\n    -\n    -\n    -\n    -\n    -\n    -\n    -\n    -\n    -\n  \n  \n    \n    string\n    \n        \n            \n            \n                \n            \n        \n    \n\n    fString\n    00\n    30.23\n    3.46\n    0.52\n    3\n    3\n    3\n    3\n    4\n    4\n    4\n    1\n  \n\n  \n  \n  \n    String columns statistics regard the string's length.\n  \n\n\n\n\n\n\n        \n\n\nThis table used above was a Polars DataFrame, but the col_summary_tbl() function works with any table supported by pointblank, including Pandas DataFrames and Ibis backend tables. Here’s an example using a DuckDB table handled by Ibis:\n\nnycflights = pb.load_dataset(dataset=\"nycflights\", tbl_type=\"duckdb\")\n\npb.col_summary_tbl(data=nycflights, tbl_name=\"nycflights\")\n\n/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/great_tables/_tbl_data.py:822: UserWarning: PyArrow Table support is currently experimental.\n  warnings.warn(\"PyArrow Table support is currently experimental.\")\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Rows336,776Columns18\n  \n\n  \n  Column\n  NA\n  UQ\n  Mean\n  SD\n  Min\n  P5\n  Q1\n  Med\n  Q3\n  P95\n  Max\n  IQR\n\n\n\n  \n    \n    numeric\n    \n        \n            \n            \n                \n            \n        \n    \n\n    yearInt64\n    00\n    1&lt;.01\n    2,013\n    0\n    2,013\n    2,013\n    2,013\n    2,013\n    2,013\n    2,013\n    2,013\n    0\n  \n  \n    \n    numeric\n    \n        \n            \n            \n                \n            \n        \n    \n\n    monthInt64\n    00\n    12&lt;.01\n    6.55\n    3.41\n    1\n    1\n    4\n    6.77\n    10\n    12\n    12\n    6\n  \n  \n    \n    numeric\n    \n        \n            \n            \n                \n            \n        \n    \n\n    dayInt64\n    00\n    31&lt;.01\n    15.71\n    8.77\n    1\n    1\n    8\n    15.64\n    23\n    29\n    31\n    15\n  \n  \n    \n    numeric\n    \n        \n            \n            \n                \n            \n        \n    \n\n    dep_timeInt64\n    82550.02\n    1319&lt;.01\n    1,349.11\n    488.28\n    1\n    514\n    907\n    1,381.15\n    1,744\n    2,112\n    2,400\n    837\n  \n  \n    \n    numeric\n    \n        \n            \n            \n                \n            \n        \n    \n\n    sched_dep_timeInt64\n    00\n    1021&lt;.01\n    1,344.25\n    467.34\n    106\n    545\n    906\n    1,377.13\n    1,729\n    2,050\n    2,359\n    823\n  \n  \n    \n    numeric\n    \n        \n            \n            \n                \n            \n        \n    \n\n    dep_delayInt64\n    82550.02\n    528&lt;.01\n    12.64\n    40.21\n    −43\n    −13\n    −5\n    −1.58\n    11\n    88\n    1,301\n    16\n  \n  \n    \n    numeric\n    \n        \n            \n            \n                \n            \n        \n    \n\n    arr_timeInt64\n    87130.03\n    1412&lt;.01\n    1,502.05\n    533.26\n    1\n    10\n    1,104\n    1,539.25\n    1,940\n    2,248\n    2,400\n    836\n  \n  \n    \n    numeric\n    \n        \n            \n            \n                \n            \n        \n    \n\n    sched_arr_timeInt64\n    00\n    1163&lt;.01\n    1,536.38\n    497.46\n    1\n    15\n    1,124\n    1,575.93\n    1,945\n    2,246\n    2,359\n    821\n  \n  \n    \n    numeric\n    \n        \n            \n            \n                \n            \n        \n    \n\n    arr_delayInt64\n    94300.03\n    578&lt;.01\n    6.9\n    44.63\n    −86\n    −48\n    −17\n    −4.92\n    14\n    91\n    1,272\n    31\n  \n  \n    \n    string\n    \n        \n            \n            \n                \n            \n        \n    \n\n    carrierString\n    00\n    16&lt;.01\n    2\n    0\n    2\n    2\n    2\n    2\n    2\n    2\n    2\n    0\n  \n  \n    \n    numeric\n    \n        \n            \n            \n                \n            \n        \n    \n\n    flightInt64\n    00\n    38440.01\n    1,971.92\n    1,632.47\n    1\n    4\n    553\n    1,499.04\n    3,465\n    4,695\n    8,500\n    2,912\n  \n  \n    \n    string\n    \n        \n            \n            \n                \n            \n        \n    \n\n    tailnumString\n    2512&lt;.01\n    40440.01\n    6\n    0.07\n    5\n    6\n    6\n    6\n    6\n    6\n    6\n    0\n  \n  \n    \n    string\n    \n        \n            \n            \n                \n            \n        \n    \n\n    originString\n    00\n    3&lt;.01\n    3\n    0\n    3\n    3\n    3\n    3\n    3\n    3\n    3\n    0\n  \n  \n    \n    string\n    \n        \n            \n            \n                \n            \n        \n    \n\n    destString\n    00\n    105&lt;.01\n    3\n    0\n    3\n    3\n    3\n    3\n    3\n    3\n    3\n    0\n  \n  \n    \n    numeric\n    \n        \n            \n            \n                \n            \n        \n    \n\n    air_timeInt64\n    94300.03\n    510&lt;.01\n    150.69\n    93.69\n    20\n    31\n    82\n    129.35\n    192\n    339\n    695\n    110\n  \n  \n    \n    numeric\n    \n        \n            \n            \n                \n            \n        \n    \n\n    distanceInt64\n    00\n    214&lt;.01\n    1,039.91\n    733.23\n    17\n    116\n    502\n    861.05\n    1,389\n    2,475\n    4,983\n    887\n  \n  \n    \n    numeric\n    \n        \n            \n            \n                \n            \n        \n    \n\n    hourInt64\n    00\n    20&lt;.01\n    13.18\n    4.66\n    1\n    5\n    9\n    13.4\n    17\n    20\n    23\n    8\n  \n  \n    \n    numeric\n    \n        \n            \n            \n                \n            \n        \n    \n\n    minuteInt64\n    00\n    60&lt;.01\n    26.23\n    19.3\n    0\n    0\n    8\n    28.3\n    44\n    58\n    59\n    36\n  \n\n  \n  \n  \n    String columns statistics regard the string's length."
  },
  {
    "objectID": "reference/connect_to_table.html",
    "href": "reference/connect_to_table.html",
    "title": "connect_to_table",
    "section": "",
    "text": "connect_to_table(connection_string)\nConnect to a database table using a connection string.\nThis utility function tests whether a connection string leads to a valid table and returns the table object if successful. It provides helpful error messages when no table is specified or when backend dependencies are missing."
  },
  {
    "objectID": "reference/connect_to_table.html#parameters",
    "href": "reference/connect_to_table.html#parameters",
    "title": "connect_to_table",
    "section": "Parameters",
    "text": "Parameters\n\nconnection_string : str\n\nA database connection string with a required table specification using the ::table_name suffix. Supported formats are outlined in the Supported Connection String Formats section."
  },
  {
    "objectID": "reference/connect_to_table.html#returns",
    "href": "reference/connect_to_table.html#returns",
    "title": "connect_to_table",
    "section": "Returns",
    "text": "Returns\n\n : Any\n\nAn Ibis table object for the specified database table."
  },
  {
    "objectID": "reference/connect_to_table.html#supported-connection-string-formats",
    "href": "reference/connect_to_table.html#supported-connection-string-formats",
    "title": "connect_to_table",
    "section": "Supported Connection String Formats",
    "text": "Supported Connection String Formats\nThe connection_string parameter must include a valid connection string with a table name specified using the :: syntax. Here are some examples on how to format connection strings for various backends:\nDuckDB:     \"duckdb:///path/to/database.ddb::table_name\"\nSQLite:     \"sqlite:///path/to/database.db::table_name\"\nPostgreSQL: \"postgresql://user:password@localhost:5432/database::table_name\"\nMySQL:      \"mysql://user:password@localhost:3306/database::table_name\"\nBigQuery:   \"bigquery://project/dataset::table_name\"\nSnowflake:  \"snowflake://user:password@account/database/schema::table_name\"\nIf the connection string does not include a table name, the function will attempt to connect to the database and list available tables, providing guidance on how to specify a table."
  },
  {
    "objectID": "reference/connect_to_table.html#examples",
    "href": "reference/connect_to_table.html#examples",
    "title": "connect_to_table",
    "section": "Examples",
    "text": "Examples\nConnect to a DuckDB table:\n\nimport pointblank as pb\n\n# Get path to a DuckDB database file from package data\nduckdb_path = pb.get_data_path(\"game_revenue\", \"duckdb\")\n\n# Connect to the `game_revenue` table in the DuckDB database\ngame_revenue = pb.connect_to_table(f\"duckdb:///{duckdb_path}::game_revenue\")\n\n# Use with the `preview()` function\npb.preview(game_revenue)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    DuckDBRows2,000Columns11\n  \n\n  \n  player_idstring\n  session_idstring\n  session_starttimestamp\n  timetimestamp\n  item_typestring\n  item_namestring\n  item_revenuefloat64\n  session_durationfloat64\n  start_daydate\n  acquisitionstring\n  countrystring\n\n\n\n  \n    1\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:31:27+00:00\n    iap\n    offer2\n    8.99\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    2\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:36:57+00:00\n    iap\n    gems3\n    22.49\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    3\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:37:45+00:00\n    iap\n    gold7\n    107.99\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    4\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:42:33+00:00\n    ad\n    ad_20sec\n    0.76\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    5\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-hdu9jkls\n    2015-01-01 11:50:02+00:00\n    2015-01-01 11:55:20+00:00\n    ad\n    ad_5sec\n    0.03\n    35.2\n    2015-01-01\n    google\n    Germany\n  \n  \n    1996\n    NAOJRDMCSEBI281\n    NAOJRDMCSEBI281-j2vs9ilp\n    2015-01-21 01:57:50+00:00\n    2015-01-21 02:02:50+00:00\n    ad\n    ad_survey\n    1.332\n    25.8\n    2015-01-11\n    organic\n    Norway\n  \n  \n    1997\n    NAOJRDMCSEBI281\n    NAOJRDMCSEBI281-j2vs9ilp\n    2015-01-21 01:57:50+00:00\n    2015-01-21 02:22:14+00:00\n    ad\n    ad_survey\n    1.35\n    25.8\n    2015-01-11\n    organic\n    Norway\n  \n  \n    1998\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-vbhcsmtr\n    2015-01-21 02:39:48+00:00\n    2015-01-21 02:40:00+00:00\n    ad\n    ad_5sec\n    0.03\n    8.4\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    1999\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-vbhcsmtr\n    2015-01-21 02:39:48+00:00\n    2015-01-21 02:47:12+00:00\n    iap\n    offer5\n    26.09\n    8.4\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    2000\n    GJCXNTWEBIPQ369\n    GJCXNTWEBIPQ369-9elq67md\n    2015-01-21 03:59:23+00:00\n    2015-01-21 04:06:29+00:00\n    ad\n    ad_5sec\n    0.12\n    18.5\n    2015-01-14\n    organic\n    United States\n  \n\n\n\n\n\n\n        \n\n\nHere are some backend-specific connection examples:\n# PostgreSQL\npg_table = pb.connect_to_table(\n    \"postgresql://user:password@localhost:5432/warehouse::customer_data\"\n)\n\n# SQLite\nsqlite_table = pb.connect_to_table(\"sqlite:///local_data.db::products\")\n\n# BigQuery\nbq_table = pb.connect_to_table(\"bigquery://my-project/analytics::daily_metrics\")\nThis function requires the Ibis library with appropriate backend drivers:\n# You can install a set of common backends:\npip install 'ibis-framework[duckdb,postgres,mysql,sqlite]'\n\n# ...or specific backends as needed:\npip install 'ibis-framework[duckdb]'    # for DuckDB\npip install 'ibis-framework[postgres]'  # for PostgreSQL"
  },
  {
    "objectID": "reference/connect_to_table.html#see-also",
    "href": "reference/connect_to_table.html#see-also",
    "title": "connect_to_table",
    "section": "See Also",
    "text": "See Also\nprint_database_tables : List all available tables in a database for discovery"
  },
  {
    "objectID": "reference/print_database_tables.html",
    "href": "reference/print_database_tables.html",
    "title": "print_database_tables",
    "section": "",
    "text": "print_database_tables(connection_string)\nList all tables in a database from a connection string.\nThe print_database_tables() function connects to a database and returns a list of all available tables. This is particularly useful for discovering what tables exist in a database before connecting to a specific table with `connect_to_table(). The function automatically filters out temporary Ibis tables (memtables) to show only user tables. It supports all database backends available through Ibis, including DuckDB, SQLite, PostgreSQL, MySQL, BigQuery, and Snowflake.\n\n\n\nconnection_string : str\n\nA database connection string without the ::table_name suffix. Example: \"duckdb:///path/to/database.ddb\".\n\n\n\n\n\n\n : list[str]\n\nList of table names, excluding temporary Ibis tables.\n\n\n\n\n\nconnect_to_table : Connect to a database table with full connection string documentation"
  },
  {
    "objectID": "reference/print_database_tables.html#parameters",
    "href": "reference/print_database_tables.html#parameters",
    "title": "print_database_tables",
    "section": "",
    "text": "connection_string : str\n\nA database connection string without the ::table_name suffix. Example: \"duckdb:///path/to/database.ddb\"."
  },
  {
    "objectID": "reference/print_database_tables.html#returns",
    "href": "reference/print_database_tables.html#returns",
    "title": "print_database_tables",
    "section": "",
    "text": ": list[str]\n\nList of table names, excluding temporary Ibis tables."
  },
  {
    "objectID": "reference/print_database_tables.html#see-also",
    "href": "reference/print_database_tables.html#see-also",
    "title": "print_database_tables",
    "section": "",
    "text": "connect_to_table : Connect to a database table with full connection string documentation"
  },
  {
    "objectID": "reference/preview.html",
    "href": "reference/preview.html",
    "title": "preview",
    "section": "",
    "text": "preview(\n    data,\n    columns_subset=None,\n    n_head=5,\n    n_tail=5,\n    limit=50,\n    show_row_numbers=True,\n    max_col_width=250,\n    min_tbl_width=500,\n    incl_header=None,\n)\nDisplay a table preview that shows some rows from the top, some from the bottom.\nTo get a quick look at the data in a table, we can use the preview() function to display a preview of the table. The function shows a subset of the rows from the start and end of the table, with the number of rows from the start and end determined by the n_head= and n_tail= parameters (set to 5 by default). This function works with any table that is supported by the pointblank library, including Pandas, Polars, and Ibis backend tables (e.g., DuckDB, MySQL, PostgreSQL, SQLite, Parquet, etc.).\nThe view is optimized for readability, with column names and data types displayed in a compact format. The column widths are sized to fit the column names, dtypes, and column content up to a configurable maximum width of max_col_width= pixels. The table can be scrolled horizontally to view even very large datasets. Since the output is a Great Tables (GT) object, it can be further customized using the great_tables API."
  },
  {
    "objectID": "reference/preview.html#parameters",
    "href": "reference/preview.html#parameters",
    "title": "preview",
    "section": "Parameters",
    "text": "Parameters\n\ndata : FrameT | Any\n\nThe table to preview, which could be a DataFrame object, an Ibis table object, a CSV file path, a Parquet file path, or a database connection string. When providing a CSV or Parquet file path (as a string or pathlib.Path object), the file will be automatically loaded using an available DataFrame library (Polars or Pandas). Parquet input also supports glob patterns, directories containing .parquet files, and Spark-style partitioned datasets. Connection strings enable direct database access via Ibis with optional table specification using the ::table_name suffix. Read the Supported Input Table Types section for details on the supported table types.\n\ncolumns_subset : str | list[str] | Column | None = None\n\nThe columns to display in the table, by default None (all columns are shown). This can be a string, a list of strings, a Column object, or a ColumnSelector object. The latter two options allow for more flexible column selection using column selector functions. Errors are raised if the column names provided don’t match any columns in the table (when provided as a string or list of strings) or if column selector expressions don’t resolve to any columns.\n\nn_head : int = 5\n\nThe number of rows to show from the start of the table. Set to 5 by default.\n\nn_tail : int = 5\n\nThe number of rows to show from the end of the table. Set to 5 by default.\n\nlimit : int = 50\n\nThe limit value for the sum of n_head= and n_tail= (the total number of rows shown). If the sum of n_head= and n_tail= exceeds the limit, an error is raised. The default value is 50.\n\nshow_row_numbers : bool = True\n\nShould row numbers be shown? The numbers shown reflect the row numbers of the head and tail in the input data= table. By default, this is set to True.\n\nmax_col_width : int = 250\n\nThe maximum width of the columns (in pixels) before the text is truncated. The default value is 250 (\"250px\").\n\nmin_tbl_width : int = 500\n\nThe minimum width of the table in pixels. If the sum of the column widths is less than this value, the all columns are sized up to reach this minimum width value. The default value is 500 (\"500px\").\n\nincl_header : bool = None\n\nShould the table include a header with the table type and table dimensions? Set to True by default."
  },
  {
    "objectID": "reference/preview.html#returns",
    "href": "reference/preview.html#returns",
    "title": "preview",
    "section": "Returns",
    "text": "Returns\n\n : GT\n\nA GT object that displays the preview of the table."
  },
  {
    "objectID": "reference/preview.html#supported-input-table-types",
    "href": "reference/preview.html#supported-input-table-types",
    "title": "preview",
    "section": "Supported Input Table Types",
    "text": "Supported Input Table Types\nThe data= parameter can be given any of the following table types:\n\nPolars DataFrame (\"polars\")\nPandas DataFrame (\"pandas\")\nPySpark table (\"pyspark\")\nDuckDB table (\"duckdb\")*\nMySQL table (\"mysql\")*\nPostgreSQL table (\"postgresql\")*\nSQLite table (\"sqlite\")*\nMicrosoft SQL Server table (\"mssql\")*\nSnowflake table (\"snowflake\")*\nDatabricks table (\"databricks\")*\nBigQuery table (\"bigquery\")*\nParquet table (\"parquet\")*\nCSV files (string path or pathlib.Path object with .csv extension)\nParquet files (string path, pathlib.Path object, glob pattern, directory with .parquet extension, or partitioned dataset)\nDatabase connection strings (URI format with optional table specification)\n\nThe table types marked with an asterisk need to be prepared as Ibis tables (with type of ibis.expr.types.relations.Table). Furthermore, using preview() with these types of tables requires the Ibis library (v9.5.0 or above) to be installed. If the input table is a Polars or Pandas DataFrame, the availability of Ibis is not needed.\nTo use a CSV file, ensure that a string or pathlib.Path object with a .csv extension is provided. The file will be automatically detected and loaded using the best available DataFrame library. The loading preference is Polars first, then Pandas as a fallback.\nConnection strings follow database URL formats and must also specify a table using the ::table_name suffix. Examples include:\n\"duckdb:///path/to/database.ddb::table_name\"\n\"sqlite:///path/to/database.db::table_name\"\n\"postgresql://user:password@localhost:5432/database::table_name\"\n\"mysql://user:password@localhost:3306/database::table_name\"\n\"bigquery://project/dataset::table_name\"\n\"snowflake://user:password@account/database/schema::table_name\"\nWhen using connection strings, the Ibis library with the appropriate backend driver is required."
  },
  {
    "objectID": "reference/preview.html#examples",
    "href": "reference/preview.html#examples",
    "title": "preview",
    "section": "Examples",
    "text": "Examples\nIt’s easy to preview a table using the preview() function. Here’s an example using the small_table dataset (itself loaded using the load_dataset() function):\n\nimport pointblank as pb\n\nsmall_table_polars = pb.load_dataset(\"small_table\")\n\npb.preview(small_table_polars)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows13Columns8\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05\n    6\n    8-kdg-938\n    3\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    None\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09\n    8\n    3-ldm-038\n    7\n    283.94\n    True\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26\n    4\n    2-dmx-010\n    7\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28\n    2\n    7-dmx-010\n    8\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30\n    1\n    3-dka-303\n    None\n    2230.09\n    True\n    high\n  \n\n\n\n\n\n\n        \n\n\nThis table is a Polars DataFrame, but the preview() function works with any table supported by pointblank, including Pandas DataFrames and Ibis backend tables. Here’s an example using a DuckDB table handled by Ibis:\n\nsmall_table_duckdb = pb.load_dataset(\"small_table\", tbl_type=\"duckdb\")\n\npb.preview(small_table_duckdb)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    DuckDBRows13Columns8\n  \n\n  \n  date_timetimestamp\n  datedate\n  aint64\n  bstring\n  cint64\n  dfloat64\n  eboolean\n  fstring\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05\n    6\n    8-kdg-938\n    3\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    NULL\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09\n    8\n    3-ldm-038\n    7\n    283.94\n    True\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26\n    4\n    2-dmx-010\n    7\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28\n    2\n    7-dmx-010\n    8\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30\n    1\n    3-dka-303\n    NULL\n    2230.09\n    True\n    high\n  \n\n\n\n\n\n\n        \n\n\nThe blue dividing line marks the end of the first n_head= rows and the start of the last n_tail= rows.\nWe can adjust the number of rows shown from the start and end of the table by setting the n_head= and n_tail= parameters. Let’s enlarge each of these to 10:\n\npb.preview(small_table_polars, n_head=10, n_tail=10)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows13Columns8\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05\n    6\n    8-kdg-938\n    3\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    None\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09\n    8\n    3-ldm-038\n    7\n    283.94\n    True\n    low\n  \n  \n    6\n    2016-01-11 06:15:00\n    2016-01-11\n    4\n    2-dhe-923\n    4\n    3291.03\n    True\n    mid\n  \n  \n    7\n    2016-01-15 18:46:00\n    2016-01-15\n    7\n    1-knw-093\n    3\n    843.34\n    True\n    high\n  \n  \n    8\n    2016-01-17 11:27:00\n    2016-01-17\n    4\n    5-boe-639\n    2\n    1035.64\n    False\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26\n    4\n    2-dmx-010\n    7\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28\n    2\n    7-dmx-010\n    8\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30\n    1\n    3-dka-303\n    None\n    2230.09\n    True\n    high\n  \n\n\n\n\n\n\n        \n\n\nIn the above case, the entire dataset is shown since the sum of n_head= and n_tail= is greater than the number of rows in the table (which is 13).\nThe columns_subset= parameter can be used to show only specific columns in the table. You can provide a list of column names to make the selection. Let’s try that with the \"game_revenue\" dataset as a Pandas DataFrame:\n\ngame_revenue_pandas = pb.load_dataset(\"game_revenue\", tbl_type=\"pandas\")\n\npb.preview(game_revenue_pandas, columns_subset=[\"player_id\", \"item_name\", \"item_revenue\"])\n\n\n\n\n\n  \n  \n  \n  \n\n\n\n\n  \n    PandasRows2,000Columns11\n  \n\n  \n  player_idobject\n  item_nameobject\n  item_revenuefloat64\n\n\n\n  \n    1\n    ECPANOIXLZHF896\n    offer2\n    8.99\n  \n  \n    2\n    ECPANOIXLZHF896\n    gems3\n    22.49\n  \n  \n    3\n    ECPANOIXLZHF896\n    gold7\n    107.99\n  \n  \n    4\n    ECPANOIXLZHF896\n    ad_20sec\n    0.76\n  \n  \n    5\n    ECPANOIXLZHF896\n    ad_5sec\n    0.03\n  \n  \n    1996\n    NAOJRDMCSEBI281\n    ad_survey\n    1.332\n  \n  \n    1997\n    NAOJRDMCSEBI281\n    ad_survey\n    1.35\n  \n  \n    1998\n    RMOSWHJGELCI675\n    ad_5sec\n    0.03\n  \n  \n    1999\n    RMOSWHJGELCI675\n    offer5\n    26.09\n  \n  \n    2000\n    GJCXNTWEBIPQ369\n    ad_5sec\n    0.12\n  \n\n\n\n\n\n\n        \n\n\nAlternatively, we can use column selector functions like starts_with() and matches()` to select columns based on text or patterns:\n\npb.preview(game_revenue_pandas, n_head=2, n_tail=2, columns_subset=pb.starts_with(\"session\"))\n\n\n\n\n\n  \n  \n  \n  \n\n\n\n\n  \n    PandasRows2,000Columns11\n  \n\n  \n  session_idobject\n  session_startdatetime64[ns, UTC]\n  session_durationfloat64\n\n\n\n  \n    1\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    16.3\n  \n  \n    2\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    16.3\n  \n  \n    1999\n    RMOSWHJGELCI675-vbhcsmtr\n    2015-01-21 02:39:48+00:00\n    8.4\n  \n  \n    2000\n    GJCXNTWEBIPQ369-9elq67md\n    2015-01-21 03:59:23+00:00\n    18.5\n  \n\n\n\n\n\n\n        \n\n\nMultiple column selector functions can be combined within col() using operators like | and &:\n\npb.preview(\n  game_revenue_pandas,\n  n_head=2,\n  n_tail=2,\n  columns_subset=pb.col(pb.starts_with(\"item\") | pb.matches(\"player\"))\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n\n\n\n\n  \n    PandasRows2,000Columns11\n  \n\n  \n  player_idobject\n  item_typeobject\n  item_nameobject\n  item_revenuefloat64\n\n\n\n  \n    1\n    ECPANOIXLZHF896\n    iap\n    offer2\n    8.99\n  \n  \n    2\n    ECPANOIXLZHF896\n    iap\n    gems3\n    22.49\n  \n  \n    1999\n    RMOSWHJGELCI675\n    iap\n    offer5\n    26.09\n  \n  \n    2000\n    GJCXNTWEBIPQ369\n    ad\n    ad_5sec\n    0.12\n  \n\n\n\n\n\n\n        \n\n\n\nWorking with CSV Files\nThe preview() function can directly accept CSV file paths, making it easy to preview data stored in CSV files without manual loading:\n\n# Get a path to a CSV file from the package data\ncsv_path = pb.get_data_path(\"global_sales\", \"csv\")\n\npb.preview(csv_path)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows50,000Columns20\n  \n\n  \n  product_idString\n  product_categoryString\n  customer_idString\n  customer_segmentString\n  regionString\n  countryString\n  cityString\n  timestampDatetime\n  quarterString\n  monthInt64\n  yearInt64\n  priceFloat64\n  quantityInt64\n  statusString\n  emailString\n  revenueFloat64\n  taxFloat64\n  totalFloat64\n  payment_methodString\n  sales_channelString\n\n\n\n  \n    1\n    98b70df0\n    Manufacturing\n    cf3b13c7\n    Government\n    Asia Pacific\n    Australia\n    Melbourne\n    2021-12-25 19:00:00\n    2021-Q4\n    12\n    2021\n    186.0\n    7\n    returned\n    user1651@test.org\n    1302.0\n    127.45\n    1429.45\n    Apple Pay\n    Partner\n  \n  \n    2\n    9d09fef5\n    Manufacturing\n    08b5db12\n    Consumer\n    Europe\n    France\n    Nice\n    2022-06-12 17:25:00\n    2022-Q2\n    6\n    2022\n    137.03\n    8\n    returned\n    user5200@company.io\n    1096.24\n    222.52\n    1318.76\n    PayPal\n    Distributor\n  \n  \n    3\n    8ac6b077\n    Retail\n    41079b2e\n    Consumer\n    Europe\n    France\n    Toulouse\n    2023-05-06 09:09:00\n    2023-Q2\n    5\n    2023\n    330.08\n    4\n    shipped\n    user9180@mockdata.com\n    1320.32\n    260.89\n    1581.21\n    PayPal\n    Phone\n  \n  \n    4\n    13d2df9d\n    Healthcare\n    b421eece\n    Consumer\n    North America\n    USA\n    Miami\n    2023-10-11 16:53:00\n    2023-Q4\n    10\n    2023\n    420.09\n    3\n    shipped\n    user1636@example.com\n    1260.27\n    103.99\n    1364.26\n    Bank Transfer\n    Phone\n  \n  \n    5\n    98b70df0\n    Manufacturing\n    5906a04f\n    SMB\n    North America\n    Canada\n    Calgary\n    2022-05-05 01:53:00\n    2022-Q2\n    5\n    2022\n    187.77\n    3\n    delivered\n    user9971@mockdata.com\n    563.31\n    75.73\n    639.04\n    Credit Card\n    Phone\n  \n  \n    49996\n    53a36468\n    Finance\n    966a8bbe\n    Government\n    Asia Pacific\n    Australia\n    Melbourne\n    2023-11-04 14:45:00\n    2023-Q4\n    11\n    2023\n    198.18\n    1\n    pending\n    user8593@test.org\n    198.18\n    18.3\n    216.48\n    Google Pay\n    Partner\n  \n  \n    49997\n    a42fd1ff\n    Healthcare\n    ff8933e4\n    SMB\n    Asia Pacific\n    Japan\n    Kyoto\n    2023-04-27 17:27:00\n    2023-Q2\n    4\n    2023\n    419.72\n    2\n    returned\n    user5448@company.io\n    839.44\n    90.49\n    929.93\n    Google Pay\n    Partner\n  \n  \n    49998\n    bbf158d2\n    Technology\n    f0c0af3f\n    Enterprise\n    North America\n    USA\n    Los Angeles\n    2021-04-24 23:15:00\n    2021-Q2\n    4\n    2021\n    302.52\n    1\n    pending\n    user1463@test.org\n    302.52\n    21.68\n    324.2\n    Bank Transfer\n    Online\n  \n  \n    49999\n    2a0866de\n    Healthcare\n    5b27ba59\n    SMB\n    Europe\n    France\n    Nice\n    2023-12-30 19:44:00\n    2023-Q4\n    12\n    2023\n    433.82\n    5\n    pending\n    user4167@test.org\n    2169.1\n    448.87\n    2617.97\n    Credit Card\n    Online\n  \n  \n    50000\n    6260f67c\n    Technology\n    482c1d84\n    Consumer\n    Asia Pacific\n    Japan\n    Kyoto\n    2021-12-05 09:49:00\n    2021-Q4\n    12\n    2021\n    400.31\n    8\n    returned\n    user4238@example.com\n    3202.48\n    339.84\n    3542.32\n    Apple Pay\n    Distributor\n  \n\n\n\n\n\n\n        \n\n\nYou can also use a Path object to specify the CSV file:\n\nfrom pathlib import Path\n\ncsv_file = Path(pb.get_data_path(\"game_revenue\", \"csv\"))\n\npb.preview(csv_file, n_head=3, n_tail=3)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows2,000Columns11\n  \n\n  \n  player_idString\n  session_idString\n  session_startDatetime\n  timeDatetime\n  item_typeString\n  item_nameString\n  item_revenueFloat64\n  session_durationFloat64\n  start_dayDate\n  acquisitionString\n  countryString\n\n\n\n  \n    1\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:31:27+00:00\n    iap\n    offer2\n    8.99\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    2\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:36:57+00:00\n    iap\n    gems3\n    22.49\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    3\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:37:45+00:00\n    iap\n    gold7\n    107.99\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    1998\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-vbhcsmtr\n    2015-01-21 02:39:48+00:00\n    2015-01-21 02:40:00+00:00\n    ad\n    ad_5sec\n    0.03\n    8.4\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    1999\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-vbhcsmtr\n    2015-01-21 02:39:48+00:00\n    2015-01-21 02:47:12+00:00\n    iap\n    offer5\n    26.09\n    8.4\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    2000\n    GJCXNTWEBIPQ369\n    GJCXNTWEBIPQ369-9elq67md\n    2015-01-21 03:59:23+00:00\n    2015-01-21 04:06:29+00:00\n    ad\n    ad_5sec\n    0.12\n    18.5\n    2015-01-14\n    organic\n    United States\n  \n\n\n\n\n\n\n        \n\n\n\n\nWorking with Parquet Files\nThe preview() function can directly accept Parquet files and datasets in various formats:\n\n# Single Parquet file from package data\nparquet_path = pb.get_data_path(\"nycflights\", \"parquet\")\n\npb.preview(parquet_path)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows336,776Columns18\n  \n\n  \n  yearInt64\n  monthInt64\n  dayInt64\n  dep_timeInt64\n  sched_dep_timeInt64\n  dep_delayInt64\n  arr_timeInt64\n  sched_arr_timeInt64\n  arr_delayInt64\n  carrierString\n  flightInt64\n  tailnumString\n  originString\n  destString\n  air_timeInt64\n  distanceInt64\n  hourInt64\n  minuteInt64\n\n\n\n  \n    1\n    2013\n    1\n    1\n    517\n    515\n    2\n    830\n    819\n    11\n    UA\n    1545\n    N14228\n    EWR\n    IAH\n    227\n    1400\n    5\n    15\n  \n  \n    2\n    2013\n    1\n    1\n    533\n    529\n    4\n    850\n    830\n    20\n    UA\n    1714\n    N24211\n    LGA\n    IAH\n    227\n    1416\n    5\n    29\n  \n  \n    3\n    2013\n    1\n    1\n    542\n    540\n    2\n    923\n    850\n    33\n    AA\n    1141\n    N619AA\n    JFK\n    MIA\n    160\n    1089\n    5\n    40\n  \n  \n    4\n    2013\n    1\n    1\n    544\n    545\n    -1\n    1004\n    1022\n    -18\n    B6\n    725\n    N804JB\n    JFK\n    BQN\n    183\n    1576\n    5\n    45\n  \n  \n    5\n    2013\n    1\n    1\n    554\n    600\n    -6\n    812\n    837\n    -25\n    DL\n    461\n    N668DN\n    LGA\n    ATL\n    116\n    762\n    6\n    0\n  \n  \n    336772\n    2013\n    9\n    30\n    None\n    1455\n    None\n    None\n    1634\n    None\n    9E\n    3393\n    None\n    JFK\n    DCA\n    None\n    213\n    14\n    55\n  \n  \n    336773\n    2013\n    9\n    30\n    None\n    2200\n    None\n    None\n    2312\n    None\n    9E\n    3525\n    None\n    LGA\n    SYR\n    None\n    198\n    22\n    0\n  \n  \n    336774\n    2013\n    9\n    30\n    None\n    1210\n    None\n    None\n    1330\n    None\n    MQ\n    3461\n    N535MQ\n    LGA\n    BNA\n    None\n    764\n    12\n    10\n  \n  \n    336775\n    2013\n    9\n    30\n    None\n    1159\n    None\n    None\n    1344\n    None\n    MQ\n    3572\n    N511MQ\n    LGA\n    CLE\n    None\n    419\n    11\n    59\n  \n  \n    336776\n    2013\n    9\n    30\n    None\n    840\n    None\n    None\n    1020\n    None\n    MQ\n    3531\n    N839MQ\n    LGA\n    RDU\n    None\n    431\n    8\n    40\n  \n\n\n\n\n\n\n        \n\n\nYou can also use glob patterns and directories:\n# Multiple Parquet files with glob patterns\npb.preview(\"data/sales_*.parquet\")\n\n# Directory containing Parquet files\npb.preview(\"parquet_data/\")\n\n# Partitioned Parquet dataset\npb.preview(\"sales_data/\")  # Auto-discovers partition columns\n\n\nWorking with Database Connection Strings\nThe preview() function supports database connection strings for direct preview of database tables. Connection strings must specify a table using the ::table_name suffix:\n\n# Get path to a DuckDB database file from package data\nduckdb_path = pb.get_data_path(\"game_revenue\", \"duckdb\")\n\npb.preview(f\"duckdb:///{duckdb_path}::game_revenue\")\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    DuckDBRows2,000Columns11\n  \n\n  \n  player_idstring\n  session_idstring\n  session_starttimestamp\n  timetimestamp\n  item_typestring\n  item_namestring\n  item_revenuefloat64\n  session_durationfloat64\n  start_daydate\n  acquisitionstring\n  countrystring\n\n\n\n  \n    1\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:31:27+00:00\n    iap\n    offer2\n    8.99\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    2\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:36:57+00:00\n    iap\n    gems3\n    22.49\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    3\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:37:45+00:00\n    iap\n    gold7\n    107.99\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    4\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:42:33+00:00\n    ad\n    ad_20sec\n    0.76\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    5\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-hdu9jkls\n    2015-01-01 11:50:02+00:00\n    2015-01-01 11:55:20+00:00\n    ad\n    ad_5sec\n    0.03\n    35.2\n    2015-01-01\n    google\n    Germany\n  \n  \n    1996\n    NAOJRDMCSEBI281\n    NAOJRDMCSEBI281-j2vs9ilp\n    2015-01-21 01:57:50+00:00\n    2015-01-21 02:02:50+00:00\n    ad\n    ad_survey\n    1.332\n    25.8\n    2015-01-11\n    organic\n    Norway\n  \n  \n    1997\n    NAOJRDMCSEBI281\n    NAOJRDMCSEBI281-j2vs9ilp\n    2015-01-21 01:57:50+00:00\n    2015-01-21 02:22:14+00:00\n    ad\n    ad_survey\n    1.35\n    25.8\n    2015-01-11\n    organic\n    Norway\n  \n  \n    1998\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-vbhcsmtr\n    2015-01-21 02:39:48+00:00\n    2015-01-21 02:40:00+00:00\n    ad\n    ad_5sec\n    0.03\n    8.4\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    1999\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-vbhcsmtr\n    2015-01-21 02:39:48+00:00\n    2015-01-21 02:47:12+00:00\n    iap\n    offer5\n    26.09\n    8.4\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    2000\n    GJCXNTWEBIPQ369\n    GJCXNTWEBIPQ369-9elq67md\n    2015-01-21 03:59:23+00:00\n    2015-01-21 04:06:29+00:00\n    ad\n    ad_5sec\n    0.12\n    18.5\n    2015-01-14\n    organic\n    United States\n  \n\n\n\n\n\n\n        \n\n\nFor comprehensive documentation on supported connection string formats, error handling, and installation requirements, see the connect_to_table() function."
  },
  {
    "objectID": "reference/Validate.n_failed.html",
    "href": "reference/Validate.n_failed.html",
    "title": "Validate.n_failed",
    "section": "",
    "text": "Validate.n_failed(i=None, scalar=False)\nProvides a dictionary of the number of test units that failed for each validation step.\nThe n_failed() method provides the number of test units that failed for each validation step. This is the number of test units that did not pass in the the validation step. It is always some integer value between 0 and the total number of test units.\nTest units are the atomic units of the validation process. Different validations can have different numbers of test units. For example, a validation that checks for the presence of a column in a table will have a single test unit. A validation that checks for the presence of a value in a column will have as many test units as there are rows in the table.\nThe method provides a dictionary of the number of failing test units for each validation step. If the scalar=True argument is provided and i= is a scalar, the value is returned as a scalar instead of a dictionary. Furthermore, a value obtained here will be the complement to the analogous value returned by the n_passed() method (i.e., n - n_passed)."
  },
  {
    "objectID": "reference/Validate.n_failed.html#parameters",
    "href": "reference/Validate.n_failed.html#parameters",
    "title": "Validate.n_failed",
    "section": "Parameters",
    "text": "Parameters\n\ni : int | list[int] | None = None\n\nThe validation step number(s) from which the number of failing test units is obtained. Can be provided as a list of integers or a single integer. If None, all steps are included.\n\nscalar : bool = False\n\nIf True and i= is a scalar, return the value as a scalar instead of a dictionary."
  },
  {
    "objectID": "reference/Validate.n_failed.html#returns",
    "href": "reference/Validate.n_failed.html#returns",
    "title": "Validate.n_failed",
    "section": "Returns",
    "text": "Returns\n\n : dict[int, int] | int\n\nA dictionary of the number of failing test units for each validation step or a scalar value."
  },
  {
    "objectID": "reference/Validate.n_failed.html#examples",
    "href": "reference/Validate.n_failed.html#examples",
    "title": "Validate.n_failed",
    "section": "Examples",
    "text": "Examples\nIn the example below, we’ll use a simple Polars DataFrame with three columns (a, b, and c). There will be three validation steps and, as it turns out, all of them will have failing test units. After interrogation, the n_failed() method is used to determine the number of failing test units for each validation step.\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [7, 4, 9, 7, 12],\n        \"b\": [9, 8, 10, 5, 10],\n        \"c\": [\"a\", \"b\", \"c\", \"a\", \"b\"]\n    }\n)\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_gt(columns=\"a\", value=5)\n    .col_vals_gt(columns=\"b\", value=pb.col(\"a\"))\n    .col_vals_in_set(columns=\"c\", set=[\"a\", \"b\"])\n    .interrogate()\n)\n\nvalidation.n_failed()\n\n{1: 1, 2: 2, 3: 1}\n\n\nThe returned dictionary shows that all validation steps had failing test units.\nIf we wanted to check the number of failing test units for a single validation step, we can provide the step number. Also, we could forego the dictionary and get a scalar value by setting scalar=True (ensuring that i= is a scalar).\n\nvalidation.n_failed(i=1)\n\n{1: 1}\n\n\nThe returned value of 1 is the number of failing test units for the first validation step."
  },
  {
    "objectID": "reference/Validate.interrogate.html",
    "href": "reference/Validate.interrogate.html",
    "title": "Validate.interrogate",
    "section": "",
    "text": "Validate.interrogate(\n    collect_extracts=True,\n    collect_tbl_checked=True,\n    get_first_n=None,\n    sample_n=None,\n    sample_frac=None,\n    extract_limit=500,\n)\nExecute each validation step against the table and store the results.\nWhen a validation plan has been set with a series of validation steps, the interrogation process through interrogate() should then be invoked. Interrogation will evaluate each validation step against the table and store the results.\nThe interrogation process will collect extracts of failing rows if the collect_extracts= option is set to True (the default). We can control the number of rows collected using the get_first_n=, sample_n=, and sample_frac= options. The extract_limit= option will enforce a hard limit on the number of rows collected when collect_extracts=True.\nAfter interrogation is complete, the Validate object will have gathered information, and we can use methods like n_passed(), f_failed(), etc., to understand how the table performed against the validation plan. A visual representation of the validation results can be viewed by printing the Validate object; this will display the validation table in an HTML viewing environment."
  },
  {
    "objectID": "reference/Validate.interrogate.html#parameters",
    "href": "reference/Validate.interrogate.html#parameters",
    "title": "Validate.interrogate",
    "section": "Parameters",
    "text": "Parameters\n\ncollect_extracts : bool = True\n\nAn option to collect rows of the input table that didn’t pass a particular validation step. The default is True and further options (i.e., get_first_n=, sample_*=) allow for fine control of how these rows are collected.\n\ncollect_tbl_checked : bool = True\n\nThe processed data frames produced by executing the validation steps is collected and stored in the Validate object if collect_tbl_checked=True. This information is necessary for some methods (e.g., get_sundered_data()), but it can potentially make the object grow to a large size. To opt out of attaching this data, set this to False.\n\nget_first_n : int | None = None\n\nIf the option to collect rows where test units is chosen, there is the option here to collect the first n rows. Supply an integer number of rows to extract from the top of subset table containing non-passing rows (the ordering of data from the original table is retained).\n\nsample_n : int | None = None\n\nIf the option to collect non-passing rows is chosen, this option allows for the sampling of n rows. Supply an integer number of rows to sample from the subset table. If n happens to be greater than the number of non-passing rows, then all such rows will be returned.\n\nsample_frac : int | float | None = None\n\nIf the option to collect non-passing rows is chosen, this option allows for the sampling of a fraction of those rows. Provide a number in the range of 0 and 1. The number of rows to return could be very large, however, the extract_limit= option will apply a hard limit to the returned rows.\n\nextract_limit : int = 500\n\nA value that limits the possible number of rows returned when extracting non-passing rows. The default is 500 rows. This limit is applied after any sampling or limiting options are applied. If the number of rows to be returned is greater than this limit, then the number of rows returned will be limited to this value. This is useful for preventing the collection of too many rows when the number of non-passing rows is very large."
  },
  {
    "objectID": "reference/Validate.interrogate.html#returns",
    "href": "reference/Validate.interrogate.html#returns",
    "title": "Validate.interrogate",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the results of the interrogation."
  },
  {
    "objectID": "reference/Validate.interrogate.html#examples",
    "href": "reference/Validate.interrogate.html#examples",
    "title": "Validate.interrogate",
    "section": "Examples",
    "text": "Examples\nLet’s use a built-in dataset (\"game_revenue\") to demonstrate some of the options of the interrogation process. A series of validation steps will populate our validation plan. After setting up the plan, the next step is to interrogate the table and see how well it aligns with our expectations. We’ll use the get_first_n= option so that any extracts of failing rows are limited to the first n rows.\n\nimport pointblank as pb\nimport polars as pl\n\nvalidation = (\n    pb.Validate(data=pb.load_dataset(dataset=\"game_revenue\"))\n    .col_vals_lt(columns=\"item_revenue\", value=200)\n    .col_vals_gt(columns=\"item_revenue\", value=0)\n    .col_vals_gt(columns=\"session_duration\", value=5)\n    .col_vals_in_set(columns=\"item_type\", set=[\"iap\", \"ad\"])\n    .col_vals_regex(columns=\"player_id\", pattern=r\"[A-Z]{12}[0-9]{3}\")\n)\n\nvalidation.interrogate(get_first_n=10)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:15:14Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    item_revenue\n    200\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    item_revenue\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C66\n    3\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    session_duration\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    19820.99\n    180.01\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        \n        \n    item_type\n    iap, ad\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    5\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    player_id\n    [A-Z]{12}[0-9]{3}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:15:14 UTC&lt; 1 s2025-11-23 00:15:14 UTC\n  \n\n\n\n\n\n\n        \n\n\nThe validation table shows that step 3 (checking for session_duration greater than 5) has 18 failing test units. This means that 18 rows in the table are problematic. We’d like to see the rows that failed this validation step and we can do that with the get_data_extracts() method.\n\npb.preview(validation.get_data_extracts(i=3, frame=True))\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows10Columns12\n  \n\n  \n  player_idString\n  session_idString\n  session_startDatetime\n  timeDatetime\n  item_typeString\n  item_nameString\n  item_revenueFloat64\n  session_durationFloat64\n  start_dayDate\n  acquisitionString\n  countryString\n\n\n\n  \n    549\n    QNLVRDEOXFYJ892\n    QNLVRDEOXFYJ892-lz5fmr6k\n    2015-01-10 16:44:17+00:00\n    2015-01-10 16:45:29+00:00\n    iap\n    gold3\n    3.49\n    3.7\n    2015-01-09\n    crosspromo\n    Australia\n  \n  \n    620\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-t4y8bjcu\n    2015-01-11 07:24:24+00:00\n    2015-01-11 07:25:18+00:00\n    iap\n    offer4\n    17.991\n    5.0\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    621\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-t4y8bjcu\n    2015-01-11 07:24:24+00:00\n    2015-01-11 07:26:24+00:00\n    iap\n    offer5\n    26.09\n    5.0\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    622\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-t4y8bjcu\n    2015-01-11 07:24:24+00:00\n    2015-01-11 07:28:36+00:00\n    ad\n    ad_15sec\n    0.53\n    5.0\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    663\n    GFLYJHAPMZWD631\n    GFLYJHAPMZWD631-i2v1bl7a\n    2015-01-11 16:13:24+00:00\n    2015-01-11 16:14:54+00:00\n    iap\n    gems2\n    3.99\n    3.6\n    2015-01-09\n    organic\n    India\n  \n  \n    772\n    BFNLURISJXTH647\n    BFNLURISJXTH647-6o5hx27z\n    2015-01-12 17:37:39+00:00\n    2015-01-12 17:39:27+00:00\n    iap\n    offer5\n    11.59\n    4.1\n    2015-01-10\n    organic\n    India\n  \n  \n    773\n    BFNLURISJXTH647\n    BFNLURISJXTH647-6o5hx27z\n    2015-01-12 17:37:39+00:00\n    2015-01-12 17:41:45+00:00\n    iap\n    gems3\n    9.99\n    4.1\n    2015-01-10\n    organic\n    India\n  \n  \n    908\n    KILWZYHRSJEG316\n    KILWZYHRSJEG316-uke7dhqj\n    2015-01-13 22:16:29+00:00\n    2015-01-13 22:17:35+00:00\n    iap\n    offer2\n    10.99\n    3.2\n    2015-01-04\n    organic\n    Denmark\n  \n  \n    1037\n    JUBDVFHCNQWT198\n    JUBDVFHCNQWT198-9h4xs2pb\n    2015-01-14 16:08:25+00:00\n    2015-01-14 16:08:43+00:00\n    iap\n    offer5\n    8.69\n    3.3\n    2015-01-14\n    organic\n    Philippines\n  \n  \n    1038\n    JUBDVFHCNQWT198\n    JUBDVFHCNQWT198-9h4xs2pb\n    2015-01-14 16:08:25+00:00\n    2015-01-14 16:11:01+00:00\n    iap\n    offer4\n    5.99\n    3.3\n    2015-01-14\n    organic\n    Philippines\n  \n\n\n\n\n\n\n        \n\n\nThe get_data_extracts() method will return a Polars DataFrame here with the first 10 rows that failed the validation step (we passed that into the preview() function for a better display). There are actually 18 rows that failed but we limited the collection of extracts with get_first_n=10."
  },
  {
    "objectID": "reference/Validate.col_vals_not_null.html",
    "href": "reference/Validate.col_vals_not_null.html",
    "title": "Validate.col_vals_not_null",
    "section": "",
    "text": "Validate.col_vals_not_null(\n    columns,\n    pre=None,\n    segments=None,\n    thresholds=None,\n    actions=None,\n    brief=None,\n    active=True,\n)\nValidate whether values in a column are not Null.\nThe col_vals_not_null() validation method checks whether column values in a table are not Null. This validation will operate over the number of test units that is equal to the number of rows in the table."
  },
  {
    "objectID": "reference/Validate.col_vals_not_null.html#parameters",
    "href": "reference/Validate.col_vals_not_null.html#parameters",
    "title": "Validate.col_vals_not_null",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns : str | list[str] | Column | ColumnSelector | ColumnSelectorNarwhals\n\nA single column or a list of columns to validate. Can also use col() with column selectors to specify one or more columns. If multiple columns are supplied or resolved, there will be a separate validation step generated for each column.\n\npre : Callable | None = None\n\nAn optional preprocessing function or lambda to apply to the data table during interrogation. This function should take a table as input and return a modified table. Have a look at the Preprocessing section for more information on how to use this argument.\n\nsegments : SegmentSpec | None = None\n\nAn optional directive on segmentation, which serves to split a validation step into multiple (one step per segment). Can be a single column name, a tuple that specifies a column name and its corresponding values to segment on, or a combination of both (provided as a list). Read the Segmentation section for usage information.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nSet threshold failure levels for reporting and reacting to exceedences of the levels. The thresholds are set at the step level and will override any global thresholds set in Validate(thresholds=...). The default is None, which means that no thresholds will be set locally and global thresholds (if any) will take effect. Look at the Thresholds section for information on how to set threshold levels.\n\nactions : Actions | None = None\n\nOptional actions to take when the validation step(s) meets or exceeds any set threshold levels. If provided, the Actions class should be used to define the actions.\n\nbrief : str | bool | None = None\n\nAn optional brief description of the validation step that will be displayed in the reporting table. You can use the templating elements like \"{step}\" to insert the step number, or \"{auto}\" to include an automatically generated brief. If True the entire brief will be automatically generated. If None (the default) then there won’t be a brief.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.col_vals_not_null.html#returns",
    "href": "reference/Validate.col_vals_not_null.html#returns",
    "title": "Validate.col_vals_not_null",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.col_vals_not_null.html#preprocessing",
    "href": "reference/Validate.col_vals_not_null.html#preprocessing",
    "title": "Validate.col_vals_not_null",
    "section": "Preprocessing",
    "text": "Preprocessing\nThe pre= argument allows for a preprocessing function or lambda to be applied to the data table during interrogation. This function should take a table as input and return a modified table. This is useful for performing any necessary transformations or filtering on the data before the validation step is applied.\nThe preprocessing function can be any callable that takes a table as input and returns a modified table. For example, you could use a lambda function to filter the table based on certain criteria or to apply a transformation to the data. Note that you can refer to a column via columns= that is expected to be present in the transformed table, but may not exist in the table before preprocessing. Regarding the lifetime of the transformed table, it only exists during the validation step and is not stored in the Validate object or used in subsequent validation steps."
  },
  {
    "objectID": "reference/Validate.col_vals_not_null.html#segmentation",
    "href": "reference/Validate.col_vals_not_null.html#segmentation",
    "title": "Validate.col_vals_not_null",
    "section": "Segmentation",
    "text": "Segmentation\nThe segments= argument allows for the segmentation of a validation step into multiple segments. This is useful for applying the same validation step to different subsets of the data. The segmentation can be done based on a single column or specific fields within a column.\nProviding a single column name will result in a separate validation step for each unique value in that column. For example, if you have a column called \"region\" with values \"North\", \"South\", and \"East\", the validation step will be applied separately to each region.\nAlternatively, you can provide a tuple that specifies a column name and its corresponding values to segment on. For example, if you have a column called \"date\" and you want to segment on only specific dates, you can provide a tuple like (\"date\", [\"2023-01-01\", \"2023-01-02\"]). Any other values in the column will be disregarded (i.e., no validation steps will be created for them).\nA list with a combination of column names and tuples can be provided as well. This allows for more complex segmentation scenarios. The following inputs are both valid:\n# Segments from all unique values in the `region` column\n# and specific dates in the `date` column\nsegments=[\"region\", (\"date\", [\"2023-01-01\", \"2023-01-02\"])]\n\n# Segments from all unique values in the `region` and `date` columns\nsegments=[\"region\", \"date\"]\nThe segmentation is performed during interrogation, and the resulting validation steps will be numbered sequentially. Each segment will have its own validation step, and the results will be reported separately. This allows for a more granular analysis of the data and helps identify issues within specific segments.\nImportantly, the segmentation process will be performed after any preprocessing of the data table. Because of this, one can conceivably use the pre= argument to generate a column that can be used for segmentation. For example, you could create a new column called \"segment\" through use of pre= and then use that column for segmentation."
  },
  {
    "objectID": "reference/Validate.col_vals_not_null.html#thresholds",
    "href": "reference/Validate.col_vals_not_null.html#thresholds",
    "title": "Validate.col_vals_not_null",
    "section": "Thresholds",
    "text": "Thresholds\nThe thresholds= parameter is used to set the failure-condition levels for the validation step. If they are set here at the step level, these thresholds will override any thresholds set at the global level in Validate(thresholds=...).\nThere are three threshold levels: ‘warning’, ‘error’, and ‘critical’. The threshold values can either be set as a proportion failing of all test units (a value between 0 to 1), or, the absolute number of failing test units (as integer that’s 1 or greater).\nThresholds can be defined using one of these input schemes:\n\nuse the Thresholds class (the most direct way to create thresholds)\nprovide a tuple of 1-3 values, where position 0 is the ‘warning’ level, position 1 is the ‘error’ level, and position 2 is the ‘critical’ level\ncreate a dictionary of 1-3 value entries; the valid keys: are ‘warning’, ‘error’, and ‘critical’\na single integer/float value denoting absolute number or fraction of failing test units for the ‘warning’ level only\n\nIf the number of failing test units exceeds set thresholds, the validation step will be marked as ‘warning’, ‘error’, or ‘critical’. All of the threshold levels don’t need to be set, you’re free to set any combination of them.\nAside from reporting failure conditions, thresholds can be used to determine the actions to take for each level of failure (using the actions= parameter)."
  },
  {
    "objectID": "reference/Validate.col_vals_not_null.html#examples",
    "href": "reference/Validate.col_vals_not_null.html#examples",
    "title": "Validate.col_vals_not_null",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with two numeric columns (a and b). The table is shown below:\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [4, 7, 2, 8],\n        \"b\": [5, None, 1, None],\n    }\n)\n\npb.preview(tbl)\n\n\n\n\n\n  \n  \n  \n\n\n\n\n\n  \n  aInt64\n  bInt64\n\n\n\n  \n    1\n    4\n    5\n  \n  \n    2\n    7\n    None\n  \n  \n    3\n    2\n    1\n  \n  \n    4\n    8\n    None\n  \n\n\n\n\n\n\n        \n\n\nLet’s validate that none of the values in column a are Null values. We’ll determine if this validation had any failing test units (there are four test units, one for each row).\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_not_null(columns=\"a\")\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    a\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    41.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nPrinting the validation object shows the validation table in an HTML viewing environment. The validation table shows the single entry that corresponds to the validation step created by using col_vals_not_null(). All test units passed, and there are no failing test units.\nNow, let’s use that same set of values for a validation on column b.\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_not_null(columns=\"b\")\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    b\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    20.50\n    20.50\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe validation table reports two failing test units. The specific failing cases are for the two Null values in column b."
  },
  {
    "objectID": "reference/Validate.above_threshold.html",
    "href": "reference/Validate.above_threshold.html",
    "title": "Validate.above_threshold",
    "section": "",
    "text": "Validate.above_threshold(level='warning', i=None)\nCheck if any validation steps exceed a specified threshold level.\nThe above_threshold() method checks whether validation steps exceed a given threshold level. This provides a non-exception-based alternative to assert_below_threshold() for conditional workflow control based on validation results.\nThis method is useful in scenarios where you want to check if any validation steps failed beyond a certain threshold without raising an exception, allowing for more flexible programmatic responses to validation issues."
  },
  {
    "objectID": "reference/Validate.above_threshold.html#parameters",
    "href": "reference/Validate.above_threshold.html#parameters",
    "title": "Validate.above_threshold",
    "section": "Parameters",
    "text": "Parameters\n\nlevel : str = 'warning'\n\nThe threshold level to check against. Valid options are: \"warning\" (the least severe threshold level), \"error\" (the middle severity threshold level), and \"critical\" (the most severe threshold level). The default is \"warning\".\n\ni : int | None = None\n\nSpecific validation step number(s) to check. If a single integer, checks only that step. If a list of integers, checks all specified steps. If None (the default), checks all validation steps. Step numbers are 1-based (first step is 1, not 0)."
  },
  {
    "objectID": "reference/Validate.above_threshold.html#returns",
    "href": "reference/Validate.above_threshold.html#returns",
    "title": "Validate.above_threshold",
    "section": "Returns",
    "text": "Returns\n\n : bool\n\nTrue if any of the specified validation steps exceed the given threshold level, False otherwise."
  },
  {
    "objectID": "reference/Validate.above_threshold.html#raises",
    "href": "reference/Validate.above_threshold.html#raises",
    "title": "Validate.above_threshold",
    "section": "Raises",
    "text": "Raises\n\n: ValueError\n\nIf an invalid threshold level is provided."
  },
  {
    "objectID": "reference/Validate.above_threshold.html#examples",
    "href": "reference/Validate.above_threshold.html#examples",
    "title": "Validate.above_threshold",
    "section": "Examples",
    "text": "Examples\nBelow are some examples of how to use the above_threshold() method. First, we’ll create a simple Polars DataFrame with a single column (values).\n\nimport polars as pl\n\ntbl = pl.DataFrame({\n    \"values\": [1, 2, 3, 4, 5, 0, -1]\n})\n\nThen a validation plan will be created with thresholds (warning=0.1, error=0.2, critical=0.3). After interrogating, we display the validation report table:\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(data=tbl, thresholds=(0.1, 0.2, 0.3))\n    .col_vals_gt(columns=\"values\", value=0)\n    .col_vals_lt(columns=\"values\", value=10)\n    .col_vals_between(columns=\"values\", left=0, right=5)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #EBBC14\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    values\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    7\n    50.71\n    20.29\n    ●\n    ●\n    ○\n    CSV\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    values\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    7\n    71.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #AAAAAA\n    3\n    \n        \n            \n\n    col_vals_between\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_between()\n        \n        \n        \n    values\n    [0, 5]\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    7\n    60.86\n    10.14\n    ●\n    ○\n    ○\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nLet’s check if any steps exceed the ‘warning’ threshold with the above_threshold() method. A message will be printed if that’s the case:\n\nif validation.above_threshold(level=\"warning\"):\n    print(\"Some steps have exceeded the warning threshold\")\n\nSome steps have exceeded the warning threshold\n\n\nCheck if only steps 2 and 3 exceed the ‘error’ threshold through use of the i= argument:\n\nif validation.above_threshold(level=\"error\", i=[2, 3]):\n    print(\"Steps 2 and/or 3 have exceeded the error threshold\")\n\nYou can use this in a workflow to conditionally trigger processes. Here’s a snippet of how you might use this in a function:\ndef process_data(validation_obj):\n    # Only continue processing if validation passes critical thresholds\n    if not validation_obj.above_threshold(level=\"critical\"):\n        # Continue with processing\n        print(\"Data meets critical quality thresholds, proceeding...\")\n        return True\n    else:\n        # Log failure and stop processing\n        print(\"Data fails critical quality checks, aborting...\")\n        return False\nNote that this is just a suggestion for how to implement conditional workflow processes. You should adapt this pattern to your specific requirements, which might include different threshold levels, custom logging mechanisms, or integration with your organization’s data pipelines and notification systems."
  },
  {
    "objectID": "reference/Validate.above_threshold.html#see-also",
    "href": "reference/Validate.above_threshold.html#see-also",
    "title": "Validate.above_threshold",
    "section": "See Also",
    "text": "See Also\n\nassert_below_threshold(): a similar method that raises an exception if thresholds are exceeded\nwarning(): get the ‘warning’ status for each validation step\nerror(): get the ‘error’ status for each validation step\ncritical(): get the ‘critical’ status for each validation step"
  },
  {
    "objectID": "reference/missing_vals_tbl.html",
    "href": "reference/missing_vals_tbl.html",
    "title": "missing_vals_tbl",
    "section": "",
    "text": "missing_vals_tbl(data)\nDisplay a table that shows the missing values in the input table.\nThe missing_vals_tbl() function generates a table that shows the missing values in the input table. The table is displayed using the Great Tables API, which allows for further customization of the table’s appearance if so desired."
  },
  {
    "objectID": "reference/missing_vals_tbl.html#parameters",
    "href": "reference/missing_vals_tbl.html#parameters",
    "title": "missing_vals_tbl",
    "section": "Parameters",
    "text": "Parameters\n\ndata : FrameT | Any\n\nThe table for which to display the missing values. This could be a DataFrame object, an Ibis table object, a CSV file path, a Parquet file path, or a database connection string. Read the Supported Input Table Types section for details on the supported table types."
  },
  {
    "objectID": "reference/missing_vals_tbl.html#returns",
    "href": "reference/missing_vals_tbl.html#returns",
    "title": "missing_vals_tbl",
    "section": "Returns",
    "text": "Returns\n\n : GT\n\nA GT object that displays the table of missing values in the input table."
  },
  {
    "objectID": "reference/missing_vals_tbl.html#supported-input-table-types",
    "href": "reference/missing_vals_tbl.html#supported-input-table-types",
    "title": "missing_vals_tbl",
    "section": "Supported Input Table Types",
    "text": "Supported Input Table Types\nThe data= parameter can be given any of the following table types:\n\nPolars DataFrame (\"polars\")\nPandas DataFrame (\"pandas\")\nPySpark table (\"pyspark\")\nDuckDB table (\"duckdb\")*\nMySQL table (\"mysql\")*\nPostgreSQL table (\"postgresql\")*\nSQLite table (\"sqlite\")*\nMicrosoft SQL Server table (\"mssql\")*\nSnowflake table (\"snowflake\")*\nDatabricks table (\"databricks\")*\nBigQuery table (\"bigquery\")*\nParquet table (\"parquet\")*\nCSV files (string path or pathlib.Path object with .csv extension)\nParquet files (string path, pathlib.Path object, glob pattern, directory with .parquet extension, or partitioned dataset)\nDatabase connection strings (URI format with optional table specification)\n\nThe table types marked with an asterisk need to be prepared as Ibis tables (with type of ibis.expr.types.relations.Table). Furthermore, using missing_vals_tbl() with these types of tables requires the Ibis library (v9.5.0 or above) to be installed. If the input table is a Polars or Pandas DataFrame, the availability of Ibis is not needed."
  },
  {
    "objectID": "reference/missing_vals_tbl.html#the-missing-values-table",
    "href": "reference/missing_vals_tbl.html#the-missing-values-table",
    "title": "missing_vals_tbl",
    "section": "The Missing Values Table",
    "text": "The Missing Values Table\nThe missing values table shows the proportion of missing values in each column of the input table. The table is divided into sectors, with each sector representing a range of rows in the table. The proportion of missing values in each sector is calculated for each column. The table is displayed using the Great Tables API, which allows for further customization of the table’s appearance.\nTo ensure that the table can scale to tables with many columns, each row in the reporting table represents a column in the input table. There are 10 sectors shown in the table, where the first sector represents the first 10% of the rows, the second sector represents the next 10% of the rows, and so on. Any sectors that are light blue indicate that there are no missing values in that sector. If there are missing values, the proportion of missing values is shown by a gray color (light gray for low proportions, dark gray to black for very high proportions)."
  },
  {
    "objectID": "reference/missing_vals_tbl.html#examples",
    "href": "reference/missing_vals_tbl.html#examples",
    "title": "missing_vals_tbl",
    "section": "Examples",
    "text": "Examples\nThe missing_vals_tbl() function is useful for quickly identifying columns with missing values in a table. Here’s an example using the nycflights dataset (loaded as a Polars DataFrame using the load_dataset() function):\n\nimport pointblank as pb\n\nnycflights = pb.load_dataset(\"nycflights\", tbl_type=\"polars\")\n\npb.missing_vals_tbl(nycflights)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Missing Values   46,595 in total\n  \n  \n    PolarsRows336,776Columns18\n  \n\n  Column\n  \n    Row Sector\n  \n\n\n  1\n  2\n  3\n  4\n  5\n  6\n  7\n  8\n  9\n  10\n\n\n\n  \n    year\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    month\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    day\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    dep_time\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    sched_dep_time\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    dep_delay\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    arr_time\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    sched_arr_time\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    arr_delay\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    carrier\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    flight\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    tailnum\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    origin\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    dest\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    air_time\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    distance\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    hour\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    minute\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n\n  \n  \n  \n    NO MISSING VALUES     PROPORTION MISSING:  0%100%ROW SECTORS1 – 3367733678 – 6735467355 – 101031101032 – 134708134709 – 168385168386 – 202062202063 – 235739235740 – 269416269417 – 303093303094 – 336776\n  \n\n\n\n\n\n\n        \n\n\nThe table shows the proportion of missing values in each column of the nycflights dataset. The table is divided into sectors, with each sector representing a range of rows in the table (with around 34,000 rows per sector). The proportion of missing values in each sector is calculated for each column. The various shades of gray indicate the proportion of missing values in each sector. Many columns have no missing values at all, and those sectors are colored light blue."
  },
  {
    "objectID": "reference/get_action_metadata.html",
    "href": "reference/get_action_metadata.html",
    "title": "get_action_metadata",
    "section": "",
    "text": "get_action_metadata()\nAccess step-level metadata when authoring custom actions.\nGet the metadata for the validation step where an action was triggered. This can be called by user functions to get the metadata for the current action. This function can only be used within callables crafted for the Actions class."
  },
  {
    "objectID": "reference/get_action_metadata.html#returns",
    "href": "reference/get_action_metadata.html#returns",
    "title": "get_action_metadata",
    "section": "Returns",
    "text": "Returns\n\n : dict | None\n\nA dictionary containing the metadata for the current step. If called outside of an action (i.e., when no action is being executed), this function will return None."
  },
  {
    "objectID": "reference/get_action_metadata.html#description-of-the-metadata-fields",
    "href": "reference/get_action_metadata.html#description-of-the-metadata-fields",
    "title": "get_action_metadata",
    "section": "Description of the Metadata Fields",
    "text": "Description of the Metadata Fields\nThe metadata dictionary contains the following fields for a given validation step:\n\nstep: The step number.\ncolumn: The column name.\nvalue: The value being compared (only available in certain validation steps).\ntype: The assertion type (e.g., \"col_vals_gt\", etc.).\ntime: The time the validation step was executed (in ISO format).\nlevel: The severity level (\"warning\", \"error\", or \"critical\").\nlevel_num: The severity level as a numeric value (30, 40, or 50).\nautobrief: A localized and brief statement of the expectation for the step.\nfailure_text: Localized text that explains how the validation step failed."
  },
  {
    "objectID": "reference/get_action_metadata.html#examples",
    "href": "reference/get_action_metadata.html#examples",
    "title": "get_action_metadata",
    "section": "Examples",
    "text": "Examples\nWhen creating a custom action, you can access the metadata for the current step using the get_action_metadata() function. Here’s an example of a custom action that logs the metadata for the current step:\n\nimport pointblank as pb\n\ndef log_issue():\n    metadata = pb.get_action_metadata()\n    print(f\"Type: {metadata['type']}, Step: {metadata['step']}\")\n\nvalidation = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"duckdb\"),\n        thresholds=pb.Thresholds(warning=0.05, error=0.10, critical=0.15),\n        actions=pb.Actions(warning=log_issue),\n    )\n    .col_vals_regex(columns=\"player_id\", pattern=r\"[A-Z]{12}[0-9]{3}\")\n    .col_vals_gt(columns=\"item_revenue\", value=0.05)\n    .col_vals_gt(\n        columns=\"session_duration\",\n        value=15,\n    )\n    .interrogate()\n)\n\nvalidation\n\nType: col_vals_gt, Step: 2\nType: col_vals_gt, Step: 3\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:15:46DuckDBWARNING0.05ERROR0.1CRITICAL0.15\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    player_id\n    [A-Z]{12}[0-9]{3}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #EBBC14\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    item_revenue\n    0.05\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    17010.85\n    2990.15\n    ●\n    ●\n    ○\n    —\n  \n  \n    #FF3300\n    3\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    session_duration\n    15\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    16750.84\n    3250.16\n    ●\n    ●\n    ●\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:15:46 UTC&lt; 1 s2025-11-23 00:15:46 UTC\n  \n\n\n\n\n\n\n        \n\n\nKey pieces to note in the above example:\n\nlog_issue() (the custom action) collects metadata by calling get_action_metadata()\nthe metadata is a dictionary that is used to craft the log message\nthe action is passed as a bare function to the Actions object within the Validate object (placing it within Validate(actions=) ensures it’s set as an action for every validation step)"
  },
  {
    "objectID": "reference/get_action_metadata.html#see-also",
    "href": "reference/get_action_metadata.html#see-also",
    "title": "get_action_metadata",
    "section": "See Also",
    "text": "See Also\nHave a look at Actions for more information on how to create custom actions for validation steps that exceed a set threshold value."
  },
  {
    "objectID": "reference/Validate.col_vals_outside.html",
    "href": "reference/Validate.col_vals_outside.html",
    "title": "Validate.col_vals_outside",
    "section": "",
    "text": "Validate.col_vals_outside(\n    columns,\n    left,\n    right,\n    inclusive=(True, True),\n    na_pass=False,\n    pre=None,\n    segments=None,\n    thresholds=None,\n    actions=None,\n    brief=None,\n    active=True,\n)\nDo column data lie outside of two specified values or data in other columns?\nThe col_vals_between() validation method checks whether column values in a table do not fall within a certain range. The range is specified with three arguments: left=, right=, and inclusive=. The left= and right= values specify the lower and upper bounds. These bounds can be specified as literal values or as column names provided within col(). The validation will operate over the number of test units that is equal to the number of rows in the table (determined after any pre= mutation has been applied)."
  },
  {
    "objectID": "reference/Validate.col_vals_outside.html#parameters",
    "href": "reference/Validate.col_vals_outside.html#parameters",
    "title": "Validate.col_vals_outside",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns : str | list[str] | Column | ColumnSelector | ColumnSelectorNarwhals\n\nA single column or a list of columns to validate. Can also use col() with column selectors to specify one or more columns. If multiple columns are supplied or resolved, there will be a separate validation step generated for each column.\n\nleft : float | int | Column\n\nThe lower bound of the range. This can be a single value or a single column name given in col(). The latter option allows for a column-to-column comparison for this bound. See the What Can Be Used in left= and right=? section for details on this.\n\nright : float | int | Column\n\nThe upper bound of the range. This can be a single value or a single column name given in col(). The latter option allows for a column-to-column comparison for this bound. See the What Can Be Used in left= and right=? section for details on this.\n\ninclusive : tuple[bool, bool] = (True, True)\n\nA tuple of two boolean values indicating whether the comparison should be inclusive. The position of the boolean values correspond to the left= and right= values, respectively. By default, both values are True.\n\nna_pass : bool = False\n\nShould any encountered None, NA, or Null values be considered as passing test units? By default, this is False. Set to True to pass test units with missing values.\n\npre : Callable | None = None\n\nAn optional preprocessing function or lambda to apply to the data table during interrogation. This function should take a table as input and return a modified table. Have a look at the Preprocessing section for more information on how to use this argument.\n\nsegments : SegmentSpec | None = None\n\nAn optional directive on segmentation, which serves to split a validation step into multiple (one step per segment). Can be a single column name, a tuple that specifies a column name and its corresponding values to segment on, or a combination of both (provided as a list). Read the Segmentation section for usage information.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nSet threshold failure levels for reporting and reacting to exceedences of the levels. The thresholds are set at the step level and will override any global thresholds set in Validate(thresholds=...). The default is None, which means that no thresholds will be set locally and global thresholds (if any) will take effect. Look at the Thresholds section for information on how to set threshold levels.\n\nactions : Actions | None = None\n\nOptional actions to take when the validation step(s) meets or exceeds any set threshold levels. If provided, the Actions class should be used to define the actions.\n\nbrief : str | bool | None = None\n\nAn optional brief description of the validation step that will be displayed in the reporting table. You can use the templating elements like \"{step}\" to insert the step number, or \"{auto}\" to include an automatically generated brief. If True the entire brief will be automatically generated. If None (the default) then there won’t be a brief.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.col_vals_outside.html#returns",
    "href": "reference/Validate.col_vals_outside.html#returns",
    "title": "Validate.col_vals_outside",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.col_vals_outside.html#what-can-be-used-in-left-and-right",
    "href": "reference/Validate.col_vals_outside.html#what-can-be-used-in-left-and-right",
    "title": "Validate.col_vals_outside",
    "section": "What Can Be Used in left= and right=?",
    "text": "What Can Be Used in left= and right=?\nThe left= and right= arguments both allow for a variety of input types. The most common are:\n\na single numeric value\na single date or datetime value\nA col() object that represents a column in the target table\n\nWhen supplying a number as the basis of comparison, keep in mind that all resolved columns must also be numeric. Should you have columns that are of the date or datetime types, you can supply a date or datetime value within left= and right=. There is flexibility in how you provide the date or datetime values for the bounds; they can be:\n\nstring-based dates or datetimes (e.g., \"2023-10-01\", \"2023-10-01 13:45:30\", etc.)\ndate or datetime objects using the datetime module (e.g., datetime.date(2023, 10, 1), datetime.datetime(2023, 10, 1, 13, 45, 30), etc.)\n\nFinally, when supplying a column name in either left= or right= (or both), it must be specified within col(). This facilitates column-to-column comparisons and, crucially, the columns being compared to either/both of the bounds must be of the same type as the column data (e.g., all numeric, all dates, etc.)."
  },
  {
    "objectID": "reference/Validate.col_vals_outside.html#preprocessing",
    "href": "reference/Validate.col_vals_outside.html#preprocessing",
    "title": "Validate.col_vals_outside",
    "section": "Preprocessing",
    "text": "Preprocessing\nThe pre= argument allows for a preprocessing function or lambda to be applied to the data table during interrogation. This function should take a table as input and return a modified table. This is useful for performing any necessary transformations or filtering on the data before the validation step is applied.\nThe preprocessing function can be any callable that takes a table as input and returns a modified table. For example, you could use a lambda function to filter the table based on certain criteria or to apply a transformation to the data. Note that you can refer to columns via columns= and left=col(...)/right=col(...) that are expected to be present in the transformed table, but may not exist in the table before preprocessing. Regarding the lifetime of the transformed table, it only exists during the validation step and is not stored in the Validate object or used in subsequent validation steps."
  },
  {
    "objectID": "reference/Validate.col_vals_outside.html#segmentation",
    "href": "reference/Validate.col_vals_outside.html#segmentation",
    "title": "Validate.col_vals_outside",
    "section": "Segmentation",
    "text": "Segmentation\nThe segments= argument allows for the segmentation of a validation step into multiple segments. This is useful for applying the same validation step to different subsets of the data. The segmentation can be done based on a single column or specific fields within a column.\nProviding a single column name will result in a separate validation step for each unique value in that column. For example, if you have a column called \"region\" with values \"North\", \"South\", and \"East\", the validation step will be applied separately to each region.\nAlternatively, you can provide a tuple that specifies a column name and its corresponding values to segment on. For example, if you have a column called \"date\" and you want to segment on only specific dates, you can provide a tuple like (\"date\", [\"2023-01-01\", \"2023-01-02\"]). Any other values in the column will be disregarded (i.e., no validation steps will be created for them).\nA list with a combination of column names and tuples can be provided as well. This allows for more complex segmentation scenarios. The following inputs are both valid:\n# Segments from all unique values in the `region` column\n# and specific dates in the `date` column\nsegments=[\"region\", (\"date\", [\"2023-01-01\", \"2023-01-02\"])]\n\n# Segments from all unique values in the `region` and `date` columns\nsegments=[\"region\", \"date\"]\nThe segmentation is performed during interrogation, and the resulting validation steps will be numbered sequentially. Each segment will have its own validation step, and the results will be reported separately. This allows for a more granular analysis of the data and helps identify issues within specific segments.\nImportantly, the segmentation process will be performed after any preprocessing of the data table. Because of this, one can conceivably use the pre= argument to generate a column that can be used for segmentation. For example, you could create a new column called \"segment\" through use of pre= and then use that column for segmentation."
  },
  {
    "objectID": "reference/Validate.col_vals_outside.html#thresholds",
    "href": "reference/Validate.col_vals_outside.html#thresholds",
    "title": "Validate.col_vals_outside",
    "section": "Thresholds",
    "text": "Thresholds\nThe thresholds= parameter is used to set the failure-condition levels for the validation step. If they are set here at the step level, these thresholds will override any thresholds set at the global level in Validate(thresholds=...).\nThere are three threshold levels: ‘warning’, ‘error’, and ‘critical’. The threshold values can either be set as a proportion failing of all test units (a value between 0 to 1), or, the absolute number of failing test units (as integer that’s 1 or greater).\nThresholds can be defined using one of these input schemes:\n\nuse the Thresholds class (the most direct way to create thresholds)\nprovide a tuple of 1-3 values, where position 0 is the ‘warning’ level, position 1 is the ‘error’ level, and position 2 is the ‘critical’ level\ncreate a dictionary of 1-3 value entries; the valid keys: are ‘warning’, ‘error’, and ‘critical’\na single integer/float value denoting absolute number or fraction of failing test units for the ‘warning’ level only\n\nIf the number of failing test units exceeds set thresholds, the validation step will be marked as ‘warning’, ‘error’, or ‘critical’. All of the threshold levels don’t need to be set, you’re free to set any combination of them.\nAside from reporting failure conditions, thresholds can be used to determine the actions to take for each level of failure (using the actions= parameter)."
  },
  {
    "objectID": "reference/Validate.col_vals_outside.html#examples",
    "href": "reference/Validate.col_vals_outside.html#examples",
    "title": "Validate.col_vals_outside",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with three numeric columns (a, b, and c). The table is shown below:\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [5, 6, 5, 7, 5, 5],\n        \"b\": [2, 3, 6, 4, 3, 6],\n        \"c\": [9, 8, 8, 9, 9, 7],\n    }\n)\n\npb.preview(tbl)\n\n\n\n\n\n  \n  \n  \n  \n\n\n\n\n\n  \n  aInt64\n  bInt64\n  cInt64\n\n\n\n  \n    1\n    5\n    2\n    9\n  \n  \n    2\n    6\n    3\n    8\n  \n  \n    3\n    5\n    6\n    8\n  \n  \n    4\n    7\n    4\n    9\n  \n  \n    5\n    5\n    3\n    9\n  \n  \n    6\n    5\n    6\n    7\n  \n\n\n\n\n\n\n        \n\n\nLet’s validate that values in column a are all outside the fixed boundary values of 1 and 4. We’ll determine if this validation had any failing test units (there are six test units, one for each row).\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_outside(columns=\"a\", left=1, right=4)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_outside\n    \n        \n            \n            \n                \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_outside()\n        \n        \n        \n    a\n    [1, 4]\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    61.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nPrinting the validation object shows the validation table in an HTML viewing environment. The validation table shows the single entry that corresponds to the validation step created by using col_vals_outside(). All test units passed, and there are no failing test units.\nAside from checking a column against two literal values representing the lower and upper bounds, we can also provide column names to the left= and/or right= arguments (by using the helper function col(). In this way, we can perform three additional comparison types:\n\nleft=column, right=column\nleft=literal, right=column\nleft=column, right=literal\n\nFor the next example, we’ll use col_vals_outside() to check whether the values in column b are outside of the range formed by the corresponding values in columns a (lower bound) and c (upper bound).\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_outside(columns=\"b\", left=pb.col(\"a\"), right=pb.col(\"c\"))\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_outside\n    \n        \n            \n            \n                \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_outside()\n        \n        \n        \n    b\n    [a, c]\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    40.67\n    20.33\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe validation table reports two failing test units. The specific failing cases are:\n\nRow 2: b is 6 and the bounds are 5 (a) and 8 (c).\nRow 5: b is 6 and the bounds are 5 (a) and 7 (c)."
  },
  {
    "objectID": "reference/Validate.row_count_match.html",
    "href": "reference/Validate.row_count_match.html",
    "title": "Validate.row_count_match",
    "section": "",
    "text": "Validate.row_count_match(\n    count,\n    tol=0,\n    inverse=False,\n    pre=None,\n    thresholds=None,\n    actions=None,\n    brief=None,\n    active=True,\n)\nValidate whether the row count of the table matches a specified count.\nThe row_count_match() method checks whether the row count of the target table matches a specified count. This validation will operate over a single test unit, which is whether the row count matches the specified count.\nWe also have the option to invert the validation step by setting inverse=True. This will make the expectation that the row count of the target table does not match the specified count."
  },
  {
    "objectID": "reference/Validate.row_count_match.html#parameters",
    "href": "reference/Validate.row_count_match.html#parameters",
    "title": "Validate.row_count_match",
    "section": "Parameters",
    "text": "Parameters\n\ncount : int | FrameT | Any\n\nThe expected row count of the table. This can be an integer value, a Polars or Pandas DataFrame object, or an Ibis backend table. If a DataFrame/table is provided, the row count of that object will be used as the expected count.\n\ntol : Tolerance = 0\n\nThe tolerance allowable for the row count match. This can be specified as a single numeric value (integer or float) or as a tuple of two integers representing the lower and upper bounds of the tolerance range. If a single integer value (greater than 1) is provided, it represents the absolute bounds of the tolerance, ie. plus or minus the value. If a float value (between 0-1) is provided, it represents the relative tolerance, ie. plus or minus the relative percentage of the target. If a tuple is provided, it represents the lower and upper absolute bounds of the tolerance range. See the examples for more.\n\ninverse : bool = False\n\nShould the validation step be inverted? If True, then the expectation is that the row count of the target table should not match the specified count= value.\n\npre : Callable | None = None\n\nAn optional preprocessing function or lambda to apply to the data table during interrogation. This function should take a table as input and return a modified table. Have a look at the Preprocessing section for more information on how to use this argument.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nSet threshold failure levels for reporting and reacting to exceedences of the levels. The thresholds are set at the step level and will override any global thresholds set in Validate(thresholds=...). The default is None, which means that no thresholds will be set locally and global thresholds (if any) will take effect. Look at the Thresholds section for information on how to set threshold levels.\n\nactions : Actions | None = None\n\nOptional actions to take when the validation step meets or exceeds any set threshold levels. If provided, the Actions class should be used to define the actions.\n\nbrief : str | bool | None = None\n\nAn optional brief description of the validation step that will be displayed in the reporting table. You can use the templating elements like \"{step}\" to insert the step number, or \"{auto}\" to include an automatically generated brief. If True the entire brief will be automatically generated. If None (the default) then there won’t be a brief.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.row_count_match.html#returns",
    "href": "reference/Validate.row_count_match.html#returns",
    "title": "Validate.row_count_match",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.row_count_match.html#preprocessing",
    "href": "reference/Validate.row_count_match.html#preprocessing",
    "title": "Validate.row_count_match",
    "section": "Preprocessing",
    "text": "Preprocessing\nThe pre= argument allows for a preprocessing function or lambda to be applied to the data table during interrogation. This function should take a table as input and return a modified table. This is useful for performing any necessary transformations or filtering on the data before the validation step is applied.\nThe preprocessing function can be any callable that takes a table as input and returns a modified table. For example, you could use a lambda function to filter the table based on certain criteria or to apply a transformation to the data. Regarding the lifetime of the transformed table, it only exists during the validation step and is not stored in the Validate object or used in subsequent validation steps."
  },
  {
    "objectID": "reference/Validate.row_count_match.html#thresholds",
    "href": "reference/Validate.row_count_match.html#thresholds",
    "title": "Validate.row_count_match",
    "section": "Thresholds",
    "text": "Thresholds\nThe thresholds= parameter is used to set the failure-condition levels for the validation step. If they are set here at the step level, these thresholds will override any thresholds set at the global level in Validate(thresholds=...).\nThere are three threshold levels: ‘warning’, ‘error’, and ‘critical’. The threshold values can either be set as a proportion failing of all test units (a value between 0 to 1), or, the absolute number of failing test units (as integer that’s 1 or greater).\nThresholds can be defined using one of these input schemes:\n\nuse the Thresholds class (the most direct way to create thresholds)\nprovide a tuple of 1-3 values, where position 0 is the ‘warning’ level, position 1 is the ‘error’ level, and position 2 is the ‘critical’ level\ncreate a dictionary of 1-3 value entries; the valid keys: are ‘warning’, ‘error’, and ‘critical’\na single integer/float value denoting absolute number or fraction of failing test units for the ‘warning’ level only\n\nIf the number of failing test units exceeds set thresholds, the validation step will be marked as ‘warning’, ‘error’, or ‘critical’. All of the threshold levels don’t need to be set, you’re free to set any combination of them.\nAside from reporting failure conditions, thresholds can be used to determine the actions to take for each level of failure (using the actions= parameter)."
  },
  {
    "objectID": "reference/Validate.row_count_match.html#examples",
    "href": "reference/Validate.row_count_match.html#examples",
    "title": "Validate.row_count_match",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use the built in dataset \"small_table\". The table can be obtained by calling load_dataset(\"small_table\").\n\nimport pointblank as pb\n\nsmall_table = pb.load_dataset(\"small_table\")\n\npb.preview(small_table)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows13Columns8\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05\n    6\n    8-kdg-938\n    3\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    None\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09\n    8\n    3-ldm-038\n    7\n    283.94\n    True\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26\n    4\n    2-dmx-010\n    7\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28\n    2\n    7-dmx-010\n    8\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30\n    1\n    3-dka-303\n    None\n    2230.09\n    True\n    high\n  \n\n\n\n\n\n\n        \n\n\nLet’s validate that the number of rows in the table matches a fixed value. In this case, we will use the value 13 as the expected row count.\n\nvalidation = (\n    pb.Validate(data=small_table)\n    .row_count_match(count=13)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    row_count_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            row_count_match()\n        \n        \n        \n    —\n    13\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe validation table shows that the expectation value of 13 matches the actual count of rows in the target table. So, the single test unit passed.\nLet’s modify our example to show the different ways we can allow some tolerance to our validation by using the tol argument.\n\nsmaller_small_table = small_table.sample(n = 12) # within the lower bound\nvalidation = (\n    pb.Validate(data=smaller_small_table)\n    .row_count_match(count=13,tol=(2, 0)) # minus 2 but plus 0, ie. 11-13\n    .interrogate()\n)\n\nvalidation\n\nvalidation = (\n    pb.Validate(data=smaller_small_table)\n    .row_count_match(count=13,tol=.05) # .05% tolerance of 13\n    .interrogate()\n)\n\neven_smaller_table = small_table.sample(n = 2)\nvalidation = (\n    pb.Validate(data=even_smaller_table)\n    .row_count_match(count=13,tol=5) # plus or minus 5; this test will fail\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    row_count_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            row_count_match()\n        \n        \n        \n    —\n    13\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    00.00\n    11.00\n    —\n    —\n    —\n    —"
  },
  {
    "objectID": "reference/Actions.html",
    "href": "reference/Actions.html",
    "title": "Actions",
    "section": "",
    "text": "Actions(\n    warning=None,\n    error=None,\n    critical=None,\n    default=None,\n    highest_only=True,\n)\nDefinition of action values.\nActions complement threshold values by defining what action should be taken when a threshold level is reached. The action can be a string or a Callable. When a string is used, it is interpreted as a message to be displayed. When a Callable is used, it will be invoked at interrogation time if the threshold level is met or exceeded.\nThere are three threshold levels: ‘warning’, ‘error’, and ‘critical’. These levels correspond to different levels of severity when a threshold is reached. Those thresholds can be defined using the Thresholds class or various shorthand forms. Actions don’t have to be defined for all threshold levels; if an action is not defined for a level in exceedance, no action will be taken. Likewise, there is no negative consequence (other than a no-op) for defining actions for thresholds that don’t exist (e.g., setting an action for the ‘critical’ level when no corresponding ‘critical’ threshold has been set)."
  },
  {
    "objectID": "reference/Actions.html#parameters",
    "href": "reference/Actions.html#parameters",
    "title": "Actions",
    "section": "Parameters",
    "text": "Parameters\n\nwarning : str | Callable | list[str | Callable] | None = None\n\nA string, Callable, or list of Callable/string values for the ‘warning’ level. Using None means no action should be performed at the ‘warning’ level.\n\nerror : str | Callable | list[str | Callable] | None = None\n\nA string, Callable, or list of Callable/string values for the ‘error’ level. Using None means no action should be performed at the ‘error’ level.\n\ncritical : str | Callable | list[str | Callable] | None = None\n\nA string, Callable, or list of Callable/string values for the ‘critical’ level. Using None means no action should be performed at the ‘critical’ level.\n\ndefault : str | Callable | list[str | Callable] | None = None\n\nA string, Callable, or list of Callable/string values for all threshold levels. This parameter can be used to set the same action for all threshold levels. If an action is defined for a specific threshold level, it will override the action set for all levels.\n\nhighest_only : bool = True\n\nA boolean value that, when set to True (the default), results in executing only the action for the highest threshold level that is exceeded. Useful when you want to ensure that only the most severe action is taken when multiple threshold levels are exceeded."
  },
  {
    "objectID": "reference/Actions.html#returns",
    "href": "reference/Actions.html#returns",
    "title": "Actions",
    "section": "Returns",
    "text": "Returns\n\n : Actions\n\nAn Actions object. This can be used when using the Validate class (to set actions for meeting different threshold levels globally) or when defining validation steps like col_vals_gt() (so that actions are scoped to individual validation steps, overriding any globally set actions)."
  },
  {
    "objectID": "reference/Actions.html#types-of-actions",
    "href": "reference/Actions.html#types-of-actions",
    "title": "Actions",
    "section": "Types of Actions",
    "text": "Types of Actions\nActions can be defined in different ways:\n\nString: A message to be displayed when the threshold level is met or exceeded.\nCallable: A function that is called when the threshold level is met or exceeded.\nList of Strings/Callables: Multiple messages or functions to be called when the threshold level is met or exceeded.\n\nThe actions are executed at interrogation time when the threshold level assigned to the action is exceeded by the number or proportion of failing test units. When providing a string, it will simply be printed to the console. A callable will also be executed at the time of interrogation. If providing a list of strings or callables, each item in the list will be executed in order. Such a list can contain a mix of strings and callables."
  },
  {
    "objectID": "reference/Actions.html#string-templating",
    "href": "reference/Actions.html#string-templating",
    "title": "Actions",
    "section": "String Templating",
    "text": "String Templating\nWhen using a string as an action, you can include placeholders for the following variables:\n\n{type}: The validation step type where the action is executed (e.g., ‘col_vals_gt’, ‘col_vals_lt’, etc.)\n{level}: The threshold level where the action is executed (‘warning’, ‘error’, or ‘critical’)\n{step} or {i}: The step number in the validation workflow where the action is executed\n{col} or {column}: The column name where the action is executed\n{val} or {value}: An associated value for the validation method (e.g., the value to compare against in a ‘col_vals_gt’ validation step)\n{time}: A datetime value for when the action was executed\n\nThe first two placeholders can also be used in uppercase (e.g., {TYPE} or {LEVEL}) and the corresponding values will be displayed in uppercase. The placeholders are replaced with the actual values during interrogation.\nFor example, the string \"{LEVEL}: '{type}' threshold exceeded for column {col}.\" will be displayed as \"WARNING: 'col_vals_gt' threshold exceeded for column a.\" when the ‘warning’ threshold is exceeded in a ‘col_vals_gt’ validation step involving column a."
  },
  {
    "objectID": "reference/Actions.html#crafting-callables-with-get_action_metadata",
    "href": "reference/Actions.html#crafting-callables-with-get_action_metadata",
    "title": "Actions",
    "section": "Crafting Callables with get_action_metadata()",
    "text": "Crafting Callables with get_action_metadata()\nWhen creating a callable function to be used as an action, you can use the get_action_metadata() function to retrieve metadata about the step where the action is executed. This metadata contains information about the validation step, including the step type, level, step number, column name, and associated value. You can use this information to craft your action message or to take specific actions based on the metadata provided."
  },
  {
    "objectID": "reference/Actions.html#examples",
    "href": "reference/Actions.html#examples",
    "title": "Actions",
    "section": "Examples",
    "text": "Examples\nLet’s define both threshold values and actions for a data validation workflow. We’ll set these thresholds and actions globally for all validation steps. In this specific example, the only actions we’ll define are for the ‘critical’ level:\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"duckdb\"),\n        thresholds=pb.Thresholds(warning=0.05, error=0.10, critical=0.15),\n        actions=pb.Actions(critical=\"Major data quality issue found in step {step}.\"),\n    )\n    .col_vals_regex(columns=\"player_id\", pattern=r\"[A-Z]{12}[0-9]{3}\")\n    .col_vals_gt(columns=\"item_revenue\", value=0.05)\n    .col_vals_gt(columns=\"session_duration\", value=15)\n    .interrogate()\n)\n\nvalidation\n\nMajor data quality issue found in step 3.\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:16:10DuckDBWARNING0.05ERROR0.1CRITICAL0.15\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    player_id\n    [A-Z]{12}[0-9]{3}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #EBBC14\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    item_revenue\n    0.05\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    17010.85\n    2990.15\n    ●\n    ●\n    ○\n    —\n  \n  \n    #FF3300\n    3\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    session_duration\n    15\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    16750.84\n    3250.16\n    ●\n    ●\n    ●\n    —\n  \n\n\n\n\n\n\n        \n\n\nBecause we set the ‘critical’ action to display \"Major data quality issue found.\" in the console, this message will be displayed if the number of failing test units exceeds the ‘critical’ threshold (set to 15% of the total number of test units). In step 3 of the validation workflow, the ‘critical’ threshold is exceeded, so the message is displayed in the console.\nActions can be defined locally for individual validation steps, which will override any global actions set at the beginning of the validation workflow. Here’s a variation of the above example where we set global threshold values but assign an action only for an individual validation step:\n\ndef dq_issue():\n    from datetime import datetime\n\n    print(f\"Data quality issue found ({datetime.now()}).\")\n\nvalidation = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"duckdb\"),\n        thresholds=pb.Thresholds(warning=0.05, error=0.10, critical=0.15),\n    )\n    .col_vals_regex(columns=\"player_id\", pattern=r\"[A-Z]{12}[0-9]{3}\")\n    .col_vals_gt(columns=\"item_revenue\", value=0.05)\n    .col_vals_gt(\n        columns=\"session_duration\",\n        value=15,\n        actions=pb.Actions(warning=dq_issue),\n    )\n    .interrogate()\n)\n\nvalidation\n\nData quality issue found (2025-11-23 00:16:11.424660).\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:16:11DuckDBWARNING0.05ERROR0.1CRITICAL0.15\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    player_id\n    [A-Z]{12}[0-9]{3}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #EBBC14\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    item_revenue\n    0.05\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    17010.85\n    2990.15\n    ●\n    ●\n    ○\n    —\n  \n  \n    #FF3300\n    3\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    session_duration\n    15\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    16750.84\n    3250.16\n    ●\n    ●\n    ●\n    —\n  \n\n\n\n\n\n\n        \n\n\nIn this case, the ‘warning’ action is set to call the dq_issue() function. This action is only executed when the ‘warning’ threshold is exceeded in the ‘session_duration’ column. Because all three thresholds are exceeded in step 3, the ‘warning’ action of executing the function occurs (resulting in a message being printed to the console). If actions were set for the other two threshold levels, they would also be executed."
  },
  {
    "objectID": "reference/Actions.html#see-also",
    "href": "reference/Actions.html#see-also",
    "title": "Actions",
    "section": "See Also",
    "text": "See Also\nThe get_action_metadata() function, which can be used to retrieve metadata about the step where the action is executed."
  },
  {
    "objectID": "reference/Validate.col_vals_ge.html",
    "href": "reference/Validate.col_vals_ge.html",
    "title": "Validate.col_vals_ge",
    "section": "",
    "text": "Validate.col_vals_ge(\n    columns,\n    value,\n    na_pass=False,\n    pre=None,\n    segments=None,\n    thresholds=None,\n    actions=None,\n    brief=None,\n    active=True,\n)\nAre column data greater than or equal to a fixed value or data in another column?\nThe col_vals_ge() validation method checks whether column values in a table are greater than or equal to a specified value= (the exact comparison used in this function is col_val &gt;= value). The value= can be specified as a single, literal value or as a column name given in col(). This validation will operate over the number of test units that is equal to the number of rows in the table (determined after any pre= mutation has been applied)."
  },
  {
    "objectID": "reference/Validate.col_vals_ge.html#parameters",
    "href": "reference/Validate.col_vals_ge.html#parameters",
    "title": "Validate.col_vals_ge",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns : str | list[str] | Column | ColumnSelector | ColumnSelectorNarwhals\n\nA single column or a list of columns to validate. Can also use col() with column selectors to specify one or more columns. If multiple columns are supplied or resolved, there will be a separate validation step generated for each column.\n\nvalue : float | int | Column\n\nThe value to compare against. This can be a single value or a single column name given in col(). The latter option allows for a column-to-column comparison. For more information on which types of values are allowed, see the What Can Be Used in value=? section.\n\nna_pass : bool = False\n\nShould any encountered None, NA, or Null values be considered as passing test units? By default, this is False. Set to True to pass test units with missing values.\n\npre : Callable | None = None\n\nAn optional preprocessing function or lambda to apply to the data table during interrogation. This function should take a table as input and return a modified table. Have a look at the Preprocessing section for more information on how to use this argument.\n\nsegments : SegmentSpec | None = None\n\nAn optional directive on segmentation, which serves to split a validation step into multiple (one step per segment). Can be a single column name, a tuple that specifies a column name and its corresponding values to segment on, or a combination of both (provided as a list). Read the Segmentation section for usage information.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nSet threshold failure levels for reporting and reacting to exceedences of the levels. The thresholds are set at the step level and will override any global thresholds set in Validate(thresholds=...). The default is None, which means that no thresholds will be set locally and global thresholds (if any) will take effect. Look at the Thresholds section for information on how to set threshold levels.\n\nactions : Actions | None = None\n\nOptional actions to take when the validation step(s) meets or exceeds any set threshold levels. If provided, the Actions class should be used to define the actions.\n\nbrief : str | bool | None = None\n\nAn optional brief description of the validation step that will be displayed in the reporting table. You can use the templating elements like \"{step}\" to insert the step number, or \"{auto}\" to include an automatically generated brief. If True the entire brief will be automatically generated. If None (the default) then there won’t be a brief.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.col_vals_ge.html#returns",
    "href": "reference/Validate.col_vals_ge.html#returns",
    "title": "Validate.col_vals_ge",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.col_vals_ge.html#what-can-be-used-in-value",
    "href": "reference/Validate.col_vals_ge.html#what-can-be-used-in-value",
    "title": "Validate.col_vals_ge",
    "section": "What Can Be Used in value=?",
    "text": "What Can Be Used in value=?\nThe value= argument allows for a variety of input types. The most common are:\n\na single numeric value\na single date or datetime value\nA col() object that represents a column name\n\nWhen supplying a number as the basis of comparison, keep in mind that all resolved columns must also be numeric. Should you have columns that are of the date or datetime types, you can supply a date or datetime value as the value= argument. There is flexibility in how you provide the date or datetime value, as it can be:\n\na string-based date or datetime (e.g., \"2023-10-01\", \"2023-10-01 13:45:30\", etc.)\na date or datetime object using the datetime module (e.g., datetime.date(2023, 10, 1), datetime.datetime(2023, 10, 1, 13, 45, 30), etc.)\n\nFinally, when supplying a column name in the value= argument, it must be specified within col(). This is a column-to-column comparison and, crucially, the columns being compared must be of the same type (e.g., both numeric, both date, etc.)."
  },
  {
    "objectID": "reference/Validate.col_vals_ge.html#preprocessing",
    "href": "reference/Validate.col_vals_ge.html#preprocessing",
    "title": "Validate.col_vals_ge",
    "section": "Preprocessing",
    "text": "Preprocessing\nThe pre= argument allows for a preprocessing function or lambda to be applied to the data table during interrogation. This function should take a table as input and return a modified table. This is useful for performing any necessary transformations or filtering on the data before the validation step is applied.\nThe preprocessing function can be any callable that takes a table as input and returns a modified table. For example, you could use a lambda function to filter the table based on certain criteria or to apply a transformation to the data. Note that you can refer to columns via columns= and value=col(...) that are expected to be present in the transformed table, but may not exist in the table before preprocessing. Regarding the lifetime of the transformed table, it only exists during the validation step and is not stored in the Validate object or used in subsequent validation steps."
  },
  {
    "objectID": "reference/Validate.col_vals_ge.html#segmentation",
    "href": "reference/Validate.col_vals_ge.html#segmentation",
    "title": "Validate.col_vals_ge",
    "section": "Segmentation",
    "text": "Segmentation\nThe segments= argument allows for the segmentation of a validation step into multiple segments. This is useful for applying the same validation step to different subsets of the data. The segmentation can be done based on a single column or specific fields within a column.\nProviding a single column name will result in a separate validation step for each unique value in that column. For example, if you have a column called \"region\" with values \"North\", \"South\", and \"East\", the validation step will be applied separately to each region.\nAlternatively, you can provide a tuple that specifies a column name and its corresponding values to segment on. For example, if you have a column called \"date\" and you want to segment on only specific dates, you can provide a tuple like (\"date\", [\"2023-01-01\", \"2023-01-02\"]). Any other values in the column will be disregarded (i.e., no validation steps will be created for them).\nA list with a combination of column names and tuples can be provided as well. This allows for more complex segmentation scenarios. The following inputs are both valid:\n# Segments from all unique values in the `region` column\n# and specific dates in the `date` column\nsegments=[\"region\", (\"date\", [\"2023-01-01\", \"2023-01-02\"])]\n\n# Segments from all unique values in the `region` and `date` columns\nsegments=[\"region\", \"date\"]\nThe segmentation is performed during interrogation, and the resulting validation steps will be numbered sequentially. Each segment will have its own validation step, and the results will be reported separately. This allows for a more granular analysis of the data and helps identify issues within specific segments.\nImportantly, the segmentation process will be performed after any preprocessing of the data table. Because of this, one can conceivably use the pre= argument to generate a column that can be used for segmentation. For example, you could create a new column called \"segment\" through use of pre= and then use that column for segmentation."
  },
  {
    "objectID": "reference/Validate.col_vals_ge.html#thresholds",
    "href": "reference/Validate.col_vals_ge.html#thresholds",
    "title": "Validate.col_vals_ge",
    "section": "Thresholds",
    "text": "Thresholds\nThe thresholds= parameter is used to set the failure-condition levels for the validation step. If they are set here at the step level, these thresholds will override any thresholds set at the global level in Validate(thresholds=...).\nThere are three threshold levels: ‘warning’, ‘error’, and ‘critical’. The threshold values can either be set as a proportion failing of all test units (a value between 0 to 1), or, the absolute number of failing test units (as integer that’s 1 or greater).\nThresholds can be defined using one of these input schemes:\n\nuse the Thresholds class (the most direct way to create thresholds)\nprovide a tuple of 1-3 values, where position 0 is the ‘warning’ level, position 1 is the ‘error’ level, and position 2 is the ‘critical’ level\ncreate a dictionary of 1-3 value entries; the valid keys: are ‘warning’, ‘error’, and ‘critical’\na single integer/float value denoting absolute number or fraction of failing test units for the ‘warning’ level only\n\nIf the number of failing test units exceeds set thresholds, the validation step will be marked as ‘warning’, ‘error’, or ‘critical’. All of the threshold levels don’t need to be set, you’re free to set any combination of them.\nAside from reporting failure conditions, thresholds can be used to determine the actions to take for each level of failure (using the actions= parameter)."
  },
  {
    "objectID": "reference/Validate.col_vals_ge.html#examples",
    "href": "reference/Validate.col_vals_ge.html#examples",
    "title": "Validate.col_vals_ge",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with three numeric columns (a, b, and c). The table is shown below:\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [5, 6, 5, 9, 7, 5],\n        \"b\": [5, 3, 1, 8, 2, 3],\n        \"c\": [2, 3, 1, 4, 3, 4],\n    }\n)\n\npb.preview(tbl)\n\n\n\n\n\n  \n  \n  \n  \n\n\n\n\n\n  \n  aInt64\n  bInt64\n  cInt64\n\n\n\n  \n    1\n    5\n    5\n    2\n  \n  \n    2\n    6\n    3\n    3\n  \n  \n    3\n    5\n    1\n    1\n  \n  \n    4\n    9\n    8\n    4\n  \n  \n    5\n    7\n    2\n    3\n  \n  \n    6\n    5\n    3\n    4\n  \n\n\n\n\n\n\n        \n\n\nLet’s validate that values in column a are all greater than or equal to the value of 5. We’ll determine if this validation had any failing test units (there are six test units, one for each row).\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_ge(columns=\"a\", value=5)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_ge\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_ge()\n        \n        \n        \n    a\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    61.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nPrinting the validation object shows the validation table in an HTML viewing environment. The validation table shows the single entry that corresponds to the validation step created by using col_vals_ge(). All test units passed, and there are no failing test units.\nAside from checking a column against a literal value, we can also use a column name in the value= argument (with the helper function col() to perform a column-to-column comparison. For the next example, we’ll use col_vals_ge() to check whether the values in column b are greater than values in column c.\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_ge(columns=\"b\", value=pb.col(\"c\"))\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_ge\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_ge()\n        \n        \n        \n    b\n    c\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    40.67\n    20.33\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe validation table reports two failing test units. The specific failing cases are:\n\nRow 0: b is 2 and c is 3.\nRow 4: b is 3 and c is 4."
  },
  {
    "objectID": "reference/Validate.col_vals_le.html",
    "href": "reference/Validate.col_vals_le.html",
    "title": "Validate.col_vals_le",
    "section": "",
    "text": "Validate.col_vals_le(\n    columns,\n    value,\n    na_pass=False,\n    pre=None,\n    segments=None,\n    thresholds=None,\n    actions=None,\n    brief=None,\n    active=True,\n)\nAre column data less than or equal to a fixed value or data in another column?\nThe col_vals_le() validation method checks whether column values in a table are less than or equal to a specified value= (the exact comparison used in this function is col_val &lt;= value). The value= can be specified as a single, literal value or as a column name given in col(). This validation will operate over the number of test units that is equal to the number of rows in the table (determined after any pre= mutation has been applied)."
  },
  {
    "objectID": "reference/Validate.col_vals_le.html#parameters",
    "href": "reference/Validate.col_vals_le.html#parameters",
    "title": "Validate.col_vals_le",
    "section": "Parameters",
    "text": "Parameters\n\ncolumns : str | list[str] | Column | ColumnSelector | ColumnSelectorNarwhals\n\nA single column or a list of columns to validate. Can also use col() with column selectors to specify one or more columns. If multiple columns are supplied or resolved, there will be a separate validation step generated for each column.\n\nvalue : float | int | Column\n\nThe value to compare against. This can be a single value or a single column name given in col(). The latter option allows for a column-to-column comparison. For more information on which types of values are allowed, see the What Can Be Used in value=? section.\n\nna_pass : bool = False\n\nShould any encountered None, NA, or Null values be considered as passing test units? By default, this is False. Set to True to pass test units with missing values.\n\npre : Callable | None = None\n\nAn optional preprocessing function or lambda to apply to the data table during interrogation. This function should take a table as input and return a modified table. Have a look at the Preprocessing section for more information on how to use this argument.\n\nsegments : SegmentSpec | None = None\n\nAn optional directive on segmentation, which serves to split a validation step into multiple (one step per segment). Can be a single column name, a tuple that specifies a column name and its corresponding values to segment on, or a combination of both (provided as a list). Read the Segmentation section for usage information.\n\nthresholds : int | float | bool | tuple | dict | Thresholds = None\n\nSet threshold failure levels for reporting and reacting to exceedences of the levels. The thresholds are set at the step level and will override any global thresholds set in Validate(thresholds=...). The default is None, which means that no thresholds will be set locally and global thresholds (if any) will take effect. Look at the Thresholds section for information on how to set threshold levels.\n\nactions : Actions | None = None\n\nOptional actions to take when the validation step(s) meets or exceeds any set threshold levels. If provided, the Actions class should be used to define the actions.\n\nbrief : str | bool | None = None\n\nAn optional brief description of the validation step that will be displayed in the reporting table. You can use the templating elements like \"{step}\" to insert the step number, or \"{auto}\" to include an automatically generated brief. If True the entire brief will be automatically generated. If None (the default) then there won’t be a brief.\n\nactive : bool = True\n\nA boolean value indicating whether the validation step should be active. Using False will make the validation step inactive (still reporting its presence and keeping indexes for the steps unchanged)."
  },
  {
    "objectID": "reference/Validate.col_vals_le.html#returns",
    "href": "reference/Validate.col_vals_le.html#returns",
    "title": "Validate.col_vals_le",
    "section": "Returns",
    "text": "Returns\n\n : Validate\n\nThe Validate object with the added validation step."
  },
  {
    "objectID": "reference/Validate.col_vals_le.html#what-can-be-used-in-value",
    "href": "reference/Validate.col_vals_le.html#what-can-be-used-in-value",
    "title": "Validate.col_vals_le",
    "section": "What Can Be Used in value=?",
    "text": "What Can Be Used in value=?\nThe value= argument allows for a variety of input types. The most common are:\n\na single numeric value\na single date or datetime value\nA col() object that represents a column name\n\nWhen supplying a number as the basis of comparison, keep in mind that all resolved columns must also be numeric. Should you have columns that are of the date or datetime types, you can supply a date or datetime value as the value= argument. There is flexibility in how you provide the date or datetime value, as it can be:\n\na string-based date or datetime (e.g., \"2023-10-01\", \"2023-10-01 13:45:30\", etc.)\na date or datetime object using the datetime module (e.g., datetime.date(2023, 10, 1), datetime.datetime(2023, 10, 1, 13, 45, 30), etc.)\n\nFinally, when supplying a column name in the value= argument, it must be specified within col(). This is a column-to-column comparison and, crucially, the columns being compared must be of the same type (e.g., both numeric, both date, etc.)."
  },
  {
    "objectID": "reference/Validate.col_vals_le.html#preprocessing",
    "href": "reference/Validate.col_vals_le.html#preprocessing",
    "title": "Validate.col_vals_le",
    "section": "Preprocessing",
    "text": "Preprocessing\nThe pre= argument allows for a preprocessing function or lambda to be applied to the data table during interrogation. This function should take a table as input and return a modified table. This is useful for performing any necessary transformations or filtering on the data before the validation step is applied.\nThe preprocessing function can be any callable that takes a table as input and returns a modified table. For example, you could use a lambda function to filter the table based on certain criteria or to apply a transformation to the data. Note that you can refer to columns via columns= and value=col(...) that are expected to be present in the transformed table, but may not exist in the table before preprocessing. Regarding the lifetime of the transformed table, it only exists during the validation step and is not stored in the Validate object or used in subsequent validation steps."
  },
  {
    "objectID": "reference/Validate.col_vals_le.html#segmentation",
    "href": "reference/Validate.col_vals_le.html#segmentation",
    "title": "Validate.col_vals_le",
    "section": "Segmentation",
    "text": "Segmentation\nThe segments= argument allows for the segmentation of a validation step into multiple segments. This is useful for applying the same validation step to different subsets of the data. The segmentation can be done based on a single column or specific fields within a column.\nProviding a single column name will result in a separate validation step for each unique value in that column. For example, if you have a column called \"region\" with values \"North\", \"South\", and \"East\", the validation step will be applied separately to each region.\nAlternatively, you can provide a tuple that specifies a column name and its corresponding values to segment on. For example, if you have a column called \"date\" and you want to segment on only specific dates, you can provide a tuple like (\"date\", [\"2023-01-01\", \"2023-01-02\"]). Any other values in the column will be disregarded (i.e., no validation steps will be created for them).\nA list with a combination of column names and tuples can be provided as well. This allows for more complex segmentation scenarios. The following inputs are both valid:\n# Segments from all unique values in the `region` column\n# and specific dates in the `date` column\nsegments=[\"region\", (\"date\", [\"2023-01-01\", \"2023-01-02\"])]\n\n# Segments from all unique values in the `region` and `date` columns\nsegments=[\"region\", \"date\"]\nThe segmentation is performed during interrogation, and the resulting validation steps will be numbered sequentially. Each segment will have its own validation step, and the results will be reported separately. This allows for a more granular analysis of the data and helps identify issues within specific segments.\nImportantly, the segmentation process will be performed after any preprocessing of the data table. Because of this, one can conceivably use the pre= argument to generate a column that can be used for segmentation. For example, you could create a new column called \"segment\" through use of pre= and then use that column for segmentation."
  },
  {
    "objectID": "reference/Validate.col_vals_le.html#thresholds",
    "href": "reference/Validate.col_vals_le.html#thresholds",
    "title": "Validate.col_vals_le",
    "section": "Thresholds",
    "text": "Thresholds\nThe thresholds= parameter is used to set the failure-condition levels for the validation step. If they are set here at the step level, these thresholds will override any thresholds set at the global level in Validate(thresholds=...).\nThere are three threshold levels: ‘warning’, ‘error’, and ‘critical’. The threshold values can either be set as a proportion failing of all test units (a value between 0 to 1), or, the absolute number of failing test units (as integer that’s 1 or greater).\nThresholds can be defined using one of these input schemes:\n\nuse the Thresholds class (the most direct way to create thresholds)\nprovide a tuple of 1-3 values, where position 0 is the ‘warning’ level, position 1 is the ‘error’ level, and position 2 is the ‘critical’ level\ncreate a dictionary of 1-3 value entries; the valid keys: are ‘warning’, ‘error’, and ‘critical’\na single integer/float value denoting absolute number or fraction of failing test units for the ‘warning’ level only\n\nIf the number of failing test units exceeds set thresholds, the validation step will be marked as ‘warning’, ‘error’, or ‘critical’. All of the threshold levels don’t need to be set, you’re free to set any combination of them.\nAside from reporting failure conditions, thresholds can be used to determine the actions to take for each level of failure (using the actions= parameter)."
  },
  {
    "objectID": "reference/Validate.col_vals_le.html#examples",
    "href": "reference/Validate.col_vals_le.html#examples",
    "title": "Validate.col_vals_le",
    "section": "Examples",
    "text": "Examples\nFor the examples here, we’ll use a simple Polars DataFrame with three numeric columns (a, b, and c). The table is shown below:\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [5, 6, 5, 9, 7, 5],\n        \"b\": [1, 3, 1, 5, 2, 5],\n        \"c\": [2, 1, 1, 4, 3, 4],\n    }\n)\n\npb.preview(tbl)\n\n\n\n\n\n  \n  \n  \n  \n\n\n\n\n\n  \n  aInt64\n  bInt64\n  cInt64\n\n\n\n  \n    1\n    5\n    1\n    2\n  \n  \n    2\n    6\n    3\n    1\n  \n  \n    3\n    5\n    1\n    1\n  \n  \n    4\n    9\n    5\n    4\n  \n  \n    5\n    7\n    2\n    3\n  \n  \n    6\n    5\n    5\n    4\n  \n\n\n\n\n\n\n        \n\n\nLet’s validate that values in column a are all less than or equal to the value of 9. We’ll determine if this validation had any failing test units (there are six test units, one for each row).\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_le(columns=\"a\", value=9)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_le\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_le()\n        \n        \n        \n    a\n    9\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    61.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nPrinting the validation object shows the validation table in an HTML viewing environment. The validation table shows the single entry that corresponds to the validation step created by using col_vals_le(). All test units passed, and there are no failing test units.\nAside from checking a column against a literal value, we can also use a column name in the value= argument (with the helper function col() to perform a column-to-column comparison. For the next example, we’ll use col_vals_le() to check whether the values in column c are less than values in column b.\n\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_vals_le(columns=\"c\", value=pb.col(\"b\"))\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_le\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_le()\n        \n        \n        \n    c\n    b\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    40.67\n    20.33\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe validation table reports two failing test units. The specific failing cases are:\n\nRow 0: c is 2 and b is 1.\nRow 4: c is 3 and b is 2."
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Pointblank",
    "section": "",
    "text": "Order By\n      Default\n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Title\n      \n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\n\nTitle\n\n\n\nAuthor\n\n\n\n\n\n\n\n\nJun 4, 2025\n\n\nData Validation Libraries for Polars (2025 Edition)\n\n\nRich Iannone\n\n\n\n\n\n\nJun 3, 2025\n\n\nC’mon C’mon: Let’s Do a Pointblank Workshop!\n\n\nRich Iannone\n\n\n\n\n\n\nMay 20, 2025\n\n\nOverhauling Pointblank’s User Guide\n\n\nRich Iannone and Michael Chow\n\n\n\n\n\n\nMay 2, 2025\n\n\nLevel Up Your Data Validation with Actions and FinalActions\n\n\nRich Iannone\n\n\n\n\n\n\nApr 4, 2025\n\n\nIntroducing Pointblank\n\n\nRich Iannone\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/overhauled-user-guide/index.html",
    "href": "blog/overhauled-user-guide/index.html",
    "title": "Overhauling Pointblank’s User Guide",
    "section": "",
    "text": "The Pointblank documentation just got a major upgrade! We’ve completely overhauled our User Guide. Our goal was to enable readers to start fast on validation and work through the many pieces needed in realistic situations.\nWe realized that at the core of Pointblank is the validation plan. Its made up of rules, results, and steps.\nFor example, the first row is a step that checks whether values in column ‘a’ are less than 10. The COLUMNS and VALUES column contain the rules used to configure the step. The PASS column for the first row indicates that all 13 values in the column passed.\nIn this post, we’ll cover:\nLet us walk you through the key improvements in our refreshed User Guide!"
  },
  {
    "objectID": "blog/overhauled-user-guide/index.html#introduction-embracing-the-spiral-sequence",
    "href": "blog/overhauled-user-guide/index.html#introduction-embracing-the-spiral-sequence",
    "title": "Overhauling Pointblank’s User Guide",
    "section": "Introduction: Embracing the Spiral Sequence",
    "text": "Introduction: Embracing the Spiral Sequence\nWe chose to use a spiral sequence for our Introduction and Validation Plan section. The Introduction quickly covers parts of validation plan, while each article of the Validation Plan section dives deeper into different aspects of defining validation rules.\n\n\n\nThe introduction does a broad pass on the validation plan table diagram, identifying the core pieces of the output and then giving a quick overview of the code that produced it. This sets people up for the Validation Plan section in the guide, where each concept is discussed in depth."
  },
  {
    "objectID": "blog/overhauled-user-guide/index.html#improving-examples",
    "href": "blog/overhauled-user-guide/index.html#improving-examples",
    "title": "Overhauling Pointblank’s User Guide",
    "section": "Improving Examples",
    "text": "Improving Examples\nExamples are everywhere in the User Guide. We’ve tightened up our approach to examples by:\n\npresenting example code, output, or both, early in each section\nshowing the actual output you’ll see in your environment\nfollowing up with explanatory text that guides attention to specific places in the output\n\nThis approach makes learning more intuitive. Here’s an excerpt that shows this in practice.\n\nThe blue arrow marks the flow of reading and the red arrows map where we anticipate people will look from the text to the output. Focusing explicitly on where we think attention will go forces us to think carefully about exactly what readers will get from the output. The hope is that readers get to work more quickly on new concepts."
  },
  {
    "objectID": "blog/overhauled-user-guide/index.html#rounding-out-api-coverage",
    "href": "blog/overhauled-user-guide/index.html#rounding-out-api-coverage",
    "title": "Overhauling Pointblank’s User Guide",
    "section": "Rounding Out API Coverage",
    "text": "Rounding Out API Coverage\nDocumentation has to balance jobs between a user guide and an API Reference:\n\nUser Guide: explains concepts that cut across functions (like common arguments across validation methods)\nAPI Reference: explains each individual function\n\nImportantly, user guides often link to the API reference so, as part of this work, we made sure that all individual API entries are well-documented and linked to from the guide. Here’s an excerpt from the User Guide that shows links marked:"
  },
  {
    "objectID": "blog/overhauled-user-guide/index.html#surfacing-advanced-topics",
    "href": "blog/overhauled-user-guide/index.html#surfacing-advanced-topics",
    "title": "Overhauling Pointblank’s User Guide",
    "section": "Surfacing Advanced Topics",
    "text": "Surfacing Advanced Topics\nThere’s a lot of potential slicing and dicing involved in validation, as well as work after validation (post interrogation) to make sense of the results. We added pages to the User Guide for some core situations. In this section, I’ll highlight two advanced topics we added pages for:\n\nsegmentation: splitting a column into groups, and validating each group\nstep reports: view failing cases (e.g., view rows of data that failed validation)\n\nThese are marked in the User Guide sidebar screenshot below:\n\n\n\n\nSegmentation\nHere’s a screenshot of a validation report with two validation steps, one for each segment (\"low\" and \"high\") in the f column of the small_table dataset.\n\nNotice that segments split columns into groups and apply the same validation to each of the groups. Each group is given its own step.\nEach of the 20+ validation methods accept a segment= argument. The value of the Segmentation article in the User Guide is to describe this cross-cutting behavior in a single place.\nCompare the segments= parameter in the API Reference (e.g., look at col_vals_gt()) and the Segmentation article to get a feel for how each location documents the segments feature.\n\n\nStep Report\nStep reports display failing cases (e.g., rows) for a validation step, so you can dig deeper into validation failures. Here’s a screenshot of a step report for some validation step 2:\n\nNotice the arrow pointing to ‘Step 2’ in the title. Failing values are highlighted in red. Once we know we have failures, it’s important to take action and discover why data is failing. Looking at failing cases in step reports often uncovers obvious causes behind failures.\nThe get_step_report() entry is one of 50 in the API Reference. Here it is listed the API Reference, in the Interrogation and Reporting section. Critically, it’s only one of 20 entries in the User Guide, which emphasizes its importance in validation workflows."
  },
  {
    "objectID": "blog/overhauled-user-guide/index.html#looking-forward",
    "href": "blog/overhauled-user-guide/index.html#looking-forward",
    "title": "Overhauling Pointblank’s User Guide",
    "section": "Looking Forward",
    "text": "Looking Forward\nThe refreshed User Guide is just the beginning of our documentation improvements. We’re committed to continuously enhancing our documentation to support your data validation needs.\nMichael Chow gave feedback on this User Guide in preparation for his upcoming talk at SciPy 2025.\nWe’d love to hear your feedback on the new User Guide! Feel free to open an issue on our GitHub repository with suggestions, corrections, or requests for additional topics you’d like to see covered. You can also join our community discussions in the dedicated #Documentation channel on our Discord server, where you can share ideas, ask questions, and get help directly from the Pointblank team and other users."
  },
  {
    "objectID": "blog/lets-workshop-together/index.html",
    "href": "blog/lets-workshop-together/index.html",
    "title": "C’mon C’mon: Let’s Do a Pointblank Workshop!",
    "section": "",
    "text": "Recently, I’ve been giving free workshops to data teams on Pointblank. These sorts of engagements energize me, and I truly enjoy hearing what people are concerned with when it comes to data validation. If your team is interested, I would love to schedule something with y’all! Please reach out at rich@posit.co or message me on the (Pointblank Discord).\nWorkshops have been especially helpful for understanding how people use and share Pointblank’s validation results table. For example, I learned that people like to email or pull up the table for stakeholders so they can walk through problem cases (it’s a great conversation starter for getting to the heart of data quality issues).\nA couple of months ago, I gave a workshop to one of Apple’s data teams. During the Q&A afterwards, someone asked whether you can perform the same validation on different chunks of table rows. This was a very helpful nudge for me to add a segments= argument to all of Pointblank’s validation methods!\nWe are excited about how things are going with the Pointblank project and are always up for providing a workshop to your data team (at no cost). If this sounds interesting to you please feel free to contact me through email or via Discord. Don’t be shy. Just know that if you have a need for data validation, we’re here to help!"
  },
  {
    "objectID": "blog/lets-workshop-together/index.html#acknowledgment",
    "href": "blog/lets-workshop-together/index.html#acknowledgment",
    "title": "C’mon C’mon: Let’s Do a Pointblank Workshop!",
    "section": "Acknowledgment",
    "text": "Acknowledgment\nI’d like to give special thanks to Rami Krispin for his interest in Pointblank and for facilitating a recent workshop. If you’re interested in more data science insights, check out Rami’s Data Newsletter where he shares valuable perspectives on data engineering, LLMs, and analytics."
  },
  {
    "objectID": "user-guide/draft-validation.html",
    "href": "user-guide/draft-validation.html",
    "title": "Draft Validation",
    "section": "",
    "text": "Draft validation in Pointblank leverages large language models (LLMs) to automatically generate validation plans for your data. This feature is especially useful when starting validation on a new dataset or when you need to quickly establish baseline validation coverage.\nThe DraftValidation class connects to various LLM providers to analyze your data’s characteristics and generate a complete validation plan tailored to its structure and content.",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Draft Validation"
    ]
  },
  {
    "objectID": "user-guide/draft-validation.html#how-draftvalidation-works",
    "href": "user-guide/draft-validation.html#how-draftvalidation-works",
    "title": "Draft Validation",
    "section": "How DraftValidation Works",
    "text": "How DraftValidation Works\nWhen you use DraftValidation, the process works through these steps:\n\na statistical summary of your data is generated using the DataScan class\nthis summary is converted to JSON format and sent to your selected LLM provider\nthe LLM uses the summary along with knowledge about Pointblank’s validation capabilities to generate a validation plan\nthe result is returned as executable Python code that you can use directly or modify as needed\n\nThe entire process happens without sending all of the data to the LLM provider, but only a summary that includes column names, data types, basic statistics, and a small sample of values.",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Draft Validation"
    ]
  },
  {
    "objectID": "user-guide/draft-validation.html#requirements-and-setup",
    "href": "user-guide/draft-validation.html#requirements-and-setup",
    "title": "Draft Validation",
    "section": "Requirements and Setup",
    "text": "Requirements and Setup\nTo use the DraftValidation feature, you’ll need:\n\nan API key from a supported LLM provider\nthe required Python packages installed\n\nYou can install all necessary dependencies with:\npip install pointblank[generate]\nThis will install the chatlas package and other dependencies required for DraftValidation.\n\nSupported LLM Providers\nThe DraftValidation class supports multiple LLM providers:\n\nAnthropic (Claude models)\nOpenAI (GPT models)\nOllama (local LLMs)\nAmazon Bedrock (AWS-hosted models)\n\nEach provider has different capabilities and performance characteristics, but all can be used to generate validation plans through a consistent interface.",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Draft Validation"
    ]
  },
  {
    "objectID": "user-guide/draft-validation.html#basic-usage",
    "href": "user-guide/draft-validation.html#basic-usage",
    "title": "Draft Validation",
    "section": "Basic Usage",
    "text": "Basic Usage\nThe simplest way to use DraftValidation is to provide your data and specify an LLM model. Let’s try it out with the global_sales dataset.\nimport pointblank as pb\n\n# Load a dataset\ndata = pb.load_dataset(dataset=\"global_sales\", tbl_type=\"polars\")\n\n# Generate a validation plan\npb.DraftValidation(\n    data=data,\n    model=\"anthropic:claude-sonnet-4-5\",\n    api_key=\"your_api_key_here\"  # Replace with your actual API key\n)\n```python\nimport pointblank as pb\n\n# Define schema based on column names and dtypes\nschema = pb.Schema(columns=[\n    (\"product_id\", \"String\"),\n    (\"product_category\", \"String\"),\n    (\"customer_id\", \"String\"),\n    (\"customer_segment\", \"String\"),\n    (\"region\", \"String\"),\n    (\"country\", \"String\"),\n    (\"city\", \"String\"),\n    (\"timestamp\", \"Datetime(time_unit='us', time_zone=None)\"),\n    (\"quarter\", \"String\"),\n    (\"month\", \"Int64\"),\n    (\"year\", \"Int64\"),\n    (\"price\", \"Float64\"),\n    (\"quantity\", \"Int64\"),\n    (\"status\", \"String\"),\n    (\"email\", \"String\"),\n    (\"revenue\", \"Float64\"),\n    (\"tax\", \"Float64\"),\n    (\"total\", \"Float64\"),\n    (\"payment_method\", \"String\"),\n    (\"sales_channel\", \"String\")\n])\n\n# The validation plan\nvalidation = (\n    pb.Validate(\n        data=your_data,  # Replace your_data with the actual data variable\n        label=\"Draft Validation\",\n        thresholds=pb.Thresholds(warning=0.10, error=0.25, critical=0.35)\n    )\n    .col_schema_match(schema=schema)\n    .col_vals_not_null(columns=[\n        \"product_category\", \"customer_segment\", \"region\", \"country\",\n        \"price\", \"quantity\", \"status\", \"email\", \"revenue\", \"tax\",\n        \"total\", \"payment_method\", \"sales_channel\"\n    ])\n    .col_vals_between(columns=\"month\", left=1, right=12, na_pass=True)\n    .col_vals_between(columns=\"year\", left=2021, right=2023, na_pass=True)\n    .col_vals_gt(columns=\"price\", value=0)\n    .col_vals_gt(columns=\"quantity\", value=0)\n    .col_vals_gt(columns=\"revenue\", value=0)\n    .col_vals_gt(columns=\"tax\", value=0)\n    .col_vals_gt(columns=\"total\", value=0)\n    .col_vals_in_set(columns=\"product_category\", set=[\n        \"Manufacturing\", \"Retail\", \"Healthcare\"\n    ])\n    .col_vals_in_set(columns=\"customer_segment\", set=[\n        \"Government\", \"Consumer\", \"SMB\"\n    ])\n    .col_vals_in_set(columns=\"region\", set=[\n        \"Asia Pacific\", \"Europe\", \"North America\"\n    ])\n    .col_vals_in_set(columns=\"status\", set=[\n        \"returned\", \"shipped\", \"delivered\"\n    ])\n    .col_vals_in_set(columns=\"payment_method\", set=[\n        \"Apple Pay\", \"PayPal\", \"Bank Transfer\", \"Credit Card\"\n    ])\n    .col_vals_in_set(columns=\"sales_channel\", set=[\n        \"Partner\", \"Distributor\", \"Phone\"\n    ])\n    .row_count_match(count=50000)\n    .col_count_match(count=20)\n    .rows_distinct()\n    .interrogate()\n)\n\nvalidation\n```\n\nManaging API Keys\nWhile you can directly provide API keys as shown above, there are more secure approaches:\nimport os\n\n# Get API key from environment variable\napi_key = os.getenv(\"ANTHROPIC_API_KEY\")\n\ndraft_validation = pb.DraftValidation(\n    data=data,\n    model=\"anthropic:claude-sonnet-4-5\",\n    api_key=api_key\n)\nYou can also store API keys in a .env file in your project’s root directory:\n# Contents of .env file\nANTHROPIC_API_KEY=your_anthropic_api_key_here\nOPENAI_API_KEY=your_openai_api_key_here\nIf your API keys have standard names (like ANTHROPIC_API_KEY or OPENAI_API_KEY), DraftValidation will automatically find and use them:\n# No API key needed if stored in .env with standard names\ndraft_validation = pb.DraftValidation(\n    data=data,\n    model=\"anthropic:claude-sonnet-4-5\"\n)",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Draft Validation"
    ]
  },
  {
    "objectID": "user-guide/draft-validation.html#example-output-for-nycflights",
    "href": "user-guide/draft-validation.html#example-output-for-nycflights",
    "title": "Draft Validation",
    "section": "Example Output for nycflights",
    "text": "Example Output for nycflights\nHere’s an example of a validation plan that might be generated by DraftValidation for the nycflights dataset:\npb.DraftValidation(\n    pb.load_dataset(dataset=\"nycflights\", tbl_type=\"duckdb\",\n    model=\"anthropic:claude-sonnet-4-5\"\n)\n```python\nimport pointblank as pb\n\n# Define schema based on column names and dtypes\nschema = pb.Schema(columns=[\n    (\"year\", \"int64\"),\n    (\"month\", \"int64\"),\n    (\"day\", \"int64\"),\n    (\"dep_time\", \"int64\"),\n    (\"sched_dep_time\", \"int64\"),\n    (\"dep_delay\", \"int64\"),\n    (\"arr_time\", \"int64\"),\n    (\"sched_arr_time\", \"int64\"),\n    (\"arr_delay\", \"int64\"),\n    (\"carrier\", \"string\"),\n    (\"flight\", \"int64\"),\n    (\"tailnum\", \"string\"),\n    (\"origin\", \"string\"),\n    (\"dest\", \"string\"),\n    (\"air_time\", \"int64\"),\n    (\"distance\", \"int64\"),\n    (\"hour\", \"int64\"),\n    (\"minute\", \"int64\")\n])\n\n# The validation plan\nvalidation = (\n    pb.Validate(\n        data=your_data,  # Replace your_data with the actual data variable\n        label=\"Draft Validation\",\n        thresholds=pb.Thresholds(warning=0.10, error=0.25, critical=0.35)\n    )\n    .col_schema_match(schema=schema)\n    .col_vals_not_null(columns=[\n        \"year\", \"month\", \"day\", \"sched_dep_time\", \"carrier\", \"flight\",\n        \"origin\", \"dest\", \"distance\", \"hour\", \"minute\"\n    ])\n    .col_vals_between(columns=\"month\", left=1, right=12)\n    .col_vals_between(columns=\"day\", left=1, right=31)\n    .col_vals_between(columns=\"sched_dep_time\", left=106, right=2359)\n    .col_vals_between(columns=\"dep_delay\", left=-43, right=1301, na_pass=True)\n    .col_vals_between(columns=\"air_time\", left=20, right=695, na_pass=True)\n    .col_vals_between(columns=\"distance\", left=17, right=4983)\n    .col_vals_between(columns=\"hour\", left=1, right=23)\n    .col_vals_between(columns=\"minute\", left=0, right=59)\n    .col_vals_in_set(columns=\"origin\", set=[\"EWR\", \"LGA\", \"JFK\"])\n    .col_count_match(count=18)\n    .row_count_match(count=336776)\n    .rows_distinct()\n    .interrogate()\n)\n\nvalidation\n```\nNotice how the generated plan includes:\n\nA schema validation with appropriate data types\nNot-null checks for required columns\nRange validations for numerical data\nSet membership checks for categorical data\nRow and column count validations\nAppropriate handling of missing values with na_pass=True",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Draft Validation"
    ]
  },
  {
    "objectID": "user-guide/draft-validation.html#working-with-model-providers",
    "href": "user-guide/draft-validation.html#working-with-model-providers",
    "title": "Draft Validation",
    "section": "Working with Model Providers",
    "text": "Working with Model Providers\n\nSpecifying Models\nWhen using DraftValidation, you specify the model in the format \"provider:model_name\":\n# Using Anthropic's Claude model\npb.DraftValidation(data=data, model=\"anthropic:claude-sonnet-4-5\")\n\n# Using OpenAI's GPT model\npb.DraftValidation(data=data, model=\"openai:gpt-4-turbo\")\n\n# Using a local model with Ollama\npb.DraftValidation(data=data, model=\"ollama:llama3:latest\")\n\n# Using Amazon Bedrock\npb.DraftValidation(data=data, model=\"bedrock:anthropic.claude-3-sonnet-20240229-v1:0\")\n\n\nModel Performance and Privacy\nDifferent models have different capabilities when it comes to generating validation plans:\n\nAnthropic Claude Sonnet 4.5 generally provides the most comprehensive and accurate validation plans\nOpenAI GPT-4 models also perform well\nLocal models through Ollama can be useful for private data but they currently have reduced capabilities here\n\nA key advantage of DraftValidation is that your actual dataset is not sent to the LLM provider. Instead, only a summary is transmitted, which includes:\n\nthe number of rows and columns\ncolumn names and data types\nbasic statistics (min, max, mean, median, missing values count)\na small sample of values from each column (usually 5-10 values)\n\nThis approach protects your data while still providing enough context for the LLM to generate relevant validation rules.",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Draft Validation"
    ]
  },
  {
    "objectID": "user-guide/draft-validation.html#customizing-generated-plans",
    "href": "user-guide/draft-validation.html#customizing-generated-plans",
    "title": "Draft Validation",
    "section": "Customizing Generated Plans",
    "text": "Customizing Generated Plans\nThe validation plan generated by DraftValidation is just a starting point. You’ll typically want to:\n\nreview the generated code for correctness\nreplace your_data with your actual data variable name that exists in your workspace\nensure the data object referenced is actually present in your workspace\nadjust thresholds and validation parameters\nadd domain-specific validation rules\nremove any unnecessary checks\n\nFor example, you might start by capturing the text representation of your draft validation. This will give you the raw Python code that you can copy into a new code cell in your notebook or script. From there, you can customize it by modifying thresholds to match your organization’s data quality standards, adding business-specific validation rules that require domain knowledge, or removing checks that aren’t relevant to your use case. Once you’ve made your modifications, you can execute the customized validation plan as you would any other Pointblank validation.",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Draft Validation"
    ]
  },
  {
    "objectID": "user-guide/draft-validation.html#under-the-hood",
    "href": "user-guide/draft-validation.html#under-the-hood",
    "title": "Draft Validation",
    "section": "Under the Hood",
    "text": "Under the Hood\n\nThe Generated Data Summary\nTo understand what the LLM works with, here’s an example of the data summary format that’s sent:\n{\n  \"table_info\": {\n    \"rows\": 336776,\n    \"columns\": 18,\n    \"table_type\": \"duckdb\"\n  },\n  \"column_info\": [\n    {\n      \"column_name\": \"year\",\n      \"column_type\": \"int64\",\n      \"missing_values\": 0,\n      \"min\": 2013,\n      \"max\": 2013,\n      \"mean\": 2013.0,\n      \"median\": 2013,\n      \"sample_values\": [2013, 2013, 2013, 2013, 2013]\n    },\n    {\n      \"column_name\": \"month\",\n      \"column_type\": \"int64\",\n      \"missing_values\": 0,\n      \"min\": 1,\n      \"max\": 12,\n      \"mean\": 6.548819,\n      \"median\": 7,\n      \"sample_values\": [1, 1, 1, 1, 1]\n    },\n    // Additional columns...\n  ]\n}\n\n\nThe Prompt Strategy\nThe DraftValidation class uses a carefully crafted prompt that instructs the LLM to:\n\nuse the schema information to create a Schema object\ninclude col_vals_not_null() for columns with no missing values\nadd appropriate range validations based on min/max values\ninclude row and column count validations\nformat the output as clean, executable Python code\n\nThe prompt also contains constraints to ensure consistent, high-quality results, such as using line breaks in long lists for readability, applying na_pass=True for columns with missing values, and avoiding duplicate validations.",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Draft Validation"
    ]
  },
  {
    "objectID": "user-guide/draft-validation.html#best-practices-and-troubleshooting",
    "href": "user-guide/draft-validation.html#best-practices-and-troubleshooting",
    "title": "Draft Validation",
    "section": "Best Practices and Troubleshooting",
    "text": "Best Practices and Troubleshooting\n\nWhen to Use DraftValidation\nDrafting a validation is most useful when:\n\nworking with a new dataset for the first time\nneeding to quickly establish baseline validation\nexploring potential validation rules before formalizing them\nvalidating columns with consistent patterns (numeric ranges, categories, etc.)\n\nConsider writing validation plans manually when you need very specific business rules, are working with sensitive data, need complex validation logic, or need to validate relationships between columns.\n\n\nRecommended Workflow and Common Issues\nHere’s a recommended workflow incorporating DraftValidation:\n\ngenerate an initial plan with DraftValidation\nreview the generated validations for relevance\nadjust thresholds and parameters as needed\nadd specific business logic and cross-column validations\nstore the final validation plan in version control\n\nIt’s possible that you might bump up against some issues. Here are some common ones and solutions you might try:\n\nAuthentication Errors: ensure your API key is valid and correctly passed to DraftValidation\nPackage Not Found: make sure you’ve installed the required packages with pip install pointblank[generate]\nUnsupported Model: verify you’re using the correct provider:model format\nPoor Quality Plans: try a more capable model",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Draft Validation"
    ]
  },
  {
    "objectID": "user-guide/draft-validation.html#conclusion",
    "href": "user-guide/draft-validation.html#conclusion",
    "title": "Draft Validation",
    "section": "Conclusion",
    "text": "Conclusion\nDraftValidation provides a powerful way to jumpstart your data validation process by leveraging LLMs to generate context-aware validation plans. By analyzing your data’s structure and content, DraftValidation can create comprehensive validation rules that would otherwise take significant time to develop manually.\nThe feature balances privacy (by sending only data summaries) with utility (by generating executable validation code). While the generated plans should always be reviewed and refined, they provide an excellent starting point for ensuring your data meets your quality requirements.\nBy understanding how DraftValidation works and how to customize its output, you can significantly accelerate your data validation workflows and improve the quality of your data throughout your projects.",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Draft Validation"
    ]
  },
  {
    "objectID": "user-guide/actions.html",
    "href": "user-guide/actions.html",
    "title": "Actions",
    "section": "",
    "text": "Actions transform data validation from passive reporting to active response by automatically executing code when quality issues arise. They bridge the gap between detection and intervention, enabling immediate notifications and comprehensive logging when thresholds are exceeded.\nWhether you need simple console messages for interactive analysis or complex alerting for production pipelines, Actions provide the framework to make your validation workflows responsive. For example, when validating revenue values, you can configure immediate alerts if failures exceed acceptable thresholds, ensuring data issues are addressed promptly rather than discovered later.\nIn this article, we’ll explore how to use Actions to respond to threshold violations during data validation, and Final Actions to execute code after all validation steps are complete, giving you powerful tools to monitor, alert, and report on your data’s quality.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Actions"
    ]
  },
  {
    "objectID": "user-guide/actions.html#how-actions-work",
    "href": "user-guide/actions.html#how-actions-work",
    "title": "Actions",
    "section": "How Actions Work",
    "text": "How Actions Work\nLet’s look at an example on how this works in practice. The following validation plan contains a single step (using col_vals_gt()) where the thresholds= and actions= parameters are set using Thresholds and Actions calls:\n\nimport pointblank as pb\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\"))\n    .col_vals_gt(\n        columns=\"c\", value=2,\n        thresholds=pb.Thresholds(warning=1, error=5),\n\n        # Emit a console message when the warning threshold is exceeded ---\n        actions=pb.Actions(warning=\"WARNING: failing test found.\")\n    )\n    .interrogate()\n)\n\nWARNING: failing test found.\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:17:15Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #AAAAAA\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    c\n    2\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    100.77\n    30.23\n    ●\n    ○\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThe code uses thresholds=pb.Thresholds(warning=1, error=5) to set a ‘warning’ threshold of 1 and an ‘error’ threshold of 5 failing test units. The results part of the validation table shows that:\n\nThe FAIL column shows that 3 tests units have failed\nThe W column (short for ‘warning’) shows a filled gray circle indicating it’s reached its threshold level\nThe E (‘error’) column shows an open yellow circle indicating it’s below the threshold level\n\nMore importantly, the text \"WARNING: failing test found.\" has been emitted. Here it appears above the validation table and that’s because the action is executed eagerly during interrogation (before the report has even been generated).\nSo, an action is executed for a particular condition (e.g., ‘warning’) within a validation step if these three things are true:\n\nthere is a threshold set for that condition (either globally, or as part of that step)\nthere is an associated action set for the condition (again, either set globally or within the step)\nduring interrogation, the threshold value for the condition was exceeded by the number or proportion of failing test units\n\nThere is a lot of flexibility for setting both thresholds and actions and everything here is considered optional. Put another way, you can set various thresholds and various actions as needed and the interrogation phase will determine whether all the requirements are met for executing an action.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Actions"
    ]
  },
  {
    "objectID": "user-guide/actions.html#defining-actions",
    "href": "user-guide/actions.html#defining-actions",
    "title": "Actions",
    "section": "Defining Actions",
    "text": "Defining Actions\nActions can be defined in several ways, providing flexibility for different notification needs.\n\nUsing String Messages\nThere are a few options in how to define the actions:\n\nString: a message to be displayed in the console\nCallable: a function to be called\nList of Strings/Callables: for execution of multiple messages or functions\n\nThe actions are executed at interrogation time when the threshold level assigned to the action is exceeded by the number or proportion of failing test units. When providing a string, it will simply be printed to the console. A callable will also be executed at the time of interrogation. If providing a list of strings or callables, each item in the list will be executed in order. Such a list can contain a mix of strings and callables.\nDisplaying console messages may be a simple approach, but it is effective. And the strings don’t have to be static, there are templating features that can be useful for constructing strings for a variety of situations. The following placeholders are available for use:\n\n{type}: The validation step type where the action is executed (e.g., ‘col_vals_gt’, etc.)\n{level}: The threshold level where the action is executed (‘warning’, ‘error’, or ‘critical’)\n{step} or {i}: The step number in the validation workflow where the action is executed\n{col} or {column}: The column name where the action is executed\n{val} or {value}: An associated value for the validation method\n{time}: A datetime value for when the action was executed\n\nHere’s an example where we prepare a console message with a number of value placeholders (action_str) and use it globally at Actions(critical=):\n\naction_str = \"[{LEVEL}: {TYPE}]: Step {step} has failed validation. ({time})\"\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"duckdb\"),\n        thresholds=pb.Thresholds(warning=0.05, error=0.10, critical=0.15),\n\n        # Use `action_str` for any critical thresholds exceeded ---\n        actions=pb.Actions(critical=action_str),\n    )\n    .col_vals_regex(columns=\"player_id\", pattern=r\"[A-Z]{12}\\d{3}\")\n    .col_vals_gt(columns=\"item_revenue\", value=0.10)\n    .col_vals_ge(columns=\"session_duration\", value=15)\n    .interrogate()\n)\n\n[CRITICAL: COL_VALS_GT]: Step 2 has failed validation. (2025-11-23 00:17:16.240389+00:00)\n[CRITICAL: COL_VALS_GE]: Step 3 has failed validation. (2025-11-23 00:17:16.285786+00:00)\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:17:16DuckDBWARNING0.05ERROR0.1CRITICAL0.15\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    player_id\n    [A-Z]{12}\\d{3}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #FF3300\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    item_revenue\n    0.1\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    14400.72\n    5600.28\n    ●\n    ●\n    ●\n    —\n  \n  \n    #FF3300\n    3\n    \n        \n            \n\n    col_vals_ge\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_ge()\n        \n        \n        \n    session_duration\n    15\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    16860.84\n    3140.16\n    ●\n    ●\n    ●\n    —\n  \n\n\n\n\n\n\n        \n\n\nWhat we get here are two messages in the console, corresponding to critical failures in steps 2 and 3. The placeholders were replaced with the correct text for the context. Note that some of the resulting text is capitalized (e.g., \"CRITICAL\", \"COL_VALS_GT\", etc.) and this is because we capitalized the placeholder text itself. Have a look at the documentation article of Actions for more details on this.\n\n\nUsing Callable Functions\nAside from strings, any callable can be used as an action value. Here’s an example where we use a custom function as part of an action:\n\ndef duration_issue():\n    from datetime import datetime\n    print(f\"Data quality issue found ({datetime.now()}).\")\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"duckdb\"),\n        thresholds=pb.Thresholds(warning=0.05, error=0.10, critical=0.15),\n    )\n    .col_vals_regex(columns=\"player_id\", pattern=r\"[A-Z]{12}\\d{3}\")\n    .col_vals_gt(columns=\"item_revenue\", value=0.05)\n    .col_vals_gt(\n        columns=\"session_duration\", value=15,\n\n        # Use the `duration_issue()` function as an action for this step ---\n        actions=pb.Actions(warning=duration_issue),\n    )\n    .interrogate()\n)\n\nData quality issue found (2025-11-23 00:17:16.640147).\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:17:16DuckDBWARNING0.05ERROR0.1CRITICAL0.15\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    player_id\n    [A-Z]{12}\\d{3}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #EBBC14\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    item_revenue\n    0.05\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    17010.85\n    2990.15\n    ●\n    ●\n    ○\n    —\n  \n  \n    #FF3300\n    3\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    session_duration\n    15\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    16750.84\n    3250.16\n    ●\n    ●\n    ●\n    —\n  \n\n\n\n\n\n\n        \n\n\nIn this case, the ‘warning’ action is set to call the user’s dq_issue() function. This action is only executed when the ‘warning’ threshold is exceeded in step 3. Because all three thresholds are exceeded in that step, the ‘warning’ action of executing the function occurs (resulting in a message being printed to the console).\nThis is an example where actions can be defined locally for an individual validation step. The global threshold setting applied to all three validation steps but the step-level action only applied to step 3. You are free to mix and match both threshold and action settings at the global level (i.e., set in the Validate call) or at the step level. The key thing to be aware of is that step-level settings of thresholds and actions take precedence.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Actions"
    ]
  },
  {
    "objectID": "user-guide/actions.html#accessing-context-in-actions",
    "href": "user-guide/actions.html#accessing-context-in-actions",
    "title": "Actions",
    "section": "Accessing Context in Actions",
    "text": "Accessing Context in Actions\nWhile string templates provide helpful placeholders to access information about validation steps, callable functions offer more flexibility through access to detailed metadata. When using functions as actions, you can retrieve comprehensive information about the validation context, allowing for complex logic and dynamic responses to validation issues.\n\nUsing get_action_metadata() in Callables\nTo access information about the validation step where an action was triggered, we can call get_action_metadata() in the body of a function to be used within Actions. This provides useful context about the validation step that triggered the action.\n\ndef print_problem():\n    m = pb.get_action_metadata()\n    print(f\"{m['level']} ({m['level_num']}) for Step {m['step']}: {m['failure_text']}\")\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"duckdb\"),\n        thresholds=pb.Thresholds(warning=0.05, error=0.10, critical=0.15),\n\n        # Use the `print_problem()` function as the action ---\n        actions=pb.Actions(default=print_problem),\n        brief=True,\n    )\n    .col_vals_regex(columns=\"player_id\", pattern=r\"[A-Z]{12}\\d{3}\")\n    .col_vals_gt(columns=\"item_revenue\", value=0.05)\n    .col_vals_gt(columns=\"session_duration\", value=15)\n    .interrogate()\n)\n\nerror (40) for Step 2: Exceedance of failed test units where values in `item_revenue` should have been &gt; `0.05`.\ncritical (50) for Step 3: Exceedance of failed test units where values in `session_duration` should have been &gt; `15`.\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:17:16DuckDBWARNING0.05ERROR0.1CRITICAL0.15\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        Expect that values in player_id should match the regular expression: [A-Z]{12}\\d{3}.\n\n        \n    player_id\n    [A-Z]{12}\\d{3}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #EBBC14\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Expect that values in item_revenue should be &gt; 0.05.\n\n        \n    item_revenue\n    0.05\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    17010.85\n    2990.15\n    ●\n    ●\n    ○\n    —\n  \n  \n    #FF3300\n    3\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Expect that values in session_duration should be &gt; 15.\n\n        \n    session_duration\n    15\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    16750.84\n    3250.16\n    ●\n    ●\n    ●\n    —\n  \n\n\n\n\n\n\n        \n\n\nIn this example, we’re creating a function called print_problem() that prints information about each validation step that fails. We then apply this function as the default action for all threshold levels using actions=pb.Actions(default=print_problem). (Note that the default= and highest_only= parameters will be covered in more detail in following sections.)\nWe end up seeing two messages printed for failures in Steps 2 and 3. And though those steps had more than one threshold exceeded, only the most severe level in each yielded a console message (due to the default highest_only=True behavior).\nBy setting the action in Validate(actions=), we applied it to all validation steps where thresholds are exceeded. This eliminates the need to set actions= at every validation step (though you can do this as a local override, even setting actions=None to disable globally set actions).\n\n\nAvailable Metadata Fields\nThe dictionary returned by get_action_metadata() contains the following fields:\n\nstep: The step number.\ncolumn: The column name.\nvalue: The value being compared (only available in certain validation steps).\ntype: The assertion type (e.g., \"col_vals_gt\", etc.).\ntime: The time the validation step was executed (in ISO format).\nlevel: The severity level (\"warning\", \"error\", or \"critical\").\nlevel_num: The severity level as a numeric value (30, 40, or 50).\nautobrief: A localized and brief statement of the expectation for the step.\nfailure_text: Localized text that explains how the validation step failed.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Actions"
    ]
  },
  {
    "objectID": "user-guide/actions.html#customizing-action-behavior",
    "href": "user-guide/actions.html#customizing-action-behavior",
    "title": "Actions",
    "section": "Customizing Action Behavior",
    "text": "Customizing Action Behavior\nThe Actions class has two additional parameters that provide more control over how actions are executed:\n\nSetting Default Actions with default=\nInstead of specifying actions separately for each threshold level, you can use the default= parameter to set a common action for all levels:\n\ndef log_all_issues():\n    m = pb.get_action_metadata()\n    print(f\"[{m['level'].upper()}] Validation failed in step {m['step']} with level {m['level']}\")\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"duckdb\"),\n        thresholds=pb.Thresholds(warning=0.05, error=0.10, critical=0.15),\n\n        # The `log_all_issues()` callable is set to every threshold ---\n        actions=pb.Actions(default=log_all_issues),\n    )\n    .col_vals_regex(columns=\"player_id\", pattern=r\"[A-Z]{12}\\d{3}\")\n    .col_vals_gt(columns=\"item_revenue\", value=0.05)\n    .col_vals_gt(columns=\"session_duration\", value=15)\n    .interrogate()\n)\n\n[ERROR] Validation failed in step 2 with level error\n[CRITICAL] Validation failed in step 3 with level critical\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:17:17DuckDBWARNING0.05ERROR0.1CRITICAL0.15\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    player_id\n    [A-Z]{12}\\d{3}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #EBBC14\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    item_revenue\n    0.05\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    17010.85\n    2990.15\n    ●\n    ●\n    ○\n    —\n  \n  \n    #FF3300\n    3\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    session_duration\n    15\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    16750.84\n    3250.16\n    ●\n    ●\n    ●\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe default= parameter sets the same action for all threshold levels. If you later specify an action for a specific level, it will override this default for that level only.\nWhen using the default= parameter, be aware that your action (whether a string template or callable function) needs to work across all validation steps where thresholds might be exceeded. Not all validation methods provide the same context for string templates or in the metadata dictionary returned by get_action_metadata().\nFor example, some validation steps like col_vals_gt() provide a value field that can be accessed with {value} in string templates, while others like col_exists() don’t have this concept. When creating default actions, either use only the universally available placeholders ({step}, {level}, {type}, and {time}), or include conditional logic in your callable functions to handle different validation types appropriately.\n\n\nControlling Action Execution with highest_only=\nBy default, Pointblank only executes the action for the most severe threshold level that’s been exceeded. If you want actions for all exceeded thresholds to be executed, you can set highest_only=False:\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"duckdb\"),\n        thresholds=pb.Thresholds(warning=0.05, error=0.10, critical=0.15),\n        actions=pb.Actions(\n            warning=\"Warning threshold exceeded in step {step}\",\n            error=\"Error threshold exceeded in step {step}\",\n            critical=\"Critical threshold exceeded in step {step}\",\n\n            # Execute all applicable actions ---\n            highest_only=False\n        ),\n    )\n    .col_vals_gt(columns=\"session_duration\", value=15)\n    .interrogate()\n)\n\nCritical threshold exceeded in step 1\nError threshold exceeded in step 1\nWarning threshold exceeded in step 1\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:17:17DuckDBWARNING0.05ERROR0.1CRITICAL0.15\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #FF3300\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    session_duration\n    15\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    16750.84\n    3250.16\n    ●\n    ●\n    ●\n    —\n  \n\n\n\n\n\n\n        \n\n\nIn this example, if all three thresholds are exceeded in a step, you’ll see all three messages printed, rather than just the critical one.\nThe default behavior (highest_only=True) helps prevent notification fatigue by limiting the number of actions executed when multiple thresholds are exceeded in the same validation step. For example, if a validation step fails with 60% of rows not passing, it would exceed ‘warning’, ‘error’, and ‘critical’ thresholds simultaneously. With highest_only=True, only the critical action would execute.\nYou might want to set highest_only=False when:\n\ndifferent threshold levels need to trigger different types of notifications (e.g., warnings to Slack, errors to email, critical to urgent notifications)\nyou need comprehensive logging of all severity levels for audit purposes\nyou’re building a dashboard that displays counts of issues at each severity level",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Actions"
    ]
  },
  {
    "objectID": "user-guide/actions.html#using-multiple-actions-for-a-threshold",
    "href": "user-guide/actions.html#using-multiple-actions-for-a-threshold",
    "title": "Actions",
    "section": "Using Multiple Actions for a Threshold",
    "text": "Using Multiple Actions for a Threshold\nYou can specify multiple actions to be executed for a single threshold level by providing a list:\n\ndef send_notification():\n    print(\"📧 Notification sent to data team\")\n\ndef log_to_system():\n    print(\"📝 Issue logged in system\")\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"duckdb\"),\n        thresholds=pb.Thresholds(critical=0.15),\n\n        # Set multiple actions for the critical threshold exceedance ---\n        actions=pb.Actions(\n            critical=[\n                \"CRITICAL: Data validation failed\",  # First action: display message\n                send_notification,                   # Second action: call function\n                log_to_system                        # Third action: call another function\n            ]\n        ),\n    )\n    .col_vals_gt(columns=\"session_duration\", value=15)\n    .interrogate()\n)\n\nCRITICAL: Data validation failed\n📧 Notification sent to data team\n📝 Issue logged in system\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:17:17DuckDBWARNING—ERROR—CRITICAL0.15\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #FF3300\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    session_duration\n    15\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    16750.84\n    3250.16\n    —\n    —\n    ●\n    —\n  \n\n\n\n\n\n\n        \n\n\nWhen providing a list of actions, they will be executed in sequence when the threshold is exceeded. This allows you to combine different types of actions such as displaying messages, sending notifications, and logging events.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Actions"
    ]
  },
  {
    "objectID": "user-guide/actions.html#final-actions",
    "href": "user-guide/actions.html#final-actions",
    "title": "Actions",
    "section": "Final Actions",
    "text": "Final Actions\n\nCreating Final Actions\nWhen you need to execute actions after all validation steps are complete, Pointblank provides the FinalActions class. Unlike Actions which triggers on a per-step basis during the validation process, FinalActions executes after the entire validation is complete, giving you a way to respond to the overall validation results.\nHere’s how to use FinalActions:\n\ndef send_alert():\n    summary = pb.get_validation_summary()\n    if summary[\"highest_severity\"] == \"critical\":\n        print(f\"ALERT: Critical validation failures found in `{summary['tbl_name']}`\")\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"duckdb\"),\n        tbl_name=\"game_revenue\",\n        thresholds=pb.Thresholds(warning=0.05, error=0.10, critical=0.15),\n\n        # Set final actions to be executed after all interrogations ---\n        final_actions=pb.FinalActions(\n            \"Validation complete.\",  # 1. a string message\n            send_alert               # 2. a callable function\n        )\n    )\n    .col_vals_regex(columns=\"player_id\", pattern=r\"[A-Z]{12}\\d{3}\")\n    .col_vals_gt(columns=\"item_revenue\", value=0.10)\n    .interrogate()\n)\n\nValidation complete.\nALERT: Critical validation failures found in `game_revenue`\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:17:17DuckDBgame_revenueWARNING0.05ERROR0.1CRITICAL0.15\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    player_id\n    [A-Z]{12}\\d{3}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #FF3300\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    item_revenue\n    0.1\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    14400.72\n    5600.28\n    ●\n    ●\n    ●\n    —\n  \n\n\n\n\n\n\n        \n\n\nIn this example:\n\nWe define the function send_alert() that checks the validation summary for critical failures\nWe provide a simple string message \"Validation complete.\" that will print to the console\nBoth actions will execute in order after all validation steps have completed\n\nBecause the ‘critical’ threshold was exceeded in Step 2, we see the printed alert of send_alert() after the simple string message.\nFinalActions accepts any number of actions as positional arguments. Each argument can be:\n\nString: A message to be displayed in the console\nCallable: A function to be called with no arguments\nList of Strings/Callables: Multiple actions to execute in sequence\n\nAll actions will be executed in the order they are provided after all validation steps have completed.\n\n\nUsing get_validation_summary() in Final Actions\nWhen creating a callable function to use with FinalActions, you can access information about the overall validation results using the get_validation_summary() function. This gives you a dictionary with comprehensive information about the validation:\ndef comprehensive_report():\n    summary = pb.get_validation_summary()\n    print(f\"Validation Report for {summary['tbl_name']}:\")\n    print(f\"- Steps: {summary['n_steps']}\")\n    print(f\"- Passing steps: {summary['n_passing_steps']}\")\n    print(f\"- Failing steps: {summary['n_failing_steps']}\")\n\n    # Take additional actions based on results\n    if summary[\"n_failing_steps\"] &gt; 0:\n\n        # Create a Slack notification function ---\n        notify = pb.send_slack_notification(\n            webhook_url=\"https://hooks.slack.com/services/your/webhook/url\",\n            summary_msg=\"\"\"\n            🚨 *Validation Failure Alert*\n            • Table: {tbl_name}\n            • Failed Steps: {n_failing_steps} of {n_steps}\n            • Highest Severity: {highest_severity}\n            • Time: {time}\n            \"\"\",\n        )\n\n        # Execute the notification function\n        notify()\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"duckdb\"),\n        tbl_name=\"game_revenue\",\n        final_actions=pb.FinalActions(comprehensive_report),\n    )\n    .col_vals_regex(columns=\"player_id\", pattern=r\"[A-Z]{12}\\d{3}\")\n    .col_vals_gt(columns=\"item_revenue\", value=0.05)\n    .interrogate()\n)\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:17:17DuckDBgame_revenue\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    player_id\n    [A-Z]{12}\\d{3}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    item_revenue\n    0.05\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    17010.85\n    2990.15\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nHere we used the send_slack_notification() function, which is available in Pointblank as a pre-built action. It can be used by itself in final_actions= but here it’s integrated into the user’s comprehensive_report() function to provide finer control with conditional logic.\n\n\nCombining Step-level and Final Actions\nYou can use both Actions and FinalActions together for comprehensive validation control:\n\ndef log_step_failure():\n    m = pb.get_action_metadata()\n    print(f\"Step {m['step']} failed with {m['level']}\")\n\n\ndef generate_summary():\n    summary = pb.get_validation_summary()\n    # Sum up total failed test units across all steps\n    total_failed = sum(summary[\"dict_n_failed\"].values())\n    # Sum up total test units across all steps\n    total_units = sum(summary[\"dict_n\"].values())\n    print(f\"Validation complete: {total_failed} failures out of {total_units} tests\")\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"duckdb\"),\n        thresholds=pb.Thresholds(warning=0.05, error=0.10),\n\n        # Set an action for each step (highest threshold exceeded) ---\n        actions=pb.Actions(default=log_step_failure),\n\n        # Set a final action to get a summary of the validation process ---\n        final_actions=pb.FinalActions(generate_summary),\n    )\n    .col_vals_regex(columns=\"player_id\", pattern=r\"[A-Z]{12}\\d{3}\")\n    .col_vals_gt(columns=\"item_revenue\", value=0.05)\n    .interrogate()\n)\n\nStep 2 failed with error\nValidation complete: 299 failures out of 4000 tests\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:17:18DuckDBWARNING0.05ERROR0.1CRITICAL—\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    player_id\n    [A-Z]{12}\\d{3}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    —\n    —\n  \n  \n    #EBBC14\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    item_revenue\n    0.05\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    17010.85\n    2990.15\n    ●\n    ●\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThis approach allows you to:\n\nlog individual step failures during the validation process using Actions\ngenerate a comprehensive report after all validation steps are complete using FinalActions\n\nUsing both action types gives you fine-grained control over when and how notifications and other actions are triggered in your validation workflow.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Actions"
    ]
  },
  {
    "objectID": "user-guide/actions.html#conclusion",
    "href": "user-guide/actions.html#conclusion",
    "title": "Actions",
    "section": "Conclusion",
    "text": "Conclusion\nActions provide a powerful mechanism for responding to data validation results in Pointblank. By combining threshold settings with appropriate actions, you can create sophisticated data quality workflows that:\n\nprovide immediate feedback through console messages\nexecute custom functions when validation thresholds are exceeded\ncustomize notifications based on severity levels\ngenerate comprehensive reports after validation is complete\nautomate responses to data quality issues\n\nThe flexible design of Actions and FinalActions allows you to start simple with basic console messages and gradually build up to complex validation workflows with conditional logic, custom reporting, and integrations with other systems like Slack, email, or logging services.\nWhen designing your validation strategy, consider leveraging both step-level actions for immediate responses and final actions for holistic reporting. This combination provides comprehensive control over your data validation process and helps ensure that data quality issues are detected, reported, and addressed efficiently.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Actions"
    ]
  },
  {
    "objectID": "user-guide/index.html",
    "href": "user-guide/index.html",
    "title": "Introduction",
    "section": "",
    "text": "Redirecting to the Introduction…"
  },
  {
    "objectID": "user-guide/index.html#a-simple-validation-table",
    "href": "user-guide/index.html#a-simple-validation-table",
    "title": "Introduction",
    "section": "A Simple Validation Table",
    "text": "A Simple Validation Table\nThis is a validation report table that is produced from a validation of a Polars DataFrame:\n\n\nShow the code\nimport pointblank as pb\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\"), label=\"Example Validation\")\n    .col_vals_lt(columns=\"a\", value=10)\n    .col_vals_between(columns=\"d\", left=0, right=5000)\n    .col_vals_in_set(columns=\"f\", set=[\"low\", \"mid\", \"high\"])\n    .col_vals_regex(columns=\"b\", pattern=r\"^[0-9]-[a-z]{3}-[0-9]{3}$\")\n    .interrogate()\n)\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Example ValidationPolars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    a\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_between\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_between()\n        \n        \n        \n    d\n    [0, 5000]\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    120.92\n    10.08\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        \n        \n    f\n    low, mid, high\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    b\n    ^[0-9]-[a-z]{3}-[0-9]{3}$\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:17:28 UTC&lt; 1 s2025-11-23 00:17:28 UTC\n  \n\n\n\n\n\n\n        \n\n\nEach row in this reporting table constitutes a single validation step. Roughly, the left-hand side outlines the validation rules and the right-hand side provides the results of each validation step. While simple in principle, there’s a lot of useful information packed into this validation table.\nHere’s a diagram that describes a few of the important parts of the validation table:\n\nThere are three things that should be noted here:\n\nvalidation steps: each step is a separate test on the table, focused on a certain aspect of the table\nvalidation rules: the validation type is provided here along with key constraints\nvalidation results: interrogation results are provided here, with a breakdown of test units (total, passing, and failing), threshold flags, and more\n\nThe intent is to provide the key information in one place, and have it be interpretable by data stakeholders. For example, a failure can be seen in the second row (notice there’s a CSV button). A data quality stakeholder could click this to download a CSV of the failing rows for that step."
  },
  {
    "objectID": "user-guide/index.html#example-code-step-by-step",
    "href": "user-guide/index.html#example-code-step-by-step",
    "title": "Introduction",
    "section": "Example Code, Step-by-Step",
    "text": "Example Code, Step-by-Step\nThis section will walk you through the example code used above.\nimport pointblank as pb\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\"))\n    .col_vals_lt(columns=\"a\", value=10)\n    .col_vals_between(columns=\"d\", left=0, right=5000)\n    .col_vals_in_set(columns=\"f\", set=[\"low\", \"mid\", \"high\"])\n    .col_vals_regex(columns=\"b\", pattern=r\"^[0-9]-[a-z]{3}-[0-9]{3}$\")\n    .interrogate()\n)\nNote these three key pieces in the code:\n\ndata: the Validate(data=) argument takes a DataFrame or database table that you want to validate\nsteps: the methods starting with col_vals_ specify validation steps that run on specific columns\nexecution: the interrogate() method executes the validation plan on the table\n\nThis common pattern is used in a validation workflow, where Validate and interrogate() bookend a validation plan generated through calling validation methods.\nIn the next few sections we’ll go a bit further by understanding how we can measure data quality and respond to failures."
  },
  {
    "objectID": "user-guide/index.html#understanding-test-units",
    "href": "user-guide/index.html#understanding-test-units",
    "title": "Introduction",
    "section": "Understanding Test Units",
    "text": "Understanding Test Units\nEach validation step will execute a type of validation test on the target table. For example, a col_vals_lt() validation step can test that each value in a column is less than a specified number. And the key finding that’s reported in each step is the number of test units that pass or fail.\nIn the validation report table, test unit metrics are displayed under the UNITS, PASS, and FAIL columns. This diagram explains what the tabulated values signify:\n\nTest units are dependent on the test being run. Some validation methods might test every value in a particular column, so each value will be a test unit. Others will only have a single test unit since they aren’t testing individual values but rather if the overall test passes or fails."
  },
  {
    "objectID": "user-guide/index.html#setting-thresholds-for-data-quality-signals",
    "href": "user-guide/index.html#setting-thresholds-for-data-quality-signals",
    "title": "Introduction",
    "section": "Setting Thresholds for Data Quality Signals",
    "text": "Setting Thresholds for Data Quality Signals\nUnderstanding test units is essential because they form the foundation of Pointblank’s threshold system. Thresholds let you define acceptable levels of data quality, triggering different severity signals (‘warning’, ‘error’, or ‘critical’) when certain failure conditions are met.\nHere’s a simple example that uses a single validation step along with thresholds set using the Thresholds class:\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\"))\n    .col_vals_lt(\n        columns=\"a\",\n        value=7,\n\n        # Set the 'warning' and 'error' thresholds ---\n        thresholds=pb.Thresholds(warning=2, error=4)\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:17:28Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #AAAAAA\n    1\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    a\n    7\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    ●\n    ○\n    —\n    CSV\n  \n\n  \n  \n  \n    2025-11-23 00:17:28 UTC&lt; 1 s2025-11-23 00:17:28 UTC\n  \n\n\n  \n    \nNotes\nStep 1 (local_thresholds) Step-specific thresholds set with W:2|E:4.\n  \n\n\n\n\n\n\n        \n\n\nIf you look at the validation report table, we can see:\n\nthe FAIL column shows that 2 tests units have failed\nthe W column (short for ‘warning’) shows a filled gray circle indicating those failing test units reached that threshold value\nthe E column (short for ‘error’) shows an open yellow circle indicating that the number of failing test units is below that threshold\n\nThe one final threshold level, C (for ‘critical’), wasn’t set so it appears on the validation table as a long dash."
  },
  {
    "objectID": "user-guide/index.html#taking-action-on-threshold-exceedances",
    "href": "user-guide/index.html#taking-action-on-threshold-exceedances",
    "title": "Introduction",
    "section": "Taking Action on Threshold Exceedances",
    "text": "Taking Action on Threshold Exceedances\nPointblank becomes even more powerful when you combine thresholds with actions. The Actions class lets you trigger responses when validation failures exceed threshold levels, turning passive reporting into active notifications.\nHere’s a simple example that adds an action to the previous validation:\n\n(\n    pb.Validate(data=pb.load_dataset(dataset=\"small_table\"))\n    .col_vals_lt(\n        columns=\"a\",\n        value=7,\n        thresholds=pb.Thresholds(warning=2, error=4),\n\n        # Set an action for the 'warning' threshold ---\n        actions=pb.Actions(\n            warning=\"WARNING: Column 'a' has values that aren't less than 7.\"\n        )\n    )\n    .interrogate()\n)\n\nWARNING: Column 'a' has values that aren't less than 7.\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:17:28Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #AAAAAA\n    1\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    a\n    7\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    ●\n    ○\n    —\n    CSV\n  \n\n  \n  \n  \n    2025-11-23 00:17:28 UTC&lt; 1 s2025-11-23 00:17:28 UTC\n  \n\n\n  \n    \nNotes\nStep 1 (local_thresholds) Step-specific thresholds set with W:2|E:4.\n  \n\n\n\n\n\n\n        \n\n\nNotice the printed warning message: \"WARNING: Column 'a' has values that aren't less than 7.\". The warning indicator (filled gray circle) visually confirms this threshold was reached and the action should trigger.\nActions make your validation workflows more responsive and integrated with your data pipelines. For example, you can generate console messages, Slack notifications, and more."
  },
  {
    "objectID": "user-guide/index.html#navigating-the-user-guide",
    "href": "user-guide/index.html#navigating-the-user-guide",
    "title": "Introduction",
    "section": "Navigating the User Guide",
    "text": "Navigating the User Guide\nAs you continue exploring Pointblank’s capabilities, you’ll find the User Guide organized into sections that will help you navigate the various features.\n\nGetting Started\nThe Getting Started section introduces you to Pointblank:\n\nIntroduction: Overview of Pointblank and core concepts (this article)\nInstallation: How to install and set up Pointblank\n\n\n\nValidation Plan\nThe Validation Plan section covers everything you need to know about creating robust validation plans:\n\nOverview: Survey of validation methods and their shared parameters\nValidation Methods: A closer look at the more common validation methods\nColumn Selection Patterns: Techniques for targeting specific columns\nPreprocessing: Transform data before validation\nSegmentation: Apply validations to specific segments of your data\nThresholds: Set quality standards and trigger severity levels\nActions: Respond to threshold exceedances with notifications or custom functions\nBriefs: Add context to validation steps\n\n\n\nAdvanced Validation\nThe Advanced Validation section explores more specialized validation techniques:\n\nExpression-Based Validation: Use column expressions for advanced validation\nSchema Validation: Enforce table structure and column types\nAssertions: Raise exceptions to enforce data quality requirements\nDraft Validation: Create validation plans from existing data\n\n\n\nPost Interrogation\nAfter validating your data, the Post Interrogation section helps you analyze and respond to results:\n\nValidation Reports: Understand and customize the validation report table\nStep Reports: View detailed results for individual validation steps\nData Extracts: Extract and analyze failing data\nSundering Validated Data: Split data based on validation results\n\n\n\nData Inspection\nThe Data Inspection section provides tools to explore and understand your data:\n\nPreviewing Data: View samples of your data\nColumn Summaries: Get statistical summaries of your data\nMissing Values Reporting: Identify and visualize missing data\n\nBy following this guide, you’ll gain a comprehensive understanding of how to validate, monitor, and maintain high-quality data with Pointblank."
  },
  {
    "objectID": "user-guide/missing-vals-tbl.html",
    "href": "user-guide/missing-vals-tbl.html",
    "title": "Missing Values Reporting",
    "section": "",
    "text": "Sometimes values just aren’t there: they’re missing. This can either be expected or another thing to worry about. Either way, we can dig a little deeper if need be and use the missing_vals_tbl() function to generate a summary table that can elucidate how many values are missing, and roughly where.",
    "crumbs": [
      "Get Started",
      "Data Inspection",
      "Missing Values Reporting"
    ]
  },
  {
    "objectID": "user-guide/missing-vals-tbl.html#using-and-understanding-missing_vals_tbl",
    "href": "user-guide/missing-vals-tbl.html#using-and-understanding-missing_vals_tbl",
    "title": "Missing Values Reporting",
    "section": "Using and Understanding missing_vals_tbl()",
    "text": "Using and Understanding missing_vals_tbl()\nThe missing values table is arranged a lot like the column summary table (generated via the col_summary_tbl() function) in that columns of the input table are arranged as rows in the reporting table. Let’s use missing_vals_tbl() on the nycflights dataset, which has a lot of missing values:\n\nimport pointblank as pb\n\nnycflights = pb.load_dataset(dataset=\"nycflights\", tbl_type=\"polars\")\n\npb.missing_vals_tbl(nycflights)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Missing Values   46,595 in total\n  \n  \n    PolarsRows336,776Columns18\n  \n\n  Column\n  \n    Row Sector\n  \n\n\n  1\n  2\n  3\n  4\n  5\n  6\n  7\n  8\n  9\n  10\n\n\n\n  \n    year\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    month\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    day\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    dep_time\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    sched_dep_time\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    dep_delay\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    arr_time\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    sched_arr_time\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    arr_delay\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    carrier\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    flight\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    tailnum\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    origin\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    dest\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    air_time\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    distance\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    hour\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    minute\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n\n  \n  \n  \n    NO MISSING VALUES     PROPORTION MISSING:  0%100%ROW SECTORS1 – 3367733678 – 6735467355 – 101031101032 – 134708134709 – 168385168386 – 202062202063 – 235739235740 – 269416269417 – 303093303094 – 336776\n  \n\n\n\n\n\n\n        \n\n\nThere are 18 columns in nycflights and they’re arranged down the missing values table as rows. To the right we see column headers indicating 10 columns that are row sectors. Row sectors are groups of rows and each sector contains a tenth of the total rows in the table. The leftmost sectors are the rows at the top of the table whereas the sectors on the right are closer to the bottom. If you’d like to know which rows make up each row sector, there are details on this in the table footer area (click the ROW SECTORS text or the disclosure triangle).\nNow that we know about row sectors, we need to understand the visuals here. A light blue cell indicates there are no (0) missing values within a given row sector of a column. For nycflights we can see that several columns have no missing values at all (i.e., the light blue color makes up the entire row in the missing values table).\nWhen there are missing values in a column’s row sector, you’ll be met with a grayscale color. The proportion of missing values corresponds to the color ramp from light gray to solid black. Interestingly, most of the columns that have missing values appear to be related to each other in terms of the extent of missing values (i.e., the appearance in the reporting table looks roughly the same, indicating a sort of systematic missingness). These columns are dep_time, dep_delay, arr_time, arr_delay, and air_time.\nThe odd column out with regard to the distribution of missing values is tailnum. By scanning the row and observing that the grayscale color values are all a little different we see that the degree of missingness of more variable and not related to the other columns containing missing values.",
    "crumbs": [
      "Get Started",
      "Data Inspection",
      "Missing Values Reporting"
    ]
  },
  {
    "objectID": "user-guide/missing-vals-tbl.html#missing-value-tables-from-the-other-datasets",
    "href": "user-guide/missing-vals-tbl.html#missing-value-tables-from-the-other-datasets",
    "title": "Missing Values Reporting",
    "section": "Missing Value Tables from the Other Datasets",
    "text": "Missing Value Tables from the Other Datasets\nThe small_table dataset has only 13 rows to it. Let’s use that as a Pandas DataFrame with missing_vals_tbl():\n\nsmall_table = pb.load_dataset(dataset=\"small_table\", tbl_type=\"pandas\")\n\npb.missing_vals_tbl(small_table)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Missing Values   2 in total\n  \n  \n    PandasRows13Columns8\n  \n\n  Column\n  \n    Row Sector\n  \n\n\n  1\n  2\n  3\n  4\n  5\n  6\n  7\n  8\n  9\n  10\n\n\n\n  \n    date_time\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    date\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    a\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    b\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    c\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    d\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    e\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    f\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n\n  \n  \n  \n    NO MISSING VALUES     PROPORTION MISSING:  0%100%ROW SECTORS1 – 12 – 23 – 34 – 45 – 56 – 67 – 78 – 89 – 910 – 13\n  \n\n\n\n\n\n\n        \n\n\nIt appears that only column c has missing values. And since the table is very small in terms of row count, most of the row sectors contain only a single row.\nThe game_revenue dataset has no missing values. And this can be easily proven by using missing_vals_tbl() with it:\n\ngame_revenue = pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"duckdb\")\n\npb.missing_vals_tbl(game_revenue)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Missing Values ✓\n  \n  \n    DuckDBRows2,000Columns11\n  \n\n  Column\n  \n    Row Sector\n  \n\n\n  1\n  2\n  3\n  4\n  5\n  6\n  7\n  8\n  9\n  10\n\n\n\n  \n    player_id\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    session_id\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    session_start\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    time\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    item_type\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    item_name\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    item_revenue\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    session_duration\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    start_day\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    acquisition\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n  \n    country\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n\n  \n  \n  \n    NO MISSING VALUES     PROPORTION MISSING:  0%100%ROW SECTORS1 – 200201 – 400401 – 600601 – 800801 – 10001001 – 12001201 – 14001401 – 16001601 – 18001801 – 2000\n  \n\n\n\n\n\n\n        \n\n\nWe see nothing but light blue in this report! The header also indicates that there are no missing values by displaying a large green check mark (the other report tables provided a count of total missing values across all columns).",
    "crumbs": [
      "Get Started",
      "Data Inspection",
      "Missing Values Reporting"
    ]
  },
  {
    "objectID": "user-guide/schema-validation.html",
    "href": "user-guide/schema-validation.html",
    "title": "Schema Validation",
    "section": "",
    "text": "Schema validation in Pointblank allows you to verify that your data conforms to an expected structure and type specification. This is particularly useful when ensuring data consistency across systems or validating incoming data against predefined requirements.\nLet’s first look at the dataset we’ll use for the first example:\nimport pointblank as pb\n\n# Preview the small_table dataset we'll use throughout this guide\npb.preview(pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"))\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows13Columns8\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05\n    6\n    8-kdg-938\n    3\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    None\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09\n    8\n    3-ldm-038\n    7\n    283.94\n    True\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26\n    4\n    2-dmx-010\n    7\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28\n    2\n    7-dmx-010\n    8\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30\n    1\n    3-dka-303\n    None\n    2230.09\n    True\n    high",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Schema Validation"
    ]
  },
  {
    "objectID": "user-guide/schema-validation.html#schema-definition-and-validation",
    "href": "user-guide/schema-validation.html#schema-definition-and-validation",
    "title": "Schema Validation",
    "section": "Schema Definition and Validation",
    "text": "Schema Definition and Validation\nA schema in Pointblank is created using the Schema class which defines the expected structure of a table. Once created, you apply schema validation through the col_schema_match() validation step.\n\n# Create a schema definition matching small_table structure\nschema = pb.Schema(\n    columns=[\n        (\"date_time\",),   # Only check column name\n        (\"date\",),        # Only check column name\n        (\"a\", \"Int64\"),   # Check name and type\n        (\"b\", \"String\"),  # Check name and type\n        (\"c\", \"Int64\"),   # Check name and type\n        (\"d\", \"Float64\"), # Check name and type\n        (\"e\", \"Boolean\"), # Check name and type\n        (\"f\",),           # Only check column name\n    ]\n)\n\n# Validate the small_table against the schema\nsmall_table_validation = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"),\n        label=\"Schema validation of `small_table`.\",\n    )\n    .col_schema_match(schema=schema)\n    .interrogate()\n)\n\nsmall_table_validation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Schema validation of `small_table`.Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_schema_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            col_schema_match()\n        \n        \n        \n    —\n    SCHEMA\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe output shows the validation passed successfully. When all columns have the correct names and types as specified in the schema, the validation passes with a single passing test unit. If there were discrepancies, this would fail, but the basic output wouldn’t show specific issues.\nFor detailed information about validation results, use get_step_report():\n\nsmall_table_validation.get_step_report(i=1)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 1 ✓COLUMN SCHEMA MATCHCOMPLETEIN ORDERCOLUMN ≠ columnDTYPE ≠ dtypefloat ≠ float64\n  \n\n  \n    TARGET\n  \n  \n    EXPECTED\n  \n\n\n  \n  COLUMN\n  DATA TYPE\n  \n  COLUMN\n  \n  DATA TYPE\n  \n\n\n\n  \n    1\n    date_time\n    Datetime(time_unit='us', time_zone=None)\n    1\n    date_time\n    ✓\n    —\n    \n  \n  \n    2\n    date\n    Date\n    2\n    date\n    ✓\n    —\n    \n  \n  \n    3\n    a\n    Int64\n    3\n    a\n    ✓\n    Int64\n    ✓\n  \n  \n    4\n    b\n    String\n    4\n    b\n    ✓\n    String\n    ✓\n  \n  \n    5\n    c\n    Int64\n    5\n    c\n    ✓\n    Int64\n    ✓\n  \n  \n    6\n    d\n    Float64\n    6\n    d\n    ✓\n    Float64\n    ✓\n  \n  \n    7\n    e\n    Boolean\n    7\n    e\n    ✓\n    Boolean\n    ✓\n  \n  \n    8\n    f\n    String\n    8\n    f\n    ✓\n    —\n    \n  \n\n  \n  \n  \n    Supplied Column Schema:[('date_time',), ('date',), ('a', 'Int64'), ('b', 'String'), ('c', 'Int64'), ('d', 'Float64'), ('e', 'Boolean'), ('f',)]\n  \n\n\n\n\n\n\n        \n\n\nThe step report provides specific details about which columns were checked and whether they matched the schema, helping diagnose issues when validation fails.",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Schema Validation"
    ]
  },
  {
    "objectID": "user-guide/schema-validation.html#schema-components-and-column-types",
    "href": "user-guide/schema-validation.html#schema-components-and-column-types",
    "title": "Schema Validation",
    "section": "Schema Components and Column Types",
    "text": "Schema Components and Column Types\nWhen defining a schema, you need to specify column names and optionally their data types. By default, Pointblank enforces strict validation where:\n\nall columns in your table must match the specified schema\ncolumn order must match the schema\ncolumn types are case-sensitive\ntype names must match exactly\n\nThe schema definition accepts column types as string representations, which vary depending on your data source:\n\nstring: Character data (may also be \"String\", \"varchar\", \"character\", etc.)\ninteger: Integer values (may also be \"Int64\", \"int\", \"bigint\", etc.)\nnumeric: Numeric values including integers and floating-point numbers (may also be \"Float64\", \"double\", \"decimal\", etc.)\nboolean: Logical values (True/False) (may also be \"Boolean\", \"bool\", etc.)\ndatetime: Date and time values (may also be \"Datetime\", \"timestamp\", etc.)\ndate: Date values (may also be \"Date\", etc.)\ntime: Time values\n\nFor specific database engines or DataFrame libraries, you may need to use their exact type names (like \"VARCHAR(255)\" for SQL databases or \"Int64\" for Polars integers).",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Schema Validation"
    ]
  },
  {
    "objectID": "user-guide/schema-validation.html#discovering-column-types",
    "href": "user-guide/schema-validation.html#discovering-column-types",
    "title": "Schema Validation",
    "section": "Discovering Column Types",
    "text": "Discovering Column Types\nTo easily determine the correct type string for columns in your data, Pointblank provides two helpful functions:\n\nimport polars as pl\nfrom datetime import date\n\n# Define a sample dataframe\nsample_df = pl.DataFrame({\n    \"id\": [1, 2, 3],\n    \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n    \"join_date\": [date(2020, 1, 1), date(2021, 3, 15), date(2022, 7, 10)]\n})\n\n\n# Method 1: Using `preview()` with `show_types=True` to see column types\npb.preview(sample_df)\n\n\n\n\n\n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows3Columns3\n  \n\n  \n  idInt64\n  nameString\n  join_dateDate\n\n\n\n  \n    1\n    1\n    Alice\n    2020-01-01\n  \n  \n    2\n    2\n    Bob\n    2021-03-15\n  \n  \n    3\n    3\n    Charlie\n    2022-07-10\n  \n\n\n\n\n\n\n        \n\n\n\n# Method 2: Using `col_summary_tbl()` which shows column types and other details\npb.col_summary_tbl(sample_df)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows3Columns3\n  \n\n  \n  Column\n  NA\n  UQ\n  Mean\n  SD\n  Min\n  P5\n  Q1\n  Med\n  Q3\n  P95\n  Max\n  IQR\n\n\n\n  \n    \n    numeric\n    \n        \n            \n            \n                \n            \n        \n    \n\n    idInt64\n    00\n    31\n    2\n    1\n    1\n    1.01\n    1.5\n    2\n    2.5\n    2.9\n    3\n    1\n  \n  \n    \n    string\n    \n        \n            \n            \n                \n            \n        \n    \n\n    nameString\n    00\n    31\n    5\n    2\n    3\n    3.02\n    4\n    5\n    6\n    6.8\n    7\n    2\n  \n  \n    \n    date\n    \n        \n            \n            \n                \n            \n        \n    \n\n    join_dateDate\n    00\n    31\n    -\n    -\n    20200101\n    -\n    -\n    -\n    -\n    -\n    20220710\n    -\n  \n\n  \n  \n  \n    String columns statistics regard the string's length.\n  \n\n\n\n\n\n\n        \n\n\nThese functions help you identify the exact type strings to use in your schema definitions, eliminating guesswork and ensuring compatibility with your data source.",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Schema Validation"
    ]
  },
  {
    "objectID": "user-guide/schema-validation.html#creating-a-schema",
    "href": "user-guide/schema-validation.html#creating-a-schema",
    "title": "Schema Validation",
    "section": "Creating a Schema",
    "text": "Creating a Schema\nYou can create a schema in four different ways, each with its own advantages. All schema objects can be printed to display their column names and data types.\n\n1. Using a List of Tuples with columns=\nThis approach allows for mixed validation: some columns checked for both name and type, others only for name:\n\nschema_tuples = pb.Schema(\n\n    # List of tuples approach: flexible for mixed type/name checking ---\n    columns=[\n        (\"name\", \"String\"), # Check name and type\n        (\"age\", \"Int64\"),   # Check name and type\n        (\"height\",)         # Check name only\n    ]\n)\n\nprint(schema_tuples)\n\nPointblank Schema\n  name: String\n  age: Int64\n  height: &lt;ANY&gt;\n\n\nThis is the only method that allows checking just column names for some columns while checking both names and types for others.\n\n\n2. Using a Dictionary with columns=\nThis approach is often the most readable when defining a schema manually, especially for larger schemas:\n\nschema_dict = pb.Schema(\n\n    # Dictionary approach (keys are column names, values are data types) ---\n    columns={\n        \"name\": \"String\",\n        \"age\": \"Int64\",\n        \"height\": \"Float64\",\n        \"created_at\": \"Datetime\"\n    }\n)\n\nprint(schema_dict)\n\nPointblank Schema\n  name: String\n  age: Int64\n  height: Float64\n  created_at: Datetime\n\n\nWith this method, you must always provide both column names (as keys) and their types (as values).\n\n\n3. Using Keyword Arguments\nFor more readable code with a small number of columns:\n\nschema_kwargs = pb.Schema(\n\n    # Keyword arguments approach (more readable for simple schemas) ---\n    name=\"String\",\n    age=\"Int64\",\n    height=\"Float64\"\n)\n\nprint(schema_kwargs)\n\nPointblank Schema\n  name: String\n  age: Int64\n  height: Float64\n\n\nLike the dictionary method, this approach requires both column names and types.\n\n\n4. Extracting from an Existing Table with tbl=\nYou can automatically extract a schema from an existing table:\n\nimport polars as pl\n\n# Create a sample dataframe\ndf = pl.DataFrame({\n    \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n    \"age\": [25, 30, 35],\n    \"height\": [5.6, 6.0, 5.8]\n})\n\n# Extract schema from table\nschema_from_table = pb.Schema(tbl=df)\n\nprint(schema_from_table)\n\nPointblank Schema\n  name: String\n  age: Int64\n  height: Float64\n\n\nThis is especially useful when you want to validate that future data matches the structure of a reference dataset.",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Schema Validation"
    ]
  },
  {
    "objectID": "user-guide/schema-validation.html#multiple-data-types-for-a-column",
    "href": "user-guide/schema-validation.html#multiple-data-types-for-a-column",
    "title": "Schema Validation",
    "section": "Multiple Data Types for a Column",
    "text": "Multiple Data Types for a Column\nYou can specify multiple acceptable types for a column by providing a list of types:\n\n# Schema with multiple possible types for a column\nschema_multi_types = pb.Schema(\n    columns={\n        \"name\": \"String\",\n        \"age\": [\"Int64\", \"Float64\"],  # Accept either integer or float\n        \"active\": \"Boolean\"\n    }\n)\n\nprint(schema_multi_types)\n\nPointblank Schema\n  name: String\n  age: ['Int64', 'Float64']\n  active: Boolean\n\n\nThis is useful when working with data sources that might represent the same information in different ways (e.g., integers sometimes stored as floats).",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Schema Validation"
    ]
  },
  {
    "objectID": "user-guide/schema-validation.html#schema-validation-options",
    "href": "user-guide/schema-validation.html#schema-validation-options",
    "title": "Schema Validation",
    "section": "Schema Validation Options",
    "text": "Schema Validation Options\nWhen using col_schema_match(), you can customize validation behavior with several important options:\n\n\n\n\n\n\n\n\nOption\nDefault\nDescription\n\n\n\n\ncomplete\nTrue\nRequire exact column presence (no extra columns allowed)\n\n\nin_order\nTrue\nEnforce column order\n\n\ncase_sensitive_colnames\nTrue\nMake column name matching case-sensitive\n\n\ncase_sensitive_dtypes\nTrue\nMake data type matching case-sensitive\n\n\nfull_match_dtypes\nTrue\nRequire exact (not partial) type name matches\n\n\n\n\nControlling Column Presence\nBy default, col_schema_match() requires a complete match between the schema’s columns and the table’s columns. You can make this more flexible:\n\n# Create a sample table\nusers_table_extra = pl.DataFrame({\n    \"id\": [1, 2, 3],\n    \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n    \"age\": [25, 30, 35],\n    \"extra_col\": [\"a\", \"b\", \"c\"]  # Extra column not in schema\n})\n\n# Create a schema\nschema = pb.Schema(\n    columns={\"id\": \"Int64\", \"name\": \"String\", \"age\": \"Int64\"}\n)\n\n# Validate without requiring all columns to be present\nvalidation = (\n    pb.Validate(data=users_table_extra)\n    .col_schema_match(\n        schema=schema,\n\n        # Allow schema columns to be a subset ---\n        complete=False\n    )\n    .interrogate()\n)\n\nvalidation.get_step_report(i=1)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 1 ✓COLUMN SCHEMA MATCHCOMPLETEIN ORDERCOLUMN ≠ columnDTYPE ≠ dtypefloat ≠ float64\n  \n\n  \n    TARGET\n  \n  \n    EXPECTED\n  \n\n\n  \n  COLUMN\n  DATA TYPE\n  \n  COLUMN\n  \n  DATA TYPE\n  \n\n\n\n  \n    1\n    id\n    Int64\n    1\n    id\n    ✓\n    Int64\n    ✓\n  \n  \n    2\n    name\n    String\n    2\n    name\n    ✓\n    String\n    ✓\n  \n  \n    3\n    age\n    Int64\n    3\n    age\n    ✓\n    Int64\n    ✓\n  \n  \n    4\n    extra_col\n    String\n    \n    \n    \n    \n    \n  \n\n  \n  \n  \n    Supplied Column Schema:[('id', 'Int64'), ('name', 'String'), ('age', 'Int64')]\n  \n\n\n\n\n\n\n        \n\n\n\n\nColumn Order Enforcement\nYou can control whether column order matters in your validation:\n\n# Create a sample table\nusers_table = pl.DataFrame({\n    \"id\": [1, 2, 3],\n    \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n    \"age\": [25, 30, 35],\n})\n\n# Create a schema\nschema = pb.Schema(\n    columns={\"name\": \"String\", \"age\": \"Int64\", \"id\": \"Int64\"}\n)\n\n# Validate without enforcing column order\nvalidation = (\n    pb.Validate(data=users_table)\n    .col_schema_match(\n        schema=schema,\n\n        # Don't enforce column order ---\n        in_order=False\n    )\n    .interrogate()\n)\n\nvalidation.get_step_report(i=1)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 1 ✓COLUMN SCHEMA MATCHCOMPLETEIN ORDERCOLUMN ≠ columnDTYPE ≠ dtypefloat ≠ float64\n  \n\n  \n    TARGET\n  \n  \n    EXPECTED\n  \n\n\n  \n  COLUMN\n  DATA TYPE\n  \n  COLUMN\n  \n  DATA TYPE\n  \n\n\n\n  \n    1\n    id\n    Int64\n    3\n    id\n    ✓\n    Int64\n    ✓\n  \n  \n    2\n    name\n    String\n    1\n    name\n    ✓\n    String\n    ✓\n  \n  \n    3\n    age\n    Int64\n    2\n    age\n    ✓\n    Int64\n    ✓\n  \n\n  \n  \n  \n    Supplied Column Schema:[('name', 'String'), ('age', 'Int64'), ('id', 'Int64')]\n  \n\n\n\n\n\n\n        \n\n\n\n\nCase Sensitivity\nControl whether column names and data types are case-sensitive:\n\n# Create schema with different case charactistics\ncase_schema = pb.Schema(\n    columns={\"ID\": \"int64\", \"NAME\": \"string\", \"AGE\": \"int64\"}\n)\n\n# Create validation with case-insensitive column names and types\nvalidation = (\n    pb.Validate(data=users_table)\n    .col_schema_match(\n        schema=case_schema,\n\n        # Ignore case in column names ---\n        case_sensitive_colnames=False,\n\n        # Ignore case in data type names ---\n        case_sensitive_dtypes=False\n    )\n    .interrogate()\n)\n\nvalidation.get_step_report(i=1)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 1 ✓COLUMN SCHEMA MATCHCOMPLETEIN ORDERCOLUMN = columnDTYPE = dtypefloat ≠ float64\n  \n\n  \n    TARGET\n  \n  \n    EXPECTED\n  \n\n\n  \n  COLUMN\n  DATA TYPE\n  \n  COLUMN\n  \n  DATA TYPE\n  \n\n\n\n  \n    1\n    id\n    Int64\n    1\n    ID\n    ✓\n    int64\n    ✓\n  \n  \n    2\n    name\n    String\n    2\n    NAME\n    ✓\n    string\n    ✓\n  \n  \n    3\n    age\n    Int64\n    3\n    AGE\n    ✓\n    int64\n    ✓\n  \n\n  \n  \n  \n    Supplied Column Schema:[('ID', 'int64'), ('NAME', 'string'), ('AGE', 'int64')]\n  \n\n\n\n\n\n\n        \n\n\n\n\nType Matching Precision\nControl how strictly data types must match:\n\n# Create schema with simplified type names\ntype_schema = pb.Schema(\n\n    # Using simplified type names ---\n    columns={\"id\": \"int\", \"name\": \"str\", \"age\": \"int\"}\n)\n\n# Allow partial type matches\nvalidation = (\n    pb.Validate(data=users_table)\n    .col_schema_match(\n        schema=type_schema,\n\n        # Ignore case in data type names ---\n        case_sensitive_dtypes=False,\n\n        # Allow partial type name matches ---\n        full_match_dtypes=False\n    )\n    .interrogate()\n)\n\nvalidation.get_step_report(i=1)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 1 ✓COLUMN SCHEMA MATCHCOMPLETEIN ORDERCOLUMN ≠ columnDTYPE = dtypefloat = float64\n  \n\n  \n    TARGET\n  \n  \n    EXPECTED\n  \n\n\n  \n  COLUMN\n  DATA TYPE\n  \n  COLUMN\n  \n  DATA TYPE\n  \n\n\n\n  \n    1\n    id\n    Int64\n    1\n    id\n    ✓\n    int\n    ✓\n  \n  \n    2\n    name\n    String\n    2\n    name\n    ✓\n    str\n    ✓\n  \n  \n    3\n    age\n    Int64\n    3\n    age\n    ✓\n    int\n    ✓\n  \n\n  \n  \n  \n    Supplied Column Schema:[('id', 'int'), ('name', 'str'), ('age', 'int')]",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Schema Validation"
    ]
  },
  {
    "objectID": "user-guide/schema-validation.html#common-schema-validation-patterns",
    "href": "user-guide/schema-validation.html#common-schema-validation-patterns",
    "title": "Schema Validation",
    "section": "Common Schema Validation Patterns",
    "text": "Common Schema Validation Patterns\nThis section explores common patterns for applying schema validation to different scenarios. Each pattern addresses specific validation needs you might encounter when working with real-world data. We’ll examine the step reports for these validations since they provide more detailed information about what was checked and how the validation performed, offering an intuitive way to understand the results beyond simple pass/fail indicators.",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Schema Validation"
    ]
  },
  {
    "objectID": "user-guide/schema-validation.html#common-schema-validation-patterns-1",
    "href": "user-guide/schema-validation.html#common-schema-validation-patterns-1",
    "title": "Schema Validation",
    "section": "Common Schema Validation Patterns",
    "text": "Common Schema Validation Patterns\nThis section explores common patterns for applying schema validation to different scenarios. Each pattern addresses specific validation needs you might encounter when working with real-world data. We’ll examine the step reports (get_step_report()) for these validations since they provide more detailed information about what was checked and how the validation performed, offering an intuitive way to understand the results beyond simple pass/fail indicators.\n\nStructural Validation Only\nWhen you only care about column names but not their types:\n\n# Create a schema with only column names\nstructure_schema = pb.Schema(\n    columns=[\"id\", \"name\", \"age\", \"extra_col\"]\n)\n\n# Validate structure only\nvalidation = (\n    pb.Validate(data=users_table_extra)\n    .col_schema_match(schema=structure_schema)\n    .interrogate()\n)\n\nvalidation.get_step_report(i=1)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 1 ✓COLUMN SCHEMA MATCHCOMPLETEIN ORDERCOLUMN ≠ columnDTYPE ≠ dtypefloat ≠ float64\n  \n\n  \n    TARGET\n  \n  \n    EXPECTED\n  \n\n\n  \n  COLUMN\n  DATA TYPE\n  \n  COLUMN\n  \n  DATA TYPE\n  \n\n\n\n  \n    1\n    id\n    Int64\n    1\n    id\n    ✓\n    —\n    \n  \n  \n    2\n    name\n    String\n    2\n    name\n    ✓\n    —\n    \n  \n  \n    3\n    age\n    Int64\n    3\n    age\n    ✓\n    —\n    \n  \n  \n    4\n    extra_col\n    String\n    4\n    extra_col\n    ✓\n    —\n    \n  \n\n  \n  \n  \n    Supplied Column Schema:[('id',), ('name',), ('age',), ('extra_col',)]\n  \n\n\n\n\n\n\n        \n\n\n\n\nMixed Validation\nValidate types for critical columns but just presence for others:\n\n# Mixed validation for different columns\nmixed_schema = pb.Schema(\n    columns=[\n        (\"id\", \"Int64\"),     # Check name and type\n        (\"name\", \"String\"),  # Check name and type\n        (\"age\",),            # Check name only\n        (\"extra_col\",)       # Check name only\n    ]\n)\n\n# Validate with mixed approach\nvalidation = (\n    pb.Validate(data=users_table_extra)\n    .col_schema_match(schema=mixed_schema)\n    .interrogate()\n)\n\nvalidation.get_step_report(i=1)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 1 ✓COLUMN SCHEMA MATCHCOMPLETEIN ORDERCOLUMN ≠ columnDTYPE ≠ dtypefloat ≠ float64\n  \n\n  \n    TARGET\n  \n  \n    EXPECTED\n  \n\n\n  \n  COLUMN\n  DATA TYPE\n  \n  COLUMN\n  \n  DATA TYPE\n  \n\n\n\n  \n    1\n    id\n    Int64\n    1\n    id\n    ✓\n    Int64\n    ✓\n  \n  \n    2\n    name\n    String\n    2\n    name\n    ✓\n    String\n    ✓\n  \n  \n    3\n    age\n    Int64\n    3\n    age\n    ✓\n    —\n    \n  \n  \n    4\n    extra_col\n    String\n    4\n    extra_col\n    ✓\n    —\n    \n  \n\n  \n  \n  \n    Supplied Column Schema:[('id', 'Int64'), ('name', 'String'), ('age',), ('extra_col',)]\n  \n\n\n\n\n\n\n        \n\n\n\n\nProgressive Schema Evolution\nAs your data evolves, you might need to adapt your validation approach:\n\n# Original schema\noriginal_schema = pb.Schema(\n    columns={\n        \"id\": \"Int64\",\n        \"name\": \"String\"\n    }\n)\n\n# New data with additional columns\nevolved_data = pl.DataFrame({\n    \"id\": [1, 2, 3],\n    \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n    \"age\": [25, 30, 35],           # New column\n    \"active\": [True, False, True]  # New column\n})\n\n# Validate with flexible parameters\nvalidation = (\n    pb.Validate(evolved_data)\n    .col_schema_match(\n        schema=original_schema,\n\n        # Allow extra columns ---\n        complete=False,\n\n        # Don't enforce order ---\n        in_order=False\n    )\n    .interrogate()\n)\n\nvalidation.get_step_report(i=1)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 1 ✓COLUMN SCHEMA MATCHCOMPLETEIN ORDERCOLUMN ≠ columnDTYPE ≠ dtypefloat ≠ float64\n  \n\n  \n    TARGET\n  \n  \n    EXPECTED\n  \n\n\n  \n  COLUMN\n  DATA TYPE\n  \n  COLUMN\n  \n  DATA TYPE\n  \n\n\n\n  \n    1\n    id\n    Int64\n    1\n    id\n    ✓\n    Int64\n    ✓\n  \n  \n    2\n    name\n    String\n    2\n    name\n    ✓\n    String\n    ✓\n  \n  \n    3\n    age\n    Int64\n    \n    \n    \n    \n    \n  \n  \n    4\n    active\n    Boolean\n    \n    \n    \n    \n    \n  \n\n  \n  \n  \n    Supplied Column Schema:[('id', 'Int64'), ('name', 'String')]",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Schema Validation"
    ]
  },
  {
    "objectID": "user-guide/schema-validation.html#integrating-with-larger-validation-workflows",
    "href": "user-guide/schema-validation.html#integrating-with-larger-validation-workflows",
    "title": "Schema Validation",
    "section": "Integrating with Larger Validation Workflows",
    "text": "Integrating with Larger Validation Workflows\nSchema validation is often just one part of a comprehensive data validation strategy. You can combine schema checks with other validation steps:\n\n# Define a schema\nschema = pb.Schema(\n    columns={\n        \"id\": \"Int64\",\n        \"name\": \"String\",\n        \"age\": \"Int64\"\n    }\n)\n\n# Create a validation plan\nvalidation = (\n    pb.Validate(\n        users_table,\n        label=\"User data validation\",\n        thresholds=pb.Thresholds(warning=0.05, error=0.1)\n    )\n\n    # Add schema validation ---\n    .col_schema_match(schema=schema)\n\n    # Add other validation steps ---\n    .col_vals_not_null(columns=\"id\")\n    .col_vals_gt(columns=\"age\", value=26)\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    User data validationPolarsWARNING0.05ERROR0.1CRITICAL—\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_schema_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            col_schema_match()\n        \n        \n        \n    —\n    SCHEMA\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    ○\n    ○\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    id\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    31.00\n    00.00\n    ○\n    ○\n    —\n    —\n  \n  \n    #EBBC14\n    3\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    age\n    26\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    3\n    20.67\n    10.33\n    ●\n    ●\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThis approach allows you to first validate the structure of your data and then check specific business rules or constraints.",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Schema Validation"
    ]
  },
  {
    "objectID": "user-guide/schema-validation.html#best-practices",
    "href": "user-guide/schema-validation.html#best-practices",
    "title": "Schema Validation",
    "section": "Best Practices",
    "text": "Best Practices\n\nDefine schemas early: document and define expected data structures early in your data workflow.\nChoose the right creation method:\n\nuse columns=&lt;dict&gt; for readability with many columns\nuse columns=&lt;list of tuples&gt; for mixed name/type validation\nuse kwargs for small schemas with simple column names\nuse tbl= to extract schemas from reference datasets\n\nBe deliberate about strictness: choose validation parameters based on your specific needs:\n\nstrict validation (complete=True) for critical data interfaces\nflexible validation (complete=False, in_order=False) for evolving datasets\n\nReuse schemas: create schema definitions that can be reused across multiple validation contexts.\nVersion control schemas: as your data evolves, maintain versions of your schemas to track changes.\nExtract schemas from reference data: when you have a ‘golden’ dataset that represents your ideal structure, use Schema(tbl=reference_data) to extract its schema.\nConsider type flexibility: use multiple types per column ([\"Int64\", \"Float64\"]) when working with data from diverse sources.\nCombine with targeted validation: use schema validation for structural checks and add specific validation steps for business rules.",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Schema Validation"
    ]
  },
  {
    "objectID": "user-guide/schema-validation.html#conclusion",
    "href": "user-guide/schema-validation.html#conclusion",
    "title": "Schema Validation",
    "section": "Conclusion",
    "text": "Conclusion\nSchema validation provides a powerful mechanism for ensuring your data adheres to expected structural requirements. It serves as an excellent first line of defense in your data validation strategy, verifying that the data you’re working with has the expected shape before applying more detailed business rule validations.\nThe Schema class offers multiple ways to define schemas, from manual specification with dictionaries or keyword arguments to automatic extraction from reference tables. When combined with the flexible options of col_schema_match(), you can implement validation approaches ranging from strict structural enforcement to more flexible evolution-friendly checks.\nBy understanding the different schema creation methods and validation options, you can efficiently validate the structure of your data tables and ensure they meet your requirements before processing.",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Schema Validation"
    ]
  },
  {
    "objectID": "user-guide/expressions.html",
    "href": "user-guide/expressions.html",
    "title": "Expression-Based Validation",
    "section": "",
    "text": "While Pointblank offers many specialized validation functions for common data quality checks, sometimes you need more flexibility for complex validation requirements. This is where expression-based validation with col_vals_expr() comes in.\nThe col_vals_expr() method allows you to:\nNow let’s explore how to use these capabilities through a collection of examples!",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Expression-Based Validation"
    ]
  },
  {
    "objectID": "user-guide/expressions.html#basic-usage",
    "href": "user-guide/expressions.html#basic-usage",
    "title": "Expression-Based Validation",
    "section": "Basic Usage",
    "text": "Basic Usage\nAt its core, col_vals_expr() validates whether an expression evaluates to True for each row in your data. Here’s a simple example:\n\nimport pointblank as pb\nimport polars as pl\n\n# Load small_table dataset as a Polars DataFrame\nsmall_table_pl = pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\")\n\n(\n    pb.Validate(data=small_table_pl)\n    .col_vals_expr(\n\n        # Use Polars expression syntax ---\n        expr=pl.col(\"d\") &gt; pl.col(\"a\") * 50,\n        brief=\"Column `d` should be at least 50 times larger than `a`.\"\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:18:00Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_expr\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_expr()\n        \n        Column d should be at least 50 times larger than a.\n\n        \n    —\n    COLUMN EXPR\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    120.92\n    10.08\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nIn this example, we’re validating that for each row, the value in column d is at least 50 times larger than the value in column a.",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Expression-Based Validation"
    ]
  },
  {
    "objectID": "user-guide/expressions.html#notes-on-expression-syntax",
    "href": "user-guide/expressions.html#notes-on-expression-syntax",
    "title": "Expression-Based Validation",
    "section": "Notes on Expression Syntax",
    "text": "Notes on Expression Syntax\nThe expression syntax depends on your table type:\n\nPolars: uses Polars expression syntax with pl.col(\"column_name\")\nPandas: uses standard Python/NumPy syntax\n\nThe expression should:\n\nevaluate to a boolean result for each row\nreference columns using the appropriate syntax for your table type\nuse standard operators (+, -, *, /, &gt;, &lt;, ==, etc.)\nnot include assignments",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Expression-Based Validation"
    ]
  },
  {
    "objectID": "user-guide/expressions.html#complex-expressions",
    "href": "user-guide/expressions.html#complex-expressions",
    "title": "Expression-Based Validation",
    "section": "Complex Expressions",
    "text": "Complex Expressions\nThe real power of col_vals_expr() comes with complex expressions that would be difficult to represent using the standard validation functions:\n\n# Load game_revenue dataset as a Polars DataFrame\ngame_revenue_pl = pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"polars\")\n\n(\n    pb.Validate(data=game_revenue_pl)\n    .col_vals_expr(\n\n        # Use Polars expression syntax ---\n        expr=(pl.col(\"session_duration\") &gt; 20) | (pl.col(\"item_revenue\") &gt; 10),\n        brief=\"Sessions should be either long (&gt;20 min) or high-value (&gt;$10).\"\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:18:00Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_expr\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_expr()\n        \n        Sessions should be either long (&gt;20 min) or high-value (&gt;$10).\n\n        \n    —\n    COLUMN EXPR\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    15180.76\n    4820.24\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThis validates that either the session duration is longer than 20 minutes OR the item revenue is greater than $10.",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Expression-Based Validation"
    ]
  },
  {
    "objectID": "user-guide/expressions.html#example-multiple-conditions",
    "href": "user-guide/expressions.html#example-multiple-conditions",
    "title": "Expression-Based Validation",
    "section": "Example: Multiple Conditions",
    "text": "Example: Multiple Conditions\nYou can create sophisticated validations with multiple conditions:\n\n# Create a simple Polars DataFrame\nemployee_df = pl.DataFrame({\n    \"age\": [25, 30, 15, 40, 35],\n    \"income\": [50000, 75000, 0, 100000, 60000],\n    \"years_experience\": [3, 8, 0, 15, 7]\n})\n\n(\n    pb.Validate(data=employee_df, tbl_name=\"employee_data\")\n    .col_vals_expr(\n\n        # Complex condition with multiple comparisons ---\n        expr=(\n            (pl.col(\"age\") &gt;= 18) &\n            (pl.col(\"income\") / (pl.col(\"years_experience\") + 1) &lt;= 25000)\n        ),\n        brief=\"Adults should have reasonable income-to-experience ratios.\"\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:18:00Polarsemployee_data\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_expr\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_expr()\n        \n        Adults should have reasonable income-to-experience ratios.\n\n        \n    —\n    COLUMN EXPR\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    40.80\n    10.20\n    —\n    —\n    —\n    CSV",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Expression-Based Validation"
    ]
  },
  {
    "objectID": "user-guide/expressions.html#example-handling-null-values",
    "href": "user-guide/expressions.html#example-handling-null-values",
    "title": "Expression-Based Validation",
    "section": "Example: Handling Null Values",
    "text": "Example: Handling Null Values\nWhen working with expressions, consider how to handle null/missing values:\n\n(\n    pb.Validate(data=small_table_pl)\n    .col_vals_expr(\n\n        # Check for nulls before division ---\n        expr=(pl.col(\"c\").is_not_null()) & ((pl.col(\"c\") / pl.col(\"a\")) &gt; 1.5),\n        brief=\"Ratio of `c`/`a` should exceed 1.5 (when `c` is not null).\"\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:18:00Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_expr\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_expr()\n        \n        Ratio of c/a should exceed 1.5 (when c is not null).\n\n        \n    —\n    COLUMN EXPR\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    50.38\n    80.62\n    —\n    —\n    —\n    CSV",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Expression-Based Validation"
    ]
  },
  {
    "objectID": "user-guide/expressions.html#best-practices",
    "href": "user-guide/expressions.html#best-practices",
    "title": "Expression-Based Validation",
    "section": "Best Practices",
    "text": "Best Practices\nHere are some tips and tricks for effectively using expression-based validation with col_vals_expr().\n\nDocument Your Expressions\nAlways provide clear documentation in the brief= parameter:\n\n(\n    pb.Validate(data=small_table_pl)\n    .col_vals_expr(\n        expr=pl.col(\"d\") &gt; pl.col(\"a\") * 1.5,\n\n        # Document which columns are being compared ---\n        brief=\"Column `d` should be at least 1.5 times larger than column `a`.\"\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:18:00Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_expr\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_expr()\n        \n        Column d should be at least 1.5 times larger than column a.\n\n        \n    —\n    COLUMN EXPR\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\n\n\nHandle Edge Cases\nConsider potential edge cases like division by zero or nulls:\n\n(\n    pb.Validate(data=small_table_pl)\n    .col_vals_expr(\n\n        # Check denominator before division ---\n        expr=(pl.col(\"a\") != 0) & (pl.col(\"d\") / pl.col(\"a\") &gt; 1.5),\n        brief=\"Ratio of `d`/`a` should exceed 1.5 (avoiding division by zero).\"\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:18:00Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_expr\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_expr()\n        \n        Ratio of d/a should exceed 1.5 (avoiding division by zero).\n\n        \n    —\n    COLUMN EXPR\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\n\n\nTest on Small Datasets First\nWhen developing complex expressions, test on a small sample of your data first to ensure your logic is correct before applying it to large datasets.",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Expression-Based Validation"
    ]
  },
  {
    "objectID": "user-guide/expressions.html#conclusion",
    "href": "user-guide/expressions.html#conclusion",
    "title": "Expression-Based Validation",
    "section": "Conclusion",
    "text": "Conclusion\nThe col_vals_expr() method provides a powerful way to implement complex validation logic in Pointblank when standard validation methods aren’t sufficient. By leveraging expressions, you can create sophisticated data quality checks tailored to your specific requirements, combining conditions across multiple columns and applying transformations as needed.\nThis flexibility makes expression-based validation an essential tool for addressing complex data quality scenarios in your validation workflows.",
    "crumbs": [
      "Get Started",
      "Advanced Validation",
      "Expression-Based Validation"
    ]
  },
  {
    "objectID": "user-guide/column-selection-patterns.html",
    "href": "user-guide/column-selection-patterns.html",
    "title": "Column Selection Patterns",
    "section": "",
    "text": "Data validation often requires working with columns in flexible ways. Pointblank offers two powerful approaches:\nThis guide covers both approaches in detail with practical examples.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Column Selection Patterns"
    ]
  },
  {
    "objectID": "user-guide/column-selection-patterns.html#part-1-applying-rules-across-multiple-columns",
    "href": "user-guide/column-selection-patterns.html#part-1-applying-rules-across-multiple-columns",
    "title": "Column Selection Patterns",
    "section": "Part 1: Applying Rules Across Multiple Columns",
    "text": "Part 1: Applying Rules Across Multiple Columns\nMany of Pointblank’s validation methods perform column-level checks. These methods provide the columns= parameter, which accepts not just a single column name but multiple columns through various selection methods.\nWhy is this useful? Often you’ll want to perform the same validation check (e.g., checking that numerical values are all positive) across multiple columns. Rather than defining the same rules multiple times, you can map the validation across those columns in a single step.\nLet’s explore this using the game_revenue dataset:\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows2,000Columns11\n  \n\n  \n  player_idString\n  session_idString\n  session_startDatetime\n  timeDatetime\n  item_typeString\n  item_nameString\n  item_revenueFloat64\n  session_durationFloat64\n  start_dayDate\n  acquisitionString\n  countryString\n\n\n\n  \n    1\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:31:27+00:00\n    iap\n    offer2\n    8.99\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    2\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:36:57+00:00\n    iap\n    gems3\n    22.49\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    3\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:37:45+00:00\n    iap\n    gold7\n    107.99\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    4\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:42:33+00:00\n    ad\n    ad_20sec\n    0.76\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    5\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-hdu9jkls\n    2015-01-01 11:50:02+00:00\n    2015-01-01 11:55:20+00:00\n    ad\n    ad_5sec\n    0.03\n    35.2\n    2015-01-01\n    google\n    Germany\n  \n  \n    1996\n    NAOJRDMCSEBI281\n    NAOJRDMCSEBI281-j2vs9ilp\n    2015-01-21 01:57:50+00:00\n    2015-01-21 02:02:50+00:00\n    ad\n    ad_survey\n    1.332\n    25.8\n    2015-01-11\n    organic\n    Norway\n  \n  \n    1997\n    NAOJRDMCSEBI281\n    NAOJRDMCSEBI281-j2vs9ilp\n    2015-01-21 01:57:50+00:00\n    2015-01-21 02:22:14+00:00\n    ad\n    ad_survey\n    1.35\n    25.8\n    2015-01-11\n    organic\n    Norway\n  \n  \n    1998\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-vbhcsmtr\n    2015-01-21 02:39:48+00:00\n    2015-01-21 02:40:00+00:00\n    ad\n    ad_5sec\n    0.03\n    8.4\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    1999\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-vbhcsmtr\n    2015-01-21 02:39:48+00:00\n    2015-01-21 02:47:12+00:00\n    iap\n    offer5\n    26.09\n    8.4\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    2000\n    GJCXNTWEBIPQ369\n    GJCXNTWEBIPQ369-9elq67md\n    2015-01-21 03:59:23+00:00\n    2015-01-21 04:06:29+00:00\n    ad\n    ad_5sec\n    0.12\n    18.5\n    2015-01-14\n    organic\n    United States\n  \n\n\n\n\n\n\n        \n\n\n\nUsing a List of Column Names\nThe simplest way to validate multiple columns is to provide a list to the columns= parameter. In the game_revenue dataset, we have two columns with numerical data: item_revenue and session_duration. If we expect all values in both columns to be greater than 0, we can write:\n\nimport pointblank as pb\n\n(\n    pb.Validate(data=pb.load_dataset(\"game_revenue\"))\n    .col_vals_gt(\n        columns=[\"item_revenue\", \"session_duration\"],\n        value=0\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    item_revenue\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    session_duration\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe validation report shows two validation steps were created from a single method call! All validation parameters are shared across all generated steps, including thresholds and briefs:\n\n(\n    pb.Validate(data=pb.load_dataset(\"game_revenue\"))\n    .col_vals_gt(\n        columns=[\"item_revenue\", \"session_duration\"],\n        value=0,\n        thresholds=(0.1, 0.2, 0.3),\n        brief=\"`{col}` must be greater than zero.\"\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        item_revenue must be greater than zero.\n\n        \n    item_revenue\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        session_duration must be greater than zero.\n\n        \n    session_duration\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n\n\n\n\n\n\n        \n\n\nIn this example, you can see that the validation report displays customized briefs for each column (“item_revenue must be greater than zero.” and “session_duration must be greater than zero.”), automatically substituting the column name using the {col} placeholder in the brief template. This feature is particularly helpful when reviewing reports, as it provides clear, human-readable descriptions of what each validation step is checking. When working with multiple columns through a single validation call, these dynamically generated briefs make your validation reports more understandable for both technical and non-technical stakeholders.\n\n\nUsing Pointblank’s Column Selectors\nFor more advanced column selection, Pointblank provides selector functions that resolve columns based on:\n\ntext patterns in column names\ncolumn position\ncolumn data type\n\nTwo common selectors, starts_with() and ends_with(), resolve columns based on text patterns in column names.\nThe game_revenue dataset has three columns starting with “item”: item_type, item_name, and item_revenue. Let’s check that these columns contain no missing values:\n\n(\n    pb.Validate(data=pb.load_dataset(\"game_revenue\"))\n    .col_vals_not_null(columns=pb.starts_with(\"item\"))\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    item_type\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    item_name\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    item_revenue\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThree validation steps were automatically created because three columns matched the pattern.\nThe complete list of column selectors includes:\n\nstarts_with()\nends_with()\ncontains()\nmatches()\neverything()\nfirst_n()\nlast_n()\n\n\n\nCombining Column Selectors\nColumn selectors can be combined for more powerful selection. To do this, use the col() helper function with logical operators:\n\n& (and)\n| (or)\n- (difference)\n~ (not)\n\nFor example, to select all columns except the first four:\n\ncol_selection = pb.col(pb.everything() - pb.first_n(4))\n\n(\n    pb.Validate(data=pb.load_dataset(\"game_revenue\"))\n    .col_vals_not_null(\n        columns=col_selection,\n        thresholds=(1, 0.05, 0.1)\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    item_type\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    item_name\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    item_revenue\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    session_duration\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C\n    5\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    start_day\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C\n    6\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    acquisition\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C\n    7\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    country\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n\n\n\n\n\n\n        \n\n\nThis selects every column except the first four, resulting in seven validation steps.\n\n\nNarwhals Selectors\nPointblank also supports column selectors from the Narwhals library, which include:\n\nmatches()\nby_dtype()\nboolean()\ncategorical()\ndatetime()\nnumeric()\nstring()\n\nHere’s an example selecting all numeric columns:\n\nimport narwhals.selectors as ncs\n\n(\n    pb.Validate(data=pb.load_dataset(\"game_revenue\"))\n    .col_vals_gt(\n        columns=ncs.numeric(),\n        value=0\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    item_revenue\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    session_duration\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nAnd selecting all string columns matching “item_”:\n\n(\n    pb.Validate(data=pb.load_dataset(\"game_revenue\"))\n    .col_vals_not_null(columns=pb.col(ncs.string() & ncs.matches(\"item_\")))\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    item_type\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    item_name\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThis example demonstrates the power of combining Narwhals selectors with logical operators. By using ncs.string() to select string columns and then filtering with ncs.matches(\"item_\"), we can precisely target text columns with specific naming patterns. This type of targeted selection is particularly valuable when working with wide datasets that have consistent column naming conventions, allowing you to apply appropriate validation rules to logically grouped columns without explicitly listing each one.\n\n\nCaveats for Using Column Selectors\nWhile column selectors are powerful, there are some caveats. If a selector doesn’t match any columns, the validation won’t fail but will show an ‘explosion’ in the report:\n\n(\n    pb.Validate(data=pb.load_dataset(\"game_revenue\"))\n    .col_vals_not_null(columns=pb.starts_with(\"items\"))\n    .col_vals_gt(columns=\"item_revenue\", value=0)\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    StartsWith(text='items', case_sensitive=False)\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    💥\n    —\n    —\n    —\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    item_revenue\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nNotice that although there was a problem with Step 1 (that should be addressed), the interrogation did move on to Step 2 without complication.\nTo mitigate uncertainty, include validation steps that check for the existence of key columns with col_exists() or verify the schema with col_schema_match().",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Column Selection Patterns"
    ]
  },
  {
    "objectID": "user-guide/column-selection-patterns.html#part-2-comparing-values-between-columns",
    "href": "user-guide/column-selection-patterns.html#part-2-comparing-values-between-columns",
    "title": "Column Selection Patterns",
    "section": "Part 2: Comparing Values Between Columns",
    "text": "Part 2: Comparing Values Between Columns\nSometimes you need to compare values across different columns rather than against fixed values. Pointblank enables this through the col() helper function.\nLet’s look at examples using the small_table dataset:\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows13Columns8\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05\n    6\n    8-kdg-938\n    3\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    None\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09\n    8\n    3-ldm-038\n    7\n    283.94\n    True\n    low\n  \n  \n    6\n    2016-01-11 06:15:00\n    2016-01-11\n    4\n    2-dhe-923\n    4\n    3291.03\n    True\n    mid\n  \n  \n    7\n    2016-01-15 18:46:00\n    2016-01-15\n    7\n    1-knw-093\n    3\n    843.34\n    True\n    high\n  \n  \n    8\n    2016-01-17 11:27:00\n    2016-01-17\n    4\n    5-boe-639\n    2\n    1035.64\n    False\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26\n    4\n    2-dmx-010\n    7\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28\n    2\n    7-dmx-010\n    8\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30\n    1\n    3-dka-303\n    None\n    2230.09\n    True\n    high\n  \n\n\n\n\n\n\n        \n\n\n\nUsing col() to Specify a Comparison Column\nWhile we typically use validation methods to compare column values against fixed values:\n...\n.col_vals_gt(columns=\"a\", value=2, ...)\n...\nWe can also compare values between columns by using col() in the value= parameter:\n...\n.col_vals_gt(columns=\"a\", value=pb.col(\"x\"), ...)\n...\nThis checks that each value in column a is greater than the corresponding value in column x. Here’s a concrete example:\n\n(\n    pb.Validate(data=pb.load_dataset(\"small_table\"))\n    .col_vals_gt(\n        columns=\"d\",\n        value=pb.col(\"c\")\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    c\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nNotice that the validation report shows both column names (d and c). There are two failing test units because of missing values in column c. When comparing across columns, missing values in either column can cause failures.\nTo handle missing values, use na_pass=True:\n\n(\n    pb.Validate(data=pb.load_dataset(\"small_table\"))\n    .col_vals_gt(\n        columns=\"d\",\n        value=pb.col(\"c\"),\n        na_pass=True\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    c\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nNow all tests pass.\nThe following validation methods accept a col() expression in their value= parameter:\n\ncol_vals_gt()\ncol_vals_lt()\ncol_vals_ge()\ncol_vals_le()\ncol_vals_eq()\ncol_vals_ne()\n\n\n\nUsing col() in Range Checks\nFor range validations via col_vals_between() and col_vals_outside() you can use a mix of column references and fixed values:\n\n(\n    pb.Validate(data=pb.load_dataset(\"small_table\"))\n    .col_vals_between(\n        columns=\"d\",\n        left=pb.col(\"c\"),\n        right=10_000,\n        na_pass=True\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_between\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_between()\n        \n        \n        \n    d\n    [c, 10000]\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThe validation report shows the range as [c, 10000], indicating that the lower bound comes from column c while the upper bound is fixed at 10000.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Column Selection Patterns"
    ]
  },
  {
    "objectID": "user-guide/column-selection-patterns.html#advanced-examples-combining-both-approaches",
    "href": "user-guide/column-selection-patterns.html#advanced-examples-combining-both-approaches",
    "title": "Column Selection Patterns",
    "section": "Advanced Examples: Combining Both Approaches",
    "text": "Advanced Examples: Combining Both Approaches\nThe true power comes from combining both approaches: validating multiple columns and using cross-column comparisons:\n\nvalidation = (\n    pb.Validate(data=pb.load_dataset(\"small_table\"))\n    .col_vals_gt(\n        columns=[\"c\", \"d\"],\n        value=pb.col(\"a\"),\n        na_pass=True\n    )\n    .interrogate()\n)\n\nvalidation\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    c\n    a\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    80.62\n    50.38\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    a\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThis creates validation steps checking that values in both columns d and e are greater than their corresponding values in column a.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Column Selection Patterns"
    ]
  },
  {
    "objectID": "user-guide/column-selection-patterns.html#conclusion",
    "href": "user-guide/column-selection-patterns.html#conclusion",
    "title": "Column Selection Patterns",
    "section": "Conclusion",
    "text": "Conclusion\nPointblank provides flexible approaches to working with columns:\n\nColumn selection: validate multiple columns with a single validation rule\nCross-column comparison: compare values between columns\n\nThese capabilities allow you to:\n\nwrite more concise validation code\napply consistent validation rules across similar columns\ncreate dynamic validations that check relationships between columns\nbuild comprehensive data quality checks with minimal code\n\nBy getting familiar with these techniques, you can create more elegant and powerful validation plans while also reducing repetition in your code.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Column Selection Patterns"
    ]
  },
  {
    "objectID": "user-guide/col-summary-tbl.html",
    "href": "user-guide/col-summary-tbl.html",
    "title": "Column Summaries",
    "section": "",
    "text": "While previewing a table with preview() is undoubtedly a good thing to do, sometimes you need more. This is where summarizing a table comes in. When you view a summary of a table, the column-by-column info can quickly increase your understanding of a dataset. Plus, it allows you to quickly catch anomalies in your data (e.g., the maximum value of a column could be far outside the realm of possibility).\nPointblank provides a function to make it extremely easy to view column-level summaries in a single table. That function is called col_summary_tbl() and, just like preview() does, it supports the use of any table that Pointblank can use for validation. And no matter what the input data is, the resultant reporting table is consistent in its design and construction.",
    "crumbs": [
      "Get Started",
      "Data Inspection",
      "Column Summaries"
    ]
  },
  {
    "objectID": "user-guide/col-summary-tbl.html#trying-out-col_summary_tbl",
    "href": "user-guide/col-summary-tbl.html#trying-out-col_summary_tbl",
    "title": "Column Summaries",
    "section": "Trying out col_summary_tbl()",
    "text": "Trying out col_summary_tbl()\nThe function only requires a table. Let’s use the small_table dataset (a very simple table) to start us off:\n\nimport pointblank as pb\n\nsmall_table = pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\")\n\npb.col_summary_tbl(small_table)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows13Columns8\n  \n\n  \n  Column\n  NA\n  UQ\n  Mean\n  SD\n  Min\n  P5\n  Q1\n  Med\n  Q3\n  P95\n  Max\n  IQR\n\n\n\n  \n    \n    date\n    \n        \n            \n            \n                \n            \n        \n    \n\n    date_timeDatetime(time_unit='us', time_zone=None)\n    00\n    120.92\n    -\n    -\n    20160104 00:32:00\n    -\n    -\n    -\n    -\n    -\n    20160130 11:23:00\n    -\n  \n  \n    \n    date\n    \n        \n            \n            \n                \n            \n        \n    \n\n    dateDate\n    00\n    110.85\n    -\n    -\n    20160104\n    -\n    -\n    -\n    -\n    -\n    20160130\n    -\n  \n  \n    \n    numeric\n    \n        \n            \n            \n                \n            \n        \n    \n\n    aInt64\n    00\n    70.54\n    3.77\n    2.09\n    1\n    1.06\n    2\n    3\n    4\n    7.4\n    8\n    2\n  \n  \n    \n    string\n    \n        \n            \n            \n                \n            \n        \n    \n\n    bString\n    00\n    120.92\n    9\n    0\n    9\n    9\n    9\n    9\n    9\n    9\n    9\n    0\n  \n  \n    \n    numeric\n    \n        \n            \n            \n                \n            \n        \n    \n\n    cInt64\n    20.15\n    70.54\n    5.73\n    2.72\n    2\n    2.05\n    3\n    7\n    8\n    9\n    9\n    5\n  \n  \n    \n    numeric\n    \n        \n            \n            \n                \n            \n        \n    \n\n    dFloat64\n    00\n    120.92\n    2,304.7\n    2,631.36\n    108.34\n    118.88\n    837.93\n    1,035.64\n    3,291.03\n    6,335.44\n    9999.99\n    2,453.1\n  \n  \n    \n    boolean\n    \n        \n            \n            \n                \n            \n            \n                \n            \n            \n        \n    \n\n    eBoolean\n    00\n    T0.62F0.38\n    -\n    -\n    -\n    -\n    -\n    -\n    -\n    -\n    -\n    -\n  \n  \n    \n    string\n    \n        \n            \n            \n                \n            \n        \n    \n\n    fString\n    00\n    30.23\n    3.46\n    0.52\n    3\n    3\n    3\n    3\n    4\n    4\n    4\n    1\n  \n\n  \n  \n  \n    String columns statistics regard the string's length.\n  \n\n\n\n\n\n\n        \n\n\nThe header provides the type of table we’re looking at (POLARS, since this is a Polars DataFrame) and the table dimensions. The rest of the table focuses on the column-level summaries. As such, each row represents a summary of a column in the small_table dataset. There’s a lot of information in this summary table to digest. Some of it is intuitive since this sort of table summarization isn’t all that uncommon, but other aspects of it could also give some pause. So we’ll carefully wade through how to interpret this report.",
    "crumbs": [
      "Get Started",
      "Data Inspection",
      "Column Summaries"
    ]
  },
  {
    "objectID": "user-guide/col-summary-tbl.html#data-categories-in-the-column-summary-table",
    "href": "user-guide/col-summary-tbl.html#data-categories-in-the-column-summary-table",
    "title": "Column Summaries",
    "section": "Data Categories in the Column Summary Table",
    "text": "Data Categories in the Column Summary Table\nOn the left side of the table are icons of different colors. These represent categories that the columns fall into. There are only five categories and columns can only be of one type. The categories (and their letter marks) are:\n\nN: numeric\nS: string-based\nD: date/datetime\nT/F: boolean\nO: object\n\nThe numeric category (N) takes data types such as floats and integers. The S category is for string-based columns. Date or datetime values are lumped into the D category. Boolean columns (T/F) have their own category and are not considered numeric (e.g., 0/1). The O category is a catchall for all other types of columns. Given the disparity of these categories and that we want them in the same table, some statistical measures will be sensible for certain column categories but not for others. Given that, we’ll explain how each category is represented in the column summary table.",
    "crumbs": [
      "Get Started",
      "Data Inspection",
      "Column Summaries"
    ]
  },
  {
    "objectID": "user-guide/col-summary-tbl.html#numeric-data",
    "href": "user-guide/col-summary-tbl.html#numeric-data",
    "title": "Column Summaries",
    "section": "Numeric Data",
    "text": "Numeric Data\nThree columns in small_table are numeric: a (Int64), c (Int64), and d (Float64). The common measures of the missing count/proportion (NA) and the unique value count/proportion (UQ) are provided for the numeric data type. For these two measures, the top number is the absolute count of missing values and the count of unique values. The bottom number is a proportion of the absolute count divided by the row count; this makes each proportion a value between 0 and 1 (bounds included).\nThe next two columns represent the mean (Mean) and the standard deviation (SD). The minumum (Min), maximum, (Max) and a set of quantiles occupy the next few columns (includes P5, Q1, Med for median, Q3, and P95). Finally, the interquartile range (IQR: Q3 - Q1) is the last measure provided.",
    "crumbs": [
      "Get Started",
      "Data Inspection",
      "Column Summaries"
    ]
  },
  {
    "objectID": "user-guide/col-summary-tbl.html#string-data",
    "href": "user-guide/col-summary-tbl.html#string-data",
    "title": "Column Summaries",
    "section": "String Data",
    "text": "String Data\nString data is present in small_table, being in columns b and f. The missing value (NA) and uniqueness (UQ) measures are accounted for here. The statistical measures are all based on string lengths, so what happens is that all strings in a column are converted to those numeric values and a subset of stats values is presented. To avoid some understandable confusion when reading the table, the stats values in each of the cells with values are annotated with the text \"SL\". It makes less sense to provide a full suite of quantile values so only the minimum (Min), median (Med), and maximum (Max) are provided.",
    "crumbs": [
      "Get Started",
      "Data Inspection",
      "Column Summaries"
    ]
  },
  {
    "objectID": "user-guide/col-summary-tbl.html#datedatetime-data-and-boolean-data",
    "href": "user-guide/col-summary-tbl.html#datedatetime-data-and-boolean-data",
    "title": "Column Summaries",
    "section": "Date/Datetime Data and Boolean Data",
    "text": "Date/Datetime Data and Boolean Data\nWe see that in the first two rows of our summary table there are summaries of the date_time and date columns. The summaries we provide for a date/datetime category (notice the green D to the left of the column names) are:\n\nthe missing count/proportion (NA)\nthe unique value count/proportion (UQ)\nthe minimum and maximum dates/datetimes\n\nOne column, e, is of the Boolean type. Because columns of this type could only have True, False, or missing values, we provide summary data for missingness (under NA) and proportions of True and False values (under UQ).",
    "crumbs": [
      "Get Started",
      "Data Inspection",
      "Column Summaries"
    ]
  },
  {
    "objectID": "user-guide/yaml-reference.html",
    "href": "user-guide/yaml-reference.html",
    "title": "YAML Reference",
    "section": "",
    "text": "This reference provides a comprehensive guide to all YAML keys and parameters supported by Pointblank’s YAML validation workflows. Use this document as a quick lookup when building validation configurations.",
    "crumbs": [
      "Get Started",
      "YAML",
      "YAML Reference"
    ]
  },
  {
    "objectID": "user-guide/yaml-reference.html#global-configuration-keys",
    "href": "user-guide/yaml-reference.html#global-configuration-keys",
    "title": "YAML Reference",
    "section": "Global Configuration Keys",
    "text": "Global Configuration Keys\n\nTop-level Structure\ntbl: data_source                       # REQUIRED: Data source specification\ndf_library: \"polars\"                   # OPTIONAL: DataFrame library (\"polars\", \"pandas\", \"duckdb\")\ntbl_name: \"Custom Table Name\"          # OPTIONAL: Human-readable table name\nlabel: \"Validation Description\"        # OPTIONAL: Description for the validation workflow\nlang: \"en\"                             # OPTIONAL: Language code (default: \"en\")\nlocale: \"en\"                           # OPTIONAL: Locale setting (default: \"en\")\nbrief: \"Global brief: {auto}\"          # OPTIONAL: Global brief template\nthresholds:                            # OPTIONAL: Global failure thresholds\n  warning: 0.1\n  error: 0.2\n  critical: 0.3\nactions:                               # OPTIONAL: Global failure actions\n  warning: \"Warning message template\"\n  error: \"Error message template\"\n  critical: \"Critical message template\"\n  highest_only: false\nsteps:                                 # REQUIRED: List of validation steps\n  - validation_method_name\n  - validation_method_name:\n      parameter: value\n\n\nData Source (tbl)\nThe tbl key specifies the data source and supports multiple formats:\n# File paths\ntbl: \"data/file.csv\"\ntbl: \"data/file.parquet\"\n\n# Built-in datasets\ntbl: small_table\ntbl: game_revenue\ntbl: nycflights\n\n# Python expressions for complex data loading\ntbl:\n  python: |\n    pl.scan_csv(\"data.csv\").filter(pl.col(\"date\") &gt;= \"2024-01-01\")\n\nUsing Templates with set_tbl=\nFor reusable validation templates that will always use a custom data source via the set_tbl= parameter in yaml_interrogate(), the tbl field is still required but its value doesn’t matter since it will be overridden. Recommended approaches:\n# Option 1: Use a valid dataset name (gets overridden anyway)\ntbl: small_table  # Will be ignored when `set_tbl=` is used\n\n# Option 2: Use YAML null (clearest semantic intent)\ntbl: null  # Indicates table will be provided via `set_tbl=`\nWhen using yaml_interrogate() with set_tbl=, the validation template becomes fully reusable:\n# Define reusable template\ntemplate = \"\"\"\ntbl: null  # Will be overridden\ntbl_name: \"Sales Validation\"\nsteps:\n  - col_exists:\n      columns: [customer_id, revenue, region]\n  - col_vals_gt:\n      columns: [revenue]\n      value: 0\n\"\"\"\n\n# Apply to different datasets\nq1_result = pb.yaml_interrogate(template, set_tbl=q1_data)\nq2_result = pb.yaml_interrogate(template, set_tbl=q2_data)\n\n\n\nDataFrame Library (df_library)\nThe df_library key controls which DataFrame library is used to load data sources. This parameter affects both built-in datasets and file loading:\n# Use Polars DataFrames (default)\ndf_library: polars\n\n# Use Pandas DataFrames\ndf_library: pandas\n\n# Use DuckDB tables (via Ibis)\ndf_library: duckdb\nExamples with different libraries:\n# Load built-in dataset as Pandas DataFrame\ntbl: small_table\ndf_library: pandas\nsteps:\n  - specially:\n      expr: \"lambda df: df.assign(validation_result=df['a'] &gt; 0)\"\n\n# Load CSV file as Polars DataFrame\ntbl: \"data/sales.csv\"\ndf_library: polars\nsteps:\n  - col_vals_gt:\n      columns: amount\n      value: 0\n\n# Load dataset as DuckDB table\ntbl: nycflights\ndf_library: duckdb\nsteps:\n  - row_count_match:\n      count: 336776\nThe df_library parameter is particularly useful when:\n\nusing validation expressions that require specific DataFrame APIs (e.g., Pandas .assign(), Polars .select())\nintegrating with existing pipelines that use a specific DataFrame library\noptimizing performance for different data sizes and operations\nensuring compatibility with downstream processing steps\n\n\n\nGlobal Thresholds\nThresholds define when validation failures trigger different severity levels:\nthresholds:\n  warning: 0.05    # 5% failure rate triggers warning\n  error: 0.10      # 10% failure rate triggers error\n  critical: 0.15   # 15% failure rate triggers critical\n\nvalues: numbers between 0 and 1 (percentages) or integers (row counts)\nlevels: warning, error, critical\n\n\n\nGlobal Actions\nActions define responses when thresholds are exceeded. When supplying a string to a severity level (‘warning’, ‘error’, ‘critical’), you can use template variables that will be automatically substituted with contextual information:\nactions:\n  warning: \"Warning: {n_failed} failures in step {step}\"\n  error:\n    python: |\n      lambda: print(\"Error detected!\")\n  critical: \"Critical failure at {time}\"\n  highest_only: false        # Execute all applicable actions vs. only highest severity\nTemplate variables available for action strings:\n\n{step}: current validation step number\n{col}: column name(s) being validated\n{val}: validation value or threshold\n{n_failed}: number of failing records\n{n}: total number of records\n{type}: validation method type\n{level}: severity level (‘warning’/‘error’/‘critical’)\n{time}: timestamp of validation",
    "crumbs": [
      "Get Started",
      "YAML",
      "YAML Reference"
    ]
  },
  {
    "objectID": "user-guide/yaml-reference.html#validation-methods-reference",
    "href": "user-guide/yaml-reference.html#validation-methods-reference",
    "title": "YAML Reference",
    "section": "Validation Methods Reference",
    "text": "Validation Methods Reference\n\nColumn Value Validations\n\nComparison Methods\ncol_vals_gt: are column data greater than a fixed value or data in another column?\n- col_vals_gt:\n    columns: [column_name]             # REQUIRED: Column(s) to validate\n    value: 100                         # REQUIRED: Comparison value\n    na_pass: true                      # OPTIONAL: Pass NULL values (default: false)\n    pre: |                             # OPTIONAL: Data preprocessing\n      lambda df: df.filter(condition)\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"Values must be &gt; 100\"      # OPTIONAL: Step description\ncol_vals_lt: are column data less than a fixed value or data in another column?\n- col_vals_lt:\n    columns: [column_name]\n    value: 100\n    na_pass: true\n    # ... (same parameters as col_vals_gt)\ncol_vals_ge: are column data greater than or equal to a fixed value or data in another column?\n- col_vals_ge:\n    columns: [column_name]\n    value: 100\n    na_pass: true\n    # ... (same parameters as col_vals_gt)\ncol_vals_le: are column data less than or equal to a fixed value or data in another column?\n- col_vals_le:\n    columns: [column_name]\n    value: 100\n    na_pass: true\n    # ... (same parameters as col_vals_gt)\ncol_vals_eq: are column data equal to a fixed value or data in another column?\n- col_vals_eq:\n    columns: [column_name]\n    value: \"expected_value\"\n    na_pass: true\n    # ... (same parameters as col_vals_gt)\ncol_vals_ne: are column data not equal to a fixed value or data in another column?\n- col_vals_ne:\n    columns: [column_name]\n    value: \"forbidden_value\"\n    na_pass: true\n    # ... (same parameters as col_vals_gt)\n\n\nRange Methods\ncol_vals_between: are column data between two specified values (inclusive)?\n- col_vals_between:\n    columns: [column_name]             # REQUIRED: Column(s) to validate\n    left: 0                            # REQUIRED: Lower bound\n    right: 100                         # REQUIRED: Upper bound\n    inclusive: [true, true]            # OPTIONAL: Include bounds [left, right]\n    na_pass: false                     # OPTIONAL: Pass NULL values\n    pre: |                             # OPTIONAL: Data preprocessing\n      lambda df: df.filter(condition)\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"Values between 0 and 100\"  # OPTIONAL: Step description\ncol_vals_outside: are column data outside of two specified values?\n- col_vals_outside:\n    columns: [column_name]\n    left: 0\n    right: 100\n    inclusive: [false, false]          # OPTIONAL: Exclude bounds [left, right]\n    na_pass: false\n    # ... (same parameters as col_vals_between)\n\n\nSet Membership Methods\ncol_vals_in_set: are column data part of a specified set of values?\n- col_vals_in_set:\n    columns: [column_name]             # REQUIRED: Column(s) to validate\n    set: [value1, value2, value3]      # REQUIRED: Allowed values\n    na_pass: false                     # OPTIONAL: Pass NULL values\n    pre: |                             # OPTIONAL: Data preprocessing\n      lambda df: df.filter(condition)\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"Values in allowed set\"     # OPTIONAL: Step description\ncol_vals_not_in_set: are column data not part of a specified set of values?\n- col_vals_not_in_set:\n    columns: [column_name]\n    set: [forbidden1, forbidden2]      # REQUIRED: Forbidden values\n    na_pass: false\n    # ... (same parameters as col_vals_in_set)\n\n\nNULL Value Methods\ncol_vals_null: are column data null (missing)?\n- col_vals_null:\n    columns: [column_name]             # REQUIRED: Column(s) to validate\n    pre: |                             # OPTIONAL: Data preprocessing\n      lambda df: df.filter(condition)\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"Values must be NULL\"       # OPTIONAL: Step description\ncol_vals_not_null: are column data not null (not missing)?\n- col_vals_not_null:\n    columns: [column_name]\n    # ... (same parameters as col_vals_null)\n\n\nPattern Matching Methods\ncol_vals_regex: do string-based column data match a regular expression?\n- col_vals_regex:\n    columns: [column_name]             # REQUIRED: Column(s) to validate\n    pattern: \"^[A-Z]{2,3}$\"            # REQUIRED: Regular expression pattern\n    na_pass: false                     # OPTIONAL: Pass NULL values\n    pre: |                             # OPTIONAL: Data preprocessing\n      lambda df: df.filter(condition)\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"Values match pattern\"      # OPTIONAL: Step description\ncol_vals_within_spec: do column data conform to a specification (email, URL, postal codes, etc.)?\n- col_vals_within_spec:\n    columns: [column_name]             # REQUIRED: Column(s) to validate\n    spec: \"email\"                      # REQUIRED: Specification type\n    na_pass: false                     # OPTIONAL: Pass NULL values\n    pre: |                             # OPTIONAL: Data preprocessing\n      lambda df: df.filter(condition)\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"Values match spec\"         # OPTIONAL: Step description\nAvailable specification types:\n\n\"email\" - Email addresses\n\"url\" - Internet URLs\n\"phone\" - Phone numbers\n\"ipv4\" - IPv4 addresses\n\"ipv6\" - IPv6 addresses\n\"mac\" - MAC addresses\n\"isbn\" - International Standard Book Numbers (10 or 13 digit)\n\"vin\" - Vehicle Identification Numbers\n\"credit_card\" - Credit card numbers (uses Luhn algorithm)\n\"swift\" - Business Identifier Codes (SWIFT-BIC)\n\"postal_code[&lt;country_code&gt;]\" - Postal codes for specific countries (e.g., \"postal_code[US]\", \"postal_code[CA]\")\n\"zip\" - Alias for US ZIP codes (\"postal_code[US]\")\n\"iban[&lt;country_code&gt;]\" - International Bank Account Numbers (e.g., \"iban[DE]\", \"iban[FR]\")\n\nExamples:\n# Email validation\n- col_vals_within_spec:\n    columns: user_email\n    spec: \"email\"\n\n# US postal codes\n- col_vals_within_spec:\n    columns: zip_code\n    spec: \"postal_code[US]\"\n\n# German IBAN\n- col_vals_within_spec:\n    columns: account_number\n    spec: \"iban[DE]\"\n\n\nCustom Expression Methods\ncol_vals_expr: do column data agree with a predicate expression?\n- col_vals_expr:\n    expr:                              # REQUIRED: Custom validation expression\n      python: |\n        pl.when(pl.col(\"status\") == \"active\")\n        .then(pl.col(\"value\") &gt; 0)\n        .otherwise(pl.lit(True))\n    pre: |                             # OPTIONAL: Data preprocessing\n      lambda df: df.filter(condition)\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"Custom validation rule\"    # OPTIONAL: Step description\n\n\nTrend Validation Methods\ncol_vals_increasing: are column data increasing row-by-row?\n- col_vals_increasing:\n    columns: [column_name]             # REQUIRED: Column(s) to validate\n    allow_stationary: false            # OPTIONAL: Allow consecutive equal values (default: false)\n    decreasing_tol: 0.5                # OPTIONAL: Tolerance for negative movement (default: null)\n    na_pass: false                     # OPTIONAL: Pass NULL values\n    pre: |                             # OPTIONAL: Data preprocessing\n      lambda df: df.filter(condition)\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"Values must increase\"      # OPTIONAL: Step description\nThis validation checks whether values in a column increase as you move down the rows. Useful for validating time-series data, sequence numbers, or any monotonically increasing values.\nParameters:\n\nallow_stationary: If true, allows consecutive values to be equal (stationary phases). For example, [1, 2, 2, 3] would pass when true but fail at the third value when false.\ndecreasing_tol: Absolute tolerance for negative movement. Setting this to 0.5 means values can decrease by up to 0.5 units and still pass. Setting any value also sets allow_stationary to true.\n\nExamples:\n# Strict increasing validation\n- col_vals_increasing:\n    columns: timestamp_seconds\n    brief: \"Timestamps must strictly increase\"\n\n# Allow stationary values\n- col_vals_increasing:\n    columns: version_number\n    allow_stationary: true\n    brief: \"Version numbers should increase (ties allowed)\"\n\n# With tolerance for small decreases\n- col_vals_increasing:\n    columns: temperature\n    decreasing_tol: 0.1\n    brief: \"Temperature trend (small drops allowed)\"\ncol_vals_decreasing: are column data decreasing row-by-row?\n- col_vals_decreasing:\n    columns: [column_name]             # REQUIRED: Column(s) to validate\n    allow_stationary: false            # OPTIONAL: Allow consecutive equal values (default: false)\n    increasing_tol: 0.5                # OPTIONAL: Tolerance for positive movement (default: null)\n    na_pass: false                     # OPTIONAL: Pass NULL values\n    pre: |                             # OPTIONAL: Data preprocessing\n      lambda df: df.filter(condition)\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"Values must decrease\"      # OPTIONAL: Step description\nThis validation checks whether values in a column decrease as you move down the rows. Useful for countdown timers, inventory depletion, or any monotonically decreasing values.\nParameters:\n\nallow_stationary: If true, allows consecutive values to be equal (stationary phases). For example, [10, 8, 8, 5] would pass when true but fail at the third value when false.\nincreasing_tol: Absolute tolerance for positive movement. Setting this to 0.5 means values can increase by up to 0.5 units and still pass. Setting any value also sets allow_stationary to true.\n\nExamples:\n# Strict decreasing validation\n- col_vals_decreasing:\n    columns: countdown_timer\n    brief: \"Timer must strictly decrease\"\n\n# Allow stationary values\n- col_vals_decreasing:\n    columns: priority_score\n    allow_stationary: true\n    brief: \"Priority scores should decrease (ties allowed)\"\n\n# With tolerance for small increases\n- col_vals_decreasing:\n    columns: stock_level\n    increasing_tol: 5\n    brief: \"Stock levels decrease (small restocks allowed)\"\n\n\n\nRow-based Validations\nrows_distinct: are row data distinct?\n- rows_distinct                        # Simple form\n\n- rows_distinct:                       # With parameters\n    columns_subset: [col1, col2]       # OPTIONAL: Check subset of columns\n    pre: |                             # OPTIONAL: Data preprocessing\n      lambda df: df.filter(condition)\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"No duplicate rows\"         # OPTIONAL: Step description\nrows_complete: are row data complete?\n- rows_complete                        # Simple form\n\n- rows_complete:                       # With parameters\n    columns_subset: [col1, col2]       # OPTIONAL: Check subset of columns\n    pre: |                             # OPTIONAL: Data preprocessing\n      lambda df: df.filter(condition)\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"Complete rows only\"        # OPTIONAL: Step description\n\n\nStructure Validations\ncol_exists: does column exist in the table?\n- col_exists:\n    columns: [col1, col2, col3]        # REQUIRED: Column(s) that must exist\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"Required columns exist\"    # OPTIONAL: Step description\ncol_schema_match: does the table have expected column names and data types?\n- col_schema_match:\n    schema:                            # REQUIRED: Expected schema\n      columns:\n        - [column_name, \"data_type\"]   # Column with type validation\n        - column_name                  # Column name only (no type check)\n        - [column_name]                # Alternative syntax\n    complete: true                     # OPTIONAL: Require exact column set\n    in_order: true                     # OPTIONAL: Require exact column order\n    case_sensitive_colnames: true      # OPTIONAL: Case-sensitive column names\n    case_sensitive_dtypes: true        # OPTIONAL: Case-sensitive data types\n    full_match_dtypes: true            # OPTIONAL: Exact type matching\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"Schema validation\"         # OPTIONAL: Step description\nrow_count_match: does the table have n rows?\n- row_count_match:\n    count: 1000                        # REQUIRED: Expected row count\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"Expected row count\"        # OPTIONAL: Step description\ncol_count_match: does the table have n columns?\n- col_count_match:\n    count: 10                          # REQUIRED: Expected column count\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"Expected column count\"     # OPTIONAL: Step description\ntbl_match: does the table match a comparison table?\n- tbl_match:\n    tbl_compare:                       # REQUIRED: Comparison table\n      python: |\n        pb.load_dataset(\"reference_table\", tbl_type=\"polars\")\n    pre: |                             # OPTIONAL: Data preprocessing\n      lambda df: df.filter(condition)\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.0\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"Table structure matches\"   # OPTIONAL: Step description\nThis validation performs a comprehensive comparison between the target table and a comparison table, using progressively stricter checks:\n\nColumn count match: both tables have the same number of columns\nRow count match: both tables have the same number of rows\nSchema match (loose): column names and dtypes match (case-insensitive, any order)\nSchema match (order): columns in correct order (case-insensitive names)\nSchema match (exact): column names match exactly (case-sensitive, correct order)\nData match: values in corresponding cells are identical\n\nThe validation fails at the first check that doesn’t pass, making it easy to diagnose mismatches. This operates over a single test unit (pass/fail for complete table match).\nCross-backend validation: tbl_match() supports automatic backend coercion when comparing tables from different backends (e.g., Polars vs. Pandas, DuckDB vs. SQLite). The comparison table is automatically converted to match the target table’s backend.\nExamples:\n# Compare against reference dataset\n- tbl_match:\n    tbl_compare:\n      python: |\n        pb.load_dataset(\"expected_output\", tbl_type=\"polars\")\n    brief: \"Output matches expected results\"\n\n# Compare against CSV file\n- tbl_match:\n    tbl_compare:\n      python: |\n        pl.read_csv(\"reference_data.csv\")\n    brief: \"Matches reference CSV\"\n\n# Compare with preprocessing on target table only\n- tbl_match:\n    tbl_compare:\n      python: |\n        pb.load_dataset(\"reference_table\", tbl_type=\"polars\")\n    pre: |\n      lambda df: df.select([\"id\", \"name\", \"value\"])\n    brief: \"Selected columns match reference\"\n\n\nSpecial Validation Methods\nconjointly: are multiple validations having a joint dependency?\n- conjointly:\n    expressions:                       # REQUIRED: List of lambda expressions\n      - \"lambda df: df['d'] &gt; df['a']\"\n      - \"lambda df: df['a'] &gt; 0\"\n      - \"lambda df: df['a'] + df['d'] &lt; 12000\"\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"All conditions must pass\"  # OPTIONAL: Step description\nspecially: do table data pass a custom validation function?\n- specially:\n    expr:                              # REQUIRED: Custom validation function\n      \"lambda df: df.select(pl.col('a') + pl.col('d') &gt; 0)\"\n    thresholds:                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"Custom validation\"         # OPTIONAL: Step description\nAlternative syntax with Python expressions:\n- specially:\n    expr:\n      python: |\n        lambda df: df.select(pl.col('amount') &gt; 0)\nFor Pandas DataFrames (when using df_library: pandas):\n- specially:\n    expr: \"lambda df: df.assign(is_valid=df['a'] + df['d'] &gt; 0)\"\n\n\nAI-Powered Validation\nprompt: validate rows using AI/LLM-powered analysis\n- prompt:\n    prompt: \"Values should be positive and realistic\"  # REQUIRED: Natural language criteria\n    model: \"anthropic:claude-sonnet-4\"                 # REQUIRED: Model identifier\n    columns_subset: [column1, column2]                 # OPTIONAL: Columns to validate\n    batch_size: 1000                                   # OPTIONAL: Rows per batch (default: 1000)\n    max_concurrent: 3                                  # OPTIONAL: Concurrent API requests (default: 3)\n    pre: |                                             # OPTIONAL: Data preprocessing\n      lambda df: df.filter(condition)\n    thresholds:                                        # OPTIONAL: Step-level thresholds\n      warning: 0.1\n    actions:                                           # OPTIONAL: Step-level actions\n      warning: \"Custom message\"\n    brief: \"AI validation\"                             # OPTIONAL: Step description\nThis validation method uses Large Language Models (LLMs) to validate rows of data based on natural language criteria. Each row becomes a test unit that either passes or fails the validation criteria, producing binary True/False results that integrate with standard Pointblank reporting.\nSupported models:\n\nAnthropic: \"anthropic:claude-sonnet-4\", \"anthropic:claude-opus-4\"\nOpenAI: \"openai:gpt-4\", \"openai:gpt-4-turbo\", \"openai:gpt-3.5-turbo\"\nOllama: \"ollama:&lt;model-name&gt;\" (e.g., \"ollama:llama3\")\nBedrock: \"bedrock:&lt;model-name&gt;\"\n\nAuthentication: API keys are automatically loaded from environment variables or .env files:\n\nOpenAI: Set OPENAI_API_KEY environment variable or add to .env file\nAnthropic: Set ANTHROPIC_API_KEY environment variable or add to .env file\nOllama: No API key required (runs locally)\nBedrock: Configure AWS credentials through standard AWS methods\n\nExample .env file:\nANTHROPIC_API_KEY=\"your_anthropic_api_key_here\"\nOPENAI_API_KEY=\"your_openai_api_key_here\"\nPerformance optimization: The validation process uses row signature memoization to avoid redundant LLM calls. When multiple rows have identical values in the selected columns, only one representative row is validated, and the result is applied to all matching rows. This dramatically reduces API costs and processing time for datasets with repetitive patterns.\nExamples:\n# Basic AI validation\n- prompt:\n    prompt: \"Email addresses should look realistic and professional\"\n    model: \"anthropic:claude-sonnet-4\"\n    columns_subset: [email]\n\n# Complex semantic validation\n- prompt:\n    prompt: \"Product descriptions should mention the product category and include at least one benefit\"\n    model: \"openai:gpt-4\"\n    columns_subset: [product_name, description, category]\n    batch_size: 500\n    max_concurrent: 5\n\n# Sentiment analysis\n- prompt:\n    prompt: \"Customer feedback should express positive sentiment\"\n    model: \"anthropic:claude-sonnet-4\"\n    columns_subset: [feedback_text, rating]\n\n# Context-dependent validation\n- prompt:\n    prompt: \"For high-value transactions (amount &gt; 1000), a detailed justification should be provided\"\n    model: \"openai:gpt-4\"\n    columns_subset: [amount, justification, approver]\n    thresholds:\n      warning: 0.05\n      error: 0.15\n\n# Local model with Ollama\n- prompt:\n    prompt: \"Transaction descriptions should be clear and professional\"\n    model: \"ollama:llama3\"\n    columns_subset: [description]\nBest practices for AI validation:\n\nBe specific and clear in your prompt criteria\nInclude only necessary columns in columns_subset to reduce API costs\nStart with smaller batch_size for testing, increase for production\nAdjust max_concurrent based on API rate limits\nUse thresholds appropriate for probabilistic validation results\nConsider cost implications for large datasets\nTest prompts on sample data before full deployment\n\nWhen to use AI validation:\n\nSemantic checks (e.g., “does the description match the category?”)\nContext-dependent validation (e.g., “is the justification appropriate for the amount?”)\nSubjective quality assessment (e.g., “is the text professional?”)\nPattern recognition that’s hard to express programmatically\nNatural language understanding tasks\n\nWhen NOT to use AI validation:\n\nSimple numeric comparisons (use col_vals_gt, col_vals_lt, etc.)\nExact pattern matching (use col_vals_regex)\nSchema validation (use col_schema_match)\nPerformance-critical validations with large datasets\nWhen deterministic results are required",
    "crumbs": [
      "Get Started",
      "YAML",
      "YAML Reference"
    ]
  },
  {
    "objectID": "user-guide/yaml-reference.html#column-selection-patterns",
    "href": "user-guide/yaml-reference.html#column-selection-patterns",
    "title": "YAML Reference",
    "section": "Column Selection Patterns",
    "text": "Column Selection Patterns\nAll validation methods that accept a columns parameter support these selection patterns:\n# Single column\ncolumns: column_name\n\n# Multiple columns as list\ncolumns: [col1, col2, col3]\n\n# Column selector functions (when used in Python expressions)\ncolumns:\n  python: |\n    starts_with(\"prefix_\")\n\n# Examples of common patterns\ncolumns: [customer_id, order_id]     # Specific columns\ncolumns: user_email                  # Single column",
    "crumbs": [
      "Get Started",
      "YAML",
      "YAML Reference"
    ]
  },
  {
    "objectID": "user-guide/yaml-reference.html#parameter-details",
    "href": "user-guide/yaml-reference.html#parameter-details",
    "title": "YAML Reference",
    "section": "Parameter Details",
    "text": "Parameter Details\n\nCommon Parameters\nThese parameters are available for most validation methods:\n\ncolumns: column selection (string, list, or selector expression)\nna_pass: whether to pass NULL/missing values (boolean, default: false)\npre: data preprocessing function (Python lambda expression)\nthresholds: step-level failure thresholds (dict)\nactions: step-level failure actions (dict)\nbrief: step description (string, boolean, or template)\n\n\n\nBrief Parameter Options\nThe brief parameter supports several formats:\nbrief: \"Custom description\"          # Custom text\nbrief: true                         # Auto-generated description\nbrief: false                        # No description\nbrief: \"Step {step}: {auto}\"        # Template with auto-generated text\nbrief: \"Column '{col}' validation\"  # Template with variables\ntemplate variables: {step}, {col}, {value}, {set}, {pattern}, {auto}\n\n\nPython Expressions\nSeveral parameters support Python expressions using the python: block syntax:\n# Data source loading\ntbl:\n  python: |\n    pl.scan_csv(\"data.csv\").filter(pl.col(\"active\") == True)\n\n# Preprocessing\npre:\n  python: |\n    lambda df: df.filter(pl.col(\"date\") &gt;= \"2024-01-01\")\n\n# Custom expressions\nexpr:\n  python: |\n    pl.col(\"value\").is_between(0, 100)\n\n# Callable actions\nactions:\n  error:\n    python: |\n      lambda: print(\"VALIDATION ERROR: Critical data quality issue detected!\")\nNote: The Python environment in YAML is restricted for security. Only built-in functions (print, len, str, etc.), Path from pathlib, and available DataFrame libraries (pl, pd) are accessible. You cannot import additional modules like requests, logging, or custom libraries.\nYou can also use the shortcut syntax for lambda expressions:\n# Shortcut syntax (equivalent to python: block)\npre: |\n  lambda df: df.filter(pl.col(\"status\") == \"active\")\n\n\nRestricted Python Environment\nFor security reasons, the Python environment in YAML configurations is restricted to a safe subset of functionality. The available namespace includes:\nBuilt-in functions:\n\nbasic types: str, int, float, bool, list, dict, tuple, set\nmath functions: sum, min, max, abs, round, len\niteration: range, enumerate, zip\noutput: print\n\nAvailable modules:\n\nPath from pathlib for file path operations\npb (pointblank) for dataset loading and validation functions\npl (polars) if available on the system\npd (pandas) if available on the system\n\nRestrictions:\n\ncannot import external libraries (requests, logging, os, sys, etc.)\ncannot use __import__, exec, eval, or other dynamic execution functions\nfile operations are limited to Path functionality\n\nExamples of valid callable actions:\n# Simple output with built-in functions\nactions:\n  warning:\n    python: |\n      lambda: print(f\"WARNING: {sum([1, 2, 3])} validation issues detected\")\n\n# Using available variables and string formatting\nactions:\n  error:\n    python: |\n      lambda: print(\"ERROR: Data validation failed at \" + str(len(\"validation\")))\n\n# Multiple statements in lambda (using parentheses)\nactions:\n  critical:\n    python: |\n      lambda: (\n          print(\"CRITICAL ALERT:\"),\n          print(\"Immediate attention required\"),\n          print(\"Contact data team\")\n      )[-1]  # Return the last value\nFor complex alerting, logging, or external system integration, use string template actions instead of callable actions, and handle the external communication in your application code after validation completes.",
    "crumbs": [
      "Get Started",
      "YAML",
      "YAML Reference"
    ]
  },
  {
    "objectID": "user-guide/yaml-reference.html#best-practices",
    "href": "user-guide/yaml-reference.html#best-practices",
    "title": "YAML Reference",
    "section": "Best Practices",
    "text": "Best Practices\n\nOrganization\n\nuse descriptive tbl_name and label values\nadd brief descriptions for complex validations\ngroup related validations logically\nuse consistent indentation and formatting\n\n\n\nPerformance\n\napply pre filters early to reduce data volume\norder validations from fast to slow\nuse columns_subset for row-based validations when appropriate\nconsider data source location (local vs. remote)\nchoose df_library based on data size and operations:\n\npolars: fastest for large datasets and analytical operations\npandas: best for complex transformations and data science workflows\nduckdb: optimal for analytical queries on very large datasets\n\n\n\n\nMaintainability\n\nstore YAML files in version control\nuse template variables in actions and briefs\ndocument expected failures with comments\ntest configurations with validate_yaml() before deployment\nspecify df_library explicitly when using library-specific validation expressions\nkeep DataFrame library choice consistent within related validation workflows\n\n\n\nError Handling\n\nset appropriate thresholds based on data patterns\nuse actions for monitoring and alerting\nstart with conservative thresholds and adjust\nconsider using highest_only: false for comprehensive reporting",
    "crumbs": [
      "Get Started",
      "YAML",
      "YAML Reference"
    ]
  },
  {
    "objectID": "user-guide/validation-overview.html",
    "href": "user-guide/validation-overview.html",
    "title": "Overview",
    "section": "",
    "text": "This article provides a quick overview of the data validation features in Pointblank. It introduces the key concepts and shows examples of the main functionality, giving you a foundation for using the library effectively.\nLater articles in the User Guide will expand on each section covered here, providing more explanations and examples.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Overview"
    ]
  },
  {
    "objectID": "user-guide/validation-overview.html#validation-methods",
    "href": "user-guide/validation-overview.html#validation-methods",
    "title": "Overview",
    "section": "Validation Methods",
    "text": "Validation Methods\nPointblank’s core functionality revolves around validation steps, which are individual checks that verify different aspects of your data. These steps are created by calling validation methods from the Validate class. When combined they create a comprehensive validation plan for your data.\nHere’s an example of a validation that incorporates three different validation methods:\n\nimport pointblank as pb\nimport polars as pl\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"),\n        label=\"Three different validation methods.\"\n    )\n    .col_vals_gt(columns=\"a\", value=0)\n    .rows_distinct()\n    .col_exists(columns=\"date\")\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Three different validation methods.Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    a\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    rows_distinct\n    \n        \n            \n            \n                \n                \n                \n            \n        \n    \n\n        \n        \n            rows_distinct()\n        \n        \n        \n    ALL COLUMNS\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    90.69\n    20.15\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    date\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThis example showcases how you can combine different types of validations in a single validation plan:\n\na column value validation with Validate.col_vals_gt()\na row-based validation with Validate.rows_distinct()\na table structure validation with Validate.col_exists()\n\nMost validation methods share common parameters that enhance their flexibility and power. These shared parameters (overviewed in the next few sections) create a consistent interface across all validation steps while allowing you to customize validation behavior for specific needs.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Overview"
    ]
  },
  {
    "objectID": "user-guide/validation-overview.html#column-selection-patterns",
    "href": "user-guide/validation-overview.html#column-selection-patterns",
    "title": "Overview",
    "section": "Column Selection Patterns",
    "text": "Column Selection Patterns\nYou can apply the same validation logic to multiple columns at once through use of column selection patterns (used in the columns= parameter). This reduces repetitive code and makes your validation plans more maintainable:\n\nimport narwhals.selectors as nws\n\n# Map validations across multiple columns\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"),\n        label=\"Applying column mapping in `columns`.\"\n    )\n\n    # Apply validation rules to multiple columns ---\n    .col_vals_not_null(\n        columns=[\"a\", \"b\", \"c\"]\n    )\n\n    # Apply to numeric columns only with a Narwhals selector ---\n    .col_vals_gt(\n        columns=nws.numeric(),\n        value=0\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Applying column mapping in `columns`.Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    a\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    b\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C66\n    3\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    c\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    a\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C66\n    5\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    c\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    6\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nThis technique is particularly valuable when working with wide datasets containing many similarly-structured columns or when applying standard quality checks across an entire table. It also ensures consistency in how validation rules are applied across related data columns.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Overview"
    ]
  },
  {
    "objectID": "user-guide/validation-overview.html#preprocessing",
    "href": "user-guide/validation-overview.html#preprocessing",
    "title": "Overview",
    "section": "Preprocessing",
    "text": "Preprocessing\nPreprocessing (with the pre= parameter) allows you to transform or modify your data before applying validation checks, enabling you to validate derived or modified data without altering the original dataset:\n\nimport polars as pl\n\n# Define preprocessing functions for `pre=` parameters\ndef double_column_a(df):\n    return df.with_columns(pl.col(\"a\") * 2)\n\ndef square_column_c(df):\n    return df.with_columns(pl.col(\"c\").pow(2))\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"),\n        label=\"Preprocessing validation steps via `pre=`.\"\n    )\n    .col_vals_gt(\n        columns=\"a\", value=5,\n\n        # Apply transformation before validation ---\n        pre=double_column_a  # Double values before checking\n    )\n    .col_vals_lt(\n        columns=\"c\", value=100,\n\n        # Apply more complex transformation ---\n        pre=square_column_c  # Square values before checking\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Preprocessing validation steps via `pre=`.Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    a\n    5\n    \n    \n        \n            \n            \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    90.69\n    40.31\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    c\n    100\n    \n    \n        \n            \n            \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nPreprocessing enables validation of transformed data without modifying your original dataset, making it ideal for checking derived metrics, or validating normalized values. This approach keeps your validation code clean while allowing for sophisticated data quality checks on calculated results.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Overview"
    ]
  },
  {
    "objectID": "user-guide/validation-overview.html#segmentation",
    "href": "user-guide/validation-overview.html#segmentation",
    "title": "Overview",
    "section": "Segmentation",
    "text": "Segmentation\nSegmentation (through the segments= parameter) allows you to validate data across different groups, enabling you to identify segment-specific quality issues that might be hidden in aggregate analyses:\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"),\n        label=\"Segmenting validation steps via `segments=`.\"\n    )\n    .col_vals_gt(\n        columns=\"c\", value=3,\n\n        # Split into steps by categorical values in column 'f' ---\n        segments=\"f\"\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Segmenting validation steps via `segments=`.Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    SEGMENT  f / high \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    c\n    3\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    6\n    20.33\n    40.67\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    SEGMENT  f / low \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    c\n    3\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    5\n    40.80\n    10.20\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    3\n    SEGMENT  f / mid \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    c\n    3\n    \n    \n        \n            \n            \n            \n            \n        \n    \n\n    ✓\n    2\n    10.50\n    10.50\n    —\n    —\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nSegmentation is powerful for detecting patterns of quality issues that may exist only in specific data subsets, such as certain time periods, categories, or geographical regions. It helps ensure that all significant segments of your data meet quality standards, not just the data as a whole.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Overview"
    ]
  },
  {
    "objectID": "user-guide/validation-overview.html#thresholds",
    "href": "user-guide/validation-overview.html#thresholds",
    "title": "Overview",
    "section": "Thresholds",
    "text": "Thresholds\nThresholds (set through the thresholds= parameter) let you set acceptable levels of failure before triggering warnings, errors, or critical notifications for individual validation steps:\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"),\n        label=\"Using thresholds.\"\n    )\n\n    # Add validation steps with different thresholds ---\n    .col_vals_gt(\n        columns=\"a\", value=1,\n        thresholds=pb.Thresholds(warning=0.1, error=0.2, critical=0.3)\n    )\n\n    # Add another step with stricter thresholds ---\n    .col_vals_lt(\n        columns=\"c\", value=10,\n        thresholds=pb.Thresholds(warning=0.05, error=0.1)\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Using thresholds.Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    a\n    1\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    120.92\n    10.08\n    ○\n    ○\n    ○\n    CSV\n  \n  \n    #EBBC14\n    2\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    c\n    10\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    ●\n    ●\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nThresholds provide a nuanced way to monitor data quality, allowing you to set different severity levels based on the importance of each validation and your organization’s tolerance for specific types of data issues.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Overview"
    ]
  },
  {
    "objectID": "user-guide/validation-overview.html#actions",
    "href": "user-guide/validation-overview.html#actions",
    "title": "Overview",
    "section": "Actions",
    "text": "Actions\nActions (which can be configured in the actions= parameter) allow you to define specific responses when validation thresholds are crossed. You can use simple string messages or custom functions for more complex behavior:\n\n# Example 1: Action with a string message ---\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"),\n        label=\"Using actions with a string message.\"\n    )\n    .col_vals_gt(\n        columns=\"c\", value=2,\n        thresholds=pb.Thresholds(warning=0.1, error=0.2),\n\n        # Add a print-to-console action for the 'warning' threshold ---\n        actions=pb.Actions(\n            warning=\"WARNING: Values below `{value}` detected in column 'c'.\"\n        )\n    )\n    .interrogate()\n)\n\nWARNING: Values below `2` detected in column 'c'.\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Using actions with a string message.Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #EBBC14\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    c\n    2\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    100.77\n    30.23\n    ●\n    ●\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\n\n# Example 2: Action with a callable function ---\n\ndef custom_action():\n    from datetime import datetime\n    print(f\"Data quality issue found ({datetime.now()}).\")\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"),\n        label=\"Using actions with a callable function.\"\n    )\n    .col_vals_gt(\n        columns=\"a\", value=5,\n        thresholds=pb.Thresholds(warning=0.1, error=0.2),\n\n        # Apply the function to the 'error' threshold ---\n        actions=pb.Actions(error=custom_action)\n    )\n    .interrogate()\n)\n\nData quality issue found (2025-11-23 00:18:41.811886).\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Using actions with a callable function.Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #EBBC14\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    a\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    30.23\n    100.77\n    ●\n    ●\n    —\n    CSV\n  \n\n\n\n\n\n\n        \n\n\nWith custom action functions, you can implement sophisticated responses like sending notifications or logging to external systems.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Overview"
    ]
  },
  {
    "objectID": "user-guide/validation-overview.html#briefs",
    "href": "user-guide/validation-overview.html#briefs",
    "title": "Overview",
    "section": "Briefs",
    "text": "Briefs\nBriefs (which can be set through the brief= parameter) allow you to customize descriptions associated with validation steps, making validation results more understandable to stakeholders. Briefs can be either automatically generated by setting brief=True or defined as custom messages for more specific explanations:\n\n(\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"),\n        label=\"Using `brief=` for displaying brief messages.\"\n    )\n    .col_vals_gt(\n        columns=\"a\", value=0,\n\n        # Use `True` for automatic generation of briefs ---\n        brief=True\n    )\n    .col_exists(\n        columns=[\"date\", \"date_time\"],\n\n        # Add a custom brief for this validation step ---\n        brief=\"Verify required date columns exist for time-series analysis\"\n    )\n    .interrogate()\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Using `brief=` for displaying brief messages.Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        Expect that values in a should be &gt; 0.\n\n        \n    a\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Verify required date columns exist for time-series analysis\n\n        \n    date\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        Verify required date columns exist for time-series analysis\n\n        \n    date_time\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n\n\n\n\n\n        \n\n\nBriefs make validation results more meaningful by providing context about why each check matters. They’re particularly valuable in shared reports where stakeholders from various disciplines need to understand validation results in domain-specific terms.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Overview"
    ]
  },
  {
    "objectID": "user-guide/validation-overview.html#getting-more-information",
    "href": "user-guide/validation-overview.html#getting-more-information",
    "title": "Overview",
    "section": "Getting More Information",
    "text": "Getting More Information\nEach validation step can be further customized and has additional options. See these pages for more information:\n\nValidation Methods: A closer look at the more common validation methods\nColumn Selection Patterns: Techniques for targeting specific columns\nPreprocessing: Transform data before validation\nSegmentation: Apply validations to specific segments of your data\nThresholds: Set quality standards and trigger severity levels\nActions: Respond to threshold exceedances with notifications or custom functions\nBriefs: Add context to validation steps",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Overview"
    ]
  },
  {
    "objectID": "user-guide/validation-overview.html#conclusion",
    "href": "user-guide/validation-overview.html#conclusion",
    "title": "Overview",
    "section": "Conclusion",
    "text": "Conclusion\nValidation steps are the building blocks of data validation in Pointblank. By combining steps from different categories and leveraging common features like thresholds, actions, and preprocessing, you can create comprehensive data quality checks tailored to your specific needs.\nThe next sections of this guide will dive deeper into each of these topics, providing detailed explanations and examples.",
    "crumbs": [
      "Get Started",
      "Validation Plan",
      "Overview"
    ]
  },
  {
    "objectID": "user-guide/cli-data-inspection.html",
    "href": "user-guide/cli-data-inspection.html",
    "title": "Data Inspection",
    "section": "",
    "text": "Pointblank’s CLI (pb) makes it easy to view your data before running validations. It has several commands that are exceedingly useful for understanding your data’s structure, checking for obvious issues, and confirming that your data source is being read correctly. We also make it easy to explore data in various formats and locations. Let’s go through each of the commands for inspecting and exploring data.",
    "crumbs": [
      "Get Started",
      "The Pointblank CLI",
      "Data Inspection"
    ]
  },
  {
    "objectID": "user-guide/cli-data-inspection.html#pb-info-inspecting-the-data-structure",
    "href": "user-guide/cli-data-inspection.html#pb-info-inspecting-the-data-structure",
    "title": "Data Inspection",
    "section": "pb info: Inspecting the Data Structure",
    "text": "pb info: Inspecting the Data Structure\nUse pb info to display basic information about your data source. Here’s how this works with a local CSV file:\npb info worldcities.csv\n\nThis command shows the (1) table type (e.g., pandas, polars, etc.), (2) the number of rows and columns, and (3) the data source path or identifier.\nThat example used a local CSV file. The same file is also present in Pointblank’s GitHub repository (in the data-raw directory) and the CLI is able to load the data from there as well:\npb info https://github.com/posit-dev/pointblank/blob/main/data_raw/worldcities.csv\n\nThe pb info command is useful before running validations to confirm your data source’s dimensions, and, whether it can even be loaded.\n\nYou can inspect a wide variety of data sources using the CLI! Here are some examples with pb info:\npb info small_table         # built in dataset\npb info worldcities.csv     # single CSV file\npb info meteo.parquet       # single Parquet file\npb info \"*.parquet\"         # several Parquet files\npb info \"data/*.parquet\"    # partitioned Parquet files\npb info \"duckdb:///warehouse/analytics.ddb::customer_metrics\" # DB table via connection string\npb info https://github.com/posit-dev/pointblank/blob/main/data_raw/global_sales.csv # GitHub URL\nAnd these input schemes work with all other commands that accept a DATA_SOURCE.",
    "crumbs": [
      "Get Started",
      "The Pointblank CLI",
      "Data Inspection"
    ]
  },
  {
    "objectID": "user-guide/cli-data-inspection.html#pb-preview-previewing-data",
    "href": "user-guide/cli-data-inspection.html#pb-preview-previewing-data",
    "title": "Data Inspection",
    "section": "pb preview: Previewing Data",
    "text": "pb preview: Previewing Data\nUse pb preview to view the first and last rows of your data. Let’s try it out with the worldcities.csv file:\npb preview worldcities.csv\n\nAs can be seen, pb preview gives you a preview of the dataset as a table in the console. The dataset has 41K rows but we’re electing to show only five rows from the head and from the tail.\nLet’s go over some features of the table preview. First off, the table header provides information on the data source and the DataFrame library that handled the reading of the CSV. Below the column names are simplified representations of the data types (e.g., &lt;obj&gt; for object, &lt;f64&gt; for Float64). We provide row numbers (in gray) in the table stub to indicate which of the rows are from the head or the tail (and a divider helps to distinguish these row groups). If you’d prefer to eliminate the row numbers, use the --no-row-numbers option:\npb preview worldcities.csv --no-row-numbers\n\nWhile pb preview purposefully displays only a few rows, the number of columns shown can be more than you might need. Furthermore, if a table has a lot of columns, you’ll only see some of the first and some of the last columns. This is where column selection becomes useful and there are a few methods available for subsetting the preview table’s columns. A good one (provided you know the column names) is to use the --columns option along with a comma-delimted set of column names. Let’s look at a preview of the included game_revenue dataset before subsetting the columns:\npb preview game_revenue\n\nThat’s 11 columns in total and while the all columns are shown (i.e., none in the middle are truncated from view), we start to see some necessary instances of abbreviating via … within the column names and in the displayed values.\nLet’s now use the --columns with a set of column names:\npb preview game_revenue -columns \"player_id, item_type, item_name, start_day\"\n\nWith that, the few columns that are displayed no longer have to abbreviate their data values. This is an important consideration since a selective display of column becomes more necessary if column content is large or if the width of the terminal (in terms of characters) cannot be increased.\nYou may want to view ranges of columns by their indices. This is convenient when you want to get a closer look at a few side-by-side columns and you don’t want to bother with getting the set of column names exactly right (i.e., for quick inspection). For this, we need to use the --col-range option with the desired left/right column bounds separated by a colon:\npb preview game_revenue —-col-range \"3:6\"\n\nIn the case that you want to save a table preview as an HTML table in a standalone file, you can add in the --output-html option (just add a path/filename with an .html extension).\nAnd there are many more options that allow for quick iteration while previewing a table. Use pb preview --help to get a helpful listing.",
    "crumbs": [
      "Get Started",
      "The Pointblank CLI",
      "Data Inspection"
    ]
  },
  {
    "objectID": "user-guide/cli-data-inspection.html#pb-scan-getting-column-summaries",
    "href": "user-guide/cli-data-inspection.html#pb-scan-getting-column-summaries",
    "title": "Data Inspection",
    "section": "pb scan: Getting Column Summaries",
    "text": "pb scan: Getting Column Summaries\nWe can use pb scan for fairly comprehensive summaries of column data, including:\n\ndata types\nmissing value counts\nunique value counts\nsummary statistics (mean, standard deviation, min, max, quartiles, and the interquartile range)\n\nLet’s use this on the worldcities.csv dataset:\npb scan worldcities.csv\n\nEach row in the summary table represents a column in the input dataset. Just as in pb preview we get simplified dtypes (in the Type column). The NA and UQ indicate how many missing and unique values are in the column. The remaining columns are statistical measures and there’s an important thing to note here: the values provided for any string-based columns (here, city_name and country) are derived from string lengths.\nWhen using pb scan, it’s helpful to know that large numbers in the summary table are automatically abbreviated for readability, so you’ll see values like 39.8k or 38.0M instead of long numbers that would require many more characters. For the best experience, try to use a terminal window that’s at least 150 characters wide. This will help ensure that all column values are fully visible and not adversely abbreviated by the underlying table mechanism.\nIf your table has many columns, that’s not much of a problem for the reporting! Each column is represented as a row in the report, so you’ll simply see more lines in the output (and you could always limit the number of columns reported).\nThere are two options for pb scan:\n\n--columns \"col1,col2\": scan only specified columns\n--output-html \"file.html\": save scan as an HTML file\n\nBoth of these options are also in the pb preview command and they behave the same way here.",
    "crumbs": [
      "Get Started",
      "The Pointblank CLI",
      "Data Inspection"
    ]
  },
  {
    "objectID": "user-guide/cli-data-inspection.html#pb-missing-reporting-on-missing-values",
    "href": "user-guide/cli-data-inspection.html#pb-missing-reporting-on-missing-values",
    "title": "Data Inspection",
    "section": "pb missing: Reporting on Missing Values",
    "text": "pb missing: Reporting on Missing Values\nUse pb missing to generate a missing values report, visualizing missingness across columns and 10 row sectors. Here’s an example using worldcities.csv:\npb missing worldcities.csv\n\nThis report is arranged similarly to that of pb scan, where each column in the input table gets a row in this report table. Each of the 10 row sectors represents 1/10 of the rows in the dataset, where sector 1 encompasses the head of the table, and 10 the tail.\nMore often than not, we expect few missing values so a filled green circle signifies that the collection of rows in a sector (for a column) has no missing values. We don’t see any red circles in the worldcities.csv-based example but, if we did, that would mean that sectors for a given column are entirely filled with missing values.\nWhat’s in between the no-missing and completely-missing cases are percentages of missing values. For instance, we can see that row sector 3 of the population column has 18% missing values (which is very odd for a table with the sole purpose of providing population values).\nWe also have cases where we see &lt;1% of values in a row sector missing. The reporting of pb missing is very careful not to ‘round down’ in cases where there could be very few missing values (or even just one) in a large table.\nSeeing this type of missing value report can be really important! You might not expect any missing values but finding them will inform decisions on whether to institute checks for them. Another case is that missing values will pop up in specific sectors, indicating a change in how data is processed and appended to the table.\nBy way of options, there’s only one for pb missing and it is --output-html. With that (as in the previous two commands discussed), we can write the missing values report to a standalone HTML file.",
    "crumbs": [
      "Get Started",
      "The Pointblank CLI",
      "Data Inspection"
    ]
  },
  {
    "objectID": "user-guide/cli-data-inspection.html#wrapping-up",
    "href": "user-guide/cli-data-inspection.html#wrapping-up",
    "title": "Data Inspection",
    "section": "Wrapping Up",
    "text": "Wrapping Up\nPointblank’s CLI provides a set of commands that make it easy to inspect, understand, and diagnose your data before you move on to validation or analysis. Using these tools can help you catch issues early and gain confidence in your data sources.\n\nuse pb info and before running validations to confirm your data source can be loaded\nuse pb preview to quickly understand what the data looks like\nuse pb scan for a quick data profile and to spot outliers or data quality issues\nuse pb missing to visualize and diagnose missing data patterns\n\nBy incorporating these commands into your workflow, you’ll be better equipped to work efficiently with your data (and avoid surprises down the line).",
    "crumbs": [
      "Get Started",
      "The Pointblank CLI",
      "Data Inspection"
    ]
  },
  {
    "objectID": "user-guide/langs.html",
    "href": "user-guide/langs.html",
    "title": "Languages",
    "section": "",
    "text": "It’s possible to generate reporting in various spoken languages. We do this via the lang= argument in Validate."
  },
  {
    "objectID": "user-guide/yaml-validation-workflows.html",
    "href": "user-guide/yaml-validation-workflows.html",
    "title": "YAML Validation Workflows",
    "section": "",
    "text": "Pointblank supports defining validation workflows using YAML configuration files, providing a declarative, readable, and maintainable approach to data validation. YAML workflows are particularly useful for teams, version control, automation pipelines, and scenarios where you want to separate validation logic from application code.\nYAML validation workflows offer several advantages: they’re easy to read and write, can be version controlled alongside your data processing code, enable non-programmers to contribute to data quality definitions, and provide a clear separation between validation logic and execution code.\nThe YAML approach complements Pointblank’s Python API, giving you flexibility to choose the right tool for each situation. Simple, repetitive validations work well in YAML, while complex logic with custom functions might be better suited for the Python API.",
    "crumbs": [
      "Get Started",
      "YAML",
      "YAML Validation Workflows"
    ]
  },
  {
    "objectID": "user-guide/yaml-validation-workflows.html#basic-yaml-validation-structure",
    "href": "user-guide/yaml-validation-workflows.html#basic-yaml-validation-structure",
    "title": "YAML Validation Workflows",
    "section": "Basic YAML Validation Structure",
    "text": "Basic YAML Validation Structure\nA YAML validation workflow consists of a few key components:\n\ntbl: specifies the data source (file path, dataset name, or Python expression)\nsteps: defines the validation checks to perform\nOptional metadata: table name, label, thresholds, actions, and other configuration\n\nHere’s a simple example validating the built-in small_table dataset:\ntbl: small_table\ndf_library: polars                     # Optional: specify DataFrame library\ntbl_name: \"Small Table Validation\"\nlabel: \"Basic data quality checks\"\nsteps:\n  - rows_distinct\n  - col_exists:\n      columns: [a, b, c, d]\n  - col_vals_not_null:\n      columns: [a, b]\nYou can save this configuration to a .yaml file and execute it using the yaml_interrogate() function:\n\nimport pointblank as pb\nfrom pathlib import Path\n\n# Save the YAML configuration to a file\nyaml_content = \"\"\"\ntbl: small_table\ndf_library: polars\ntbl_name: \"Small Table Validation\"\nlabel: \"Basic data quality checks\"\nsteps:\n  - rows_distinct\n  - col_exists:\n      columns: [a, b, c, d]\n  - col_vals_not_null:\n      columns: [a, b]\n\"\"\"\n\nyaml_file = Path(\"basic_validation.yaml\")\nyaml_file.write_text(yaml_content)\n\n# Execute the validation from the file\nresult = pb.yaml_interrogate(yaml_file)\nresult\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Basic data quality checksPolarsSmall Table Validation\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    rows_distinct\n    \n        \n            \n            \n                \n                \n                \n            \n        \n    \n\n        \n        \n            rows_distinct()\n        \n        \n        \n    ALL COLUMNS\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    90.69\n    20.15\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    a\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    b\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    c\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    5\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    d\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    6\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    a\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    7\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    b\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:19:07 UTC&lt; 1 s2025-11-23 00:19:07 UTC\n  \n\n\n\n\n\n\n        \n\n\nThe validation table shows the results of each step, just as if you had written the equivalent Python code. You can also pass YAML content directly as a string for quick testing, but working with files is the recommended approach for production workflows.",
    "crumbs": [
      "Get Started",
      "YAML",
      "YAML Validation Workflows"
    ]
  },
  {
    "objectID": "user-guide/yaml-validation-workflows.html#data-sources-in-yaml",
    "href": "user-guide/yaml-validation-workflows.html#data-sources-in-yaml",
    "title": "YAML Validation Workflows",
    "section": "Data Sources in YAML",
    "text": "Data Sources in YAML\nThe tbl field supports various data source types, making it easy to work with different kinds of data. You can also control the DataFrame library used for loading data with the df_library parameter.\n\nDataFrame Library Selection\nBy default, Pointblank loads data as Polars DataFrames, but you can specify alternative libraries:\n# Load as Polars DataFrame (default)\ntbl: small_table\ndf_library: polars\n\n# Load as Pandas DataFrame\ntbl: small_table\ndf_library: pandas\n\n# Load as DuckDB table (via Ibis)\ntbl: small_table\ndf_library: duckdb\nThis is particularly useful when using validation expressions that require specific DataFrame APIs:\n# Using Pandas-specific operations\ntbl: small_table\ndf_library: pandas\nsteps:\n  - specially:\n      expr: \"lambda df: df.assign(total=df['a'] + df['d'])\"\n\n# Using Polars-specific operations\ntbl: small_table\ndf_library: polars\nsteps:\n  - specially:\n      expr: \"lambda df: df.select(pl.col('a') + pl.col('d') &gt; 0)\"\n\n\nFile-based Sources\n# CSV files (respects df_library setting)\ntbl: \"data/customers.csv\"\ndf_library: pandas\n\n# Parquet files\ntbl: \"warehouse/sales.parquet\"\ndf_library: polars\n\n# Multiple files with patterns\ntbl: \"logs/*.parquet\"\n\n\nBuilt-in Datasets\n# Use Pointblank's built-in datasets\ntbl: small_table\ntbl: game_revenue\ntbl: nycflights\n\n\nPython Expressions for Complex Sources\nFor more complex data loading, use the python: block syntax. This syntax can be used with several parameters throughout your YAML configuration:\n\ntbl: For complex data source loading (as shown below)\nexpr: For custom validation expressions in col_vals_expr\npre: For data preprocessing before validation steps\nactions: For callable action functions (warning, error, critical, and default)\n\n# Load data with custom Polars operations\ntbl:\n  python: |\n    pl.scan_csv(\"sales_data.csv\")\n    .filter(pl.col(\"date\") &gt;= \"2024-01-01\")\n    .head(1000)\n\n# Load from a database connection\ntbl:\n  python: |\n    pl.read_database(\n        query=\"SELECT * FROM customers WHERE active = true\",\n        connection=\"postgresql://user:pass@localhost/db\"\n    )",
    "crumbs": [
      "Get Started",
      "YAML",
      "YAML Validation Workflows"
    ]
  },
  {
    "objectID": "user-guide/yaml-validation-workflows.html#reusable-templates-with-set_tbl",
    "href": "user-guide/yaml-validation-workflows.html#reusable-templates-with-set_tbl",
    "title": "YAML Validation Workflows",
    "section": "Reusable Templates with set_tbl=",
    "text": "Reusable Templates with set_tbl=\nOne of the most powerful features of YAML validation workflows is the ability to create reusable templates that can be applied to different datasets. Using the set_tbl= parameter with yaml_interrogate(), you can define validation logic once and apply it to multiple data sources.\n\nCreating Validation Templates\nWhen creating templates for use with set_tbl=, the tbl field is still required but its value will be overridden. The recommended approach is to use tbl: null:\ntbl: null\ntbl_name: \"Sales Data Validation Template\"\nlabel: \"Standard validation checks for sales data\"\nsteps:\n  - col_exists:\n      columns: [customer_id, revenue, region, date]\n  - col_vals_not_null:\n      columns: [customer_id, revenue]\n  - col_vals_gt:\n      columns: [revenue]\n      value: 0\n  - col_vals_in_set:\n      columns: [region]\n      set: [North, South, East, West]\n\n\nApplying Templates to Multiple Datasets\nHere’s a practical example showing how to apply the same validation template to multiple quarterly datasets, demonstrating the power of reusable YAML configurations:\n\nimport pointblank as pb\nimport polars as pl\n\n# Define the template once\nsales_template = \"\"\"\ntbl: null  # Will be overridden\ntbl_name: \"Sales Data Validation\"\nlabel: \"Standard sales validation checks\"\nthresholds:\n  warning: 0.05\n  error: 0.1\nsteps:\n  - col_exists:\n      columns: [customer_id, revenue, region]\n  - col_vals_not_null:\n      columns: [customer_id, revenue]\n  - col_vals_gt:\n      columns: [revenue]\n      value: 0\n  - col_vals_in_set:\n      columns: [region]\n      set: [North, South, East, West]\n\"\"\"\n\n# Create different datasets\nq1_data = pl.DataFrame({\n    \"customer_id\": [1, 2, 3, 4],\n    \"revenue\": [100, 200, 150, 300],\n    \"region\": [\"North\", \"South\", \"East\", \"West\"]\n})\n\nq2_data = pl.DataFrame({\n    \"customer_id\": [5, 6, 7, 8],\n    \"revenue\": [250, 180, 220, 350],\n    \"region\": [\"South\", \"North\", \"West\", \"East\"]\n})\n\n# Apply the same template to both datasets\nq1_result = pb.yaml_interrogate(sales_template, set_tbl=q1_data)\nq2_result = pb.yaml_interrogate(sales_template, set_tbl=q2_data)\n\nprint(f\"Q1 validation: {all(v.all_passed for v in q1_result.validation_info)}\")\nprint(f\"Q2 validation: {all(v.all_passed for v in q2_result.validation_info)}\")\n\nQ1 validation: True\nQ2 validation: True\n\n\n\n\nTemplate Best Practices\n\nUse tbl: null: this clearly indicates the template expects a data source to be provided\nInclude comprehensive metadata: use tbl_name, label, and brief to make results self-documenting\nSet appropriate thresholds: define warning/error levels that make sense for your use case\nVersion control templates: store templates in your repository alongside your data processing code\nTest with sample data: validate your templates work with representative datasets\n\n\n\nCommon Template Patterns\nFor API response validation, you can ensure that responses have the expected structure and valid status codes:\ntbl: null\ntbl_name: \"API Response Validation\"\nbrief: \"Standard checks for API response data\"\nsteps:\n  - col_exists:\n      columns: [user_id, status, timestamp]\n  - col_vals_in_set:\n      columns: [status]\n      set: [success, error, pending]\n  - col_vals_not_null:\n      columns: [user_id, timestamp]\nFor file upload validation, you can check file sizes and formats to ensure they meet your requirements:\ntbl: null\ntbl_name: \"File Upload Validation\"\nsteps:\n  - col_vals_gt:\n      columns: [file_size]\n      value: 0\n  - col_vals_lt:\n      columns: [file_size]\n      value: 10485760  # 10MB limit\n  - col_vals_in_set:\n      columns: [file_type]\n      set: [csv, json, xlsx, parquet]\nThis template approach is particularly valuable in data pipelines, ETL processes, and automated testing scenarios where you need to apply consistent validation logic across multiple similar datasets.",
    "crumbs": [
      "Get Started",
      "YAML",
      "YAML Validation Workflows"
    ]
  },
  {
    "objectID": "user-guide/yaml-validation-workflows.html#validation-steps",
    "href": "user-guide/yaml-validation-workflows.html#validation-steps",
    "title": "YAML Validation Workflows",
    "section": "Validation Steps",
    "text": "Validation Steps\nYAML supports all of Pointblank’s validation methods. Here are some common patterns:\n\nColumn-based Validations\ntbl: worldcities.csv\nsteps:\n  # Check for missing values\n  - col_vals_not_null:\n      columns: [city_name, country]\n\n  # Validate value ranges\n  - col_vals_between:\n      columns: latitude\n      left: -90\n      right: 90\n\n  # Check set membership\n  - col_vals_in_set:\n      columns: country_code\n      set: [US, CA, MX, UK, DE, FR]\n\n  # Regular expression validation\n  - col_vals_regex:\n      columns: postal_code\n      pattern: \"^[0-9]{5}(-[0-9]{4})?$\"\n\n\nRow-based Validations\ntbl: sales_data.csv\nsteps:\n  # Check for duplicate rows\n  - rows_distinct\n\n  # Ensure complete rows (no missing values)\n  - rows_complete\n\n  # Check row count\n  - row_count_match:\n      count: 1000\n\n\nSchema Validations\nSchema validation ensures your data has the expected structure and column types. The col_schema_match validation method uses a schema key that contains a columns list, where each item in the list can specify a column name alone or a column name with its expected data type.\nEach column entry can be specified as:\n\ncolumn_name: column name as a scalar string (structure validation, no type checking)\n[column_name, \"data_type\"]: column name with type validation (as a list with two elements)\n[column_name]: column name in a single-item list (equivalent to scalar, for consistency)\n\ntbl: customer_data.csv\nsteps:\n  # Complete schema validation (structure and types)\n  - col_schema_match:\n      schema:\n        columns:\n          - [customer_id, \"int64\"]\n          - [name, \"object\"]\n          - [email, \"object\"]\n          - [signup_date, \"datetime64[ns]\"]\n\n  # Structure-only validation (column names without types)\n  - col_schema_match:\n      schema:\n        columns:\n          - customer_id\n          - name\n          - email\n      complete: false\n      brief: \"Check that core columns exist\"\n\nSchema Validation Options\nSchema validations support the full range of validation options:\ntbl: data_file.csv\nsteps:\n  - col_schema_match:\n      schema:\n        columns:\n          - [id, \"int64\"]\n          - name\n      complete: false                  # Allow extra columns\n      in_order: false                  # Column order doesn't matter\n      case_sensitive_colnames: false   # Case-insensitive column names\n      case_sensitive_dtypes: false     # Case-insensitive type names\n      full_match_dtypes: false         # Allow partial type matching\n      brief: \"Flexible schema validation\"\n\n\nOther Structure Validations\ntbl: customer_data.csv\nsteps:\n  # Check column count\n  - col_count_match:\n      count: 4\n\n\n\nTrend Validations\nValidate that values follow increasing or decreasing patterns across rows:\ntbl: time_series_data.csv\nsteps:\n  # Ensure timestamp values increase\n  - col_vals_increasing:\n      columns: timestamp\n      brief: \"Timestamps must be in chronological order\"\n\n  # Validate countdown timer decreases\n  - col_vals_decreasing:\n      columns: countdown\n      allow_stationary: true\n      brief: \"Countdown values should decrease (ties allowed)\"\n\n  # Check trend with tolerance\n  - col_vals_increasing:\n      columns: temperature\n      decreasing_tol: 0.5\n      brief: \"Temperature trends upward (small drops &lt; 0.5°C allowed)\"\n\n\nSpecification-based Validations\nValidate values against common data specifications like email addresses, URLs, postal codes, and more:\ntbl: user_contact_info.csv\nsteps:\n  # Validate email addresses\n  - col_vals_within_spec:\n      columns: email\n      spec: \"email\"\n\n  # Validate US ZIP codes\n  - col_vals_within_spec:\n      columns: zip_code\n      spec: \"postal_code[US]\"\n\n  # Validate URLs\n  - col_vals_within_spec:\n      columns: website\n      spec: \"url\"\n      na_pass: true\nAvailable specifications include: \"email\", \"url\", \"phone\", \"ipv4\", \"ipv6\", \"mac\", \"isbn\", \"vin\", \"credit_card\", \"swift\", \"postal_code[&lt;country&gt;]\", \"iban[&lt;country&gt;]\".\n\n\nTable Comparison\nValidate that an entire table matches a reference table:\ntbl: processed_output.csv\nsteps:\n  # Compare against expected output\n  - tbl_match:\n      tbl_compare:\n        python: |\n          pb.load_dataset(\"expected_output\", tbl_type=\"polars\")\n      brief: \"Output matches expected results\"\nThe tbl_match() validation performs comprehensive comparison including column count, row count, schema, and data values. It supports cross-backend validation (e.g., comparing Polars vs. Pandas DataFrames).\n\n\nAI-Powered Validation\nUse Large Language Models to validate data based on natural language criteria:\ntbl: customer_feedback.csv\nsteps:\n  # Validate sentiment\n  - prompt:\n      prompt: \"Customer feedback should express positive sentiment\"\n      model: \"anthropic:claude-sonnet-4\"\n      columns_subset: [feedback_text, rating]\n      batch_size: 500\n      thresholds:\n        warning: 0.1\n\n  # Validate semantic correctness\n  - prompt:\n      prompt: \"Product descriptions should mention the product category and at least one benefit\"\n      model: \"openai:gpt-4\"\n      columns_subset: [product_name, description, category]\nNote: AI validations require API keys to be set as environment variables (e.g., ANTHROPIC_API_KEY, OPENAI_API_KEY) or in a .env file. These validations are best suited for semantic, context-dependent, or subjective quality checks rather than simple numeric comparisons.",
    "crumbs": [
      "Get Started",
      "YAML",
      "YAML Validation Workflows"
    ]
  },
  {
    "objectID": "user-guide/yaml-validation-workflows.html#thresholds-and-severity-levels",
    "href": "user-guide/yaml-validation-workflows.html#thresholds-and-severity-levels",
    "title": "YAML Validation Workflows",
    "section": "Thresholds and Severity Levels",
    "text": "Thresholds and Severity Levels\nThresholds determine when validation failures trigger different severity levels. You can set global thresholds for the entire workflow:\ntbl: sales_data.csv\ntbl_name: \"Sales Data Quality Check\"\nthresholds:\n  warning: 0.05    # 5% failure rate triggers warning\n  error: 0.10      # 10% failure rate triggers error\n  critical: 0.15   # 15% failure rate triggers critical\nsteps:\n  - col_vals_not_null:\n      columns: [customer_id, amount]\n  - col_vals_gt:\n      columns: amount\n      value: 0\nYou can also set thresholds for individual validation steps:\ntbl: user_data.csv\nsteps:\n  - col_vals_not_null:\n      columns: email\n      thresholds:\n        warning: 1      # Any missing email is a warning\n        error: 0.01     # 1% missing emails is an error\n\n  - col_vals_regex:\n      columns: email\n      pattern: \"^[\\\\w\\\\.-]+@[\\\\w\\\\.-]+\\\\.[a-zA-Z]{2,}$\"\n      thresholds:\n        error: 1        # Any invalid email format is an error",
    "crumbs": [
      "Get Started",
      "YAML",
      "YAML Validation Workflows"
    ]
  },
  {
    "objectID": "user-guide/yaml-validation-workflows.html#actions-responding-to-validation-failures",
    "href": "user-guide/yaml-validation-workflows.html#actions-responding-to-validation-failures",
    "title": "YAML Validation Workflows",
    "section": "Actions: Responding to Validation Failures",
    "text": "Actions: Responding to Validation Failures\nActions define what happens when validation thresholds are exceeded. You can use string templates with placeholder variables or callable functions.\n\nString Template Actions\ntbl: orders.csv\nthresholds:\n  warning: 0.02\n  error: 0.05\nactions:\n  warning: \"Warning: Step {step} found {n_failed} failures in {col} column\"\n  error: \"Error in {TYPE} validation: {n_failed}/{n} rows failed (Step {step})\"\n  critical: \"Critical failure detected at {time}\"\nsteps:\n  - col_vals_not_null:\n      columns: [order_id, customer_id]\nAvailable template variables include:\n\n{step}: validation step number\n{col}: column name being validated\n{val}: specific failing value (when applicable)\n{n_failed}: number of failing rows\n{n}: total number of rows checked\n{TYPE}: validation method name (e.g., “COL_VALS_NOT_NULL”)\n{LEVEL}: severity level (“WARNING”, “ERROR”, “CRITICAL”)\n{time}: timestamp of the validation\n\n\n\nCallable Actions\nFor more complex responses, use Python callable functions:\ntbl: critical_data.csv\nthresholds:\n  error: 1\nactions:\n  error:\n    python: |\n      lambda: print(\"ALERT: Critical data validation failed!\")\n  critical:\n    python: |\n      lambda: print(\"CRITICAL: Validation failure - manual intervention required!\")\nsteps:\n  - col_vals_not_null:\n      columns: [transaction_id, amount]\nNote: The Python environment in YAML actions is restricted for security. You can use built-in functions like print(), basic operations, and available DataFrame libraries, but cannot import external modules like requests or logging. For external notifications, consider using string template actions or handling alerts in your application code after the validation completes.\n\n\nStep-level Actions\nYou can also define actions for individual validation steps:\ntbl: financial_data.csv\nsteps:\n  - col_vals_not_null:\n      columns: account_balance\n      thresholds:\n        error: 1\n      actions:\n        error: \"Missing account balance detected in step {step}.\"\n\n  - col_vals_gt:\n      columns: account_balance\n      value: 0\n      actions:\n        warning:\n          python: |\n            lambda: print(\"Negative balance warning triggered.\")",
    "crumbs": [
      "Get Started",
      "YAML",
      "YAML Validation Workflows"
    ]
  },
  {
    "objectID": "user-guide/yaml-validation-workflows.html#advanced-features",
    "href": "user-guide/yaml-validation-workflows.html#advanced-features",
    "title": "YAML Validation Workflows",
    "section": "Advanced Features",
    "text": "Advanced Features\n\nPre-processing with the pre Parameter\nYou can apply data transformations before validation using the pre parameter:\ntbl: transactions.csv\nsteps:\n  # Validate only recent transactions\n  - col_vals_gt:\n      columns: amount\n      value: 0\n      pre:\n        python: |\n          lambda df: df.filter(\n              pl.col(\"transaction_date\") &gt;= \"2024-01-01\"\n          )\n\n  # Check completeness for active customers only\n  - col_vals_not_null:\n      columns: [email, phone]\n      pre: |\n        lambda df: df.filter(pl.col(\"status\") == \"active\")\nNote that you can use either the explicit python: block syntax or the shortcut syntax (just pre: |) for the lambda expressions.\n\n\nComplex Expressions\nFor advanced validation logic, use a col_vals_expr step with custom expressions:\ntbl: sales_data.csv\nsteps:\n  # Custom business logic validation\n  - col_vals_expr:\n      expr:\n        python: |\n          (\n            pl.when(pl.col(\"product_type\") == \"premium\")\n            .then(pl.col(\"price\") &gt;= 100)\n            .when(pl.col(\"product_type\") == \"standard\")\n            .then(pl.col(\"price\").is_between(20, 99))\n            .otherwise(pl.col(\"price\") &lt;= 19)\n          )\n\n\nBrief Descriptions\nAdd human-readable descriptions to validation steps. The brief parameter supports string templating and automatic generation:\ntbl: customer_data.csv\nbrief: \"Customer data quality validation for {auto}\"\nsteps:\n  - col_vals_not_null:\n      columns: customer_id\n      brief: \"Ensure all customers have valid IDs\"\n\n  - col_vals_regex:\n      columns: email\n      pattern: \"^[\\\\w\\\\.-]+@[\\\\w\\\\.-]+\\\\.[a-zA-Z]{2,}$\"\n      brief: \"Validate email format compliance\"\n\n  - col_vals_between:\n      columns: age\n      left: 13\n      right: 120\n      brief: \"Check reasonable age ranges\"\n\n  # Use automatic brief generation\n  - col_vals_not_null:\n      columns: phone_number\n      brief: true\n\n  # Template variables in briefs\n  - col_vals_in_set:\n      columns: status\n      set: [active, inactive, pending]\n      brief: \"Column '{col}' must be one of: {set}\"\nBrief Templating Options:\n\ncustom strings: Write your own descriptive text\ntrue: Automatically generates a brief based on the validation method and parameters\n{auto}: Placeholder for auto-generated text within custom strings\ntemplate variables: Use the same variables available in actions:\n\n{col}: column name(s) being validated\n{step}: the step number in the validation plan\n{value}: the comparison value used in the validation (for single-value comparisons)\n{pattern}: for regex validations, the pattern being matched",
    "crumbs": [
      "Get Started",
      "YAML",
      "YAML Validation Workflows"
    ]
  },
  {
    "objectID": "user-guide/yaml-validation-workflows.html#working-with-yaml-files",
    "href": "user-guide/yaml-validation-workflows.html#working-with-yaml-files",
    "title": "YAML Validation Workflows",
    "section": "Working with YAML Files",
    "text": "Working with YAML Files\n\nLoading from Files\nYou can save your YAML configuration to files and load them:\n\n# Create a YAML file\nyaml_content = \"\"\"\ntbl: small_table\ntbl_name: \"File-based Validation\"\nsteps:\n  - col_vals_between:\n      columns: c\n      left: 1\n      right: 10\n  - col_vals_in_set:\n      columns: f\n      set: [low, mid, high]\n\"\"\"\n\n# Save to file\nfrom pathlib import Path\nyaml_file = Path(\"validation_config.yaml\")\nyaml_file.write_text(yaml_content)\n\n# Load and execute\nresult = pb.yaml_interrogate(yaml_file)\nresult\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:19:07PolarsFile-based Validation\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_between\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_between()\n        \n        \n        \n    c\n    [1, 10]\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        \n        \n    f\n    low, mid, high\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:19:07 UTC&lt; 1 s2025-11-23 00:19:07 UTC\n  \n\n\n\n\n\n\n        \n\n\n\n\nConverting YAML to Python\nUse yaml_to_python() to generate equivalent Python code from your YAML configuration:\n\nyaml_config = \"\"\"\ntbl: small_table\ntbl_name: \"Example Validation\"\nthresholds:\n  warning: 0.1\n  error: 0.2\nactions:\n  warning: \"Warning: {TYPE} validation failed\"\nsteps:\n  - col_vals_gt:\n      columns: a\n      value: 0\n  - col_vals_in_set:\n      columns: f\n      set: [low, mid, high]\n\"\"\"\n\n# Generate Python code\npython_code = pb.yaml_to_python(yaml_config)\nprint(python_code)\n\n```python\nimport pointblank as pb\n\n(\n    pb.Validate(\n        data=pb.load_dataset(\"small_table\", tbl_type=\"polars\"),\n        tbl_name=\"Example Validation\",\n        thresholds=pb.Thresholds(warning=0.1, error=0.2),\n        actions=pb.Actions(warning=\"Warning: {TYPE} validation failed\"),\n    )\n    .col_vals_gt(columns=\"a\", value=0)\n    .col_vals_in_set(columns=\"f\", set=[\"low\", \"mid\", \"high\"])\n    .interrogate()\n)\n```\n\n\nThis is useful for:\n\nlearning how YAML maps to Python API calls\ntransitioning from YAML to code-based workflows\ngenerating documentation that shows both approaches\ndebugging YAML configurations",
    "crumbs": [
      "Get Started",
      "YAML",
      "YAML Validation Workflows"
    ]
  },
  {
    "objectID": "user-guide/yaml-validation-workflows.html#practical-examples",
    "href": "user-guide/yaml-validation-workflows.html#practical-examples",
    "title": "YAML Validation Workflows",
    "section": "Practical Examples",
    "text": "Practical Examples\n\nData Pipeline Validation\nHere’s a comprehensive example for validating data in a processing pipeline:\ntbl:\n  python: |\n    (\n      pl.scan_csv(\"raw_data/customer_events.csv\")\n      .filter(pl.col(\"event_date\") &gt;= \"2024-01-01\")\n    )\n\ntbl_name: \"Customer Events Pipeline Validation\"\nlabel: \"Daily data quality check for customer events\"\n\nthresholds:\n  warning: 0.01   # 1% failure rate\n  error: 0.05     # 5% failure rate\n\nactions:\n  warning: \"Pipeline warning: {TYPE} validation found {n_failed} issues\"\n  error:\n    python: |\n      lambda: print(\"ERROR: Pipeline validation failed - manual review required\")\n\nsteps:\n  # Schema validation\n  - col_schema_match:\n      schema:\n        columns:\n          - [customer_id, \"int64\"]\n          - [event_type, \"object\"]\n          - [event_date, \"object\"]\n          - [revenue, \"float64\"]\n      brief: \"Validate table structure matches expected schema\"\n\n  # Data completeness\n  - col_vals_not_null:\n      columns: [customer_id, event_type, event_date]\n      brief: \"Critical fields must be complete\"\n\n  # Business logic validation\n  - col_vals_in_set:\n      columns: event_type\n      set: [signup, purchase, cancellation, upgrade]\n      brief: \"Event types must be from approved list\"\n\n  # Data quality checks\n  - col_vals_gt:\n      columns: revenue\n      value: 0\n      na_pass: true\n      brief: \"Revenue values must be positive when present\"\n\n  # Temporal validation\n  - col_vals_expr:\n      expr:\n        python: |\n          pl.col(\"event_date\").str.strptime(pl.Date, \"%Y-%m-%d\").is_not_null()\n      brief: \"Event dates must be valid YYYY-MM-DD format\"\n\n\nQuality Monitoring Dashboard\nFor ongoing data quality monitoring:\ntbl: warehouse/daily_metrics.parquet\ntbl_name: \"Daily Metrics Quality Check\"\n\nthresholds:\n  warning: 5      # 5 failing rows\n  error: 50       # 50 failing rows\n  critical: 100   # 100 failing rows\n\nactions:\n  warning: \"Quality check warning: {n_failed} rows failed {TYPE} validation\"\n  error: \"Quality degradation detected: Step {step} failed for {n_failed}/{n} rows\"\n  critical:\n    python: |\n      lambda: print(\"CRITICAL: Data quality failure detected - immediate attention required\")\n  highest_only: false\n\nsteps:\n  - row_count_match:\n      count: 10000\n      brief: \"Verify expected daily record count\"\n\n  - col_vals_not_null:\n      columns: [date, metric_value, source_system]\n      brief: \"Core fields must be complete\"\n\n  - col_vals_between:\n      columns: metric_value\n      left: 0\n      right: 1000000\n      brief: \"Metric values within reasonable range\"\n\n  - rows_distinct:\n      columns_subset: [date, metric_name, source_system]\n      brief: \"No duplicate metric records per day\"",
    "crumbs": [
      "Get Started",
      "YAML",
      "YAML Validation Workflows"
    ]
  },
  {
    "objectID": "user-guide/yaml-validation-workflows.html#best-practices",
    "href": "user-guide/yaml-validation-workflows.html#best-practices",
    "title": "YAML Validation Workflows",
    "section": "Best Practices",
    "text": "Best Practices\n\nOrganization and Structure\n\nuse descriptive names: give your validations clear tbl_name and label values\nadd brief descriptions: document what each validation step checks\ngroup related validations: organize steps logically (schema, completeness, business rules)\nversion control: store YAML files in git alongside your data processing code\n\n\n\nError Handling and Monitoring\n\nset appropriate thresholds: start conservative and adjust based on your data patterns\nuse actions for alerting: set up notifications for critical failures\ndocument expected failures: some data quality issues might be acceptable\nmonitor validation results: track validation performance over time\n\n\n\nPerformance Considerations\n\nuse the pre parameter efficiently: apply filters early to reduce data volume\norder validations strategically: put fast, likely-to-fail checks first\nconsider data source location: local files are faster than remote sources\nuse appropriate column selections: only validate the columns you need",
    "crumbs": [
      "Get Started",
      "YAML",
      "YAML Validation Workflows"
    ]
  },
  {
    "objectID": "user-guide/yaml-validation-workflows.html#wrapping-up",
    "href": "user-guide/yaml-validation-workflows.html#wrapping-up",
    "title": "YAML Validation Workflows",
    "section": "Wrapping Up",
    "text": "Wrapping Up\nYAML validation workflows provide a powerful, declarative approach to data validation in Pointblank. Such workflows are great at expressing common validation patterns in a readable format that can be easily shared, version controlled, and maintained by teams.\nKey advantages of YAML workflows:\n\nreadable: non-programmers can understand and contribute to validation logic\nmaintainable: easy to modify validation rules without changing application code\nportable: YAML files can be shared between projects and teams\nversion controlled: track changes to validation logic over time\nflexible: support for simple checks and complex custom logic\n\nUse YAML workflows when you want declarative, maintainable validation definitions, and fall back to the Python API when you need complex programmatic logic or tight integration with application code. The two approaches complement each other well and can be used together as your validation needs evolve.",
    "crumbs": [
      "Get Started",
      "YAML",
      "YAML Validation Workflows"
    ]
  },
  {
    "objectID": "user-guide/step-reports.html",
    "href": "user-guide/step-reports.html",
    "title": "Step Reports",
    "section": "",
    "text": "While validation reports provide a comprehensive overview of all validation steps, sometimes you need to focus on a specific validation step in greater detail. This is where step reports come in. A step report is a detailed examination of a single validation step, providing in-depth information about the test units that were validated and their pass/fail status.\nStep reports are especially useful when debugging validation failures, investigating problematic data, or communicating detailed findings to colleagues who are responsible for specific data quality issues.",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Step Reports"
    ]
  },
  {
    "objectID": "user-guide/step-reports.html#creating-a-step-report",
    "href": "user-guide/step-reports.html#creating-a-step-report",
    "title": "Step Reports",
    "section": "Creating a Step Report",
    "text": "Creating a Step Report\nTo create a step report, you first need to run a validation and then use the get_step_report() method, specifying which validation step you want to examine:\n\nimport pointblank as pb\nimport polars as pl\n\n# Sample data as a Polars DataFrame\ndata = pl.DataFrame({\n    \"id\": range(1, 11),\n    \"value\": [10, 20, 3, 35, 50, 2, 70, 8, 20, 4],\n    \"category\": [\"A\", \"B\", \"C\", \"A\", \"D\", \"F\", \"A\", \"E\", \"H\", \"G\"],\n    \"ratio\": [0.5, 0.7, 0.3, 1.2, 0.8, 0.9, 0.4, 1.5, 0.6, 0.2],\n    \"status\": [\"active\", \"active\", \"inactive\", \"active\", \"inactive\",\n               \"active\", \"inactive\", \"active\", \"active\", \"inactive\"]\n})\n\n# Create a validation\nvalidation = (\n    pb.Validate(data=data, tbl_name=\"example_data\")\n    .col_vals_gt(\n        columns=\"value\",\n        value=10\n    )\n    .col_vals_in_set(\n        columns=\"category\",\n        set=[\"A\", \"B\", \"C\"]\n    )\n    .interrogate()\n)\n\n# Get step report for the second validation step (i=2)\nstep_report = validation.get_step_report(i=2)\n\nstep_report\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 2ASSERTION category ∈ {A, B, C}5 / 10 TEST UNIT FAILURES IN COLUMN 3 EXTRACT OF ALL 5 ROWS (WITH TEST UNIT FAILURES IN RED):\n  \n\n  \n  idInt64\n  valueInt64\n  categoryString\n  ratioFloat64\n  statusString\n\n\n\n  \n    5\n    5\n    50\n    D\n    0.8\n    inactive\n  \n  \n    6\n    6\n    2\n    F\n    0.9\n    active\n  \n  \n    8\n    8\n    8\n    E\n    1.5\n    active\n  \n  \n    9\n    9\n    20\n    H\n    0.6\n    active\n  \n  \n    10\n    10\n    4\n    G\n    0.2\n    inactive\n  \n\n\n\n\n\n\n        \n\n\nIn this example, we first create and interrogate a validation object with two steps. We then generate a step report for the second validation step (i=2), which checks if the values in the category column are in the set [\"A\", \"B\", \"C\"].\nNote that step numbers in Pointblank start at 1, matching what you see in the validation report’s STEP column (i.e., not 0-based indexing). So the first step is referred to with i=1, the second step with i=2, and so on.",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Step Reports"
    ]
  },
  {
    "objectID": "user-guide/step-reports.html#understanding-step-report-components",
    "href": "user-guide/step-reports.html#understanding-step-report-components",
    "title": "Step Reports",
    "section": "Understanding Step Report Components",
    "text": "Understanding Step Report Components\nA step report consists of several key components that provide detailed information about the validation step:\n\nHeader: displays the validation step number, type of validation, and a brief description\nTable Body: presents either the failing rows, a sample of completely passing data, or an expected/actual comparison (for a col_schema_match() step)\n\nThe step report table highlights passing and failing rows, making it easy to identify problematic data points. This is especially useful for diagnosing issues when dealing with large datasets.",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Step Reports"
    ]
  },
  {
    "objectID": "user-guide/step-reports.html#different-types-of-step-reports",
    "href": "user-guide/step-reports.html#different-types-of-step-reports",
    "title": "Step Reports",
    "section": "Different Types of Step Reports",
    "text": "Different Types of Step Reports\nIt’s important to note that step reports vary in appearance and structure depending on the type of validation method used:\n\nValue-based validations (like col_vals_gt(), col_vals_in_set()): show individual rows that failed validation\nUniqueness checks (rows_distinct()): group together the duplicate records in order of appearance\nSchema validations (col_schema_match()): display column-level information about expected vs. actual data types\n\nAdditionally, step reports for value-based validations and uniqueness checks operate in two distinct modes:\n\nWhen errors are present: The report shows only the failing rows and, for value-based validations, clearly highlights the column under study\nWhen no errors exist: The report header clearly indicates success, and a sample of the data is shown (along with the studied column highlighted, for value-based validations)\n\nThis variation in reporting style allows step reports to effectively communicate the specific type of validation being performed and display relevant information in the most appropriate format. When you’re working with different validation types, expect to see different step report layouts optimized for each context.\n\nValue-Based Validation Step Reports\nValue-based step reports focus on showing individual rows where values in the target column failed the validation check. These reports highlight the specific column being validated and clearly display which values violated the condition.\n\n# Create sample data with some validation failures\ndata = pl.DataFrame({\n    \"id\": range(1, 8),\n    \"value\": [120, 85, 47, 210, 30, 10, 5],\n    \"category\": [\"A\", \"B\", \"C\", \"A\", \"D\", \"B\", \"E\"]\n})\n\n# Create a validation with a value-based check\nvalidation_values = (\n    pb.Validate(data=data, tbl_name=\"sales_data\")\n    .col_vals_gt(\n        columns=\"value\",\n        value=50,\n        brief=\"Sales values should exceed $50\"\n    )\n    .interrogate()\n)\n\n# Display the step report for the value-based validation\nvalidation_values.get_step_report(i=1)\n\n\n\n\n\n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 1ASSERTION value &gt; 504 / 7 TEST UNIT FAILURES IN COLUMN 2 EXTRACT OF ALL 4 ROWS (WITH TEST UNIT FAILURES IN RED):\n  \n\n  \n  idInt64\n  valueInt64\n  categoryString\n\n\n\n  \n    3\n    3\n    47\n    C\n  \n  \n    5\n    5\n    30\n    D\n  \n  \n    6\n    6\n    10\n    B\n  \n  \n    7\n    7\n    5\n    E\n  \n\n\n\n\n\n\n        \n\n\nThis report clearly identifies which rows contain values that don’t meet our threshold, making it easy to investigate these specific data points.\n\n\nUniqueness Validation Step Reports\nUniqueness checks produce a different type of step report that groups duplicate records together. This format makes it easy to identify patterns in duplicate data.\n\n# Create sample data with some duplicate rows based on the combination of columns\ndata = pl.DataFrame({\n    \"customer_id\": [101, 102, 103, 101, 104, 105, 102],\n    \"order_date\": [\"2023-01-15\", \"2023-01-16\", \"2023-01-16\",\n                   \"2023-01-15\", \"2023-01-17\", \"2023-01-18\", \"2023-01-19\"],\n    \"product\": [\"Laptop\", \"Phone\", \"Tablet\", \"Laptop\",\n                \"Monitor\", \"Keyboard\", \"Headphones\"]\n})\n\n# Create a validation checking for unique customer-product combinations\nvalidation_duplicates = (\n    pb.Validate(data=data, tbl_name=\"order_data\")\n    .rows_distinct(\n        columns_subset=[\"customer_id\", \"product\"],\n        brief=\"Customer should not order the same product twice\"\n    )\n    .interrogate()\n)\n\n# Display the step report for the uniqueness validation\nvalidation_duplicates.get_step_report(i=1)\n\n\n\n\n\n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 1Rows are distinct across a subset of columns2 / 7 TEST UNIT FAILURESEXTRACT OF ALL 2 ROWS:\n  \n\n  \n  customer_idInt64\n  productString\n\n\n\n  \n    1\n    101\n    Laptop\n  \n  \n    4\n    101\n    Laptop\n  \n\n\n\n\n\n\n        \n\n\nThe report organizes duplicate records together, making it easy to see which combinations are repeated and how many times they appear.\n\n\nSchema Validation Step Reports\nSchema validation step reports have a completely different structure, comparing expected versus actual column data types and presence.\n\nschema = pb.Schema(\n    columns=[\n        (\"date_time\", \"timestamp\"),\n        (\"dates\", \"date\"),\n        (\"a\", \"int64\"),\n        (\"b\",),\n        (\"c\",),\n        (\"d\", \"float64\"),\n        (\"e\", [\"bool\", \"boolean\"]),\n        (\"f\", \"str\"),\n    ]\n)\n\nvalidation_schema = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"duckdb\"),\n        tbl_name=\"small_table\",\n        label=\"Step report for a schema check\"\n    )\n    .col_schema_match(schema=schema)\n    .interrogate()\n)\n\n# Display the step report for the schema validation\nvalidation_schema.get_step_report(i=1)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 1 ✗COLUMN SCHEMA MATCHCOMPLETEIN ORDERCOLUMN ≠ columnDTYPE ≠ dtypefloat ≠ float64\n  \n\n  \n    TARGET\n  \n  \n    EXPECTED\n  \n\n\n  \n  COLUMN\n  DATA TYPE\n  \n  COLUMN\n  \n  DATA TYPE\n  \n\n\n\n  \n    1\n    date_time\n    timestamp(6)\n    1\n    date_time\n    ✓\n    timestamp\n    ✗\n  \n  \n    2\n    date\n    date\n    2\n    dates\n    ✗\n    date\n    —\n  \n  \n    3\n    a\n    int64\n    3\n    a\n    ✓\n    int64\n    ✓\n  \n  \n    4\n    b\n    string\n    4\n    b\n    ✓\n    —\n    \n  \n  \n    5\n    c\n    int64\n    5\n    c\n    ✓\n    —\n    \n  \n  \n    6\n    d\n    float64\n    6\n    d\n    ✓\n    float64\n    ✓\n  \n  \n    7\n    e\n    boolean\n    7\n    e\n    ✓\n    bool | boolean\n    ✓\n  \n  \n    8\n    f\n    string\n    8\n    f\n    ✓\n    str\n    ✗\n  \n\n  \n  \n  \n    Supplied Column Schema:[('date_time', 'timestamp'), ('dates', 'date'), ('a', 'int64'), ('b',), ('c',), ('d', 'float64'), ('e', ['bool', 'boolean']), ('f', 'str')]\n  \n\n\n\n\n\n\n        \n\n\nThis report style focuses on comparing the expected schema against the actual table structure, highlighting mismatches in data types or missing/extra columns. The table format makes it easy to see exactly where the schema expectations differ from reality.",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Step Reports"
    ]
  },
  {
    "objectID": "user-guide/step-reports.html#customizing-step-reports",
    "href": "user-guide/step-reports.html#customizing-step-reports",
    "title": "Step Reports",
    "section": "Customizing Step Reports",
    "text": "Customizing Step Reports\nStep reports can be customized with several parameters to better focus your analysis and tailor the output to your specific needs. The get_step_report() method offers multiple customization options to help you create more effective reports.\nWhen a dataset has many columns, you might want to focus on just those relevant to your analysis. You can create a step report containing only a subset of the columns in the target table:\n\nvalidation.get_step_report(\n    i=2,\n\n    # Only show these columns ---\n    columns_subset=[\"id\", \"category\", \"status\"]\n)\n\n\n\n\n\n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 2ASSERTION category ∈ {A, B, C}5 / 10 TEST UNIT FAILURES IN COLUMN 3 EXTRACT OF ALL 5 ROWS (WITH TEST UNIT FAILURES IN RED):\n  \n\n  \n  idInt64\n  categoryString\n  statusString\n\n\n\n  \n    5\n    5\n    D\n    inactive\n  \n  \n    6\n    6\n    F\n    active\n  \n  \n    8\n    8\n    E\n    active\n  \n  \n    9\n    9\n    H\n    active\n  \n  \n    10\n    10\n    G\n    inactive\n  \n\n\n\n\n\n\n        \n\n\nThis approach makes step reports much easier to interpret by highlighting just the essential columns that help understand the validation failures.\nFor large datasets with many failing rows, you might want to use limit= to set a cap on the number of rows shown in the report:\n\nvalidation.get_step_report(\n    i=2,\n\n    # Only show up to 2 failing rows ---\n    limit=2\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 2ASSERTION category ∈ {A, B, C}5 / 10 TEST UNIT FAILURES IN COLUMN 3 EXTRACT OF FIRST 2 ROWS (WITH TEST UNIT FAILURES IN RED):\n  \n\n  \n  idInt64\n  valueInt64\n  categoryString\n  ratioFloat64\n  statusString\n\n\n\n  \n    5\n    5\n    50\n    D\n    0.8\n    inactive\n  \n  \n    6\n    6\n    2\n    F\n    0.9\n    active\n  \n\n\n\n\n\n\n        \n\n\nThe report header can also be extensively customized to provide more specific context. You can replace the default header with plain text or Markdown formatting:\n\nvalidation.get_step_report(\n    i=2,\n    header=\"Category Values Validation: *Critical Analysis*\"\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Category Values Validation: Critical Analysis\n  \n\n  \n  idInt64\n  valueInt64\n  categoryString\n  ratioFloat64\n  statusString\n\n\n\n  \n    5\n    5\n    50\n    D\n    0.8\n    inactive\n  \n  \n    6\n    6\n    2\n    F\n    0.9\n    active\n  \n  \n    8\n    8\n    8\n    E\n    1.5\n    active\n  \n  \n    9\n    9\n    20\n    H\n    0.6\n    active\n  \n  \n    10\n    10\n    4\n    G\n    0.2\n    inactive\n  \n\n\n\n\n\n\n        \n\n\nFor more advanced header customization, you can use the templating system with the {title} and {details} elements to retain parts of the default header while adding your own content. The {title} template is the default title whereas {details} provides information on the assertion, number of failures, etc. Let’s move away from the default template of {title}{details} and provide a custom title to go with the details text:\n\nvalidation.get_step_report(\n    i=2,\n    header=\"Custom Category Validation Report {details}\"\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Custom Category Validation Report ASSERTION category ∈ {A, B, C}5 / 10 TEST UNIT FAILURES IN COLUMN 3 EXTRACT OF ALL 5 ROWS (WITH TEST UNIT FAILURES IN RED):\n  \n\n  \n  idInt64\n  valueInt64\n  categoryString\n  ratioFloat64\n  statusString\n\n\n\n  \n    5\n    5\n    50\n    D\n    0.8\n    inactive\n  \n  \n    6\n    6\n    2\n    F\n    0.9\n    active\n  \n  \n    8\n    8\n    8\n    E\n    1.5\n    active\n  \n  \n    9\n    9\n    20\n    H\n    0.6\n    active\n  \n  \n    10\n    10\n    4\n    G\n    0.2\n    inactive\n  \n\n\n\n\n\n\n        \n\n\nWe can keep {title} and {details} and add some more context in between the two:\n\nvalidation.get_step_report(\n    i=2,\n    header=(\n        \"{title}&lt;br&gt;\"\n        \"&lt;span style='font-size: 0.75em;'&gt;\"\n        \"This validation is critical for our data quality standards.\"\n        \"&lt;/span&gt;&lt;br&gt;\"\n        \"{details}\"\n    )\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 2This validation is critical for our data quality standards.ASSERTION category ∈ {A, B, C}5 / 10 TEST UNIT FAILURES IN COLUMN 3 EXTRACT OF ALL 5 ROWS (WITH TEST UNIT FAILURES IN RED):\n  \n\n  \n  idInt64\n  valueInt64\n  categoryString\n  ratioFloat64\n  statusString\n\n\n\n  \n    5\n    5\n    50\n    D\n    0.8\n    inactive\n  \n  \n    6\n    6\n    2\n    F\n    0.9\n    active\n  \n  \n    8\n    8\n    8\n    E\n    1.5\n    active\n  \n  \n    9\n    9\n    20\n    H\n    0.6\n    active\n  \n  \n    10\n    10\n    4\n    G\n    0.2\n    inactive\n  \n\n\n\n\n\n\n        \n\n\nYou could always use more HTML and CSS to do a lot of customization:\n\nvalidation.get_step_report(\n    i=2,\n    header=(\n        \"VALIDATION SUMMARY\\n\\n{details}\\n\\n\"\n        \"&lt;hr style='color: lightblue;'&gt;\"\n        \"&lt;div style='font-size: smaller; padding-bottom: 5px; text-transform: uppercase'&gt;\"\n        \"{title}\"\n        \"&lt;/div&gt;\"\n    )\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    VALIDATION SUMMARY\nASSERTION category ∈ {A, B, C}5 / 10 TEST UNIT FAILURES IN COLUMN 3 EXTRACT OF ALL 5 ROWS (WITH TEST UNIT FAILURES IN RED):\nReport for Validation Step 2\n\n  \n\n  \n  idInt64\n  valueInt64\n  categoryString\n  ratioFloat64\n  statusString\n\n\n\n  \n    5\n    5\n    50\n    D\n    0.8\n    inactive\n  \n  \n    6\n    6\n    2\n    F\n    0.9\n    active\n  \n  \n    8\n    8\n    8\n    E\n    1.5\n    active\n  \n  \n    9\n    9\n    20\n    H\n    0.6\n    active\n  \n  \n    10\n    10\n    4\n    G\n    0.2\n    inactive\n  \n\n\n\n\n\n\n        \n\n\nIf you prefer no header at all, simply set header=None:\n\nvalidation.get_step_report(\n    i=2,\n    header=None\n)\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n\n\n\n\n\n  \n  idInt64\n  valueInt64\n  categoryString\n  ratioFloat64\n  statusString\n\n\n\n  \n    5\n    5\n    50\n    D\n    0.8\n    inactive\n  \n  \n    6\n    6\n    2\n    F\n    0.9\n    active\n  \n  \n    8\n    8\n    8\n    E\n    1.5\n    active\n  \n  \n    9\n    9\n    20\n    H\n    0.6\n    active\n  \n  \n    10\n    10\n    4\n    G\n    0.2\n    inactive\n  \n\n\n\n\n\n\n        \n\n\nThese customization options can be combined to create highly focused reports tailored to specific needs:\n\nvalidation.get_step_report(\n    i=2,\n    columns_subset=[\"id\", \"category\"],\n    header=\"*Category Validation:* Top Issues\",\n    limit=2\n)\n\n\n\n\n\n  \n  \n  \n\n\n\n\n  \n    Category Validation: Top Issues\n  \n\n  \n  idInt64\n  categoryString\n\n\n\n  \n    5\n    5\n    D\n  \n  \n    6\n    6\n    F\n  \n\n\n\n\n\n\n        \n\n\nThrough these customization options, you can craft step reports that effectively communicate the most important information to different audiences. Technical teams might benefit from seeing all columns but with a limited number of examples. Business stakeholders might prefer a focused view with only the most relevant columns. For documentation purposes, custom headers provide important context about what’s being validated.\nRemember that customizing your step reports is about more than aesthetics: it’s about making complex validation information more accessible and actionable for all stakeholders involved in data quality.",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Step Reports"
    ]
  },
  {
    "objectID": "user-guide/step-reports.html#using-step-reports-for-data-investigation",
    "href": "user-guide/step-reports.html#using-step-reports-for-data-investigation",
    "title": "Step Reports",
    "section": "Using Step Reports for Data Investigation",
    "text": "Using Step Reports for Data Investigation\nStep reports can be powerful tools for investigating data quality issues. Let’s look at a more complex example:\n\n# Create a more complex dataset with multiple issues\ncomplex_data = pl.DataFrame({\n    \"id\": range(1, 11),\n    \"value\": [10, 20, 3, 40, 50, 2, 70, 80, 90, 7],\n    \"ratio\": [0.1, 0.2, 0.3, 1.4, 0.5, 0.6, 0.7, 0.8, 1.2, 0.9],\n    \"category\": [\"A\", \"B\", \"C\", \"A\", \"D\", \"B\", \"A\", \"C\", \"B\", \"E\"]\n})\n\n# Create a validation with multiple steps\nvalidation_complex = (\n    pb.Validate(data=complex_data, tbl_name=\"complex_data\")\n    .col_vals_gt(columns=\"value\", value=10)\n    .col_vals_le(columns=\"ratio\", value=1.0)\n    .col_vals_in_set(columns=\"category\", set=[\"A\", \"B\", \"C\"])\n    .interrogate()\n)\n\n# Get step report for the ratio validation (step 2)\nratio_report = validation_complex.get_step_report(i=2)\n\nratio_report\n\n\n\n\n\n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 2ASSERTION ratio ≤ 1.02 / 10 TEST UNIT FAILURES IN COLUMN 3 EXTRACT OF ALL 2 ROWS (WITH TEST UNIT FAILURES IN RED):\n  \n\n  \n  idInt64\n  valueInt64\n  ratioFloat64\n  categoryString\n\n\n\n  \n    4\n    4\n    40\n    1.4\n    A\n  \n  \n    9\n    9\n    90\n    1.2\n    B\n  \n\n\n\n\n\n\n        \n\n\nIn this example, we’re investigating issues with the ratio column by generating a step report specifically for that validation step. The step report shows exactly which rows have values that exceed our maximum threshold of 1.0.",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Step Reports"
    ]
  },
  {
    "objectID": "user-guide/step-reports.html#combining-step-reports-with-extracts",
    "href": "user-guide/step-reports.html#combining-step-reports-with-extracts",
    "title": "Step Reports",
    "section": "Combining Step Reports with Extracts",
    "text": "Combining Step Reports with Extracts\nFor more advanced analysis, you can extract the actual data from a step report into a DataFrame:\n\n# Extract the data from the step report\nfailing_ratios = validation_complex.get_data_extracts(i=2)\n\nfailing_ratios\n\n{2: shape: (2, 5)\n ┌───────────┬─────┬───────┬───────┬──────────┐\n │ _row_num_ ┆ id  ┆ value ┆ ratio ┆ category │\n │ ---       ┆ --- ┆ ---   ┆ ---   ┆ ---      │\n │ u32       ┆ i64 ┆ i64   ┆ f64   ┆ str      │\n ╞═══════════╪═════╪═══════╪═══════╪══════════╡\n │ 4         ┆ 4   ┆ 40    ┆ 1.4   ┆ A        │\n │ 9         ┆ 9   ┆ 90    ┆ 1.2   ┆ B        │\n └───────────┴─────┴───────┴───────┴──────────┘}\n\n\nThis extracts the failing rows from the validation step, which you can then further analyze or fix as needed. Note that the parameter i=2 corresponds directly to the step number shown in the validation report; it’s the same numbering system used for get_step_report().\nThese extracts are particularly valuable for analysts who need to:\n\nperform additional calculations on problematic data\nfeed failing records into correction pipelines\ncreate visualizations of data patterns that led to validation failures\nexport problem records to share with data owners\n\nIt’s worth noting that the validation report itself includes export buttons on the far right of each row that allow you to download CSV files of the failing data directly. This serves as a convenient delivery mechanism for sharing extracts with colleagues who may not be working in Python, making the validation report not just a visual tool but also a practical means of distributing problematic data for further investigation.",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Step Reports"
    ]
  },
  {
    "objectID": "user-guide/step-reports.html#step-reports-with-segmented-data",
    "href": "user-guide/step-reports.html#step-reports-with-segmented-data",
    "title": "Step Reports",
    "section": "Step Reports with Segmented Data",
    "text": "Step Reports with Segmented Data\nWhen working with segmented validation, step reports become even more valuable as they allow you to investigate issues within specific segments:\n\n# Create data with different regions\nsegmented_data = pl.DataFrame({\n    \"id\": range(1, 10),\n    \"value\": [10, 20, 3, 40, 50, 2, 6, 8, 60],\n    \"region\": [\"North\", \"North\", \"South\", \"South\", \"East\", \"East\", \"West\", \"West\", \"West\"]\n})\n\n# Create a validation with segments\nsegmented_validation = (\n    pb.Validate(data=segmented_data, tbl_name=\"regional_data\")\n    .col_vals_gt(\n        columns=\"value\",\n        value=10,\n        segments=\"region\"  # Segment by region\n    )\n    .interrogate()\n)\n\n# Get step report for a specific segment (the 'West' region)\n# For segmented validations, each segment gets its own step number\nnorth_report = segmented_validation.get_step_report(i=4)\n\nnorth_report\n\n\n\n\n\n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 4ASSERTION value &gt; 102 / 3 TEST UNIT FAILURES IN COLUMN 2 EXTRACT OF ALL 2 ROWS (WITH TEST UNIT FAILURES IN RED):\n  \n\n  \n  idInt64\n  valueInt64\n  regionString\n\n\n\n  \n    1\n    7\n    6\n    West\n  \n  \n    2\n    8\n    8\n    West\n  \n\n\n\n\n\n\n        \n\n\nFor segmented validations, each segment is treated as a separate validation step with its own step number. This allows you to investigate issues specific to each data segment using the appropriate step number from the validation report.",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Step Reports"
    ]
  },
  {
    "objectID": "user-guide/step-reports.html#best-practices-for-using-step-reports",
    "href": "user-guide/step-reports.html#best-practices-for-using-step-reports",
    "title": "Step Reports",
    "section": "Best Practices for Using Step Reports",
    "text": "Best Practices for Using Step Reports\nHere are some guidelines for effectively using step reports in your data validation workflow:\n\nGenerate step reports selectively: create reports only for steps that require detailed investigation rather than for all steps\nUse the limit= parameter for large datasets: when working with large datasets, focus only on a subset of failing rows to avoid information overload\nShare specific step reports with stakeholders: when collaborating with domain experts, share relevant step reports to help them understand and address specific data quality issues (and customize the header to improve clarity)\nCombine with extracts for deeper analysis: use the get_data_extracts() method to extract the failing rows for further analysis or correction\nDocument findings from step reports: when you discover patterns or insights from step reports, document them to inform future data quality improvements\n\nRemember that step reports are most valuable when used strategically as part of a broader data quality framework. By following these best practices, you can use step reports not just for troubleshooting, but to develop a deeper understanding of your data’s characteristics and quality patterns over time. This approach transforms step reports from simple debugging tools into strategic assets for continuous data quality improvement.",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Step Reports"
    ]
  },
  {
    "objectID": "user-guide/step-reports.html#conclusion",
    "href": "user-guide/step-reports.html#conclusion",
    "title": "Step Reports",
    "section": "Conclusion",
    "text": "Conclusion\nStep reports provide a focused lens into specific validation steps, allowing you to investigate data quality issues in detail. By generating targeted reports for specific validation steps, you can:\n\npinpoint exactly which data points are causing validation failures\ncommunicate specific issues to relevant stakeholders\ngather insights that might be missed in the aggregate validation report\ntrack improvements in specific aspects of data quality over time\n\nWhether you’re debugging validation failures, investigating edge cases, or communicating specific data quality issues to colleagues, step reports can give you the detailed information you need to understand and resolve data quality problems effectively.",
    "crumbs": [
      "Get Started",
      "Post Interrogation",
      "Step Reports"
    ]
  },
  {
    "objectID": "demos/mutate-table-in-step/index.html",
    "href": "demos/mutate-table-in-step/index.html",
    "title": "Pointblank",
    "section": "",
    "text": "Mutate the Table in a Validation Step\nFor far more specialized validations, modify the table with the pre= argument before checking it.\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:19:28Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_between\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_between()\n        \n        \n        \n    a\n    [3, 6]\n    \n    \n        \n            \n            \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_eq\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_eq()\n        \n        \n        \n    b_len\n    9\n    \n    \n        \n            \n            \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:19:28 UTC&lt; 1 s2025-11-23 00:19:28 UTC\n  \n\n\n\n\n\n\n        \n\n\nimport pointblank as pb\nimport polars as pl\nimport narwhals as nw\n\n# Define preprocessing functions\ndef get_median_a(df):\n    \"\"\"Use a Polars expression to aggregate column `a`.\"\"\"\n    return df.select(pl.median(\"a\"))\n\ndef add_b_length_column(df):\n    \"\"\"Use Narwhals to add a string length column `b_len`.\"\"\"\n    return (\n        nw.from_native(df)\n        .with_columns(b_len=nw.col(\"b\").str.len_chars())\n    )\n\nvalidation = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\")\n    )\n    .col_vals_between(\n        columns=\"a\",\n        left=3, right=6,\n        pre=get_median_a\n    )\n    .col_vals_eq(\n        columns=\"b_len\",\n        value=9,\n        pre=add_b_length_column\n    )\n    .interrogate()\n)\n\nvalidation\n\n\nPreview of Input Table\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows13Columns8\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05\n    6\n    8-kdg-938\n    3\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    None\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09\n    8\n    3-ldm-038\n    7\n    283.94\n    True\n    low\n  \n  \n    6\n    2016-01-11 06:15:00\n    2016-01-11\n    4\n    2-dhe-923\n    4\n    3291.03\n    True\n    mid\n  \n  \n    7\n    2016-01-15 18:46:00\n    2016-01-15\n    7\n    1-knw-093\n    3\n    843.34\n    True\n    high\n  \n  \n    8\n    2016-01-17 11:27:00\n    2016-01-17\n    4\n    5-boe-639\n    2\n    1035.64\n    False\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26\n    4\n    2-dmx-010\n    7\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28\n    2\n    7-dmx-010\n    8\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30\n    1\n    3-dka-303\n    None\n    2230.09\n    True\n    high"
  },
  {
    "objectID": "demos/check-for-freshness/index.html",
    "href": "demos/check-for-freshness/index.html",
    "title": "Pointblank",
    "section": "",
    "text": "Validating Data Freshness\nUse date/datetime-based validations to ensure your data is current and recent. This is critical for applications that depend on timely data updates.\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:19:37Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    specially\n    \n        \n            \n            \n                \n            \n        \n    \n\n        \n        \n            specially()\n        \n        Recent data available (within 2 days of 2023-12-31)\n\n        \n    \n    EXPR\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_ge\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_ge()\n        \n        All data points are from the last week\n\n        \n    data_timestamp\n    2023-12-24\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    41.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    specially\n    \n        \n            \n            \n                \n            \n        \n    \n\n        \n        \n            specially()\n        \n        Most recent data is from today\n\n        \n    \n    EXPR\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        No missing timestamps\n\n        \n    data_timestamp\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    4\n    41.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:19:37 UTC&lt; 1 s2025-11-23 00:19:37 UTC\n  \n\n\n\n\n\n\n        \n\n\nimport pointblank as pb\nimport polars as pl\nfrom datetime import date, datetime, timedelta\n\n# Create sample data with mixed freshness levels\nfreshness_data = pl.DataFrame({\n    \"data_timestamp\": [\n        datetime(2023, 12, 28, 10, 30),  # 3 days ago from Dec 31\n        datetime(2023, 12, 29, 14, 15),  # 2 days ago\n        datetime(2023, 12, 30, 9, 45),   # 1 day ago\n        datetime(2023, 12, 31, 16, 20),  # Today\n    ],\n    \"sensor_id\": [\"TEMP_01\", \"TEMP_02\", \"TEMP_01\", \"TEMP_03\"],\n    \"reading\": [22.5, 21.8, 23.1, 22.9],\n    \"quality_score\": [0.95, 0.88, 0.92, 0.97]\n})\n\n# Assuming today is 2023-12-31, check for data freshness\ncurrent_date = date(2023, 12, 31)\nfreshness_cutoff = current_date - timedelta(days=2)  # Data should be within 2 days\n\nvalidation = (\n    pb.Validate(freshness_data)\n    .specially(\n        expr=lambda df: df.filter(\n            pl.col(\"data_timestamp\").dt.date() &gt;= freshness_cutoff\n        ).height &gt; 0,\n        brief=f\"Recent data available (within 2 days of {current_date})\"\n    )\n    .col_vals_ge(\n        columns=\"data_timestamp\",\n        value=current_date - timedelta(days=7),  # Within last week\n        brief=\"All data points are from the last week\"\n    )\n    .specially(\n        expr=lambda df: (\n            df.select(pl.col(\"data_timestamp\").max()).item().date() &gt;= current_date\n        ),\n        brief=\"Most recent data is from today\"\n    )\n    .col_vals_not_null(\n        columns=\"data_timestamp\",\n        brief=\"No missing timestamps\"\n    )\n    .interrogate()\n)\n\nvalidation\n\n\nPreview of Input Table\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows4Columns4\n  \n\n  \n  data_timestampDatetime\n  sensor_idString\n  readingFloat64\n  quality_scoreFloat64\n\n\n\n  \n    1\n    2023-12-28 10:30:00\n    TEMP_01\n    22.5\n    0.95\n  \n  \n    2\n    2023-12-29 14:15:00\n    TEMP_02\n    21.8\n    0.88\n  \n  \n    3\n    2023-12-30 09:45:00\n    TEMP_01\n    23.1\n    0.92\n  \n  \n    4\n    2023-12-31 16:20:00\n    TEMP_03\n    22.9\n    0.97"
  },
  {
    "objectID": "demos/expect-no-duplicate-values/index.html",
    "href": "demos/expect-no-duplicate-values/index.html",
    "title": "Pointblank",
    "section": "",
    "text": "Checking for Duplicate Values\nTo check for duplicate values down a column, use rows_distinct() with a columns_subset= value.\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:19:46Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    rows_distinct\n    \n        \n            \n            \n                \n                \n                \n            \n        \n    \n\n        \n        \n            rows_distinct()\n        \n        \n        \n    b\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    —\n    —\n    —\n    CSV\n  \n\n  \n  \n  \n    2025-11-23 00:19:46 UTC&lt; 1 s2025-11-23 00:19:46 UTC\n  \n\n\n\n\n\n\n        \n\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\")\n    )\n    .rows_distinct(columns_subset=\"b\")   # expect no duplicate values in 'b'\n    .interrogate()\n)\n\nvalidation\n\n\nPreview of Input Table\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows13Columns8\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05\n    6\n    8-kdg-938\n    3\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    None\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09\n    8\n    3-ldm-038\n    7\n    283.94\n    True\n    low\n  \n  \n    6\n    2016-01-11 06:15:00\n    2016-01-11\n    4\n    2-dhe-923\n    4\n    3291.03\n    True\n    mid\n  \n  \n    7\n    2016-01-15 18:46:00\n    2016-01-15\n    7\n    1-knw-093\n    3\n    843.34\n    True\n    high\n  \n  \n    8\n    2016-01-17 11:27:00\n    2016-01-17\n    4\n    5-boe-639\n    2\n    1035.64\n    False\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26\n    4\n    2-dmx-010\n    7\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28\n    2\n    7-dmx-010\n    8\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30\n    1\n    3-dka-303\n    None\n    2230.09\n    True\n    high"
  },
  {
    "objectID": "demos/cli-interactive/index.html",
    "href": "demos/cli-interactive/index.html",
    "title": "CLI Interactive Demos",
    "section": "",
    "text": "These CLI demos showcase practical data quality workflows that you can use!"
  },
  {
    "objectID": "demos/cli-interactive/index.html#getting-started",
    "href": "demos/cli-interactive/index.html#getting-started",
    "title": "CLI Interactive Demos",
    "section": "Getting Started",
    "text": "Getting Started\nReady to implement data quality workflows? Here’s how to get started:\n\n1. Install and Verify\npip install pointblank\npb --help\n\n\n2. Explore Various Data Sources\n# Try previewing a built-in dataset\npb preview small_table\n\n# Access local files (even use patterns to combine multiple Parquet files)\npb preview sales_data.csv\npb scan \"data/*.parquet\"\n\n# Inspect datasets in GitHub repositories (no need to download the data!)\npb preview \"https://github.com/user/repo/blob/main/data.csv\"\npb missing \"https://raw.githubusercontent.com/user/repo/main/sales.parquet\"\n\n# Work with DB tables through connection strings\npb info \"duckdb:///warehouse/analytics.ddb::customers\"\n\n\n3. Run Essential Validations\n# Check for duplicate rows\npb validate small_table --check rows-distinct\n\n# Validate data from multiple sources\npb validate \"data/*.parquet\" --check col-vals-not-null --column customer_id\npb validate \"https://github.com/user/repo/blob/main/sales.csv\" --check rows-distinct\n\n# Extract failing data for debugging\npb validate small_table --check col-vals-gt --column a --value 5 --show-extract\n\n\n4. Integrate with CI/CD\n# Use exit codes for automation (0 = pass, 1 = fail)\npb validate small_table --check rows-distinct --exit-code"
  },
  {
    "objectID": "demos/01-starter/index.html",
    "href": "demos/01-starter/index.html",
    "title": "Pointblank",
    "section": "",
    "text": "Starter Validation\nA validation with the basics.\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    A starter validationPolarssmall_table\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    1000\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    70.54\n    60.46\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    2\n    \n        \n            \n\n    col_vals_le\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_le()\n        \n        \n        \n    c\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    50.38\n    80.62\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    date\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    date_time\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:19:56 UTC&lt; 1 s2025-11-23 00:19:56 UTC\n  \n\n\n\n\n\n\n        \n\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate( # Use pb.Validate to start\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\"),\n        tbl_name=\"small_table\",\n        label=\"A starter validation\"\n    )\n    .col_vals_gt(columns=\"d\", value=1000)       # STEP 1 |\n    .col_vals_le(columns=\"c\", value=5)          # STEP 2 | &lt;-- Build up a validation plan\n    .col_exists(columns=[\"date\", \"date_time\"])  # STEP 3 |\n    .interrogate()  # This will execute all validation steps and collect intel\n)\n\nvalidation\n\n\nPreview of Input Table\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows13Columns8\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05\n    6\n    8-kdg-938\n    3\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    None\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09\n    8\n    3-ldm-038\n    7\n    283.94\n    True\n    low\n  \n  \n    6\n    2016-01-11 06:15:00\n    2016-01-11\n    4\n    2-dhe-923\n    4\n    3291.03\n    True\n    mid\n  \n  \n    7\n    2016-01-15 18:46:00\n    2016-01-15\n    7\n    1-knw-093\n    3\n    843.34\n    True\n    high\n  \n  \n    8\n    2016-01-17 11:27:00\n    2016-01-17\n    4\n    5-boe-639\n    2\n    1035.64\n    False\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26\n    4\n    2-dmx-010\n    7\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28\n    2\n    7-dmx-010\n    8\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30\n    1\n    3-dka-303\n    None\n    2230.09\n    True\n    high"
  },
  {
    "objectID": "demos/expect-text-pattern/index.html",
    "href": "demos/expect-text-pattern/index.html",
    "title": "Pointblank",
    "section": "",
    "text": "Expectations with a Text Pattern\nWith the col_vals_regex(), check for conformance to a regular expression.\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:20:04Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    b\n    ^\\d-[a-z]{3}-\\d{3}$\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    f\n    high|low|mid\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:20:04 UTC&lt; 1 s2025-11-23 00:20:04 UTC\n  \n\n\n\n\n\n\n        \n\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\")\n    )\n    .col_vals_regex(columns=\"b\", pattern=r\"^\\d-[a-z]{3}-\\d{3}$\")  # check pattern in 'b'\n    .col_vals_regex(columns=\"f\", pattern=r\"high|low|mid\")         # check pattern in 'f'\n    .interrogate()\n)\n\nvalidation\n\n\nPreview of Input Table\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows13Columns8\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05\n    6\n    8-kdg-938\n    3\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    None\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09\n    8\n    3-ldm-038\n    7\n    283.94\n    True\n    low\n  \n  \n    6\n    2016-01-11 06:15:00\n    2016-01-11\n    4\n    2-dhe-923\n    4\n    3291.03\n    True\n    mid\n  \n  \n    7\n    2016-01-15 18:46:00\n    2016-01-15\n    7\n    1-knw-093\n    3\n    843.34\n    True\n    high\n  \n  \n    8\n    2016-01-17 11:27:00\n    2016-01-17\n    4\n    5-boe-639\n    2\n    1035.64\n    False\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26\n    4\n    2-dmx-010\n    7\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28\n    2\n    7-dmx-010\n    8\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30\n    1\n    3-dka-303\n    None\n    2230.09\n    True\n    high"
  },
  {
    "objectID": "demos/col-vals-custom-expr/index.html",
    "href": "demos/col-vals-custom-expr/index.html",
    "title": "Pointblank",
    "section": "",
    "text": "Custom Expression for Checking Column Values\nA column expression can be used to check column values. Just use col_vals_expr() for this.\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:20:13Pandas\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_expr\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_expr()\n        \n        \n        \n    —\n    COLUMN EXPR\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:20:13 UTC&lt; 1 s2025-11-23 00:20:13 UTC\n  \n\n\n\n\n\n\n        \n\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"pandas\")\n    )\n    .col_vals_expr(expr=lambda df: (df[\"d\"] % 1 != 0) & (df[\"a\"] &lt; 10))  # Pandas column expr\n    .interrogate()\n)\n\nvalidation\n\n\nPreview of Input Table\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PandasRows13Columns8\n  \n\n  \n  date_timedatetime64[ns]\n  datedatetime64[ns]\n  aint64\n  bobject\n  cfloat64\n  dfloat64\n  ebool\n  fobject\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04 00:00:00\n    2\n    1-bcd-345\n    3.0\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04 00:00:00\n    3\n    5-egh-163\n    8.0\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05 00:00:00\n    6\n    8-kdg-938\n    3.0\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06 00:00:00\n    2\n    5-jdo-903\n    NA\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09 00:00:00\n    8\n    3-ldm-038\n    7.0\n    283.94\n    True\n    low\n  \n  \n    6\n    2016-01-11 06:15:00\n    2016-01-11 00:00:00\n    4\n    2-dhe-923\n    4.0\n    3291.03\n    True\n    mid\n  \n  \n    7\n    2016-01-15 18:46:00\n    2016-01-15 00:00:00\n    7\n    1-knw-093\n    3.0\n    843.34\n    True\n    high\n  \n  \n    8\n    2016-01-17 11:27:00\n    2016-01-17 00:00:00\n    4\n    5-boe-639\n    2.0\n    1035.64\n    False\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20 00:00:00\n    3\n    5-bce-642\n    9.0\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20 00:00:00\n    3\n    5-bce-642\n    9.0\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26 00:00:00\n    4\n    2-dmx-010\n    7.0\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28 00:00:00\n    2\n    7-dmx-010\n    8.0\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30 00:00:00\n    1\n    3-dka-303\n    NA\n    2230.09\n    True\n    high"
  },
  {
    "objectID": "demos/using-parquet-data/index.html",
    "href": "demos/using-parquet-data/index.html",
    "title": "Pointblank",
    "section": "",
    "text": "Using Parquet Data\nA Parquet dataset can be used for data validation, thanks to Ibis.\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Example using a Parquet dataset.Parquet\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    item_revenue\n    200\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    item_revenue\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C66\n    3\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    session_duration\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    19820.99\n    180.01\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        \n        \n    item_type\n    iap, ad\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    5\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    player_id\n    [A-Z]{12}\\d{3}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:20:22 UTC&lt; 1 s2025-11-23 00:20:23 UTC\n  \n\n\n\n\n\n\n        \n\n\nimport pointblank as pb\nimport ibis\n\ngame_revenue = ibis.read_parquet(\"data/game_revenue.parquet\")\n\nvalidation = (\n    pb.Validate(data=game_revenue, label=\"Example using a Parquet dataset.\")\n    .col_vals_lt(columns=\"item_revenue\", value=200)\n    .col_vals_gt(columns=\"item_revenue\", value=0)\n    .col_vals_gt(columns=\"session_duration\", value=5)\n    .col_vals_in_set(columns=\"item_type\", set=[\"iap\", \"ad\"])\n    .col_vals_regex(columns=\"player_id\", pattern=r\"[A-Z]{12}\\d{3}\")\n    .interrogate()\n)\n\nvalidation\n\n\nPreview of Input Table\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    ParquetRows2,000Columns11\n  \n\n  \n  player_idstring\n  session_idstring\n  session_starttimestamp\n  timetimestamp\n  item_typestring\n  item_namestring\n  item_revenuefloat64\n  session_durationfloat64\n  start_daydate\n  acquisitionstring\n  countrystring\n\n\n\n  \n    1\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:31:27+00:00\n    iap\n    offer2\n    8.99\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    2\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:36:57+00:00\n    iap\n    gems3\n    22.49\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    3\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:37:45+00:00\n    iap\n    gold7\n    107.99\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    4\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:42:33+00:00\n    ad\n    ad_20sec\n    0.76\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    5\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-hdu9jkls\n    2015-01-01 11:50:02+00:00\n    2015-01-01 11:55:20+00:00\n    ad\n    ad_5sec\n    0.03\n    35.2\n    2015-01-01\n    google\n    Germany\n  \n  \n    1996\n    NAOJRDMCSEBI281\n    NAOJRDMCSEBI281-j2vs9ilp\n    2015-01-21 01:57:50+00:00\n    2015-01-21 02:02:50+00:00\n    ad\n    ad_survey\n    1.332\n    25.8\n    2015-01-11\n    organic\n    Norway\n  \n  \n    1997\n    NAOJRDMCSEBI281\n    NAOJRDMCSEBI281-j2vs9ilp\n    2015-01-21 01:57:50+00:00\n    2015-01-21 02:22:14+00:00\n    ad\n    ad_survey\n    1.35\n    25.8\n    2015-01-11\n    organic\n    Norway\n  \n  \n    1998\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-vbhcsmtr\n    2015-01-21 02:39:48+00:00\n    2015-01-21 02:40:00+00:00\n    ad\n    ad_5sec\n    0.03\n    8.4\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    1999\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-vbhcsmtr\n    2015-01-21 02:39:48+00:00\n    2015-01-21 02:47:12+00:00\n    iap\n    offer5\n    26.09\n    8.4\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    2000\n    GJCXNTWEBIPQ369\n    GJCXNTWEBIPQ369-9elq67md\n    2015-01-21 03:59:23+00:00\n    2015-01-21 04:06:29+00:00\n    ad\n    ad_5sec\n    0.12\n    18.5\n    2015-01-14\n    organic\n    United States"
  },
  {
    "objectID": "demos/checks-for-missing/index.html",
    "href": "demos/checks-for-missing/index.html",
    "title": "Pointblank",
    "section": "",
    "text": "Checks for Missing Values\nPerform validations that check whether missing/NA/Null values are present.\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:20:32Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    a\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    b\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C66\n    3\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    c\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    d\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C66\n    5\n    \n        \n            \n\n    col_vals_null\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_null()\n        \n        \n        \n    a\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    00.00\n    131.00\n    —\n    —\n    —\n    CSV\n  \n\n  \n  \n  \n    2025-11-23 00:20:32 UTC&lt; 1 s2025-11-23 00:20:32 UTC\n  \n\n\n\n\n\n\n        \n\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\")\n    )\n    .col_vals_not_null(columns=\"a\")                  # expect no Null values\n    .col_vals_not_null(columns=\"b\")                  # \"\" \"\"\n    .col_vals_not_null(columns=\"c\")                  # \"\" \"\"\n    .col_vals_not_null(columns=\"d\")                  # \"\" \"\"\n    .col_vals_null(columns=\"a\")                      # expect all values to be Null\n    .interrogate()\n)\n\nvalidation\n\n\nPreview of Input Table\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows13Columns8\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05\n    6\n    8-kdg-938\n    3\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    None\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09\n    8\n    3-ldm-038\n    7\n    283.94\n    True\n    low\n  \n  \n    6\n    2016-01-11 06:15:00\n    2016-01-11\n    4\n    2-dhe-923\n    4\n    3291.03\n    True\n    mid\n  \n  \n    7\n    2016-01-15 18:46:00\n    2016-01-15\n    7\n    1-knw-093\n    3\n    843.34\n    True\n    high\n  \n  \n    8\n    2016-01-17 11:27:00\n    2016-01-17\n    4\n    5-boe-639\n    2\n    1035.64\n    False\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26\n    4\n    2-dmx-010\n    7\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28\n    2\n    7-dmx-010\n    8\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30\n    1\n    3-dka-303\n    None\n    2230.09\n    True\n    high"
  },
  {
    "objectID": "demos/failure-thresholds/index.html",
    "href": "demos/failure-thresholds/index.html",
    "title": "Pointblank",
    "section": "",
    "text": "Set Failure Threshold Levels\nSet threshold levels to better gauge adverse data quality.\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:20:41DuckDBWARNING0.05ERROR0.1CRITICAL0.15\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_in_set\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_in_set()\n        \n        \n        \n    item_type\n    iap, ad\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    player_id\n    [A-Z]{12}\\d{3}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    ○\n    ○\n    ○\n    —\n  \n  \n    #EBBC14\n    3\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    item_revenue\n    0.05\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    17010.85\n    2990.15\n    ●\n    ●\n    ○\n    —\n  \n  \n    #AAAAAA\n    4\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    session_duration\n    4\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    19931.00\n    70.00\n    ●\n    ○\n    ○\n    —\n  \n  \n    #FF3300\n    5\n    \n        \n            \n\n    col_exists\n    \n        \n            \n            \n            \n        \n    \n\n        \n        \n            col_exists()\n        \n        \n        \n    end_day\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    00.00\n    11.00\n    ●\n    ●\n    ●\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:20:41 UTC&lt; 1 s2025-11-23 00:20:41 UTC\n  \n\n\n  \n    \nNotes\nStep 4 (local_thresholds) Step-specific thresholds set with W:5|E:10|C:20.\n  \n\n\n\n\n\n\n        \n\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"duckdb\"),\n        thresholds=pb.Thresholds(  # setting relative threshold defaults for all steps\n            warning=0.05,          # 5% failing test units: warning threshold (gray)\n            error=0.10,            # 10% failed test units: error threshold (yellow)\n            critical=0.15          # 15% failed test units: critical threshold (red)\n        ),\n    )\n    .col_vals_in_set(columns=\"item_type\", set=[\"iap\", \"ad\"])\n    .col_vals_regex(columns=\"player_id\", pattern=r\"[A-Z]{12}\\d{3}\")\n    .col_vals_gt(columns=\"item_revenue\", value=0.05)\n    .col_vals_gt(\n        columns=\"session_duration\",\n        value=4,\n        thresholds=(5, 10, 20)     # setting absolute thresholds for *this* step (W, E, C)\n    )\n    .col_exists(columns=\"end_day\")\n    .interrogate()\n)\n\nvalidation\n\n\nPreview of Input Table\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    DuckDBRows2,000Columns11\n  \n\n  \n  player_idstring\n  session_idstring\n  session_starttimestamp\n  timetimestamp\n  item_typestring\n  item_namestring\n  item_revenuefloat64\n  session_durationfloat64\n  start_daydate\n  acquisitionstring\n  countrystring\n\n\n\n  \n    1\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:31:27+00:00\n    iap\n    offer2\n    8.99\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    2\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:36:57+00:00\n    iap\n    gems3\n    22.49\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    3\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:37:45+00:00\n    iap\n    gold7\n    107.99\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    4\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:42:33+00:00\n    ad\n    ad_20sec\n    0.76\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    5\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-hdu9jkls\n    2015-01-01 11:50:02+00:00\n    2015-01-01 11:55:20+00:00\n    ad\n    ad_5sec\n    0.03\n    35.2\n    2015-01-01\n    google\n    Germany\n  \n  \n    1996\n    NAOJRDMCSEBI281\n    NAOJRDMCSEBI281-j2vs9ilp\n    2015-01-21 01:57:50+00:00\n    2015-01-21 02:02:50+00:00\n    ad\n    ad_survey\n    1.332\n    25.8\n    2015-01-11\n    organic\n    Norway\n  \n  \n    1997\n    NAOJRDMCSEBI281\n    NAOJRDMCSEBI281-j2vs9ilp\n    2015-01-21 01:57:50+00:00\n    2015-01-21 02:22:14+00:00\n    ad\n    ad_survey\n    1.35\n    25.8\n    2015-01-11\n    organic\n    Norway\n  \n  \n    1998\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-vbhcsmtr\n    2015-01-21 02:39:48+00:00\n    2015-01-21 02:40:00+00:00\n    ad\n    ad_5sec\n    0.03\n    8.4\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    1999\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-vbhcsmtr\n    2015-01-21 02:39:48+00:00\n    2015-01-21 02:47:12+00:00\n    iap\n    offer5\n    26.09\n    8.4\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    2000\n    GJCXNTWEBIPQ369\n    GJCXNTWEBIPQ369-9elq67md\n    2015-01-21 03:59:23+00:00\n    2015-01-21 04:06:29+00:00\n    ad\n    ad_5sec\n    0.12\n    18.5\n    2015-01-14\n    organic\n    United States"
  },
  {
    "objectID": "demos/numeric-comparisons/index.html",
    "href": "demos/numeric-comparisons/index.html",
    "title": "Pointblank",
    "section": "",
    "text": "Numeric Comparisons\nPerform comparisons of values in columns to fixed values.\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:20:50Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_vals_gt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_gt()\n        \n        \n        \n    d\n    1000\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    70.54\n    60.46\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_lt\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_lt()\n        \n        \n        \n    d\n    10000\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_vals_ge\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_ge()\n        \n        \n        \n    a\n    1\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    131.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C66\n    4\n    \n        \n            \n\n    col_vals_le\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_le()\n        \n        \n        \n    c\n    5\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    50.38\n    80.62\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    5\n    \n        \n            \n\n    col_vals_ne\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_ne()\n        \n        \n        \n    a\n    7\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    120.92\n    10.08\n    —\n    —\n    —\n    CSV\n  \n  \n    #4CA64C66\n    6\n    \n        \n            \n\n    col_vals_between\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_between()\n        \n        \n        \n    c\n    [0, 15]\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    13\n    110.85\n    20.15\n    —\n    —\n    —\n    CSV\n  \n\n  \n  \n  \n    2025-11-23 00:20:50 UTC&lt; 1 s2025-11-23 00:20:50 UTC\n  \n\n\n\n\n\n\n        \n\n\nimport pointblank as pb\n\nvalidation = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"polars\")\n    )\n    .col_vals_gt(columns=\"d\", value=1000)            # values in 'd' &gt; 1000\n    .col_vals_lt(columns=\"d\", value=10000)           # values in 'd' &lt; 10000\n    .col_vals_ge(columns=\"a\", value=1)               # values in 'a' &gt;= 1\n    .col_vals_le(columns=\"c\", value=5)               # values in 'c' &lt;= 5\n    .col_vals_ne(columns=\"a\", value=7)               # values in 'a' not equal to 7\n    .col_vals_between(columns=\"c\", left=0, right=15) # 0 &lt;= 'c' values &lt;= 15\n    .interrogate()\n)\n\nvalidation\n\n\nPreview of Input Table\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows13Columns8\n  \n\n  \n  date_timeDatetime\n  dateDate\n  aInt64\n  bString\n  cInt64\n  dFloat64\n  eBoolean\n  fString\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05\n    6\n    8-kdg-938\n    3\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    None\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09\n    8\n    3-ldm-038\n    7\n    283.94\n    True\n    low\n  \n  \n    6\n    2016-01-11 06:15:00\n    2016-01-11\n    4\n    2-dhe-923\n    4\n    3291.03\n    True\n    mid\n  \n  \n    7\n    2016-01-15 18:46:00\n    2016-01-15\n    7\n    1-knw-093\n    3\n    843.34\n    True\n    high\n  \n  \n    8\n    2016-01-17 11:27:00\n    2016-01-17\n    4\n    5-boe-639\n    2\n    1035.64\n    False\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26\n    4\n    2-dmx-010\n    7\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28\n    2\n    7-dmx-010\n    8\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30\n    1\n    3-dka-303\n    None\n    2230.09\n    True\n    high"
  },
  {
    "objectID": "demos/schema-check/index.html",
    "href": "demos/schema-check/index.html",
    "title": "Pointblank",
    "section": "",
    "text": "Check the Schema of a Table\nThe schema of a table can be flexibly defined with Schema and verified with col_schema_match().\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:20:58Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_schema_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            col_schema_match()\n        \n        \n        \n    —\n    SCHEMA\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    11.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:20:58 UTC&lt; 1 s2025-11-23 00:20:58 UTC\n  \n\n\n  \n    \nNotes\nStep 1 (schema_check) ✓ Schema validation passed.\n\nSchema Comparison\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n  \n    TARGET\n  \n  \n    EXPECTED\n  \n\n\n  \n  COLUMN\n  DATA TYPE\n  \n  COLUMN\n  \n  DATA TYPE\n  \n\n\n\n  \n    1\n    a\n    String\n    1\n    a\n    ✓\n    String\n    ✓\n  \n  \n    2\n    b\n    Int64\n    2\n    b\n    ✓\n    Int | Int64\n    ✓\n  \n  \n    3\n    c\n    Float64\n    3\n    c\n    ✓\n    —\n    \n  \n\n  \n  \n    Supplied Column Schema:[('a', 'String'), ('b', ['Int', 'Int64']), ('c',)]\n  \n  \n    \nSchema Match Settings\nCOMPLETEIN ORDERCOLUMN ≠ columnDTYPE ≠ dtypefloat ≠ float64\n\n  \n\n\n\n\n\n\n  \n\n\n\n\n\n\n        \n\n\nimport pointblank as pb\nimport polars as pl\n\ntbl = pl.DataFrame(\n    {\n        \"a\": [\"apple\", \"banana\", \"cherry\", \"date\"],\n        \"b\": [1, 6, 3, 5],\n        \"c\": [1.1, 2.2, 3.3, 4.4],\n    }\n)\n\n# Use the Schema class to define the column schema as loosely or rigorously as required\nschema = pb.Schema(\n    columns=[\n        (\"a\", \"String\"),          # Column 'a' has dtype 'String'\n        (\"b\", [\"Int\", \"Int64\"]),  # Column 'b' has dtype 'Int' or 'Int64'\n        (\"c\", )                   # Column 'c' follows 'b' but we don't specify a dtype here\n    ]\n)\n\n# Use the `col_schema_match()` validation method to perform the schema check\nvalidation = (\n    pb.Validate(data=tbl)\n    .col_schema_match(schema=schema)\n    .interrogate()\n)\n\nvalidation"
  },
  {
    "objectID": "demos/06-step-report-schema-check/index.html",
    "href": "demos/06-step-report-schema-check/index.html",
    "title": "Pointblank",
    "section": "",
    "text": "Step Report: Schema Check\nWhen a schema doesn’t match, a step report gives you the details.\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    Step report for a schema checkDuckDBsmall_table\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C66\n    1\n    \n        \n            \n\n    col_schema_match\n    \n        \n            \n            \n            \n                \n                \n            \n            \n        \n    \n\n        \n        \n            col_schema_match()\n        \n        \n        \n    —\n    SCHEMA\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    1\n    00.00\n    11.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:21:07 UTC&lt; 1 s2025-11-23 00:21:07 UTC\n  \n\n\n  \n    \nNotes\nStep 1 (schema_check) ✗ Schema validation failed: 1 unmatched column(s), 2 dtype mismatch(es).\n\nSchema Comparison\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n  \n    TARGET\n  \n  \n    EXPECTED\n  \n\n\n  \n  COLUMN\n  DATA TYPE\n  \n  COLUMN\n  \n  DATA TYPE\n  \n\n\n\n  \n    1\n    date_time\n    timestamp(6)\n    1\n    date_time\n    ✓\n    timestamp\n    ✗\n  \n  \n    2\n    date\n    date\n    2\n    dates\n    ✗\n    date\n    —\n  \n  \n    3\n    a\n    int64\n    3\n    a\n    ✓\n    int64\n    ✓\n  \n  \n    4\n    b\n    string\n    4\n    b\n    ✓\n    —\n    \n  \n  \n    5\n    c\n    int64\n    5\n    c\n    ✓\n    —\n    \n  \n  \n    6\n    d\n    float64\n    6\n    d\n    ✓\n    float64\n    ✓\n  \n  \n    7\n    e\n    boolean\n    7\n    e\n    ✓\n    bool | boolean\n    ✓\n  \n  \n    8\n    f\n    string\n    8\n    f\n    ✓\n    str\n    ✗\n  \n\n  \n  \n    Supplied Column Schema:[('date_time', 'timestamp'), ('dates', 'date'), ('a', 'int64'), ('b',), ('c',), ('d', 'float64'), ('e', ['bool', 'boolean']), ('f', 'str')]\n  \n  \n    \nSchema Match Settings\nCOMPLETEIN ORDERCOLUMN ≠ columnDTYPE ≠ dtypefloat ≠ float64\n\n  \n\n\n\n\n\n\n  \n\n\n\n\n\n\n        \n\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Report for Validation Step 1 ✗COLUMN SCHEMA MATCHCOMPLETEIN ORDERCOLUMN ≠ columnDTYPE ≠ dtypefloat ≠ float64\n  \n\n  \n    TARGET\n  \n  \n    EXPECTED\n  \n\n\n  \n  COLUMN\n  DATA TYPE\n  \n  COLUMN\n  \n  DATA TYPE\n  \n\n\n\n  \n    1\n    date_time\n    timestamp(6)\n    1\n    date_time\n    ✓\n    timestamp\n    ✗\n  \n  \n    2\n    date\n    date\n    2\n    dates\n    ✗\n    date\n    —\n  \n  \n    3\n    a\n    int64\n    3\n    a\n    ✓\n    int64\n    ✓\n  \n  \n    4\n    b\n    string\n    4\n    b\n    ✓\n    —\n    \n  \n  \n    5\n    c\n    int64\n    5\n    c\n    ✓\n    —\n    \n  \n  \n    6\n    d\n    float64\n    6\n    d\n    ✓\n    float64\n    ✓\n  \n  \n    7\n    e\n    boolean\n    7\n    e\n    ✓\n    bool | boolean\n    ✓\n  \n  \n    8\n    f\n    string\n    8\n    f\n    ✓\n    str\n    ✗\n  \n\n  \n  \n  \n    Supplied Column Schema:[('date_time', 'timestamp'), ('dates', 'date'), ('a', 'int64'), ('b',), ('c',), ('d', 'float64'), ('e', ['bool', 'boolean']), ('f', 'str')]\n  \n\n\n\n\n\n\n        \n\n\nimport pointblank as pb\n\n# Create a schema for the target table (`small_table` as a DuckDB table)\nschema = pb.Schema(\n    columns=[\n        (\"date_time\", \"timestamp\"),     # this dtype doesn't match\n        (\"dates\", \"date\"),              # this column name doesn't match\n        (\"a\", \"int64\"),\n        (\"b\",),                         # omit dtype to not check for it\n        (\"c\",),                         # \"\"   \"\"   \"\"  \"\"\n        (\"d\", \"float64\"),\n        (\"e\", [\"bool\", \"boolean\"]),     # try several dtypes (second one matches)\n        (\"f\", \"str\"),                   # this dtype doesn't match\n    ]\n)\n\n# Use the `col_schema_match()` validation method to perform a schema check\nvalidation = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"small_table\", tbl_type=\"duckdb\"),\n        tbl_name=\"small_table\",\n        label=\"Step report for a schema check\"\n    )\n    .col_schema_match(schema=schema)\n    .interrogate()\n)\n\nvalidation\nvalidation.get_step_report(i=1)\n\n\nPreview of Input Table\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    DuckDBRows13Columns8\n  \n\n  \n  date_timetimestamp\n  datedate\n  aint64\n  bstring\n  cint64\n  dfloat64\n  eboolean\n  fstring\n\n\n\n  \n    1\n    2016-01-04 11:00:00\n    2016-01-04\n    2\n    1-bcd-345\n    3\n    3423.29\n    True\n    high\n  \n  \n    2\n    2016-01-04 00:32:00\n    2016-01-04\n    3\n    5-egh-163\n    8\n    9999.99\n    True\n    low\n  \n  \n    3\n    2016-01-05 13:32:00\n    2016-01-05\n    6\n    8-kdg-938\n    3\n    2343.23\n    True\n    high\n  \n  \n    4\n    2016-01-06 17:23:00\n    2016-01-06\n    2\n    5-jdo-903\n    NULL\n    3892.4\n    False\n    mid\n  \n  \n    5\n    2016-01-09 12:36:00\n    2016-01-09\n    8\n    3-ldm-038\n    7\n    283.94\n    True\n    low\n  \n  \n    6\n    2016-01-11 06:15:00\n    2016-01-11\n    4\n    2-dhe-923\n    4\n    3291.03\n    True\n    mid\n  \n  \n    7\n    2016-01-15 18:46:00\n    2016-01-15\n    7\n    1-knw-093\n    3\n    843.34\n    True\n    high\n  \n  \n    8\n    2016-01-17 11:27:00\n    2016-01-17\n    4\n    5-boe-639\n    2\n    1035.64\n    False\n    low\n  \n  \n    9\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    10\n    2016-01-20 04:30:00\n    2016-01-20\n    3\n    5-bce-642\n    9\n    837.93\n    False\n    high\n  \n  \n    11\n    2016-01-26 20:07:00\n    2016-01-26\n    4\n    2-dmx-010\n    7\n    833.98\n    True\n    low\n  \n  \n    12\n    2016-01-28 02:51:00\n    2016-01-28\n    2\n    7-dmx-010\n    8\n    108.34\n    False\n    low\n  \n  \n    13\n    2016-01-30 11:23:00\n    2016-01-30\n    1\n    3-dka-303\n    NULL\n    2230.09\n    True\n    high"
  },
  {
    "objectID": "demos/column-selector-functions/index.html",
    "href": "demos/column-selector-functions/index.html",
    "title": "Pointblank",
    "section": "",
    "text": "Column Selector Functions: Easily Pick Columns\nUse column selector functions in the columns= argument to conveniently choose columns.\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    Pointblank Validation\n  \n  \n    2025-11-23|00:21:16Polars\n  \n\n  \n  \n  STEP\n  COLUMNS\n  VALUES\n  TBL\n  EVAL\n  UNITS\n  PASS\n  FAIL\n  W\n  E\n  C\n  EXT\n\n\n\n  \n    #4CA64C\n    1\n    \n        \n            \n\n    col_vals_ge\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_ge()\n        \n        \n        \n    item_revenue\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    2\n    \n        \n            \n\n    col_vals_ge\n    \n        \n            \n            \n        \n    \n\n        \n        \n            col_vals_ge()\n        \n        \n        \n    session_duration\n    0\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    3\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    player_id\n    ^[A-Z]{12}\\d{3}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    4\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    session_id\n    ^[A-Z]{12}\\d{3}\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    5\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    acquisition\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    6\n    \n        \n            \n\n    col_vals_not_null\n    \n        \n            \n            \n            \n            \n        \n    \n\n        \n        \n            col_vals_not_null()\n        \n        \n        \n    country\n    —\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    7\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    player_id\n    (.|\\s)*\\S(.|\\s)*\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    8\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    session_id\n    (.|\\s)*\\S(.|\\s)*\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    9\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    item_type\n    (.|\\s)*\\S(.|\\s)*\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    10\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    item_name\n    (.|\\s)*\\S(.|\\s)*\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    11\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    acquisition\n    (.|\\s)*\\S(.|\\s)*\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n  \n    #4CA64C\n    12\n    \n        \n            \n\n    col_vals_regex\n    \n        \n            \n            \n                \n                \n            \n        \n    \n\n        \n        \n            col_vals_regex()\n        \n        \n        \n    country\n    (.|\\s)*\\S(.|\\s)*\n    \n    \n        \n            \n            \n            \n        \n    \n\n    ✓\n    2000\n    20001.00\n    00.00\n    —\n    —\n    —\n    —\n  \n\n  \n  \n  \n    2025-11-23 00:21:16 UTC&lt; 1 s2025-11-23 00:21:16 UTC\n  \n\n\n\n\n\n\n        \n\n\nimport pointblank as pb\nimport narwhals.selectors as ncs\n\nvalidation = (\n    pb.Validate(\n        data=pb.load_dataset(dataset=\"game_revenue\", tbl_type=\"polars\")\n    )\n    .col_vals_ge(\n        columns=pb.matches(\"rev|dur\"),  # check values in columns having 'rev' or 'dur' in name\n        value=0\n    )\n    .col_vals_regex(\n        columns=pb.ends_with(\"_id\"),    # check values in columns with names ending in '_id'\n        pattern=r\"^[A-Z]{12}\\d{3}\"\n    )\n    .col_vals_not_null(\n        columns=pb.last_n(2)            # check that the last two columns don't have Null values\n    )\n    .col_vals_regex(\n        columns=ncs.string(),           # check that all string columns are non-empty strings\n        pattern=r\"(.|\\s)*\\S(.|\\s)*\"\n    )\n    .interrogate()\n)\n\nvalidation\n\n\nPreview of Input Table\n\n\n\n\n\n\n\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n\n\n  \n    PolarsRows2,000Columns11\n  \n\n  \n  player_idString\n  session_idString\n  session_startDatetime\n  timeDatetime\n  item_typeString\n  item_nameString\n  item_revenueFloat64\n  session_durationFloat64\n  start_dayDate\n  acquisitionString\n  countryString\n\n\n\n  \n    1\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:31:27+00:00\n    iap\n    offer2\n    8.99\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    2\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:36:57+00:00\n    iap\n    gems3\n    22.49\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    3\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:37:45+00:00\n    iap\n    gold7\n    107.99\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    4\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-eol2j8bs\n    2015-01-01 01:31:03+00:00\n    2015-01-01 01:42:33+00:00\n    ad\n    ad_20sec\n    0.76\n    16.3\n    2015-01-01\n    google\n    Germany\n  \n  \n    5\n    ECPANOIXLZHF896\n    ECPANOIXLZHF896-hdu9jkls\n    2015-01-01 11:50:02+00:00\n    2015-01-01 11:55:20+00:00\n    ad\n    ad_5sec\n    0.03\n    35.2\n    2015-01-01\n    google\n    Germany\n  \n  \n    1996\n    NAOJRDMCSEBI281\n    NAOJRDMCSEBI281-j2vs9ilp\n    2015-01-21 01:57:50+00:00\n    2015-01-21 02:02:50+00:00\n    ad\n    ad_survey\n    1.332\n    25.8\n    2015-01-11\n    organic\n    Norway\n  \n  \n    1997\n    NAOJRDMCSEBI281\n    NAOJRDMCSEBI281-j2vs9ilp\n    2015-01-21 01:57:50+00:00\n    2015-01-21 02:22:14+00:00\n    ad\n    ad_survey\n    1.35\n    25.8\n    2015-01-11\n    organic\n    Norway\n  \n  \n    1998\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-vbhcsmtr\n    2015-01-21 02:39:48+00:00\n    2015-01-21 02:40:00+00:00\n    ad\n    ad_5sec\n    0.03\n    8.4\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    1999\n    RMOSWHJGELCI675\n    RMOSWHJGELCI675-vbhcsmtr\n    2015-01-21 02:39:48+00:00\n    2015-01-21 02:47:12+00:00\n    iap\n    offer5\n    26.09\n    8.4\n    2015-01-10\n    other_campaign\n    France\n  \n  \n    2000\n    GJCXNTWEBIPQ369\n    GJCXNTWEBIPQ369-9elq67md\n    2015-01-21 03:59:23+00:00\n    2015-01-21 04:06:29+00:00\n    ad\n    ad_5sec\n    0.12\n    18.5\n    2015-01-14\n    organic\n    United States"
  }
]